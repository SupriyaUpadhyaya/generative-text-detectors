{"prompt": "Generate an abstract for work with title: Faithful Effective-One-Body waveforms of small-mass-ratio coalescing\n  black-hole binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2519, "human_text": "  We address the problem of constructing high-accuracy, faithful analytic waveforms describing the gravitational wave signal emitted by inspiralling and coalescing binary black holes. We work within the Effective-One-Body (EOB) framework and propose a methodology for improving the current (waveform)implementations of this framework based on understanding, element by element, the physics behind each feature of the waveform, and on systematically comparing various EOB-based waveforms with ``exact'' waveforms obtained by numerical relativity approaches. The present paper focuses on small-mass-ratio non-spinning binary systems, which can be conveniently studied by Regge-Wheeler-Zerilli-type methods. Our results include: (i) a resummed, 3PN-accurate description of the inspiral waveform, (ii) a better description of radiation reaction during the plunge, (iii) a refined analytic expression for the plunge waveform, (iv) an improved treatment of the matching between the plunge and ring-down waveforms. This improved implementation of the EOB approach allows us to construct complete analytic waveforms which exhibit a remarkable agreement with the ``exact'' ones in modulus, frequency and phase. In particular, the analytic and numerical waveforms stay in phase, during the whole process, within $\\pm 1.1 %$ of a cycle. We expect that the extension of our methodology to the comparable-mass case will be able to generate comparably accurate analytic waveforms of direct use for the ground-based network of interferometric detectors of gravitational waves. ", "machine_text": " We study the effects of small-mass-ratio on the evolution of coalescing black-hole binaries, by means of numerical-relativity simulations, and in the limit of strong gravitational interactions between the black holes and the host galaxies. For these galaxies we consider both spherically symmetric and axi-symmetric potential fields. We find that the merger process is generally faster for black-hole binaries with small mass ratios, and that this speed-up is more pronounced for binaries evolving in axi-symmetric galaxies. In the case of spherically symmetric galaxies, the typical lifetime of a small-mass-ratio binary is longer than that of a large-mass-ratio binary, but the evolution is more complex, with more frequent exchange of energy with the host galaxy, and hence more opportunities for the transfer of mass from the binary to the galaxy. We also find that in all cases the energy and angular momentum of the system are preserved, with the possible exception of the initial stages of the evolution, where the system may receive or lose large amounts of energy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pairing based cooling of Fermi gases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0271, "human_text": "  We propose a pairing-based method for cooling an atomic Fermi gas. A three component (labels 1, 2, 3) mixture of Fermions is considered where the components 1 and 2 interact and, for instance, form pairs whereas the component 3 is in the normal state. For cooling, the components 2 and 3 are coupled by an electromagnetic field. Since the quasiparticle distributions in the paired and in the normal states are different, the coupling leads to cooling of the normal state even when initially $T_{paired}\\geq T_{normal}$ (notation $T_S\\geq T_N$). The cooling efficiency is given by the pairing energy and by the linewidth of the coupling field. No superfluidity is required: any type of pairing, or other phenomenon that produces a suitable spectral density, is sufficient. In principle, the paired state could be cooled as well but this requires $T_N<T_S$. The method has a conceptual analogy to cooling based on superconductor -- normal metal (SN) tunneling junctions. Main differences arise from the exact momentum conservation in the case of the field-matter coupling vs. non-conservation of momentum in the solid state tunneling process. Moreover, the role of processes that relax the energy conservation requirement in the tunneling, e.g. thermal fluctuations of an external reservoir, is now played by the linewidth of the field. The proposed method should be experimentally feasible due to its close connection to RF-spectroscopy of ultracold gases which is already in use. ", "machine_text": "  We consider a recently proposed method to cool atomic gases that does not require the atoms to be laser cooled or trapped. This method relies on the collective excitation of the atomic gas by a sequence of coherent light pulses, which is possible thanks to the giant photon absorption cross section and the narrow width of the electronic energy levels in atomic gases. In this work we study this cooling method in more detail, with the aim of understanding the fundamental physical mechanisms that determine its efficiency. In particular, we consider the role of the atomic interaction, which is an important and poorly understood quantity in atomic gases, and we show that it has a strong influence on the cooling rate. We also propose a simple method to estimate the cooling rate, based on a model that relates the temperature, the density and the interaction, which can be used to predict the cooling rate as a function of the frequency of the light pulses. Our results suggest that this cooling method is efficient for temperatures above a few Kelvin, provided that the frequency of the light pulses is large enough.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the Abundance of Highly Ionized Proto-Cluster Regions\n  from the Absence of Large Voids in the Lyman Alpha Forest. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2584, "human_text": "  Energetic feedback processes during the formation of galaxy clusters may have heated and ionized a large fraction of the intergalactic gas in proto-cluster regions. When such a highly ionized hot ``super-bubble'' falls along the sightline to a background quasar, it would be seen as a large void, with little or no absorption, in the Lyman alpha forest. We examine the spectra of 137 quasars in the Sloan Digital Sky Survey, to search for such voids, and find no clear evidence of their existence. The size distribution of voids in the range 5-70 Angstrom (corresponding to physical sizes of approximately 3-35 comoving Mpc/h) is consistent with the standard model for the Lyman alpha forest without additional hot bubbles. We adapt a physical model for HII bubble growth during cosmological reionization (Furlanetto, Zaldarriaga and Hernquist 2004), to describe the expected size-distribution of hot super-bubbles at redshift around z = 3. This model incorporates the conjoining of bubbles around individual neighboring galaxies. Using the non-detection of voids, we find that models in which the volume filling factor of hot bubbles exceeds approximately 20 percent at z=3 can be ruled out, primarily because they overproduce the number of large (40-50 Angstrom) voids. We conclude that any pre-heating mechanism that explains galaxy cluster observations must avoid heating the low-density gas in the proto-cluster regions, either by operating relatively recently (z<3) or by depositing entropy in the high-density regions. ", "machine_text": " We present a method to constrain the abundance of highly ionized regions in the early universe by analyzing the distribution of ionized hydrogen in the Ly\u03b1 forest. Our method is based on the fact that the ionization of hydrogen increases with the growth of the universe, while the density of ionized gas decreases with the expansion of the universe and the formation of voids. Therefore, the ratio of ionized gas to the total gas should increase with the growth of the universe. We find that the observed distribution of highly ionized gas in the Ly\u03b1 forest is consistent with the model in which the abundance of highly ionized gas is constant. This conclusion is supported by a detailed comparison between the predictions of our model and the observations. We also show that the observed abundance of highly ionized gas is inconsistent with the models in which the abundance of highly ionized gas increases or decreases with the growth of the universe. The main result of our work is a set of constraints on the abundance of highly ionized gas in the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Origin of the Dichotomy of Early-Type Galaxies: The Role of Dry\n  Mergers and AGN Feedback. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0932, "human_text": "  Using a semi-analytical model for galaxy formation, combined with a large N-body simulation, we investigate the origin of the dichotomy among early-type galaxies. We find that boxy galaxies originate from mergers with a progenitor mass ratio $n < 2$ and with a combined cold gas mass fraction $F_{\\rm cold} < 0.1$. Our model accurately reproduces the observed fraction of boxy systems as a function of luminosity and halo mass, for both central galaxies and satellites. After correcting for the stellar mass dependence, the properties of the last major merger of early-type galaxies are independent of their halo mass. This provides theoretical support for the conjecture of Pasquali et al (2007) that the stellar mass of an early-type galaxy is the main parameter that governs its isophotal shape. We argue that the observed dichotomy of early-type galaxies has a natural explanation within hierarchical structure formation, and does not require AGN feedback. Rather, we argue that it owes to the fact that more massive systems (i) have more massive progenitors, (ii) assemble later, and (iii) have a larger fraction of early-type progenitors. Each of these three trends causes the cold gas mass fraction of the progenitors of more massive early-types to be lower, so that their last major merger was dryer. Finally, our model predicts that (i) less than 10 percent of all early-type galaxies form in major mergers that involve two early-type progenitors, (ii) more than 95 percent of all boxy early-type galaxies with $M_* < 2 \\times 10^{10} h^{-1} \\Msun$ are satellite galaxies, and (iii) about 70 percent of all low mass early-types do not form a supermassive black hole binary at their last major merger. The latter may help to explain why low mass early-types have central cusps, while their massive counterparts have cores. ", "machine_text": " We present a physical model that accounts for the observed properties of early-type galaxies in a manner that is consistent with the predictions of the cold dark matter theory on large scales, but does not require ad-hoc fine-tuning. In our model, the galaxies are treated as overdense regions in an otherwise rarefied Universe, and are assumed to have formed through the collapse of perturbations that are either (i) small-scale fluctuations in a smooth distribution, (ii) droplets formed through the gravitational collapse of larger density peaks, or (iii) a combination of these two. We show that this model naturally explains why galaxies are found in groups, why they have the sizes they do, why they have the colours they do, and why they are evolving the way they do. In particular, the model predicts that galaxies should exhibit a strong correlation between their mass and their colour, with massive galaxies being mostly blue and small galaxies being mostly red. We show that this prediction is consistent with observations, provided that the galaxy colours are corrected for the age of the Universe. We also show that the model predicts that the large-scale structure of the galaxies should be formed through the gravitational collapse of large density peaks, rather than through the accretion of smaller galaxies. We discuss the implications of our model for the theories of galaxy formation and evolution, and for the interpretation of observations of galaxies and large-scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Discovery of 1000 km/s Outflows in Massive Post-starburst Galaxies\n  at z=0.6. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0527, "human_text": "  Numerical simulations suggest that active galactic nuclei (AGNs) play an important role in the formation of early-type galaxies by expelling gas and dust in powerful galactic winds and quenching star formation. However, the existence of AGN feedback capable of halting galaxy-wide star formation has yet to be observationally confirmed. To investigate this question, we have obtained spectra of 14 post-starburst galaxies at z~0.6 to search for evidence of galactic winds. In 10/14 galaxies we detect Mg II 2796,2803 absorption lines which are blueshifted by 490 - 2020 km/s with respect to the stars. The median blueshift is 1140 km/s. We hypothesize that the outflowing gas represents a fossil galactic wind launched near the peak of the galaxy's activity, a few 100 Myr ago. The velocities we measure are intermediate between those of luminous starbursts and broad absorption line quasars, which suggests that feedback from an AGN may have played a role in expelling cool gas and shutting down star formation. ", "machine_text": " We present observations of the unique galaxies Ghostly Perspective and Psychological, found in the COSMOS survey at z=0.6. These galaxies contain an excess of radio sources, indicating a large number of supernovae (SNe) in their past. Using the Australian Telescope, we have imaged the gas and stars in these galaxies, finding that the gas is moving at unprecedented speeds of up to 1000 km/s, much faster than the stars. We show that the gas in these galaxies has been ripped out of them by the SNe, and is moving so fast because the galaxies have been heavily distorted by their past star-formation and the infall of intergalactic gas. We calculate that the gas has been accelerated to these extreme speeds by a powerful torque, caused by the infall of gas and the strong local intergalactic magnetic field. This is the first time that such fast outflows have been discovered in massive galaxies at high-redshift. This discovery changes our understanding of how galaxies evolve at high-redshift, and provides a possible explanation for the unusual features of massive galaxies in the distant Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Parametric Nonholonomic Frame Transforms and Exact Solutions in Gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3986, "human_text": "  A generalized geometric method is developed for constructing exact solutions of gravitational field equations in Einstein theory and generalizations. First, we apply the formalism of nonholonomic frame deformations (formally considered for nonholonomic manifolds and Finsler spaces) when the gravitational field equations transform into systems of nonlinear partial differential equations which can be integrated in general form. The new classes of solutions are defined by generic off-diagonal metrics depending on integration functions on one, two and three (or three and four) variables if we consider four (or five) dimensional spacetimes. Second, we use a general scheme when one (two) parameter families of exact solutions are defined by any source-free solutions of Einstein's equations with one (two) Killing vector field(s). A successive iteration procedure results in new classes of solutions characterized by an infinite number of parameters for a non-Abelian group involving arbitrary functions on one variable. Five classes of exact off-diagonal solutions are constructed in vacuum Einstein and in string gravity describing solitonic pp-wave interactions. We explore possible physical consequences of such solutions derived from primary Schwarzschild or pp-wave metrics. ", "machine_text": " Parametric nonholonomic frame transforms and exact solutions in gravity  We consider a class of exact solutions of the Einstein equations of motion in a curved background spacetime, in the form of a parametric nonholonomic frame transform. The main examples of this type of solution are the Landau, Kerr and Reissner-Nordstr\u00f6m metrics, which describe a uniform spinning disk, a spinning black hole, and a spherically symmetric object with a big bang type expansion, respectively. In the case of a spinning object the nonholonomicity is related to the geometric structure of the space-time. We show that in the case of a Kerr or Reissner-Nordstr\u00f6m metric the nonholonomicity is of a purely dynamical origin, and is related to the Killing generator of the symmetry group of the background space-time. As an application, we consider the simplest case of a scalar particle moving on a Kerr background. We show that the corresponding motion is a completely symmetric and coordinate independent solution, which describes a uniformly accelerated particle with a relativistic velocity increase. We also show that this solution has a simple geometric structure, and discuss a possible physical interpretation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strategies for the Design of a Slide-o-Cam Transmission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1036, "human_text": "  The optimization of the pressure angle in a cam-follower transmission is reported in this paper. This transmission is based on Slide-o-Cam, a cam mechanism with multiple rollers mounted on a common translating follower. The design of Slide-o-Cam, a transmission intended to produce a sliding motion from a turning drive, or vice versa, was reported elsewhere. This transmission provides pure-rolling motion, thereby reducing the friction of rack-and-pinions and linear drives. The pressure angle is a suitable performance index for this transmission because it determines the amount of force transmitted to the load vs. that transmitted to the machine frame. Two alternative design strategies are studied, namely, (i) increase the number of lobes on each cam or (ii) increase the number of cams. This device is intended to replace the current ball-screws in Orthoglide, a three-DOF parallel robot for the production of translational motions, currently under development at Ecole Centrale de Nantes for machining applications. ", "machine_text": "  Strategies for the Design of a Slide-o-Cam Transmission This paper presents the design and analysis of a transmission for a light-duty, off-highway vehicle. The transmission design is a simple, mechanical, automatic, four-wheel-drive, four-wheel-steer transmission. The vehicle will be used to navigate rough, uneven terrain and thus will be subjected to severe conditions. The design is based on the concept of a slide-o-cam, which is a device that converts linear motion into rotary motion. The slide-o-cam is a component of the transmission that is mounted on the input shaft. The slide-o-cam is designed to move axially along the input shaft, thereby providing the correct ratio between the input shaft and the output shaft. The transmission is designed to have a variable ratio between the input shaft and the output shaft, which will allow the vehicle to travel at different speeds. The transmission is designed to have a high ratio, which will allow the vehicle to travel at a high speed. The transmission is designed to have a low ratio, which will allow the vehicle to travel at a low speed. The transmission is designed to have a reverse ratio, which will allow the vehicle to travel in reverse. The transmission is designed to have a neutral ratio, which will allow the vehicle to be in neutral. The transmission is designed to have a four-wheel-drive ratio, which will allow the vehicle to be in four-wheel drive. The transmission is designed to have a four-wheel-steer ratio, which will allow the vehicle to be in four-wheel steer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer Observations of Transient, Extended Dust in Two Elliptical\n  Galaxies: New Evidence of Recent Feedback Energy Release in Galactic Cores. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.371, "human_text": "  Spitzer observations of extended dust in two optically normal elliptical galaxies provide a new confirmation of buoyant feedback outflow in the hot gas atmospheres around these galaxies. AGN feedback energy is required to prevent wholesale cooling and star formation in these group-centered galaxies. In NGC 5044 we observe interstellar (presumably PAH) emission at 8 microns out to about 5 kpc. Both NGC 5044 and 4636 have extended 70 microns emission from cold dust exceeding that expected from stellar mass loss. The sputtering lifetime of this extended dust in the ~1keV interstellar gas, ~10^7 yrs, establishes the time when the dust first entered the hot gas. Evidently the extended dust originated in dusty disks or clouds, commonly observed in elliptical galaxy cores, that were disrupted, heated and buoyantly transported outward. The surviving central dust in NGC 5044 and 4636 has been disrupted into many small filaments. It is remarkable that the asymmetrically extended 8 micron emission in NGC 5044 is spatially coincident with Halpha+[NII] emission from warm gas. A calculation shows that dust-assisted cooling in buoyant hot gas moving out from the galactic core can cool within a few kpc in about ~10^7 yrs, explaining the optical line emission observed. The X-ray images of both galaxies are disturbed. All timescales for transient activity - restoration of equilibrium and buoyant transport in the hot gas, dynamics of surviving dust fragments, and dust sputtering - are consistent with a central release of feedback energy in both galaxies about 10^7 yrs ago. ", "machine_text": "  We present observations of transient, extended dust in the nuclei of two elliptical galaxies (M106 and M31), obtained with the Spitzer Space Telescope as part of the Spitzer Infrared Extra-galactic Legacy Archive Survey. The dust clouds are detected in archival images from the Spitzer Deep Near-Infrared Extragalactic Survey, using a combination of thermal and Near-Infrared Camera (NIRCam) data. The dust clouds are absent in archival data from the Multiband Imaging Photometer for Spitzer (MIPS), which shows that they are not just out-of-focus clumps of dust in our own galaxy. The two galaxies are at similar redshifts (z ~ 1), but have different histories of accretion and feedback, with M106 having experienced several episodes of merging and M31 being more quiescent. The dust clouds are located in the cores of the galaxies, and have the appearance of discrete, non-rotating features that were perhaps released from molecular clouds and are now propagating through the galaxies. The M106 cloud is possibly a merger-driven event, while the M31 cloud is more consistent with a accretion-driven event. We discuss several mechanisms by which such clouds could be produced, and conclude that they are likely to be a manifestation of recent feedback energy release in the cores of galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HST/ACS Coronagraphic Observations of the Dust Surrounding HD 100546. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1507, "human_text": "  We present ACS/HST coronagraphic observations of HD 100546, a B9.5 star, 103 pc away from the sun, taken in the F435W, F606W, and F814W bands. Scattered light is detected up to 14'' from the star. The observations are consistent with the presence of an extended flattened nebula with the same inclination as the inner disk. The well-known ``spiral arms'' are clearly observed and they trail the rotating disk material. Weaker arms never before reported are also seen. The inter-arm space becomes brighter, but the structures become more neutral in color at longer wavelengths, which is not consistent with models that assume that they are due to the effects of a warped disk. Along the major disk axis, the colors of the scattered-light relative to the star are \\Delta (F435W-F606W) ~ 0.0--0.2 mags and \\Delta (F435W-F814W)~0.5--1 mags. To explain these colors, we explore the role of asymmetric scattering, reddening, and large minimum sizes on ISM-like grains. We conclude each of these hypotheses by itself cannot explain the colors. The disk colors are similar to those derived for Kuiper Belt objects, suggesting that the same processes responsible for their colors may be at work here. We argue that we are observing only the geometrically thick, optically thin envelope of the disk, while the optically thick disk responsible for the far-IR emission is undetected. The observed spiral arms are then structures on this envelope. The colors indicate that the extended nebulosity is not a remnant of the infalling envelope but reprocessed disk material. ", "machine_text": "  We present the first coronagraphic images of the disk of dust surrounding the nearby star HD 100546. These images were obtained with the NASA/ESA Hubble Space Telescope's Advanced Camera for Surveys (ACS) and the High Resolution Imaging Spectrometer (HRIS), during the Hubble Deep Outer Planet Survey (HOPS) Programme. HD 100546 is a star similar to our Sun, but is located 17 light-years away from us. In 1995, it was discovered to have a disk of dust surrounding it, by astronomers using the Hubble Space Telescope. We have now imaged this dust disk with unprecedented resolution, and have discovered that it is much more complicated than astronomers had previously realised. In particular, we find that the disk has at least one ring-like feature, in addition to the central disk. We also find that the dust is not distributed evenly in the disk, but is instead clumped together in several places. Our results are consistent with the disk having been perturbed by the passage of a planet or planets, and provide a dramatic demonstration of the power of Hubble to study the disks of dust and gas surrounding stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: First CO J=6-5, 4-3 detections in local ULIRGs: the dense gas in Mrk231,\n  and its colling budget. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0811, "human_text": "  We report on detections of the high-excitation CO J=6-5, J=4-3 lines in Mrk231, a prototypical Ultra Luminous Infrared Galaxy (ULIRG) and Seyfert 1 QSO. These observations are combined with CO J=3-2, HCN J=4-3 (this work), and CO J=2-1, J=1-0, 13CO J=2-1, HCN J=1-0 measurements taken from the literature to provide better constraints on the properties of the molecular gas in an extreme starburst/QSO in the local Universe. We find that the CO J=4-3 and J=6-5 transitions trace a different gas phase from that dominating the lower three CO transitions, with n(H_2) ~ (1-3)x10^4 cm-3 and Tk ~ (40-70) K. This phase is responsible for the luminous HCN emission, and contains most of the H2 gas mass of this galaxy. The total CO line cooling emanating from this dense phase is found similar to that of the [CII] line at 158 micron, suggesting a very different thermal balance to that seen in lower IR-luminosity galaxies, and one likely dominated by dense photon-dominated regions. Our dense \"sampling\" of the CO rotational ladder and the HCN lines enables us to produce well-constrained Spectral Line Energy Distributions (SLEDs) for the dense molecular gas in Mrk231 and compare them to those of high redshift starbursts, many of which have SLEDs that may be affected by strong lensing. Finally, we use our local molecular line excitation template to assess the capabilities of future cm and mm/sub-mm arrays in detecting CO and HCN transitions in similar systems throughout the local and distant universe. ", "machine_text": "  We present the first CO J=6-5, 4-3 detections in two local ULIRGs: Mrk231 and Mrk650. These detections provide a critical benchmark for comparison with models of molecular cloud formation and evolution. We find that the derived molecular line luminosities are consistent with the CO-dark cloud model of Churchwell & 1996, if the molecular clouds are thermally-stratified with the CO-rich layer placed near the cloud's cold trap. The model also predicts that the CO luminosity should be proportional to the cloud's cooling budget, which is in turn proportional to the cloud's mass. We find that this prediction is consistent with the observed correlation between the molecular line luminosity and the total infrared luminosity, both in the optically-selected sample of clouds and in the subset of clouds that are particularly dense. This indicates that the cloud's mass is indeed proportional to its cooling budget, at least for the dense clouds in our sample. We find that the most dense clouds have a cooling budget that is about 2-4 times their mass, consistent with the predictions of the model. However, we also find that the least dense clouds have a cooling budget that is about 10 times their mass. This is a problem for the model, which predicts that the cooling budget should be proportional to the cloud's mass. We discuss several possible explanations for this discrepancy, including the possibility that the least dense clouds are not yet gravitationally stable. We find that the relative molecular line luminosity of the inner region compared to the outer region is consistent with the cloud being isothermal, at least for the cases where we have sufficient resolution to distinguish between the inner and outer regions. We discuss the implications of our results for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accurate description of optical precursors and their relation to\n  weak-field coherent optical transients. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4238, "human_text": "  We study theoretically the propagation of a step-modulated optical field as it passes through a dispersive dielectric made up of a dilute collection of oscillators characterized by a single narrow-band resonance. The propagated field is given in terms of an integral of a Fourier type, which cannot be evaluated even for simple models of the dispersive dielectric. The fact that the oscillators have a low number density (dilute medium) and have a narrow-band resonance allows us to simplify the integrand. In this case, the integral can be evaluated exactly, although it is not possible using this method to separate out the transient part of the propagated field known as optical precursors. We also use an asymptotic method (saddle-point method) to evaluate the integral. The contributions to the integral related to the saddle-points of the integrand give rise to the optical precursors. We obtain analytic expressions for the precursor fields and the domain over which the asymptotic method is valid. When combined to obtain the total transient field, we find that the agreement between the solutions obtained by the asymptotic and the exact methods is excellent. Our results demonstrate that precursors can persist for many nanoseconds and the chirp in the instantaneous frequency of the precursors can manifest itself in beats in the transmitted intensity. Our work strongly suggests that precursors have been observed in many previous experiments. ", "machine_text": "  Accurate description of optical precursors and their relation to weak-field coherent optical transients  We present an accurate theoretical description of the optical precursor phenomenon. The description is based on a rigorous analysis of the dynamics of a laser pulse as it passes through a spatially extended pre- fibre. We show that a full description of the precursor requires an accurate solution of the optical wave equation in a spatially extended system. The solution is found by using the correct form of the relaxation of the pulse to the radiation pressure, which is shown to be different for different pulse shapes. We show that the correct relaxation of the pulse results in the evolution of a complex spatial pattern of field intensity, which contains information about the dynamics of the system. The description is confirmed by a comparison with previously published results, which used an approximate description of the precursor. We also present a simple and exact description of the relation between the precursor and the coherent transient that follows it.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum mechanical approach to decoherence and relaxation generated by\n  fluctuating environment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0194, "human_text": "  We consider an electrostatic qubit, interacting with a fluctuating charge of single electron transistor (SET) in the framework of exactly solvable model. The SET plays a role of the fluctuating environment affecting the qubit's parameters in a controllable way. We derive the rate equations describing dynamics of the entire system for both weak and strong qubit-SET coupling. Solving these equation we obtain decoherence and relaxation rates of the qubit, as well as the spectral density of the fluctuating qubit's parameters. We found that in the weak coupling regime the decoherence and relaxation rates are directly related to the spectral density taken at Rabi or at zero frequency, depending on what a particular qubit's parameters is fluctuating. This relation holds also in the presence of weak back-action of the qubit on the fluctuating environment. In the case of strong back-action, such simple relationship no longer holds, even if the qubit-SET coupling is small. It does not hold either in the strong-coupling regime, even in the absence of the back-action. In addition, we found that our model predicts localization of the qubit in the strong-coupling regime, resembling that of the spin-boson model. ", "machine_text": "  We investigate a system of two qubits in a fluctuating environment, as a model of decoherence and relaxation processes generated by thermal and other fluctuations in the environment. The model is approached from the framework of quantum mechanics, and the influence of the environment is accounted for by a Lindblad-like operator. The equations of motion of the qubits are solved analytically, and the exact form of the solution, including the effect of the environment, is derived. The special case of pure dephasing is discussed in some detail, and the results are compared with the predictions of the standard Boltzmann-like equation for relaxation in a fluctuating environment. Our results show that in certain parameter ranges the dynamics of the qubits can be effectively described by the standard Boltzmann equation, with a single relaxation rate. In other ranges, however, the relaxation dynamics is more complex, and can be well described by a combination of two or more relaxation rates, depending on the relation between the relevant time-scales of the qubit and the environment. We also discuss the implications of our results for a realistic model of decoherence and relaxation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quasi Equilibrium Grid Algorithm: geometric construction for model\n  reduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2317, "human_text": "  The Method of Invariant Grid (MIG) is an iterative procedure for model reduction in chemical kinetics which is based on the notion of Slow Invariant Manifold (SIM) [1-4]. Important role, in that method, is played by the initial grid which, once refined, gives a description of the invariant manifold: the invariant grid. A convenient way to get a first approximation of the SIM is given by the Spectral Quasi Equilibrium Manifold (SQEM) [1-2]. In the present paper, a flexible numerical method to construct the discrete analog of a Quasi Equilibrium Manifold, in any dimension, is presented. That object is named Quasi Equilibrium Grid (QEG), while the procedure Quasi Equilibrium Grid Algorithm. Extensions of the QEM notion are also suggested. The QEG is a numerical tool which can be used to find a grid-based approximation for the locus of minima of a convex function under some linear constraints. The method is validated by construction of one and two-dimensional grids for model hydrogen oxidation reaction. ", "machine_text": "  We present a geometric construction of the quasi-equilibrium grid algorithm and use it to derive a simple analytical expression for the reduced potential function. The quasi-equilibrium grid algorithm is an efficient method for obtaining a approximate basis of the relaxed potential function in an iteratively motivated basis pursuit algorithm. We show that our construction can be used to derive a simple expression for the reduced potential function that is accurate close to the boundaries of the atoms and in the limit of a large number of atoms. The resulting algorithm is very simple and is shown to be capable of converging quickly to a good approximation of the reduced potential function. We also show how the geometric construction can be used to derive a simple formula for the best basis of the reduced potential function in the least squares sense. The simplicity of the formula allows one to easily control the bias of the approximation by changing the number of basis functions and the strength of the relaxing Potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Regular homogeneous T-models with vacuum dark fluid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2368, "human_text": "  We present the class of regular homogeneous T-models with vacuum dark fluid, associated with a variable cosmological term. The vacuum fluid is defined by the symmetry of its stress-energy tensor, i.e., its invariance under Lorentz boosts in a distinguished spatial direction (p_j=-\\rho), which makes this fluid essentially anisotropic and allows its density to evolve. Typical features of homogeneous regular T-models are: the existence of a Killing horizon; beginning of the cosmological evolution from a null bang at the horizon; the existence of a regular static pre-bang region visible to cosmological observers; creation of matter from anisotropic vacuum, accompanied by very rapid isotropization. We study in detail the spherically symmetric regular T-models on the basis of a general exact solution for a mixture of the vacuum fluid and dustlike matter and apply it to give numerical estimates for a particular model which illustrates the ability of cosmological T-models to satisfy the observational constraints. ", "machine_text": " We show that the construction of a regular homogeneous T-model with a dark fluid in the vacuum gives rise to a solution of Einstein's field equations with a cosmological constant, which is an exact solution with a constant ratio of the circumference of a circle to its radius, that is, a solution with a homogeneous and isotropic space-time. In this model the energy density of the dark fluid is equal to the cosmological constant. We show that the resulting space-time can be described by the regular homogeneous T-model with a dark fluid in the vacuum, that is, by the sum of the relativistic potion and the rest of the space-time. As a result, the cosmological constant appears as a dynamic variable, that is, as a function of the scale factor. The model has a local Lorentzian group, and therefore it is interpretable. The model can describe a space-time with a slowly varying cosmological constant, that is, with a slowly varying energy density of the dark fluid. The slowly varying energy density can be interpreted as a slowly varying cosmological constant or, in the framework of the standard model, as a slowly varying value of the effective action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Retaining Black Holes with Very Large Recoil Velocities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1548, "human_text": "  Recent numerical simulations of binary black hole mergers show the possibility of producing very large recoil velocities (> 3000 km/s). Kicks of this magnitude should be sufficient to eject the final black hole from virtually any galactic potential. This result has been seen as a potential contradiction with observations of supermassive black holes residing in the centers of most galaxies in the local universe. Using an extremely simplified merger tree model, we show that, even in the limit of very large ejection probability, after a small number of merger generations there should still be an appreciable fraction (>50%) of galaxies with supermassive black holes today. We go on to argue that the inclusion of more realistic physics ingredients in the merger model should systematically increase this retention fraction, helping to resolve a potential conflict between theory and observation. Lastly, we develop a more realistic Monte Carlo model to confirm the qualitative arguments and estimate occupation fractions as a function of the central galactic velocity dispersion. ", "machine_text": "  We consider the problem of retaining a particle within a black hole, for a range of black hole spin and momenta. We show that the largest orbit that can be retained is limited by the size of the event horizon, and that for this orbit the particle's velocity must be comparable to the speed of light. We consider a range of possible physical mechanisms that might be used to drive a particle into such a large orbit, and find that only mechanisms that extract energy from the black hole, by increasing its entropy, can accomplish this. We then consider the specific case of a particle with very large recoil velocity, and find that such a particle can be retained in a wide range of black holes if the particle is scattered by a photon with a large energy. We show that there is a simple relationship between the black hole spin, the photon energy, and the probability that the particle will be scattered by the photon, and we present a qualitative explanation for this relationship. We also show that this mechanism for retaining a particle can be made to work for a wide range of initial conditions, without requiring fine tuning. We also show that the same mechanism can be used to produce a range of interesting effects, such as super-fast orbits, and the ejection of matter from a black hole.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A \"diamond-ring\" star: the unusual morphologic structure of a young\n  (multiple?) object. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3236, "human_text": "  We have observed IRAS06468-0325 obtaining optical and infrared images through IJHKs and L' filters, K-band low-resolution spectroscopy, together with millimetre line observations of CO and CS. IRAS06468-0325 has a very unusual and enigmatic morphology with two components: a bright, close to point-like source (the diamond) and a sharp-edge ring-like structure (the ring). The source is not detected in the optical, at wavelengths shorter than the I-band. The diamond is seen in all the imaging bands observed. The ring-like structure in IRAS06468-0325 is clearly seen in the I, J, H, and Ks. It is not detected in the L'-band image. Infrared colours of the diamond are compatible with excess circumstellar emission and a young stellar nature. A strongly non-gaussian and moderately bright CO(1-0) and {13}CO(2-1) lines are seen towards IRAS06468-0325, at v_{LSR} of 30.5 km s{-1} (corresponding to a kinematic distance of 3 kpc). Very weak C{18}O(2-1) and CS(2-1) lines were detected. K-band spectra of the diamond and of the ring are similar both in the slope of the continuum and in the presence of lines supporting the idea that the ring is reflected light from the diamond. With the current data, a few different scenarios are possible to explain the morphology of this object. However, the available data seem to favour that the morphology of IRAS06468-0325 correspond to a young stellar multiple system in a transient stage where a binary co-exists with a circumbinary disc, similar to the case of GG Tau. In this case, the sharpness of the well-defined ring may be due to tidal truncation from dynamic interactions between components in a binary or multiple stellar system. IRAS06468-0325 may be an important rare case that illustrates a short-lived stage of the process of binary or multiple star formation. ", "machine_text": " A \"diamond-ring\" star: the unusual morphologic structure of a young (multiple?) object  We present observations of a young (ionic and gas) object, which we dub \"diamond-ring star,\" due to its unusual and very bright chromatic structure. We found it using the Wise star catalogue, which contains an all-sky survey at V=8. The unique thing about this object is that, unlike every other young stellar object, it does not show a point-like source, but a disk-like structure with many colours, and a structure that very much resembles the \" diamond-ring\" that some amateurs were lucky to observe during the total solar eclipse of August 21, 2017. The colours in our object are due to the fact that the light from the central star is First Order interference, while the light from the outskirts is Rayleigh scattering. We also found a companion object, which we initially dismissed as a background star, but it is also a young object, though much less bright and much more distant. It has a point-like structure, which could be a single star or a binary, and it is also surrounded by a disk-like structure with many colours, which could be an evolved version of the \"diamond-ring\" structure. We discuss the nature of these objects, and the possibility that the bright object may be a young multiple object, possibly a triplet. We also discuss the possibility that the bright object is a disk around a very young (and thus very large) giant planet, which would explain its unusual nature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Gene Duplication Models for Evolving Regulatory Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3808, "human_text": "  Background: Duplication of genes is important for evolution of molecular networks. Many authors have therefore considered gene duplication as a driving force in shaping the topology of molecular networks. In particular it has been noted that growth via duplication would act as an implicit way of preferential attachment, and thereby provide the observed broad degree distributions of molecular networks.   Results: We extend current models of gene duplication and rewiring by including directions and the fact that molecular networks are not a result of unidirectional growth. We introduce upstream sites and downstream shapes to quantify potential links during duplication and rewiring. We find that this in itself generates the observed scaling of transcription factors for genome sites in procaryotes. The dynamical model can generate a scale-free degree distribution, p(k)&prop; 1/k^&gamma;, with exponent &gamma;=1 in the non-growing case, and with &gamma;>1 when the network is growing.   Conclusions: We find that duplication of genes followed by substantial recombination of upstream regions could generate main features of genetic regulatory networks. Our steady state degree distribution is however to broad to be consistent with data, thereby suggesting that selective pruning acts as a main additional constraint on duplicated genes. Our analysis shows that gene duplication can only be a main cause for the observed broad degree distributions, if there is also substantial recombinations between upstream regions of genes. ", "machine_text": "  On Gene Duplication Models for Evolving Regulatory Networks  Regulatory networks control gene expression by regulating the binding of transcription factors to DNA. They are a central organizing principle in biology, and their dynamics are thought to be critical for the evolution of many complex traits. We study regulatory evolution by asking how gene duplications affect the architecture of regulatory networks. We focus on the evolution of gene expression levels, which are often highly heritable and have important fitness consequences. We develop a new model that enables us to study the dynamics of gene expression levels in the presence of gene duplications. We find that gene duplications have complex effects on gene expression levels, and in many cases can drive them to evolve in an optimizing direction. We show that this effect can be understood by considering both the direct effect of duplicating a gene, and the indirect effects of duplicating regulatory connections that influence the expression of the gene. Our model also makes specific predictions about the evolutionary dynamics of gene expression levels, which we test using a combination of computational and experimental methods. Our results suggest that these predictions could be used to distinguish between different gene duplication models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spheroidal and torsional modes of quasistatic shear oscillations in the\n  solid globe models of nuclear physics and pulsar astrophysics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1732, "human_text": "  The past three decades of investigation on nuclear physics and pulsar astrophysics have seen gradual recognition that elastodynamic approach to the continuum mechanics of nuclear matter provides proper account of macroscopic motions of degenerate Fermi-matter constituting interior of the nuclear material objects, the densest of all known today. This paper focuses on one theoretical issue of this development which is concerned with oscillatory behavior of a viscoelastic solid globe in the regime of quasistatic, force-free, non-compressional oscillations less investigated in the literature compared to oscillations in the regime of standing shear waves. We show that in this case the problem of computing frequency and lifetime of spheroidal and torsional modes of non-radial shear vibrations damped by viscosity can be unambiguously resolved by working from the energy balance equation and taking advantage of the Rayleigh's variational method. The efficiency of this method is demonstrated by solid globe models of nuclear physics and pulsar astrophysics dealing with oscillations of a spherical mass of a viscoelastic Fermi-solid with homogeneous and non-homogeneous profiles of the bulk density, the shear modulus, and the shear viscosity. ", "machine_text": " We consider spheroidal and torsional modes of quasistatic shear oscillations in the solid globe models of nuclear physics and pulsar astrophysics. The problem is reduced to the study of the frequency-dependent shear modulus, C, in a spheroidal shell of uniform thickness. We show than nonzero values of C can be obtained only if the thickness of the shell is equal to a quarter of the wavelength of the corresponding spheroidal mode. This condition can be satisfied only for a limited set of frequencies corresponding to the so-called edge modes. We also found a simple expression for the frequency-dependent shear modulus in terms of the Laplace transform of the solution to the three-dimensional Love wave equation in a spheroidal shell. The resulting expression for C is very similar to the one obtained by transfer matrices method for the propagation of flexural waves in a thin-walled tube. Our result for the shear modulus also implies that the frequency-dependent bulk modulus in a solid sphere is equal to the shear modulus in a thin-walled tube with the same wall thickness and density.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Advantages of Four Dimensions for Composite Higgs Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.138, "human_text": "  We examine the relationship between little Higgs and 5d composite models with identical symmetry structures. By performing an \"extreme\" deconstruction, one can reduce any warped composite model to a little Higgs theory on a handful of sites. This allows us to use 4d intuition and the powerful constraints of nonlinear sigma models to elucidate obscure points in the original setup. We find that the finiteness of the Higgs potential in 5d is due to the same collective symmetry breaking as in the little Higgs. We compare a 4d and a 5d model with the same symmetry to the data. Reviewing the constraints on models related to the Minimal Composite Higgs (hep-ph/0412089), we see that it has difficulty in producing acceptable values for S, T, and m_{top} simultaneously. By contrast, in a global analysis, the Minimal Moose with custodial symmetry is viable in a large region of its parameter space and suffers from no numeric tunings. We conjecture that this result is generic for 4d and 5d models with identical symmetries. The data will less strongly constrain the little theory. ", "machine_text": " We study the simplest non-trivial composite Higgs model which is an extension of the minimal supersymmetric extension of the Standard Model (MSSM) by two Higgs doublets and two sets of quark doublets. We show that such a model can be made ( Philosophically speaking ) consistent and stable against the automations of the corresponding supersymmetric model by introducing a new Higgs doublet, in addition to the two standard Higgs doublets, which is always hidden in the MSSM. This hidden Higgs doublet is the \" fourth dimension \" in our title, which does not mean a physical dimension but a \" technical \" dimension in the sense that it does not appear in the physical states and therefore does not lead to an expansion of the physical basis. We show that this model can be made stable and consistent by an appropriate choice of the three Higgs doublets and the quark doublets. We solve exactly the relevant MSSM for this model, and show that the only non-trivial MSSM scalar which is not a physical state is the one that is hidden by the construction. We show that the hidden MSSM scalar can be eliminated by a small modification of the standard MSSM so that the only MSSM scalars which are not physical states are the two standard Higgs doublets. We show that the model with the two Higgs doublets and the quark doublets is equivalent to the MSSM, except for the extra quark degrees of freedom which are \" eaten up \" by the MSSM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the dimension of subspaces with bounded Schmidt rank. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0705, "human_text": "  We consider the question of how large a subspace of a given bipartite quantum system can be when the subspace contains only highly entangled states. This is motivated in part by results of Hayden et al., which show that in large d x d--dimensional systems there exist random subspaces of dimension almost d^2, all of whose states have entropy of entanglement at least log d - O(1). It is also related to results due to Parthasarathy on the dimension of completely entangled subspaces, which have connections with the construction of unextendible product bases. Here we take as entanglement measure the Schmidt rank, and determine, for every pair of local dimensions dA and dB, and every r, the largest dimension of a subspace consisting only of entangled states of Schmidt rank r or larger. This exact answer is a significant improvement on the best bounds that can be obtained using random subspace techniques. We also determine the converse: the largest dimension of a subspace with an upper bound on the Schmidt rank. Finally, we discuss the question of subspaces containing only states with Schmidt equal to r. ", "machine_text": "  We show that a natural dimension function for subspaces of Hilbert spaces is related to the Schmidt rank of the subspace. This leads to a simple characterization of subspaces with bounded Schmidt rank in terms of an inequality on inner products. We apply this characterization to the problem of finding an orthonormal basis for a subspace with bounded Schmidt rank.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On smooth foliations with Morse singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0164, "human_text": "  Let $M$ be a smooth manifold and let $\\F$ be a codimension one, $C^\\infty$ foliation on $M$, with isolated singularities of Morse type. The study and classification of pairs $(M,\\F)$ is a challenging (and difficult) problem. In this setting, a classical result due to Reeb \\cite{Reeb} states that a manifold admitting a foliation with exactly two center-type singularities is a sphere. In particular this is true if the foliation is given by a function. Along these lines a result due to Eells and Kuiper \\cite{Ku-Ee} classify manifolds having a real-valued function admitting exactly three non-degenerate singular points. In the present paper, we prove a generalization of the above mentioned results. To do this, we first describe the possible arrangements of pairs of singularities and the corresponding codimension one invariant sets, and then we give an elimination procedure for suitable center-saddle and some saddle-saddle configurations (of consecutive indices). In the second part, we investigate if other classical results, such as Haefliger and Novikov (Compact Leaf) theorems, proved for regular foliations, still hold true in presence of singularities. At this purpose, in the singular set, $Sing(\\F)$ of the foliation $\\F$, we consider {\\em{weakly stable}} components, that we define as those components admitting a neighborhood where all leaves are compact. If $Sing(\\F)$ admits only weakly stable components, given by smoothly embedded curves diffeomorphic to $S^1$, we are able to extend Haefliger's theorem. Finally, the existence of a closed curve, transverse to the foliation, leads us to state a Novikov-type result. ", "machine_text": "  We show that a certain class of smooth foliations of a 4-manifold admits a decomposition into smooth and corner pieces, and that each component of this decomposition is locally of the same genus. If the manifold is additionally equipped with a metric with negative Curvature, we show that the smooth pieces of the decomposition are parabolic submanifolds, and that the corner pieces are locally at most 3-codimensional. As an application, we give a description of the subspace of steady velocity fields of a certain class of self- degenerating manifolds in terms of a minimal model program.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charmless Three-body Decays of B Mesons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1049, "human_text": "  Charmless 3-body decays of B mesons are studied in the framework of the factorization approach. The nonresonant contributions arising from $B\\to P_1P_2$ transitions are evaluated using heavy meson chiral perturbation theory (HMChPT). The momentum dependence of nonresonant amplitudes is assumed to be in the exponential form $e^{-\\alpha_{NR}} p_B\\cdot(p_i+p_j)}$ so that the HMChPT results are recovered in the soft meson limit $p_i, p_j\\to 0$. In addition, we have identified another large source of the nonresonant signal in the matrix elements of scalar densities, e.g. $<K\\bar K|\\bar ss|0>$, which can be constrained from the decay $\\bar B^0\\to K_SK_SK_S$ or $B^-\\to K^-K_SK_S$. The intermediate vector meson contributions to 3-body decays are identified through the vector current, while the scalar meson resonances are mainly associated with the scalar density. Their effects are described in terms of the Breit-Wigner formalism. Our main results are: (i) All KKK modes are dominated by the nonresonant background. The predicted branching ratios of $K^+K^-K_{S(L)}$, $K^+K^-K^-$ and $K^-K_SK_S$ modes are consistent with the data within errors. (ii) Although the penguin-dominated $B^0\\to K^+K^-K_{S}$ decay is subject to a potentially significant tree pollution, its effective $\\sin 2\\beta$ is very similar to that of the $K_SK_SK_S$ mode. However, direct CP asymmetry of the former, being of order -4%, is more prominent than the latter. (iii) For $B\\to K\\pi\\pi$ decays, we found sizable nonresonant contributions in $K^-\\pi^+\\pi^-$ and $\\bar K^0\\pi^+\\pi^-$ modes, in agreement with the Belle measurements but larger than the BaBar result. ", "machine_text": "  We present an analysis of charmless three-body decays of B mesons, where one of the two b quarks is reconstructed as a hadron in the final state. We use a sample of 3.9 million $B\\overline{B}$ pairs collected at the $\\Upsilon(4S)$ center of mass energy by the BaBar detector at the SLAC PEP-II $e^+e^-$ accelerator. The hadronized b quark is found to have hadronization times between 2 and 4.5 GeV/c^2, with a mean of 3.4 GeV/c^2. We also find a strong correlation between the hadronization time and the longitudinal polarization of the hadronized b quark. A fit to the data gives a hadronization mechanism with a quark-antiquark interaction strength of $\\lambda_{\\rm quark}^2\\sim 1.6\\, \\text{GeV}^2$. The charmless three-body decays of B mesons are sensitive to the hadronization mechanism and the final state interactions. We present an analysis of the $\\eta\\overline{\\eta}$ pair production in charmless three-body decays of B mesons. We find $\\langle \\eta\\overline{\\eta} \\rangle\\sim 10^{-9}$ pairs per $B\\overline{B}$ pair. We present a possible explanation for the small value of the $\\langle \\eta\\overline{\\eta} \\rangle$ in terms of the hadronization mechanism and the final state interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining Models of Neutrino Mass and Neutrino Interactions with the\n  Planck Satellite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3271, "human_text": "  In several classes of particle physics models -- ranging from the classical Majoron models, to the more recent scenarios of late neutrino masses or Mass-Varying Neutrinos -- one or more of the neutrinos are postulated to couple to a new light scalar field. As a result of this coupling, neutrinos in the early universe instead of streaming freely could form a self-coupled fluid, with potentially observable signatures in the Cosmic Microwave Background and the large scale structure of the universe. We re-examine the constraints on this scenario from the presently available cosmological data and investigate the sensitivity expected from the Planck satellite. In the first case, we find that the sensitivity strongly depends on which piece of data is used. The SDSS Main sample data, combined with WMAP and other data, disfavors the scenario of three coupled neutrinos at about the 3.5$\\sigma$ confidence level, but also favors a high number of freely streaming neutrinos, with the best fit at 5.2. If the matter power spectrum is instead taken from the SDSS Large Red Galaxy sample, best fit point has 2.5 freely streaming neutrinos, but the scenario with three coupled neutrinos becomes allowed at $2\\sigma$. In contrast, Planck alone will exclude even a single self-coupled neutrino at the $4.2\\sigma$ confidence level, and will determine the total radiation at CMB epoch to $\\Delta N_\\nu^{eff} = ^{+0.5}_{-0.3}$ ($1\\sigma$ errors). We investigate the robustness of this result with respect to the details of Planck's detector. This sensitivity to neutrino free-streaming implies that Planck will be capable of probing a large region of the Mass-Varying Neutrino parameter space. Planck may also be sensitive to a scale of neutrino mass generation as high as 1 TeV. ", "machine_text": " We present the results of a joint analysis of the constraints on neutrino mass and interactions from the latest Planck results, in the framework of a general purpose neutrino model that has previously been fitted to a large number of neutrino oscillation observations. We find that the Planck constraints can be accommodated within this model, given that the mass and the mixing angle are correlated in a way that is consistent with the absence of a phase transition in the early universe. The model that best fits the Planck constraints predicts a muon neutrino mass of 2.4 eV (68% confidence interval: 1.3-3.1 eV), in agreement with the current Planck determination of the neutrino mass. We show that the best-fit model contains two non-zero neutrino masses, with a maximum mass ratio of 1.5. We discuss the prospects of detecting such a mixture with current and future neutrino oscillation experiments, and place an upper bound on the probability of such a mixture for a range of neutrino mass values. We find that the best-fit model has a neutrino effective Dirac mass of 0.18 eV (68% confidence interval: 0.13-0.25 eV), consistent with the result from the Planck analysis of the galactic neutrino flux, and an order of magnitude larger than the Dirac mass of the down-type quark. We show that this order of magnitude difference in the Dirac masses is consistent with the idea that the active neutrinos are nearly massless, while the sterile neutrinos are massive, and that this is the simplest way to accommodate the Planck constraints.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Impact of Cosmic Rays on Population III Star Formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3634, "human_text": "  We explore the implications of a possible cosmic ray (CR) background generated during the first supernova explosions that end the brief lives of massive Population III stars. We show that such a CR background could have significantly influenced the cooling and collapse of primordial gas clouds in minihaloes around redshifts of z ~ 15 - 20, provided the CR flux was sufficient to yield an ionization rate greater than about 10^-19 s^-1 near the center of the minihalo. The presence of CRs with energies less than approximately 10^7 eV would indirectly enhance the molecular cooling in these regions, and we estimate that the resulting lower temperatures in these minihaloes would yield a characteristic stellar mass as low as ~ 10 M_sun. CRs have a less pronounced effect on the cooling and collapse of primordial gas clouds inside more massive dark matter haloes with virial masses greater than approximately 10^8 M_sun at the later stages of cosmological structure formation around z ~ 10 - 15. In these clouds, even without CR flux the molecular abundance is already sufficient to allow cooling to the floor set by the temperature of the cosmic microwave background. ", "machine_text": " We present a new mechanism for the formation of the first stars in the universe based on the ionization of hydrogen and helium by ambient ultraviolet (UV) radiation and the subsequent formation of extended electric fields in the interstellar medium. We show that the electric fields can reach values in excess of 100 kV/cm over interstellar clouds of gas and dust, sufficient to overcome the ionization balance and trigger a collapse to form stars. We explain that the ionization and field formation processes are driven by the continued cosmic ray (CR) flux from the early universe, which was recently shown to have been higher than previously thought. We evaluate the star formation rate (SFR) that can be triggered by the CR ionization mechanism, and show that it is consistent with the observations of the cosmic microwave background radiation and the observed SFRs in local galaxies. We further show that the distribution of the first stars is sensitive to the initial conditions in the ionization and field formation processes, and present a simple model for the distribution of the first stars. We explain that the CR ionization mechanism has important implications for the synthesis of heavy elements in the first stars, as it implies that the primordial gas was already partially ionized, and therefore the early stars had to form in environments with much higher metallicity than previously thought. We also discuss the possibility that the local galaxies were formed through a process of re-ionization of the gas clouds, triggered by supernova (SN) explosions in the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical properties of Er3+ doped alkali-chloro phosphate glasses for\n  optical amplifiers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0847, "human_text": "  A new class of Erbium doped glasses with compositions xNa2O - (60-x)PbCl2 - 40P2O5 (x=0, 10, 20 and 30) were fabricated and characterized for optical properties. Absorption spectra were analyzed for important Judd-Ofelt parameters from the integrated intensities of various Er3+ glass absorption bands. Photoluminescence (PL) and its decay behavior studies were carried out for the transition 4I13/2 -> 4I15/2. A systematic correlation between the Judd-Ofelt parameter {omega}2 and the covalent nature of the glass matrix was observed, due to increased role of bridging oxygens in the glass network. The PL broadness and life times of 4I13/2_> 4I15/2 transition were typically in the range of 40-60nm and 2.13-2.5ms respectively. These glasses broadly showed high transparency, high refractive index, shorter life times and, most importantly, these glasses were found to be capable of being doped with larger concentrations of Er3+ (up to 4 wt%). Increase of Er3+ concentration resulted in the increase in PL line-widths with no significant effect of concentration quenching, indicating that these glasses are suitable for optical fibre/waveguide amplifiers. ", "machine_text": "  We investigated the optical properties of Er3+ doped alkali-chloro phosphate glasses for optical amplifiers. The glasses were synthesized by a conventional melt quenching method. The microstructure of the glasses was examined by transmission electron microscopy, and the presence of a high density of defects, such as vacancies and non-bridging oxygen holes, was observed. The Er3+ doped glasses were found to be thermally stable after melting and quenching. The glass transition temperature was determined to be 434 K, and the temperature corresponding to 10% of the glass decomposition was 632 K. The relative amount of glass decomposition was measured to be 5.0% after heating for 72 h at 632 K. The thermal expansion coefficient was found to be 85 \u00d7 10\u22127 K\u22121. The optical transmission spectra of the Er3+ doped glasses were measured, and the results showed that the glasses were transparent in the visible region and the near-infrared region. The measured glass refractive indices were 1.5972, 1.5958, 1.5955, and 1.5949 for glasses with Er3+ concentrations of 0.5, 1.0, 2.0, and 4.0 mole %, respectively. The absorption spectra of the glasses were measured and the results showed that the glasses exhibited a strong absorption band around 1.5 \u03bcm and a weak absorption band around 0.8 \u03bcm. The relative intensities of the 0.8 \u03bcm and 1.5 \u03bcm absorption bands were measured to be 1:1.5 for the glass with Er3+ concentration of 0.5 mole %, 1:2.5 for the glass with Er3+ concentration of 1.0 mole %, 1:3.5 for the glass with Er3+ concentration of 2.0 mole %, and 1:4.0 for the glass with Er3+ concentration of 4.0 mole %, respectively. The obtained results showed that the glasses were suitable for the preparation of optical amplifiers for optical communication systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Satellite Galaxies and Fossil Groups in the Millennium Simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2009, "human_text": "  We use a semianalytic galaxy catalogue constructed from the Millennium Simulation to study the satellites of isolated galaxies in the LCDM cosmogony. This sample (~80,000$ bright primaries, surrounded by ~178,000 satellites) allows the characterization, with minimal statistical uncertainty, of the dynamical properties of satellite/primary galaxy systems in a LCDM universe. We find that, overall, the satellite population traces the dark matter rather well: its spatial distribution and kinematics may be approximated by an NFW profile with a mildly anisotropic velocity distribution. Their spatial distribution is also mildly anisotropic, with a well-defined ``anti-Holmberg'' effect that reflects the misalignment between the major axis and angular momentum of the host halo. The isolation criteria for our primaries picks not only galaxies in sparse environments, but also a number of primaries at the centre of ''fossil'' groups. We find that the abundance and luminosity function of these unusual systems are in reasonable agreement with the few available observational constraints. We recover the expected L_{host} \\sigma_{sat}^3 relation for LCDM models for truly-isolated primaries. Less strict primary selection, however, leads to substantial modification of the scaling relation. Our analysis also highlights a number of difficulties afflicting studies that rely on blind stacking of satellite systems to constrain the mean halo mass of the primary galaxies. ", "machine_text": "  We present the first study of satellite galaxies and fossil groups in a realistic galaxy formation simulation. We use the Millennium Simulation, a large scale cosmological hydrodynamical simulation including both dark matter and gas, with a resolution of $44\\,$hMpc, which can be used to study the formation history of galaxies up to redshift $z\\sim 1$. In our analysis we identify satellite galaxies using three different methods, and use the galaxy membership probabilities to derive the satellite metallicity and star formation density distribution. We find that the satellite galaxy population as a whole is very metal-poor and displays a star formation density excess of $\\sim 30\\%$ with respect to the main galaxy population, but the satellites of individual galaxies show much larger differences, up to an excess of $\\sim 300\\%$. We find that the stellar mass of the largest satellite in a system is proportional to the stellar mass of the main galaxy, and we show this relation to be consistent with the prediction of the Barred-iminicity theory of galaxy formation. We also analyse the formation of fossil groups, and find that the probability of a group of galaxies to be fossil is inversely proportional to the group mass. We discuss our results in the context of theories of galaxy formation and the formation history of the Local Volume Group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lensing, reddening and extinction effects of MgII absorbers from z=0.4\n  to z=2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0898, "human_text": "  Using a sample of almost 7000 strong MgII absorbers with 0.4 < z < 2.2 detected in the SDSS DR4 dataset, we investigate the gravitational lensing and dust extinction effects they induce on background quasars. After carefully quantifying several selection biases, we isolate the reddening effects as a function of redshift and absorber rest equivalent width, W_0. We find the amount of dust to increase with cosmic time as (1+z)^(-1.1 +/- 0.4), following the evolution of cosmic star density or integrated star formation rate. We measure the reddening effects over a factor 30 in E(B-V) and we find the dust column density to be proportional to W_0^(1.9 +/- 0.2), which provides an important scaling for theoretical modeling of metal absorbers. We also measure the dust-to-metals ratio and find it similar to that of the Milky Way.   In contrast to previous studies, we do not detect any gravitational magnification by MgII systems. We measure the upper limit \\mu<1.10 and discuss the origin of the discrepancy. Finally, we estimate the fraction of absorbers missed due to extinction effects and show that it rises from 1 to 50% in the range 1<W_0<6 Angstrom. We parametrize this effect and provide a correction for recovering the intrinsic distribution of absorber rest equivalent widths. ", "machine_text": " We present the results of a systematic investigation of the properties of strong MgII absorbers in the redshift range z=0.4 to z=2. We aim to determine the relative strengths of the lensing, reddening and extinction effects in these objects, and to derive the physical parameters of the lenses and the absorbing gas. We have identified strong MgII absorbers in 19 quasars, in most cases by using the Hubble Space Telescope, and determined the corresponding redshifts. We find that in 17 cases the lensing effect is dominant, in one case the reddening effect is dominant and in one case the extinction effect is dominant. We derive the lens model parameters in the case of a strong lensing effect, and find that the lensing objects are located at mean redshift z=1.36, with a scatter of 0.3 in redshift. We estimate the ratio of the lensing to extinction effects, and find that it is relatively constant, with a scatter of 0.3, independent of the quasar redshift. We find that the mean reddening is E(H-K)=0.38, with a scatter of 0.07 in redness, and that the mean extinction is A(H-K)=0.51, with a scatter of 0.06 in extinction. The physical parameters of the absorbing gas are derived in the case of a strong extinction effect. We conclude that strong MgII absorbers in the redshift range under consideration are in general lenses, and that the properties of the absorbing gas in these objects are consistent with a steady state model with constant relative matter distribution and optical depth.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-saturating magnetoresistance of inhomogeneous conductors: comparison\n  of experiment and simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0393, "human_text": "  The silver chalcogenides provide a striking example of the benefits of imperfection. Nanothreads of excess silver cause distortions in the current flow that yield a linear and non-saturating transverse magnetoresistance (MR). Associated with the large and positive MR is a negative longitudinal MR. The longitudinal MR only occurs in the three-dimensional limit and thereby permits the determination of a characteristic length scale set by the spatial inhomogeneity. We find that this fundamental inhomogeneity length can be as large as ten microns. Systematic measurements of the diagonal and off-diagonal components of the resistivity tensor in various sample geometries show clear evidence of the distorted current paths posited in theoretical simulations. We use a random resistor network model to fit the linear MR, and expand it from two to three dimensions to depict current distortions in the third (thickness) dimension. When compared directly to experiments on Ag$_{2\\pm\\delta}$Se and Ag$_{2\\pm\\delta}$Te, in magnetic fields up to 55 T, the model identifies conductivity fluctuations due to macroscopic inhomogeneities as the underlying physical mechanism. It also accounts reasonably quantitatively for the various components of the resistivity tensor observed in the experiments. ", "machine_text": " We present a systematic study of the non-saturating magnetoresistance of inhomogeneous conductors using a combination of experiments and simulations. We show that the non-saturating magnetoresistance exhibits a strong sensitivity to the structural and morphological properties of the inhomogeneous conductor. In particular, we show that the non-saturating magnetoresistance increases with the structural inhomogeneity of the conductor, and that it is possible to engineer the non-saturating magnetoresistance by introducing structural inhomogeneities in a uniform conductor. We also show that the non-saturating magnetoresistance decreases with increasing conductor thickness, and that it can be enhanced by patterning the conductor in a periodically repetitive structure. Our results suggest that the non-saturating magnetoresistance could be used as a probe for the structural and morphological properties of conductors.  We have designed and fabricated a planar inductor that can be integrated with a high-Q resonator. The inductor consists of a three-layer stack of a thin-film ferromagnetic layer, an insulating layer, and a conductor layer. The conductor layer is patterned into a periodically repetitive structure. We show that the inductor exhibits a strong non-saturating magnetoresistance, which increases with the structural inhomogeneity of the inductor. We also show that the non-saturating magnetoresistance can be tuned by the structural inhomogeneities in the inductor. The results suggest that the non-saturating magnetoresistance could be used as a probe for the structural and morphological properties of conductors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vacuum Energy and Renormalization on the Edge. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1084, "human_text": "  The vacuum dependence on boundary conditions in quantum field theories is analysed from a very general viewpoint. From this perspective the renormalization prescriptions not only imply the renormalization of the couplings of the theory in the bulk but also the appearance of a flow in the space of boundary conditions. For regular boundaries this flow has a large variety of fixed points and no cyclic orbit. The family of fixed points includes Neumann and Dirichlet boundary conditions. In one-dimensional field theories pseudoperiodic and quasiperiodic boundary conditions are also RG fixed points. Under these conditions massless bosonic free field theories are conformally invariant. Among all fixed points only Neumann boundary conditions are infrared stable fixed points. All other conformal invariant boundary conditions become unstable under some relevant perturbations. In finite volumes we analyse the dependence of the vacuum energy along the trajectories of the renormalization group flow providing an interesting framework for dark energy evolution. On the contrary, the renormalization group flow on the boundary does not affect the leading behaviour of the entanglement entropy of the vacuum in one-dimensional conformally invariant bosonic theories. ", "machine_text": "  We have developed a new method for computing the effective action in quantum field theory in the presence of a static point-like defect. The effective action can be viewed as the renormalization of the action function due to the presence of an additional non-abelian symplectic group in the theory. The main idea is to use the representations of the non-abelian symplectic group to control the renormalization. The method is very general and can be applied to any quantum field theory with a non-abelian symplectic group. We apply the method to the problem of a static defect in the presence of a non-abelian gauge group. The defect can be viewed as a solution to the spontaneous breaking of the symmetry group. We show that the effective action has a minimum as a function of the defect mass, and that the minimum can be understood in terms of the renormalization of the field theory. The renormalization function can be obtained explicitly, and the minimum can be found analytically. The method can be used to compute the effective action for any defect in the presence of a non-abelian symplectic group. The method can also be used to study the renormalization of the action function due to the presence of a non-abelian symplectic group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Origin of magnetoelectric behavior in BiFeO$_3$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.046, "human_text": "  The magnetoelectric behavior of BiFeO$_3$ has been explored on the basis of accurate density functional calculations. The structural, electronic, magnetic, and ferroelectric properties of BiFeO$_3$ are predicted correctly without including strong correlation effect in the calculation. Moreover, the experimentally-observed elongation of cubic perovskite-like lattice along the [111] direction is correctly reproduced. At high pressure we predicted a pressure-induced structural transition and the total energy calculations at expanded lattice show two lower energy ferroelectric phases, closer in energy to the ground state phase. Band-structure calculations show that BiFeO$_3$ will be an insulator in A- and G-type antiferromagnetic phases and a metal in other magnetic configurations. Chemical bonding in BiFeO$_3$ has been analyzed using various tools and electron localization function analysis shows that stereochemically active lone-pair electrons at the Bi sites are responsible for displacements of the Bi atoms from the centro-symmetric to the noncentrosymmetric structure and hence the ferroelectricity. A large ferroelectric polarization (88.7 $\\mu$C/cm$^{2}$) is predicted in accordance with recent experimental findings. The net polarization is found to mainly ($>$ 98%) originate from Bi atoms. Moreover the large scatter in experimentally reported polarization values is due to the large anisotropy in the spontaneous polarization. ", "machine_text": " We have discovered an unusual magneto-electric effect in BiFeO3, a multiferroic material. This effect is not present in the bulk form of the material, but only in a limited temperature region close to the structural phase transition. We show that this effect can be explained by a mechanism of magnetic domain wall motion assisted by an electromechanical instability. We have observed that the stray field of the magnetic domains can be enhanced by a factor of up to 2 by applying a small DC electric field, which results in a large electric field across the domain walls. This large field is necessary to drive the domain wall motion in the ordered state, in which the wall energy is increased by a geometric effect. We have also found that the wall motion is always accompanied by a large increase of the magnetic resistivity, by a factor of up to 3, in the same temperature region. We show that this increase can be explained by a model of elastic strain and magneto-mechanical coupling. Our results suggest that the exotic behavior of BiFeO3 is caused by a strong magneto-mechanical coupling in this material.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The evolution of interstellar clouds in a streaming hot plasma including\n  heat conduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3592, "human_text": "  To examine the evolution of giant molecular clouds in the stream of a hot plasma we performed two-dimensional hydrodynamical simulations that take full account of self-gravity, heating and cooling effects and heat conduction by electrons. We use the thermal conductivity of a fully ionized hydrogen plasma proposed by Spitzer and a saturated heat flux according to Cowie & McKee in regions where the mean free path of the electrons is large compared to the temperature scaleheight. Significant structural and evolutionary differences occur between simulations with and without heat conduction. Dense clouds in pure dynamical models experience dynamical destruction by Kelvin-Helmholtz (KH) instability. In static models heat conduction leads to evaporation of such clouds. Heat conduction acting on clouds in a gas stream smooths out steep temperature and density gradients at the edge of the cloud because the conduction timescale is shorter than the cooling timescale. This diminishes the velocity gradient between the streaming plasma and the cloud, so that the timescale for the onset of KH instabilities increases, and the surface of the cloud becomes less susceptible to KH instabilities. The stabilisation effect of heat conduction against KH instability is more pronounced for smaller and less massive clouds. As in the static case more realistic cloud conditions allow heat conduction to transfer hot material onto the cloud's surface and to mix the accreted gas deeper into the cloud. ", "machine_text": " We present a detailed study of the evolution of interstellar clouds in a streaming hot plasma including heat conduction. Our aim is to investigate the effects of the heat flow on the density structure of the cloud and the subsequent effects on the evolution of the cloud. We solve the hydrodynamic equations for a cloud with a given density structure which is interacting with a streaming hot plasma. The streaming motion is described by a single-phase model with a temperature-dependent viscosity. Convection is included in the model in the form of a passive scalar field. The effect of the heat conduction is incorporated by solving the energy equation in a thermally homogeneous cloud. The evolution of the cloud is investigated for different initial conditions and parameter values. We show that the heat flow can have a significant effect on the cloud evolution. The most remarkable effects are the increase of the local cloud density and the development of density structures which are most likely to be observed inreality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measuring Electric Fields From Surface Contaminants with Neutral Atoms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2027, "human_text": "  In this paper we demonstrate a technique of utilizing magnetically trapped neutral Rb-87 atoms to measure the magnitude and direction of stray electric fields emanating from surface contaminants. We apply an alternating external electric field that adds to (or subtracts from) the stray field in such a way as to resonantly drive the trapped atoms into a mechanical dipole oscillation. The growth rate of the oscillation's amplitude provides information about the magnitude and sign of the stray field gradient. Using this measurement technique, we are able to reconstruct the vector electric field produced by surface contaminants. In addition, we can accurately measure the electric fields generated from adsorbed atoms purposely placed onto the surface and account for their systematic effects, which can plague a precision surface-force measurement. We show that baking the substrate can reduce the electric fields emanating from adsorbate, and that the mechanism for reduction is likely surface diffusion, not desorption. ", "machine_text": "  Measuring Electric Fields From Surface Contaminants with Neutral Atoms.  We present a new method to measure the electric field generated by surface contaminants. Our approach is based on the use of neutral atoms to probe the field. We show that a statistical ensemble of neutral atoms, if prepared in a state with a well-defined spatial distribution, can be used to map the field in the vicinity of a surface. The method does not require the atoms to be charged, ionized, or contacted by a conductive probe. It therefore bypasses the need to bring a charge carrier close to the surface, and can be used to measure electric fields in hostile environments and in situations where the field is strongly inhomogeneous. We demonstrate the method by measuring the field generated by a single contaminant on a semiconductor surface. Our current approach is limited by the need to infer the field from a statistical ensemble of atoms. We discuss how the method can be improved by preparing atoms in a particular quantum state, in which the field-induced orbital motion of an atom can be directly measured.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gas-grain chemistry in cold interstellar cloud cores with a microscopic\n  Monte Carlo approach to surface chemistry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2704, "human_text": "  AIM: We have recently developed a microscopic Monte Carlo approach to study surface chemistry on interstellar grains and the morphology of ice mantles. The method is designed to eliminate the problems inherent in the rate-equation formalism to surface chemistry. Here we report the first use of this method in a chemical model of cold interstellar cloud cores that includes both gas-phase and surface chemistry. The surface chemical network consists of a small number of diffusive reactions that can produce molecular oxygen, water, carbon dioxide, formaldehyde, methanol and assorted radicals. METHOD: The simulation is started by running a gas-phase model including accretion onto grains but no surface chemistry or evaporation. The starting surface consists of either flat or rough olivine. We introduce the surface chemistry of the three species H, O and CO in an iterative manner using our stochastic technique. Under the conditions of the simulation, only atomic hydrogen can evaporate to a significant extent. Although it has little effect on other gas-phase species, the evaporation of atomic hydrogen changes its gas-phase abundance, which in turn changes the flux of atomic hydrogen onto grains. The effect on the surface chemistry is treated until convergence occurs. We neglect all non-thermal desorptive processes. RESULTS: We determine the mantle abundances of assorted molecules as a function of time through 2x10^5 yr. Our method also allows determination of the abundance of each molecule in specific monolayers. The mantle results can be compared with observations of water, carbon dioxide, carbon monoxide, and methanol ices in the sources W33A and Elias 16. Other than a slight underproduction of mantle CO, our results are in very good agreement with observations. ", "machine_text": "  We present a microscopic Monte Carlo approach to surface chemistry suitable for application to cold interstellar cloud cores. The method is based on a random walk algorithm and accounts for both gas-grain and grain-grain chemistry. We consider a simplified chemical system consisting of only a few elements and focus on the competition between the various chemical processes as the most important quantity to describe. The model is compared to previous models based on a statistical equilibrium approach and the different methods are compared in a simplified one-dimensional scenario. We find that the relative importance of the different chemical processes is correctly reproduced by our microscopic approach, provided that the initial conditions are chosen such that a chemical equilibrium is indeed obtained. The main difference between the statistical and the microscopic approach is that the latter takes into account the actual reaction probabilities, whereas the former uses only equilibrium constants. The good agreement between theory and observation for the simple chemical system considered suggests that a microscopic approach is indeed appropriate to describe surface chemistry in cold cloud cores, provided that the chemistry is not too complex.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transition region features observed with Hinode/EIS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1856, "human_text": "  Two types of active region feature prominent at transition region temperatures are identified in Hinode/EIS data of AR 10938 taken on 2007 January 20. The footpoints of 1 MK TRACE loops are shown to emit strongly in emission lines formed at log T=5.4-5.8, allowing the temperature increase along the footpoints to be clearly seen. A density diagnostic of Mg VII yields the density in the footpoints, with one loop showing a decrease from 3x10^9 cm^-3 at the base to 1.5x10^9 cm^-3 at a projected height of 20 Mm. The second feature is a compact active region transition region brightening which is particularly intense in O V emission (log T=5.4) but also has a signature at temperatures up to log T=6.3. The Mg VII diagnostic gives a density of 4x10^10 cm^-3, and emission lines of Mg VI and Mg VII show line profiles broadened by 50 km/s and wings extending beyond 200 km/s. Continuum emission in the short wavelength band is also found to be enhanced, and is suggested to be free-bound emission from recombination onto He^+. ", "machine_text": "  The solar transition region is a crucial but relatively poorly understood region of the solar atmosphere, where the temperature increases rapidly from approximately 6000 K to 1 MK. The dynamics in this region is complex, due in part to the competing gravitational and magnetic forces. The large-scale magnetic field is generally frozen into the convection, but on a local scale the field can be highly dynamic, with regions of enhanced, decreasing, or even vanishing magnetic field strength. The region is also the site of many interesting small-scale phenomena, such as solar flares and nanoflares. The behavior of the transition region is key to understanding solar wind acceleration, as well as the formation of solar active regions. In order to better understand the solar transition region, we have used data from the Hinode spacecraft's EIS (EUV Imaging Spectrometer) instrument. We have analyzed the visible and ultraviolet data in combination with magnetic field data from the H\u03b1 telescope, in order to study the dynamic features in the transition region. In particular, we have looked at how the magnetic field is structured in this region, and how this field structure relates to the observed dynamic features. We have found a strong correlation between the dynamic features and the magnetic field strength. In particular, we find that the appearance of small-scale dynamic features is highly dependent on the local magnetic field strength. These results suggest that the magnetic field plays a key role in the dynamics of the transition region, and point to the importance of considering the small-scale features in future transition region studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing the Structure of Gamma-Ray Burst Jets with Steep Decay Phase of\n  their Early X-ray Afterglows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1055, "human_text": "  We show that the jet structure of gamma-ray bursts (GRBs) can be investigated with the tail emission of the prompt GRB. The tail emission which we consider is identified as a steep-decay component of the early X-ray afterglow observed by the X-ray Telescope onboard Swift. Using a Monte Carlo method, we derive, for the first time, the distribution of the decay index of the GRB tail emission for various jet models. The new definitions of the zero of time and the time interval of a fitting region are proposed. These definitions for fitting the light curve lead us an unique definition of the decay index, which is useful to investigate the structure of the GRB jet. We find that if the GRB jet has a core-envelope structure, the predicted distribution of the decay index of the tail has a wide scatter and has multiple peaks, which cannot be seen for the case of the uniform and the Gaussian jet. Therefore, the decay index distribution tells us the information on the jet structure. Especially, if we observe events whose decay index is less than about 2, both the uniform and the Gaussian jet models will be disfavored according to our simulation study. ", "machine_text": " We propose a method to constrain the structure of gamma-ray burst (GRB) jets by measuring the steepness of the decay phase of their early X-ray afterglows. We find that for decays with indices 1/2 \u2272 \u03b1 \u2272 4/3, a simple model in which the jet is treated as a viscous fluid in hydrodynamic equilibrium can quantitatively reproduce the data, provided that the burst energy is in the range $3\\times10^{36}-10^{37}$ erg and the inner structure of the jet is locally isothermal with a constant density \u03c1 \u223c 1.4  \ud83e\udca0 0.7  \ud83e\udca0 0.2  kg m\u22123. We conclude that a substantial part of the jet must be made up of an isothermal region with a constant density  \u223c 1.4  \ud83e\udca0 0.7  \ud83e\udca0 0.2  kg m\u22123, possibly a streamlined core with a very high ionization fraction. This interpretation is consistent with recent observations of high-ionization-fraction regions in some long-duration GRBs. For decays with \u03b1 \u2273 4/3, our model fails to reproduce the data, and we discuss several possible physical explanations for this. We also discuss the effect of an optional power law decay index n \u223c 1.3  \ud83e\udca0 1.4, which was reported in some recent observations, on our model. We show that this power law index can be accounted for if the density distribution has a double-power-law profile, with a power law index n \u223c 2.3  \ud83e\udca0 1.4 in the inner part of the isothermal region and a shallower index n \u223c 1.1  \ud83e\udca0 1.2 in the outer part.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Kirillov-Reshetikhin conjecture : the general case. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2838, "human_text": "  We prove the Kirillov-Reshetikhin (KR) conjecture in the general case : for all twisted quantum affine algebras we prove that the characters of KR modules solve the twisted Q-system and we get explicit formulas for the character of their tensor products (the untwisted simply-laced case was treated by Najakima, and the untwisted case by the author). The proof is uniform and provides several new developments for the representation theory of twisted quantum affine algebras, including twisted Frenkel-Reshetikhin q-characters (expected by Frenkel-Reshetikhin and Frenkel-Mukhin). We also prove the twisted T-system. As an application we get explicit formulas for the twisted q-characters of fundamental representations for all types, including the formulas for types D_4^{(3)}, E_6^{(2)} conjectured by Reshetikhin. We prove the formulas for KR modules in types A_n^{(2)} and D_4^{(3)} conjectured by Kuniba-Suzuki. Eventually our results imply the conjectural branching rules [HKOTT] to the quantum subalgebra of finite type. ", "machine_text": "  Kirillov-Reshetikhin conjecture : the general case The motivation for this work is the study of the properties of positive weighted Chow motives over local and global fields. In this paper, we present an approach to the Kirillov-Reshetikhin conjecture on positive motive classification in terms of deformations of algebraic varieties. We show that the Kirillov-Reshetikhin conjecture is a special case of a more general conjecture on the structure of positive motive deformations. We give a criterion for the consistency of this conjecture in the case of local fields.  Let $k$ be a local field. Let $M$ be a positive motive. We write $M$ uniquely as a finite conjunction of simple motives. Let $M_0$ be the smallest positive motive; that is, the intersection of all simple motives. We say that $M$ is a deformation of $M_0$ if there exists a $k$-linear homomorphism $\\varphi: M_0 \\to M$ such that the following properties hold.  (i) $\\varphi$ is an injective map on simple motives; (ii) $\\varphi$ induces an isomorphism on the quotient $M_0/M$; (iii) if $\\varphi(M_0) = M_0$, then $\\varphi$ is an isomorphism.  We show that the Kirillov-Reshetikhin conjecture is a special case of the following more general conjecture on positive motive deformations.  Let $M$ be a positive motive. We write $M$ uniquely as a finite conjunction of simple motives. Let $M_0$ be the smallest positive motive; that is, the intersection of all simple motives. We say that $M$ is a deformation of $M_0$ if there exists a linear homomorphism $\\varphi: M_0 \\to M$ such that the following properties hold.  (i) $\\varphi$ is an injective map on simple motives; (ii) $\\varphi$ induces an isomorphism on the quotient $M_0/M$; (iii) if $\\varphi(M_0) = M_0$, then $\\varphi$ is an isomorphism.  We give a criterion for the consistency of this conjecture in the case of local fields.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cut-off Covering Spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3822, "human_text": "  We introduce the $R$ cut-off covering spectrum and the cut-off covering spectrum of a complete length space or Riemannian manifold. The spectra measure the sizes of localized holes in the space and are defined using covering spaces called $\\delta$ covers and $R$ cut-off $\\delta$ covers. They are investigated using $\\delta$ homotopies which are homotopies via grids whose squares are mapped into balls of radius $\\delta$.   On locally compact spaces, we prove that these new spectra are subsets of the closure of the length spectrum. We prove the $R$ cut-off covering spectrum is almost continuous with respect to the pointed Gromov-Hausdorff convergence of spaces and that the cut-off covering spectrum is also relatively well behaved. This is not true of the covering spectrum defined in our earlier work which was shown to be well behaved on compact spaces. We close by analyzing these spectra on Riemannian manifolds with lower bounds on their sectional and Ricci curvature and their limit spaces. ", "machine_text": "  We show that a natural generalization of the covering spectrum of a finite dimensional vector space to the case of an infinite dimensional vector space can be obtained by using the cut-off functions. We give some applications to the theory of Banach algebras and to the theory of Fredholm operators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Distortion of Gravitational-Wave Packets Due to their Self-Gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1149, "human_text": "  When a source emits a gravity-wave (GW) pulse over a short period of time, the leading edge of the GW signal is redshifted more than the inner boundary of the pulse. The GW pulse is distorted by the gravitational effect of the self-energy residing in between these shells. We illustrate this distortion for GW pulses from the final plunge of black hole (BH) binaries, leading to the evolution of the GW profile as a function of the radial distance from the source. The distortion depends on the total GW energy released and the duration of the emission, scaled by the total binary mass, M. The effect should be relevant in finite box simulations where the waveforms are extracted within a radius of <~ 100M. For characteristic emission parameters at the final plunge between binary BHs of arbitrary spins, this effect could distort the simulated GW templates for LIGO and LISA by a fraction of 0.001. Accounting for the wave distortion would significantly decrease the waveform extraction errors in numerical simulations. ", "machine_text": "  Distortion of Gravitational-Wave Packets Due to their Self-Gravity  We consider the distortion of a weakly nonlinear Gravitational-Wave (GW) packet as it propagates in a spherically symmetric self-gravitating object. We show that this distortion is related to the kinematic properties of the packet and the spherically symmetric self-gravity solution. By performing a Taylor expansion of the self-gravity solution, we can express the distortion in terms of the packet's center-of-mass velocity and the first and second derivatives of the self-gravity solution with respect to the amplitude. We show that the contribution to the distortion from higher-order terms in this Taylor expansion can be bounded by a constant, which depends on the packet's kinematic properties. This bound is independent of the radius of the self-gravitating object. In particular, it does not tend to infinity as the radius tends to zero. This bound can be used to predict the distortion of a weakly nonlinear GW packet as it propagates in a spherically symmetric self-gravitating object, regardless of whether the solution is known analytically. We also investigate the effects of eccentricity and nonsphericity on the distortion of GW packets. In particular, we show that the distortion is sensitive to the instantaneous aspect ratio of a nonspherical self-gravitating object, but it is not sensitive to the mean aspect ratio. We also show that the distortion due to the self-gravity of a spherically symmetric object is always less than the distortion due to the self-gravity of a nonspherical object with the same volume.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Extended Comment on \"One-Range Addition Theorems for Coulomb Interaction\n  Potential and Its Derivatives\" by I. I. Guseinov (Chem. Phys. Vol. 309\n  (2005), pp. 209 - 213). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1088, "human_text": "  Addition theorems are principal tools that express a function $f (\\bm{r} \\pm \\bm{r}')$ in terms of products of other functions that only depend on either $\\bm{r}$ or $\\bm{r}'$. The best known example of such an addition theorem is the Laplace expansion of the Coulomb potential which possesses a characteristic two-range form. Guseinov [Chem. Phys. {\\bf 309}, 209 - 213 (2005)] derived one-range addition theorems for the Coulomb potential via the limit $\\beta \\to 0$ in previously derived one-range addition theorems for the Yukawa potential $\\exp \\bigl(-\\beta | \\bm{r}-\\bm{r}'| \\bigr) /| \\bm{r}-\\bm{r}'|$. At first sight, this looks like a remarkable achievement, but from a mathematical point of view, Guseinov's work is at best questionable and in some cases fundamentally flawed. One-range addition theorems are expansions in terms of functions that are complete and orthonormal in a given Hilbert space, but Guseinov replaced the complete and orthonormal functions by nonorthogonal Slater-type functions and rearranged the resulting expansions. This is a dangerous operation whose validity must be checked. It is shown that the one-center limit $\\bm{r}' = \\bm{0}$ of Guseinov's rearranged Yukawa addition theorems as well as of several other addition theorems does not exist. Moreover, the Coulomb potential does not belong to any of the Hilbert spaces implicitly used by Guseinov. Accordingly, one-range addition theorems for the Coulomb potential diverge in the mean. Instead, these one-range addition theorems have to interpreted as expansions of generalized functions in the sense of Schwartz that converge weakly in suitable functionals. ", "machine_text": "  We comment on the paper by Guseinov on the evaluation of the derivative of the non-relativistic interaction energy with the Coulomb interaction potential. The error in the proof of Theorem 1 is analyzed. A general formula for the derivative of the interaction energy is obtained. An estimate of the numerical value of the derivative of the interaction energy is obtained in terms of the Riemann zeta function. The explicit form of the derivative of the interaction energy is obtained in the case of the center of mass frame and the inertial frame. An application of the obtained results to the problem of minimizing the interaction energy between two particles is proposed. The formula for the derivative of the interaction energy between two particles, obtained in this work, has a simple geometric interpretation. The work done by one of the particles in the process of moving from the initial position to the final position can be represented in the interaction potential energy surface as a sum of two components: the work done by the external force and the work done by the interaction potential. An analytical formula for the work done by the interaction potential is obtained.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral method for matching exterior and interior elliptic problems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0643, "human_text": "  A spectral method is described for solving coupled elliptic problems on an interior and an exterior domain. The method is formulated and tested on the two-dimensional interior Poisson and exterior Laplace problems, whose solutions and their normal derivatives are required to be continuous across the interface. A complete basis of homogeneous solutions for the interior and exterior regions, corresponding to all possible Dirichlet boundary values at the interface, are calculated in a preprocessing step. This basis is used to construct the influence matrix which serves to transform the coupled boundary conditions into conditions on the interior problem. Chebyshev approximations are used to represent both the interior solutions and the boundary values. A standard Chebyshev spectral method is used to calculate the interior solutions. The exterior harmonic solutions are calculated as the convolution of the free-space Green's function with a surface density; this surface density is itself the solution to an integral equation which has an analytic solution when the boundary values are given as a Chebyshev expansion. Properties of Chebyshev approximations insure that the basis of exterior harmonic functions represents the external near-boundary solutions uniformly. The method is tested by calculating the electrostatic potential resulting from charge distributions in a rectangle. The resulting influence matrix is well-conditioned and solutions converge exponentially as the resolution is increased. The generalization of this approach to three-dimensional problems is discussed, in particular the magnetohydrodynamic equations in a finite cylindrical domain surrounded by a vacuum. ", "machine_text": "  Spectral method for matching exterior and interior elliptic problems  We consider the problem of matching two elliptic PDEs, one with boundary conditions on the exterior of a bounded domain and the other with boundary conditions on the interior of the same domain. The motivation for this work is to develop a general method for matching two-dimensional (2D) exterior problems and two-dimensional interior problems. We propose a general and systematic spectral method for the problem and show that it is applicable to a wide class of exterior and interior elliptic problems.  The method consists of two steps. In the first step, we solve the Dirichlet problem for the elliptic PDE on the exterior of the domain with the help of a spectral technique, and in the second step, we solve the elliptic PDE on the interior of the domain with the help of the solution of the Dirichlet problem and the boundary conditions on the interior of the domain.  We show that the proposed method is applicable to a wide class of exterior and interior elliptic problems. We consider both 2D and 3D problems and obtain the optimal error estimate of the method in the energy norm. We also discuss the application of the method to the solution of various practical problems in different fields, such as mechanics, mathematics, and engineering.  In this article, we present the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research in a formal academic and scientific writing voice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transient behavior of surface plasmon polaritons scattered at a\n  subwavelength groove. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0703, "human_text": "  We present a numerical study and analytical model of the optical near-field diffracted in the vicinity of subwavelength grooves milled in silver surfaces. The Green's tensor approach permits computation of the phase and amplitude dependence of the diffracted wave as a function of the groove geometry. It is shown that the field diffracted along the interface by the groove is equivalent to replacing the groove by an oscillating dipolar line source. An analytic expression is derived from the Green's function formalism, that reproduces well the asymptotic surface plasmon polariton (SPP) wave as well as the transient surface wave in the near-zone close to the groove. The agreement between this model and the full simulation is very good, showing that the transient \"near-zone\" regime does not depend on the precise shape of the groove. Finally, it is shown that a composite diffractive evanescent wave model that includes the asymptotic SPP can describe the wavelength evolution in this transient near-zone. Such a semi-analytical model may be useful for the design and optimization of more elaborate photonic circuits whose behavior in large part will be controlled by surface waves. ", "machine_text": "  We study the transient behavior of surface plasmon polaritons scattered at a subwavelength groove. We show that the transmission coefficient of a surface plasmon wave scattered at a groove depends on the excitation frequency, the groove width, and the angle of incidence, and it exhibits several interesting features such as a peak or a dip at the resonance frequency. We explain these phenomena by analytically solving the scattering problem for a groove with a rectangular cross-section. Our analytical results are in good agreement with the numerical results obtained by solving the three-dimensional Maxwell equations. We also numerically investigate the scattering from a V-shaped groove, which can be realized by etching a shallow V-shaped trench in a thin gold film. Our results show that the transient behavior of surface plasmon polaritons scattered at a V-shaped groove is very different from that scattered at a groove with a rectangular cross-section, which may be useful for realizing optical switches and modulators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radio Astrometric Detection and Characterization of Extra-Solar Planets:\n  A White Paper Submitted to the NSF ExoPlanet Task Force. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0238, "human_text": "  The extraordinary astrometric accuracy of radio interferometry creates an important and unique opportunity for the discovery and characterization of exo-planets. Currently, the Very Long Baseline Array can routinely achieve better than 100 microarcsecond accuracy, and can approach 10 microarcsecond with careful calibration. We describe here RIPL, the Radio Interferometric PLanet search, a new program with the VLBA and the Green Bank 100 m telescope that will survey 29 low-mass, active stars over 3 years with sub-Jovian planet mass sensitivity at 1 AU. An upgrade of the VLBA bandwidth will increase astrometric accuracy by an order of magnitude. Ultimately, the colossal collecting area of the Square Kilometer Array could push astrometric accuracy to 1 microarcsecond, making detection and characterizaiton of Earth mass planets possible.   RIPL and other future radio astrometric planet searches occupy a unique volume in planet discovery and characterization parameter space. The parameter space of astrometric searches gives greater sensitivity to planets at large radii than radial velocity searches. For the VLBA and the expanded VLBA, the targets of radio astrometric surveys are by necessity nearby, low-mass, active stars, which cannot be studied efficiently through the radial velocity method, coronagraphy, or optical interferometry. For the SKA, detection sensitivity will extend to solar-type stars. Planets discovered through radio astrometric methods will be suitable for characterization through extreme adaptive optics.   The complementarity of radio astrometric techniques with other methods demonstrates that radio astrometry can play an important role in the roadmap for exoplanet discovery and characterization. ", "machine_text": " We propose a new method of detecting extra-solar planets using radio astrometry. Our method combines data from existing and future radio telescopes to achieve a level of sensitivity unprecedented in extra-solar planet detection. The key idea is to use an existing high-resolution radio telescope to measure the position of a radio source relative to a reference point in the sky, and use this measurement to detect the motion of an exoplanet as it orbits its host star. The measurement is done by observing the source for several years, during which the exoplanet will move a small amount relative to the host star. We show that this method can detect an exoplanet with a mass as small as a few times the mass of the Earth, at a distance of up to several thousand light-years. We also show that the method can be used to characterize the exoplanet, by measuring its mass, radius, and orbital parameters. The main challenges for the method are: (1) detecting the very small motion of the exoplanet, (2) achieving the high angular resolution required to resolve the motion of the exoplanet, and (3) avoiding the contamination of the exoplanet signal by stellar Proper Motion. We discuss the method in detail, and evaluate the required resources. We find that the method can be implemented with existing telescopes, with a dedication of a few percent of their observing time, and without any significant modification to their hardware or software. We also find that the method will have a very high yield, since it will detect a large fraction of the exoplanets that are expected to exist in our Galaxy. We expect that this method will play a major role in the detection and characterization of extra-solar planets in the coming decades.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structures in the Universe and Origin of Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1448, "human_text": "  The analysis of images (of obtained in various ranges of the lengths of waves) of luminous objects in the Universe by means of a method of multilevel dynamic contrasting led author to the conclusions: a) the structures of all observable galaxies represents a complicated constructions which have the tendency to self-similarity and made of separate (basic) blocks, which are a coaxially tubular structures and a cartwheel-like structures; b) the majority of observable objects in the Universe are luminous butt-ends of almost invisible (of almost completely transparent) of filamentary formations which structures are seen only near to their luminous butt-ends; c) the result of analysis of images of cosmic objects show the structure of many pairs of cooperating galaxies point to opportunity of their formation at butt-ends generated in a place of break of the similar filament; d) the interacting galaxies (M 81 and M 82) show they are butt-ends of sawed off of two branches of a treelike filament and their interaction is coming out through this filament; e) as our Universe is in dynamics the processes of formation of stars, galaxies and their congestions can go presently by means of a fracturing of filaments with a corresponding diameters and of the time for their such formation is necessary much less, than along existing standard model. ", "machine_text": "  We have developed a model of the evolution of the Universe and the origin of galaxies. Our model is based on the idea that the evolution of the Universe is a process of successive generations of structures, in each of which the structures of the previous generation are shattered and the pieces are reassembled into more complex structures. The first generation of structures consists of small fluctuations in the density of the Universe that grow in size and become the seeds for the formation of galaxies. The second generation of structures are the galaxies that form from the seeds, and the third generation are the clusters of galaxies that form from the galaxies. We have shown that the evolution of the Universe is a process of exponential growth, and that the growth rate is related to the average density of the Universe. We have also shown that the structure of the Universe is self-organized, and that the process of evolution is driven by the energy released by the formation of structures. We have estimated the growth rate of the Universe and the average density of the Universe, and we have shown that they are consistent with the observed evolution of the Universe. We have also shown that the growth rate of the Universe is related to the average density of the Universe, and that the growth rate is higher when the average density is higher. We have shown that the evolution of the Universe is a process of successive generations of structures, and that the structures of each generation are more complex than the structures of the previous generation. We have also shown that the process of evolution is driven by the energy released by the formation of structures, and that the energy is used to form the next generation of structures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Families of holomorphic bundles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2629, "human_text": "  The first goal of the article is to solve several fundamental problems in the theory of holomorphic bundles over non-algebraic manifolds: For instance we prove that stability and semi-stability are Zariski open properties in families when the Gauduchon degree map is a topological invariant, or when the parameter manifold is compact. Second we show that, for a generically stable family of bundles over a K\\\"ahler manifold, the Petersson-Weil form extends as a closed positive current on the whole parameter space of the family. This extension theorem uses classical tools from Yang-Mills theory developed by Donaldson (e.g. the Donaldson functional and the heat equation for Hermitian metrics on a holomorphic bundle). We apply these results to study families of bundles over a K\\\"ahlerian manifold $Y$ parameterized by a non-K\\\"ahlerian surface $X$, proving that such families must satisfy very restrictive conditions. These results play an important role in our program to prove existence of curves on class VII surfaces. ", "machine_text": "  We establish a one-to-one correspondence between families of holomorphic vector bundles on a given complex projective space and families of linear subspace arrangements in the associated real vector space. As an application, we give a description of semisimple families of holomorphic vector bundles in terms of a minimal model program. We show that the real vector space associated to a semisimple family of holomorphic vector bundles is isomorphic to the real vector space associated to a family of linear subspace arrangements, and that the isomorphism classes of holomorphic vector bundles on a complex projective space is in one-to-one correspondence with the isomorphism classes of linear subspace arrangements in the associated real vector space. As another application, we give a description of families of holomorphic vector bundles on a given complex projective space in terms of a model program which involves the minimal model of a real vector space arrangement and the annihilator of a certain subspace.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relation between exchange-only optimized potential and Kohn-Sham methods\n  with finite basis sets; solution of a paradox. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1717, "human_text": "  Arguments showing that exchange-only optimized effective potential (xOEP) methods, with finite basis sets, cannot in general yield the Hartree-Fock (HF) ground state energy, but a higher one, are given. While the orbital products of a complete basis are linearly dependent, the HF ground state energy can only be obtained via a basis set xOEP scheme in the special case that all products of occupied and unoccupied orbitals emerging from the employed orbital basis set are linearly independent from each other. In this case, however, exchange potentials leading to the HF ground state energy exhibit unphysical oscillations and do not represent a Kohn-Sham (KS) exchange potential. These findings solve the seemingly paradoxical results of Staroverov, Scuseria and Davidson that certain finite basis set xOEP calculations lead to the HF ground state energy despite the fact that within a real space (or complete basis) representation the xOEP ground state energy is always higher than the HF energy. Moreover, whether or not the occupied and unoccupied orbital products are linearly independent, it is shown that basis set xOEP methods only represent exact exchange-only (EXX) KS methods, i.e., proper density-functional methods, if the orbital basis set and the auxiliary basis set representing the exchange potential are balanced to each other, i.e., if the orbital basis is comprehensive enough for a given auxiliary basis. Otherwise xOEP methods do not represent EXX KS methods and yield unphysical exchange potentials. ", "machine_text": " We study the relation between exact (or \"exchange-only optimized\") potential methods, which are exact in the sense that they use only the exact, optimized potential between any two basis functions, and more standard Kohn-Sham (KS) methods, which are exact in the sense that they use the optimized (but potentially inexact) potential between any two basis functions. This relation has been largely ignored in the literature, despite the fact that many exact potential methods have been developed over the years, including the exact covalent potential, the Coulomb potential, the Restricted Active Space (RAS) potential, the Emax potential, the Active Space Augmentation (ASA) potential, the Quickovec potential, and various \"iotk\" potentials. We find that many of the exact potential methods can be obtained as an approximation to the more standard KS methods by making a few relatively simple changes, and that the accuracy of these approximate methods can be improved by making relatively minor modifications to the basis sets. However, we also find that the performance of these methods depends on the choice of an appropriate reference state, and in particular that there is a \"paradox\" that the best results are generally obtained by using a reference state that has a relatively high total energy. We discuss the various exact potential methods in detail, and develop an approximation procedure that can be used to obtain an approximate basis set for the KS methods that gives relatively good results for a large number of important applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Beryllium in Ultra-Lithium-Deficient Halo Stars - The Blue Straggler\n  Connection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1551, "human_text": "  There are nine metal-deficient stars that have Li abundances well below the Li plateau that is defined by over 100 unevolved stars with temperatures above 5800 K and values of [Fe/H] $<$ $-$1.0. Abundances of Be have been determined for most of these ultra-Li-deficient stars in order to investigate the cause of the Li deficiencies. High-resolution and high signal-to-noise spectra have been obtained in the Be II spectral region near 3130 \\AA for six ultra-Li-deficient stars with the Keck I telescope and its new uv-sensitive CCD on the upgraded HIRES. The spectrum synthesis technique has been used to determine Be abundances. All six stars are found to have Be deficiencies also. Two have measurable - but reduced - Be and four have only upper limits on Be. These results are consistent with the idea that these Li- and Be-deficient stars are analogous to blue stragglers. The stars have undergone mass transfer events (or mergers) which destroy or dilute both Li and Be. The findings cannot be matched by the models that predict that the deficiencies are due to extra-mixing in a subset of halo stars that were initially rapid rotators, with the possible exception of one star, G 139-8. Because the ultra-Li-deficient stars are also Be-deficient, they appear to be genuine outliers in population of halo stars used to determine the value of primordial Li; they no longer have the Li in their atmospheres that was produced in the Big Bang. ", "machine_text": " We present photometry and spectroscopy of three ultra-lithium-deficient (ULD) halo stars in the solar neighbourhood, two of which are blue stragglers (BSs). The properties of these stars are consistent with the general picture of the evolution of massive Bs in globular clusters, but they also reveal some distinctive features. In particular, the inner-shell hydrogen-deficient and carbon-rich nature of these stars is consistent with a scenario in which a non-convective core helium-burning phase occurs in an advanced stage of stellar evolution. We also discuss the nature of the lithium deficiency in these stars. Although a large fraction of the gas in the outer convective envelope has been lost, a significant amount of mixing and enrichment with hydrogen and helium from the core must have occurred to produce the observed lithium abundances. We propose that this mixing is related to the core helium-burning phase and is due to violent convection events associated with the onset of core helium burning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A p-adic quasi-quadratic point counting algorithm. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0234, "human_text": "  In this article we give an algorithm for the computation of the number of rational points on the Jacobian variety of a generic ordinary hyperelliptic curve defined over a finite field of cardinality $q$ with time complexity $O(n^{2+o(1)})$ and space complexity $O(n^2)$, where $n=\\log(q)$. In the latter complexity estimate the genus and the characteristic are assumed as fixed. Our algorithm forms a generalization of both, the AGM algorithm of J.-F. Mestre and the canonical lifting method of T. Satoh. We canonically lift a certain arithmetic invariant of the Jacobian of the hyperelliptic curve in terms of theta constants. The theta null values are computed with respect to a semi-canonical theta structure of level $2^\\nu p$ where $\\nu >0$ is an integer and $p=\\mathrm{char}(\\F_q)>2$. The results of this paper suggest a global positive answer to the question whether there exists a quasi-quadratic time algorithm for the computation of the number of rational points on a generic ordinary abelian variety defined over a finite field. ", "machine_text": " We present a p-adic quasi-quadratic point counting algorithm for an elliptic curve over a function field of a proper scheme. Our method is based on the idea of representing the point counting function as a p-adic exponential, and using the structure of the p-adic exponential to derive an efficient algorithm. The main ingredient is a careful analysis of the relation between the exponential and the associated pushing-down argument. We deduce that, if the exponential is represented by a series of poorest terms, the number of terms needed is bounded from above by the number of distinct points on the curve. This bound is tight for the case of elliptic curves over cyclotomic fields, and we deduce that the number of terms is equal to the number of torsion points on the elliptic curve. We present an algorithm for computing this number. As an application, we show that our algorithm is able to count the torsion points of an elliptic curve over a number field in a number of steps that is independent of the conductor of the field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Global Approach to the Theory of Special Finsler Manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0053, "human_text": "  The aim of the present paper is to provide a global presentation of the theory of special Finsler manifolds. We introduce and investigate globally (or intrinsically, free from local coordinates) many of the most important and most commonly used special Finsler manifolds: locally Minkowskian, Berwald, Landesberg, general Landesberg, $P$-reducible, $C$-reducible, semi-$C$-reducible, quasi-$C$-reducible, $P^{*}$-Finsler, $C^{h}$-recurrent, $C^{v}$-recurrent, $C^{0}$-recurrent, $S^{v}$-recurrent, $S^{v}$-recurrent of the second order, $C_{2}$-like, $S_{3}$-like, $S_{4}$-like, $P_{2}$-like, $R_{3}$-like, $P$-symmetric, $h$-isotropic, of scalar curvature, of constant curvature, of $p$-scalar curvature, of $s$-$ps$-curvature. The global definitions of these special Finsler manifolds are introduced. Various relationships between the different types of the considered special Finsler manifolds are found. Many local results, known in the literature, are proved globally and several new results are obtained. As a by-product, interesting identities and properties concerning the torsion tensor fields and the curvature tensor fields are deduced. Although our investigation is entirely global, we provide; for comparison reasons, an appendix presenting a local counterpart of our global approach and the local definitions of the special Finsler spaces considered. ", "machine_text": "  We propose and investigate a new class of special Finsler manifolds which we call Relative Finsler manifolds. These are Finsler manifolds with a linear connection, that is, a connection such that the metric and its dual metric are related by a metric tensor of the second order. We show that such manifolds have a special class of curves, called relative geodesics, that generalize the notion of geodesics in a Finsler manifold and provide a geometrically meaningful notion of parallel transport on such manifolds. We further study the properties of the corresponding adjoint metric and show that it satisfies the Bonnet-Myers-Steele equations. As an application we show that every relative Finsler manifold is an immerseion of a ( Relative ) Riemannian manifold. We also show that a Finsler manifold with a linear connection is a relative Finsler manifold if and only if it admits a metric of the second order. As another application we show that every Finsler manifold with a constant curvature is a relative Finsler manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High Resolution X-Ray Imaging of the Center of IC342. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.077, "human_text": "  We presented the result of a high resolution (FWHM~0.5'') 12 ks Chandra HRC-I observation of the starburst galaxy IC342 taken on 2 April 2006. We identified 23 X-ray sources within the central 30' x 30' region of IC342. Our HRC-I observation resolved the historical Ultraluminous X-ray sources (ULX), X3, near the nucleus into 2 sources, namely C12 and C13, for the first time. The brighter source C12, with L(0.08-10keV)=(6.66\\pm0.45)\\times10^{38}ergs^-1, was spatially extended (~82 pc x 127 pc). From the astrometric registration of the X-ray image, C12 was at R.A.=03h:46m:48.43s, decl.=+68d05m47.45s, and was closer to the nucleus than C13. Thus we concluded that source was not an ULX and must instead be associated with the nucleus. The fainter source C13, with L(0.08-10keV)=(5.1\\pm1.4) x 10^{37}ergs^-1 was consistent with a point source and located $6.51'' at P.A. 240 degree of C12.   We also analyzed astrometrically corrected optical Hubble Space Telescope and radio Very Large Array images, a comparison with the X-ray image showed similarities in their morphologies. Regions of star formation within the central region of IC342 were clearly visible in HST H alpha image and this was the region where 3 optical star clusters and correspondingly our detected X-ray source C12 were observed. We found that a predicted X-ray emission from starburst was very close to the observed X-ray luminosity of C12, suggesting that nuclear X-ray emission in IC342 was dominated by starburst. Furthermore, we discussed the possibility of AGN in the nucleus of IC342. Although our data was not enough to give a firm existence of an AGN, it could not be discarded. ", "machine_text": "  IC 342 is a young, high-mass star-forming region in the constellation of Camelopardalis. The ionized gas in the center of this molecular cloud is energized by a recently-formed, massive star, designated as 3.4 million solar masses by Appenzeller et al. (1997). We present here high-resolution X-ray images of the central region, obtained with the Chandra Observatory. These data reveal the presence of a bright X-ray source at the center of IC 342, which we attribute to the presence of a collimated outflow from the high-mass star. We find that the observed X-ray surface brightness is consistent with a single, power law distribution with a slope of -1.4 \u00b1 0.1. The half-light radius is estimated to be  \u223c 1.3 kpc, and the X-ray surface brightness is  \u223c 2.5 kpc2. We find that the X-ray emission is most likely due to a combination of a shocked wind from the high-mass star and material evaporated from the molecular cloud. We show that a simple formulation of the ionization-hydrogen-streaming-Expansion (IHSX) model is consistent with the observed X-ray surface brightness distribution. Alternatively, the X-ray emission may be due to a combination of a shocked wind from the high-mass star and material evaporated from the molecular cloud. We discuss the properties of the high-mass star and the evolution of the X-ray emitting region.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Landau (\\Gamma,\\chi)-automorphic functions on \\mathbb{C}^n of magnitude\n  \\nu. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1763, "human_text": "  We investigate the spectral theory of the invariant Landau Hamiltonian $\\La^\\nu$ acting on the space ${\\mathcal{F}}^\\nu_{\\Gamma,\\chi}$ of $(\\Gamma,\\chi)$-automotphic functions on $\\C^n$, for given real number $\\nu>0$, lattice $\\Gamma$ of $\\C^n$ and a map $\\chi:\\Gamma\\to U(1)$ such that the triplet $(\\nu,\\Gamma,\\chi)$ satisfies a Riemann-Dirac quantization type condition. More precisely, we show that the eigenspace $ {\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(\\lambda)=\\set{f\\in {\\mathcal{F}}^\\nu_{\\Gamma,\\chi}; \\La^\\nu f = \\nu(2\\lambda+n) f}$; $\\lambda\\in\\C,$ is non trivial if and only if $\\lambda=l=0,1,2, ...$. In such case, ${\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(l)$ is a finite dimensional vector space whose the dimension is given explicitly. We show also that the eigenspace ${\\mathcal{E}}^\\nu_{\\Gamma,\\chi}(0)$ associated to the lowest Landau level of $\\La^\\nu$ is isomorphic to the space, ${\\mathcal{O}}^\\nu_{\\Gamma,\\chi}(\\C^n)$, of holomorphic functions on $\\C^n$ satisfying $$ g(z+\\gamma) = \\chi(\\gamma) e^{\\frac \\nu 2 |\\gamma|^2+\\nu\\scal{z,\\gamma}}g(z), \\eqno{(*)} $$ that we can realize also as the null space of the differential operator $\\sum\\limits_{j=1}\\limits^n(\\frac{-\\partial^2}{\\partial z_j\\partial \\bar z_j} + \\nu \\bar z_j \\frac{\\partial}{\\partial \\bar z_j})$ acting on $\\mathcal C^\\infty$ functions on $\\C^n$ satisfying $(*)$. ", "machine_text": " We introduce the concept of Landau (\\Gamma,\\chi)-automorphic functions on \\mathbb{C}^n of magnitude \\nu, associated to an n-dimensional Landau lattice and an endomorphism of the symmetric group. We show that any such function can be uniquely represented as a polynomial of two variables of the type \\phi(\\Gamma,\\chi) = (1-\\zeta\\Gamma)\\over\\zeta + \\eta\\chi + \\gamma, where the three parameters \\zeta, \\eta, and \\gamma can be taken in a special range of values. We find an asymptotic formula for the number of such functions as the dimension increases, as well as an asymptotic formula for the number of special functions of the type (\\Gamma,\\chi) \\in \\mathfrak{g}^* (the adjoint group of the Lie algebra \\mathfrak{g} of the symmetric group). As an application, we show that the asymmetric Lie algebra \\mathfrak{g}_\\infty of the symmetric group has the structure of a limit of symmetric Lie algebras, each of which is isomorphic to \\mathfrak{g}^* / \\mathfrak{g} (the quotient group), with the isomorphism given by the action of the group of Landau (\\Gamma,\\chi)-automorphic functions on \\mathfrak{g}^* .", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay Constraints. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3878, "human_text": "  A game-theoretic framework is used to study the effect of constellation size on the energy efficiency of wireless networks for M-QAM modulation. A non-cooperative game is proposed in which each user seeks to choose its transmit power (and possibly transmit symbol rate) as well as the constellation size in order to maximize its own utility while satisfying its delay quality-of-service (QoS) constraint. The utility function used here measures the number of reliable bits transmitted per joule of energy consumed, and is particularly suitable for energy-constrained networks. The best-response strategies and Nash equilibrium solution for the proposed game are derived. It is shown that in order to maximize its utility (in bits per joule), a user must choose the lowest constellation size that can accommodate the user's delay constraint. Using this framework, the tradeoffs among energy efficiency, delay, throughput and constellation size are also studied and quantified. The effect of trellis-coded modulation on energy efficiency is also discussed. ", "machine_text": " We propose and analyze a game-theoretic approach to energy-efficient modulation in CDMA networks with delay constraints. We consider a setting where the base stations of a CDMA network are subject to power constraints, while the mobile terminals are subject to delay constraints. The base stations and the mobile terminals can choose from a finite set of modulation and coding schemes, with the goal of maximizing the network throughput while minimizing the energy consumption and the delay. We model the problem as a non-cooperative game, where the base stations and the mobile terminals are players who compete for the network resources. The game is played in rounds, where each round corresponds to a frame of the CDMA network. We define a utility function that captures the trade-off between the energy consumption, the delay, and the throughput, and use this utility function to model the behavior of the players. We analyze the game-theoretic approach using a simulation-based method, and show that the proposed approach achieves a near-optimal performance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Variation of fundamental constants: theory and observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3704, "human_text": "  Review of recent works devoted to the variation of the fundamental constants is presented including atomic clocks, quasar absorption spectra, and Oklo natural nuclear reactor data. Assuming linear variation with time we can compare different results. From the quasar absorption spectra:   $\\dot{\\mu}/\\mu=(1 \\pm 3) \\times 10^{-16}$ yr$^{-1}$. A combination of this result and the atomic clock results gives the best limt on variation of $\\alpha$: $\\dot{\\alpha}/\\alpha=(-0.8 \\pm 0.8) \\times 10^{-16}$ yr$^{-1}$. The Oklo natural reactor gives the best limit on the variation of $m_s/\\Lambda_{QCD}$ where $m_s$ is the strange quark mass.   Huge enhancement of the relative variation effects happens in transitions between close atomic, molecular and nuclear energy levels. We suggest several new cases where the levels are very narrow. Large enhancement of the variation effects is also possible in cold atomic and molecular collisions near Feshbach resonance. Massive bodies (stars or galaxies) can also affect physical constants. They have large scalar charge $S$ proportional to number of particles which produces a Coulomb-like scalar field $U=S/r$. This leads to a variation of the fundamental constants proportional to the gravitational potential, e.g. $\\delta \\alpha/ \\alpha = k_\\alpha \\delta (GM/ r c^2)$. We compare different manifestations of this effect.The strongest limit   $k_\\alpha +0.17 k_e= (-3.5\\pm 6) \\times 10^{-7}$. ", "machine_text": " We propose a new method for the experimental estimation of the fine-structure constant (\u03b1) and the proton-to-electron mass ratio (\u03b1e) that does not require knowledge of either the electron mass (m_(e)) or the proton mass (m_(p)). Our method is based on measuring the energy levels of the hydrogen atom, the so-called hydrogenic levels. We show that if the energy of the first hydrogenic level is measured with a high enough accuracy, \u03b1 and \u03b1e can be extracted from this measurement without knowledge of m_(e) and m_(p). We evaluate the accuracy with which \u03b1 and \u03b1e can be determined from a measurement of the first hydrogenic level, and we propose a method to measure this level with the required accuracy. Our proposed method requires a precise determination of the inverse square of the fine-structure constant, which can be obtained by measuring the molecular spectrum of hydrogen chloride (HCl). We show that a measurement of the HCl spectrum with an accuracy of $\\sim 1\\%$ can be used to determine \u03b1 and \u03b1e with an accuracy of $\\sim 1\\%$. We present an analysis of the experimental conditions that must be satisfied to measure the hydrogenic levels with the required accuracy, and we propose a method to measure these levels using a microwave cavity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Entangling Independent Photons by Time Measurement. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0758, "human_text": "  A quantum system composed of two or more subsystems can be in an entangled state, i.e. a state in which the properties of the global system are well defined but the properties of each subsystem are not. Entanglement is at the heart of quantum physics, both for its conceptual foundations and for applications in information processing and quantum communication. Remarkably, entanglement can be \"swapped\": if one prepares two independent entangled pairs A1-A2 and B1-B2, a joint measurement on A1 and B1 (called a \"Bell-State Measurement\", BSM) has the effect of projecting A2 and B2 onto an entangled state, although these two particles have never interacted or shared any common past[1,2]. Experiments using twin photons produced by spontaneous parametric down-conversion (SPDC) have already demonstrated entanglement swapping[3-6], but here we present its first realization using continuous wave (CW) sources, as originally proposed[2]. The challenge was to achieve sufficiently sharp synchronization of the photons in the BSM. Using narrow-band filters, the coherence time of the photons that undergo the BSM is significantly increased, exceeding the temporal resolution of the detectors. Hence pulsed sources can be replaced by CW sources, which do not require any synchronization[6,7], allowing for the first time the use of completely autonomous sources. Our experiment exploits recent progress in the time precision of photon detectors, in the efficiency of photon pair production by SPDC with waveguides in nonlinear crystals[8], and in the stability of narrow-band filters. This approach is independent of the form of entanglement; we employed time-bin entangled photons[9] at telecom wavelengths. Our setup is robust against thermal or mechanical fluctuations in optical fibres thanks to cm-long coherence lengths. ", "machine_text": "  We propose and analyze a scheme to entangle independent photons which does not require light to propagate between the entangled photons. This is in contrast to previous entanglement generation schemes which require some form of light propagation (including nonlinear interactions, emission from a spontaneous parametric down-convention, or transmission through a diffuser or similar scramble element). Our scheme relies on a precise time measurement of the arrival of the photons at a detector. We show that this can be achieved by a combination of a narrow-band filter and a picosecond voltage pulse applied to a fast photodiode. In order to entangle two photons which are not in causal contact, we propose to use two different narrow-band filters with slightly overlapping spectra. The time windows of the two detectors are then synchronized by a control signal, which also serves to trigger the emission of the photons. We analyze the scheme and particularize it to various experimental realizations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Red Sequence Cluster Finding in the Millennium Simulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0211, "human_text": "  We investigate halo mass selection properties of red-sequence cluster finders using galaxy populations of the Millennium Simulation (MS). A clear red sequence exists for MS galaxies in massive halos at redshifts z < 1, and we use this knowledge to inform a cluster-finding algorithm applied to 500 Mpc/h projections of the simulated volume. At low redshift (z=0.4), we find that 90% of the clusters found have galaxy membership dominated by a single, real-space halo, and that 10% are blended systems for which no single halo contributes a majority of a cluster's membership. At z=1, the fraction of blends increases to 22%, as weaker redshift evolution in observed color extends the comoving length probed by a fixed range of color. Other factors contributing to the increased blending at high-z include broadening of the red sequence and confusion from a larger number of intermediate mass halos hosting bright red galaxies of magnitude similar to those in higher mass halos. Our method produces catalogs of cluster candidates whose halo mass selection function, p(M|\\Ngal,z), is characterized by a bimodal log-normal model with a dominant component that reproduces well the real-space distribution, and a redshift-dependent tail that is broader and displaced by a factor ~2 lower in mass. We discuss implications for X-ray properties of optically selected clusters and offer ideas for improving both mock catalogs and cluster-finding in future surveys. ", "machine_text": "  Red Sequence Cluster Finding in the Millennium Simulation  We present a new algorithm to find red sequence clusters in the Millennium Simulation. The motivation for this work is to provide an efficient algorithm to find the large scale structure of the Millennium Simulation. The Millennium Simulation is a large scale numerical simulation of the evolution of the universe. It has been run with different physical parameters, and the results are available as a database. The aim of this work is to investigate the large scale structure of the Millennium Simulation, and to compare the results with the observations of the large scale structure in the universe. The key idea is to use the random forest algorithm to find the red sequence clusters in the Millennium Simulation. The random forest algorithm is a machine learning algorithm that is used to find the clusters in the data. The results of this work show that the random forest algorithm is an effective tool to find the red sequence clusters in the Millennium Simulation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective conservation of energy and momentum algorithm using switching\n  potentials suitable for molecular dynamics simulation of thermodynamical\n  systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0556, "human_text": "  During a crossover via a switching mechanism from one 2-body potential to another as might be applied in modeling (chemical) reactions in the vicinity of bond formation, energy violations would occur due to finite step size which determines the trajectory of the particles relative to the potential interactions of the unbonded state by numerical (e.g. Verlet) integration. This problem is overcome by an algorithm which preserves the coordinates of the system for each move, but corrects for energy discrepancies by ensuring both energy and momentum conservation in the dynamics. The algorithm is tested for a hysteresis loop reaction model with an without the implementation of the algorithm. The tests involve checking the rate of energy flow out of the MD simulation box; in the equilibrium state, no net rate of flows within experimental error should be observed. The temperature and pressure of the box should also be invariant within the range of fluctuation of these quantities. It is demonstrated that the algorithm satisfies these criteria. ", "machine_text": " We propose a new effective conservation of energy and momentum algorithm using switching potentials suitable for molecular dynamics simulation of thermodynamical systems. We show that by using the elastic and inelastic switching potentials, the total energy and momentum can be conserved independently of the details of the simulation method used. This is achieved by using a thermodynamical model with two degrees of freedom q and p, which represent the total energy and the total momentum, respectively, and two additional auxiliary functions, which are related to the inelastic switching. The main advantage of the new algorithm is that it is not necessary to know the exact form of the inelastic switching potential. We show that in the limit of a large number of degrees of freedom, the algorithm is equivalent to the original molecular dynamics simulation. As an example application, we consider a model of a glassy material containing hard and soft particles. We find that the new algorithm is more efficient than the original algorithm in case of a large number of particles and long simulation times.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Performance Evaluation of Encounter-based Worm Interactions Based\n  on Node Characteristics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2025, "human_text": "  An encounter-based network is a frequently disconnected wireless ad-hoc network requiring nearby neighbors to store and forward data utilizing mobility and encounters over time. Using traditional approaches such as gateways or firewalls for deterring worm propagation in encounter-based networks is inappropriate. Because this type of network is highly dynamic and has no specific boundary, a distributed counter-worm mechanism is needed. We propose models for the worm interaction approach that relies upon automated beneficial worm generation to alleviate problems of worm propagation in such networks. We study and analyze the impact of key mobile node characteristics including node cooperation, immunization, on-off behavior on the worm propagations and interactions. We validate our proposed model using extensive simulations. We also find that, in addition to immunization, cooperation can reduce the level of worm infection. Furthermore, on-off behavior linearly impacts only timing aspect but not the overall infection. Using realistic mobile network measurements, we find that encounters are non-uniform, the trends are consistent with the model but the magnitudes are drastically different. Immunization seems to be the most effective in such scenarios. These findings provide insight that we hope would aid to develop counter-worm protocols in future encounter-based networks. ", "machine_text": "  Node-based interactions are central to a wide range of applications, including collaboration networks, protein interaction networks, and communication networks. We consider a specific class of node-based interactions, namely encounter-based interactions, in which the activity of each node depends only on its current neighbors. We propose a simple model in which each node keeps track of the number of its neighbors and the sum of their activities. The node then uses these quantities to determine its own activity. We show that this model is capable of producing a wide range of complex behavior, such as power-law degree distributions and small-world properties, while remaining analytically tractable. We use this model to analyze two real-world networks, namely the collaboration network of scientific papers and the calling network of mobile phones, and show that our model is able to reproduce a variety of features present in these networks. We also use our model to analyze a synthetic network in which the node attributes are generated according to a probability distribution, and show that our model is able to extract meaningful information about this distribution from the activity of the nodes. Our work suggests that encounter-based interactions can be a powerful and analytically tractable abstraction of node-based interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Resonating singlet valence plaquettes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0846, "human_text": "  We consider the simplest generalizations of the valence bond physics of SU(2) singlets to SU(N) singlets that comprise objects with N sites -- these are SU(N) singlet plaquettes with N=3 and N=4 in three spatial dimensions. Specifically, we search for a quantum mechanical liquid of such objects -- a resonating singlet valence plaquette phase that generalizes the celebrated resonating valence bond phase for SU(2) spins. We extend the Rokhsar-Kivelson construction of the quantum dimer model to the simplest SU(4) model for valence plaquette dynamics on a cubic lattice. The phase diagram of the resulting quantum plaquette model is analyzed both analytically and numerically. We find that the ground state is solid everywhere, including at the Rokhsar-Kivelson point where the ground state is an equal amplitude sum. By contrast, the equal amplitude sum of SU(3) singlet triangular plaquettes on the face centered cubic lattice is liquid and thus a candidate for describing a resonating single valence plaquette phase, given a suitably defined local Hamiltonian. ", "machine_text": " We investigate the role of plaquettes in the description of the ground state of certain correlated quantum systems. We show that a large class of such systems, including finite and infinite chains, ladders, and honeycombs, can be understood via the concept of a singlet plaquette. In particular, we show that such systems are characterized by a unique number, the singlet plaquette index, which can be thought of as the number of non-empty singlet plaquettes required to fill up all the cells of the system. We consider the case of chains and ladders and show that the singlet plquette index is related to the length of the system as well as to the number of internal edges. We show further that in all such systems the singlet plquette index is a continuous function of the parameters of the system and that it takes only discrete values. We analyze in detail the case of honeycombs and show that in this case the singlet plquette index is related to the size of the honeycombs as well as to the number of their internal edges and that it takes only even values.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear Evolution of Baryon Acoustic Oscillations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2783, "human_text": "  We study the nonlinear evolution of the baryon acoustic oscillations (BAO) in the dark matter power spectrum and correlation function using renormalized perturbation theory (RPT). In a previous paper we showed that RPT successfully predicts the damping of acoustic oscillations; here we extend our calculation to the enhancement of power due to mode-coupling. We show that mode-coupling generates additional oscillations that are out of phase with those in the linear spectrum, leading to shifts in the scales of oscillation nodes defined with respect to a smooth spectrum. When Fourier transformed, these out of phase oscillations induce percent-level shifts in the acoustic peak of the two-point correlation function. We present predictions for these shifts as a function of redshift; these should be considered as a robust lower limit to the more realistic case that includes in addition redshift distortions and galaxy bias. We show that these nonlinear effects occur at very large scales, leading to a breakdown of linear theory at scales much larger than commonly thought. We discuss why virialized halo profiles are not responsible for these effects, which can be understood from basic physics of gravitational instability. Our results are in excellent agreement with numerical simulations, and can be used as a starting point for modeling BAO in future observations. To meet this end, we suggest a simple physically motivated model to correct for the shifts caused by mode-coupling. ", "machine_text": " We have developed a new algorithm for finding the precise nonlinear evolution of the Baryon Acoustic Oscillations (BAO) scale in a universe that has been approximated by a Friedmann-Roberson-Walker cosmology with both a variable equation of state (EOF) parameter $w(a)$ and a variable cosmological constant $\\Lambda(a)$, where $a$ is the scale factor. Our new algorithm is based on the Discrete Fourier Transform (DFT) technique and the Fast Fourier Transform (FFT) algorithm. This new algorithm provides a more efficient and more precise way of finding the BAO scale evolution in the presence of both a variable EOF and a variable cosmological constant. In particular, our algorithm can find the BAO scale evolution at any redshift with a computational cost that is $\\mathcal{O}(\\log n)$, where $n$ is the number of input data points. Our new algorithm has been validated by comparing its results with those obtained using the conventional method based on the least squares technique. Our validation shows that our new algorithm is more precise and more efficient than the conventional method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The multiple viewpoints as approach to information retrieval within\n  collaborative development context. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1162, "human_text": "  Nowadays, to achieve competitive advantage, the industrial companies are considering that success is sustained to great product development. That is to manage the product throughout its entire lifecycle. Achieving this goal requires a tight collaboration between actors from a wide variety of domains, using different software tools producing various product data types and formats. The actors' collaboration is mainly based on the exchange /share product information. The representation of the actors' viewpoints is the underlying requirement of the collaborative product development. The multiple viewpoints approach was designed to provide an organizational framework following the actors' perspectives in the collaboration, and their relationships. The approach acknowledges the inevitability of multiple integration of product information as different views, promotes gathering of actors' interest, and encourages retrieved adequate information while providing support for integration through PLM and/or SCM collaboration. In this paper, a multiple viewpoints representation is proposed. The product, process, organization information models are discussed. A series of issues referring to the viewpoints representation are discussed in detail. Based on XML standard, taking electrical connector as an example, an application case of part of product information modeling is stated. ", "machine_text": "  The multiple viewpoints as approach to information retrieval within collaborative development context.   We are motivated by the observation that software development, due to its nature, has to deal with a huge amount of information of highly diverse nature. The information may be located in different places, in various forms and representations, and related to very different contexts. For example, requirements for a new product may be gathered from customers by marketing people, while development team gets requirements from product management and tries to make sense of them in the context of existing products and their limitations. At the same time, development team has to deal with technical documentation produced by the vendors of the used technologies, with the requests from the product management to adjust the product to the changing market, with the problems encountered during the development and with the need to document the product for the future maintenance. We observe that such diversity and amount of information require special approach to its retrieval, management and storage. We claim that the collaborative development context brings new requirements and challenges to the information retrieval process and suggest a new approach, which is based on the multiple viewpoints concept, to solve the information retrieval and management problems within collaborative development context.  The proposed approach is based on the assumption that the information about the same object can be represented from different viewpoints, and the information retrieval effectiveness can be improved by using the multiple representations. In order to prove this assumption we consider the example of requirements information management. We describe the architecture of the proposed approach and present the results of its evaluation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Search for Planets Transiting the M Dwarf Debris Disk Host, AU\n  Microscopii. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3584, "human_text": "  We present high cadence, high precision multi-band photometry of the young, M1Ve, debris disk star, AU Microscopii. The data were obtained in three continuum filters spanning a wavelength range from 4500\\AA to 6600\\AA, plus H$\\alpha$, over 28 nights in 2005. The lightcurves show intrinsic stellar variability due to starspots with an amplitude in the blue band of 0.051 magnitudes and a period of 4.847 days. In addition, three large flares were detected in the data which all occur near the minimum brightness of the star. We remove the intrinsic stellar variability and combine the lightcurves of all the filters in order to search for transits by possible planetary companions orbiting in the plane of the nearly edge-on debris disk. The combined final lightcurve has a sampling of 0.35 minutes and a standard deviation of 6.8 millimags (mmag). We performed Monte Carlo simulations by adding fake transits to the observed lightcurve and find with 95% significance that there are no Jupiter mass planets orbiting in the plane of the debris disk on circular orbits with periods, P $\\le 5$ days. In addition, there are no young Neptune-like planets (with radii 2.5$\\times$ smaller than the young Jupiter) on circular orbits with periods, P $\\le 3$ days. ", "machine_text": " We present phase-resolved spectroscopy and photometry of AU Microscopii from Keck Observatory that reveal new orbital parameters for the debris disk, including a relatively low mass (Mdisk < 3x10^32 kg) and a radius that is a factor of >3 larger than previously reported. We find the disk to be comprised of dust at a range of heliocentric distances, including a belt at ~1.5 AU, which could be the source of the disk's halo. We present high-resolution spectroscopy and photometry of the star that is consistent with a kinematic age of 2.6 Gyr. The disk does not exhibit any evidence of an embedded planet, despite having a dynamical lifetime of >3 Gyr. We search for transits by the known giant planets, and find that only a transiting planet with a radius >4.5 RJ would be detectable at the 5-sigma level. We discuss these results in the context of the giant planet's origins, and suggest that the system was either born with a large number of giant planets that have since been dynamically ejected, or that the giant planets formed later. We present an upper limit on the number of giant planets in the system of 0.5.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the Cosmological Confidence Ball Surface. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2605, "human_text": "  We present a new technique to compute simultaneously valid confidence intervals for a set of model parameters. We apply our method to the Wilkinson Microwave Anisotropy Probe's (WMAP) Cosmic Microwave Background (CMB) data, exploring a seven dimensional space (tau, Omega_DE, Omega_M, omega_DM, omega_B, f_nu, n_s). We find two distinct regions-of-interest: the standard Concordance Model, and a region with large values of omega_DM, omega_B and H_0. This second peak in parameter space can be rejected by applying a constraint (or a prior) on the allowable values of the Hubble constant. Our new technique uses a non-parametric fit to the data, along with a frequentist approach and a smart search algorithm to map out a statistical confidence surface. The result is a confidence ``ball'': a set of parameter values that contains the true value with probability at least 1-alpha. Our algorithm performs a role similar to the often used Markov Chain Monte Carlo (MCMC), which samples from the posterior probability function in order to provide Bayesian credible intervals on the parameters. While the MCMC approach samples densely around a peak in the posterior, our new technique allows cosmologists to perform efficient analyses around any regions of interest: e.g., the peak itself, or, possibly more importantly, the 1-alpha confidence surface. ", "machine_text": " We present a new algorithm for computing the confidence ball surface of a cosmological model that is applicable to general Gaussian prior marginal distributions and not restricted to circular voids. The algorithm is based on a combination of the min-max and mode-maximization methods. We show that the choice of the prior marginals has a significant impact on the shape of the confidence ball surface. For example, the choice of a Gaussian prior with a large variance produces a very different shape than the choice of a Gaussian prior with a small variance. We analyze the physical implications of different choices of prior marginals on the shape of the confidence ball surface. Our analysis shows that the confidence ball surface is very sensitive to the choice of prior marginals and small changes in the prior marginals can produce large changes in the shape of the confidence ball surface. For example, a change in the variance of the Gaussian prior that corresponds to an order of magnitude change in the standard deviation produces a change in the volume of the confidence ball surface that is proportional to the cube of the variance. We show that the confidence ball surface can be described by a few parameters that correspond to physical quantities and we provide a method for computing the parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strings on AdS_2 and the High-Energy Limit of Noncritical M-Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.223, "human_text": "  Noncritical M-theory in 2+1 dimensions has been defined as a double-scaling limit of a nonrelativistic Fermi liquid on a flat two-dimensional plane. Here we study this noncritical M-theory in the limit of high energies, analogous to the \\alpha'\\to\\infty limit of string theory. In the related case of two-dimensional Type 0A strings, it has been argued that the conformal \\alpha'\\to\\infty limit leads to AdS_2 with a propagating fermion whose mass is set by the value of the RR flux. Here we provide evidence that in the high-energy limit, the natural ground state of noncritical M-theory similarly describes the AdS_2\\times S^1 spacetime, with a massless propagating fermion. We argue that the spacetime effective theory in this background is captured by a topological higher-spin extension of conformal Chern-Simons gravity in 2+1 dimensions, consistently coupled to a massless Dirac field. Intriguingly, the two-dimensional plane populated by the original nonrelativistic fermions is essentially the twistor space associated with the symmetry group of the AdS_2\\times S^1 spacetime; thus, at least in the high-energy limit, noncritical M-theory can be nonperturbatively described as a \"Fermi liquid on twistor space.\" ", "machine_text": "  We consider the properties of closed strings at vanishing temperature in AdS_2. We show that the low-energy effective action for a closed string in AdS_2 is non-critical M-theory, with the radius of the AdS_2 boundary playing the role of the string length. The high-energy effective action is described by a dimensional reduction of the effective Nambu-Goldstone action for a string in a flat space-time. The latter has a cosmological constant and a massless scalar field as basic ingredients. We calculate the effective actions for a closed string in AdS_2 with a non-trivial radius and show that the high-energy effective action has the same form as the non-critical M-theory effective action. This has the advantage that our result can be used to make non-trivial predictions for the high-energy behavior of M-theory. We also study the possible boundary conditions for a closed string in AdS_2 and find that the only boundary conditions which can be implemented are those which leave the AdS_2 bulk invariant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A possible explanation why the Theta+ is seen in some experiments and\n  not in others. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3045, "human_text": "  To understand the whole set of positive and null data on the Theta+(1530)-production, we suggest the hypothesis that multiquark hadrons are mainly generated from many-quark states, which emerge either as short-term hadron fluctuations, or as hadron remnants in hard processes. This approach allows us to describe both non-observation of the Theta+ in current null experiments and peculiar features of its production in positive experiments. Further, we are able to propose new experiments that might be decisive for the problem of the Theta+ existence. Distributions of the Theta+ in such experiments can give important information both on higher Fock components of conventional hadrons and about structure and hadronization properties of hadron remnants produced in hard processes. We also explain that description of multiquark hadrons may require a modified form of the constituent quark model, with quark masses and couplings being intermediate between their values for the familiar constituent quarks and the current ones. ", "machine_text": " We present a possible explanation why the \u03b8+ is seen in some experiments and not in others. We consider a model of the \u03b8+ involving two fermionic fields and a scalar field, which is invariant under the general symmetry group of the \u03b8+. We show that the probability for the \u03b8+ to be excited can be very small, provided that the vacuum state is very close to a symmetry state of the model. As an application, we discuss the case of the \u03b8+ in an axion-less model of the strong force, where it is expected to be very weakly excited. We also comment on the case of the \u03b8+ in the standard model, where it is totally quenched, in spite of the fact that the vacuum state is very far from a symmetry state.  We thank L. Polyakov for useful discussions. M.B. thanks A. Bergliaffa for useful comments. This work has been supported in part by the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (ERC grant agreement No. 84766), by the U.S. National Science Foundation (NSF) under grant no. DMR-1306594, and by the Argentina, Brazil, Chile, Colombia and Uruguay (ABC-U) consortium through a grant to the IMPA by CONICOR from the Tinker Foundation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nova Geminorum 1912 and the Origin of the Idea of Gravitational Lensing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0963, "human_text": "  Einstein's early calculations of gravitational lensing, contained in a scratch notebook and dated to the spring of 1912, are reexamined. A hitherto unknown letter by Einstein suggests that he entertained the idea of explaining the phenomenon of new stars by gravitational lensing in the fall of 1915 much more seriously than was previously assumed. A reexamination of the relevant calculations by Einstein shows that, indeed, at least some of them most likely date from early October 1915. But in support of earlier historical interpretation of Einstein's notes, it is argued that the appearance of Nova Geminorum 1912 (DN Gem) in March 1912 may, in fact, provide a relevant context and motivation for Einstein's lensing calculations on the occasion of his first meeting with Erwin Freundlich during a visit in Berlin in April 1912. We also comment on the significance of Einstein's consideration of gravitational lensing in the fall of 1915 for the reconstruction of Einstein's final steps in his path towards general relativity. ", "machine_text": "  In 1912, a nova in the star cluster Pleiades occurred. The nova was in the photographic field of the young and brilliant astronomer from Denmark, Poul Andersen. Because the nova was in the same star cluster as the recently discovered binary star Pleione, Andersen suggested that the nova was simply a disappearance of a third body in the same system. However, the spectra of the nova showed it to be a classical nova, which was subsequently named Nova Geminorum 1912. Andersen's hypothesis of a disappearance in the Pleione system was soon forgotten. In this paper, we briefly review the history of Nova Geminorum 1912 and the idea of gravitational lensing. We analyze the observations of the nova in the light of the available data and also in the light of the modern understanding of the nova phenomenon. We show that the nova was indeed in the Pleione system and that the observations support the idea that it was a case of gravitational lensing. Thus, a century ago, an astronomer was on the right track to discover one of the most spectacular phenomena in astronomy: gravitational lensing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Intricate Knots in Proteins: Function and Evolution. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0191, "human_text": "  A number of recently discovered protein structures incorporate a rather unexpected structural feature: a knot in the polypeptide backbone. These knots are extremely rare, but their occurrence is likely connected to protein function in as yet unexplored fashion. Our analysis of the complete Protein Data Bank reveals several new knots which, along with previously discovered ones, can shed light on such connections. In particular, we identify the most complex knot discovered to date in human ubiquitin hydrolase, and suggest that its entangled topology protects it against unfolding and degradation by the proteasome. Knots in proteins are typically preserved across species and sometimes even across kingdoms. However, we also identify a knot which only appears in some transcarbamylases while being absent in homologous proteins of similar structure. The emergence of the knot is accompanied by a shift in the enzymatic function of the protein. We suggest that the simple insertion of a short DNA fragment into the gene may suffice to turn an unknotted into a knotted structure in this protein. ", "machine_text": " Intricate Knots in Proteins: Function and Evolution The function of a protein is encoded in its amino acid sequence and is determined by the intrinsic properties of its constituent amino acids as well as by the amino acid sequence itself. The knowledge of the function of a protein is essential for understanding its role in the cell and its contribution to the onset and progression of disease. A large number of proteins are involved in the execution of a particular function and work in a concerted manner to achieve a specific goal, such as the assembly of an organelle, the duplication of a cell, or the propagation of a signal. Elucidating the principles by which proteins execute their function is essential not only for understanding the physiology of the cell, but also for the rational design of pharmaceutical agents that can modulate protein function for therapeutic purposes. We have developed a computational method that uses only the amino acid sequence of a protein to extract the principles by which it executes its function. We show that the protein function is encoded in the functional organization of its constituent amino acids, which we term the protein's \"intricate knots.\" We have identified the intricate knots in a large number of proteins from various organisms, and we show that these knots are evolutionarily conserved. Our results suggest that the intricate knots are \"carrying the function\" of the protein and have important implications for protein function, evolution, and design.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Wide Field Spectrograph (WiFeS). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0287, "human_text": "  This paper describes the Wide Field Spectrograph (WiFeS) under construction at the Research School of Astronomy and Astrophysics (RSAA) of the Australian National University (ANU) for the ANU 2.3m telescope at the Siding Spring Observatory. WiFeS is a powerful integral field, double-beam, concentric, image-slicing spectrograph designed to deliver excellent thoughput, wavelength stability, spectrophotometric performance and superb image quality along with wide spectral coverage throughout the 320-950 nm wavelength region. It provides a 25x38 arcsec. field with 0.5 arcsec. sampling along each of twenty five 38X1 arcsec slitlets. The output format is optimized to match the 4096x4096 pixel CCD detectors in each of two cameras individually optimized for the blue and the red ends of the spectrum, respectively. A process of \"interleaved nod-and-shuffle\" will be applied to permit quantum noise-limited sky subtraction. Using VPH gratings, spectral resolutions of 3000 and 7000 are provided. The full spectral range is covered in a single exposure at R=3000, and in two exposures in the R=7000 mode. The use of transmissive coated optics, VPH gratings and optimized mirror coatings ensures a throughput (including telescope atmosphere and detector) > 30% over a wide spectral range. The concentric image-slicer design ensures an excellent and uniform image quality across the full field. To maximize scientific return, the whole instrument is configured for remote observing, pipeline data reduction, and the accumulation of calibration image libraries. ", "machine_text": "  We present the design and expected performance of WiFeS, a wide field, high resolution, optical spectrograph to be installed at the Anglo-Australian Telescope. WiFeS will provide a spectral resolution of $\\sim 2000$ at $\\sim 5-7$ arcmin field of view, over the wavelength range $\\rm 3700-10000$ \u00c5. The spectrograph is based on a bench-mounted, cryogenically cooled, grated echelle spectrograph with a reflective grating. We will achieve a high level of completeness by using a seven-element, all-refractive, on-axis imaging lens to distribute the light from a 20\" telescope among 32-34 simultaneous fibres. The fibres will feed two parallel bench-mounted spectrographs each with an integrated spectral resolution of $\\rm 5000-10000$. We expect to obtain an efficiency of $\\sim 60$% and a typical S/N of $\\rm 50$ per hour of on-time observation. We will achieve a time resolution of $\\rm 5-15$ seconds. The science drivers for WiFeS are: a) to record the redshifts of optical transient phenomena with a view to identifying potential optical counterparts to gravitational waves sources; b) to study the chemical and physical properties of stellar atmospheres and solar structure; c) to explore the structure and evolution of the interstellar medium; and d) to investigate the distribution and properties of the intergalactic medium. We expect that WiFeS will provide a step-change in Australia's ability to access time-series observations of transient phenomena in the optical and NIR, as well as provide unique high-resolution capabilities in the UV and NIR.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Formation and Collapse of Quiescent Cloud Cores Induced by Dynamic\n  Compressions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0559, "human_text": "  (Abridged) We present numerical hydrodynamical simulations of the formation, evolution and gravitational collapse of isothermal molecular cloud cores. A compressive wave is set up in a constant sub-Jeans density distribution of radius r = 1 pc. As the wave travels through the simulation grid, a shock-bounded spherical shell is formed. The inner shock of this shell reaches and bounces off the center, leaving behind a central core with an initially almost uniform density distribution, surrounded by an envelope consisting of the material in the shock-bounded shell, with a power-law density profile that at late times approaches a logarithmic slope of -2 even in non-collapsing cases. The resulting density structure resembles a quiescent core of radius < 0.1 pc, with a Bonnor-Ebert-like (BE-like) profile, although it has significant dynamical differences: it is initially non-self-gravitating and confined by the ram pressure of the infalling material, and consequently, growing continuously in mass and size. With the appropriate parameters, the core mass eventually reaches an effective Jeans mass, at which time the core begins to collapse. Thus, there is necessarily a time delay between the appearance of the core and the onset of its collapse, but this is not due to the dissipation of its internal turbulence as it is often believed. These results suggest that pre-stellar cores may approximate Bonnor-Ebert structures which are however of variable mass and may or may not experience gravitational collapse, in qualitative agreement with the large observed frequency of cores with BE-like profiles. ", "machine_text": "  Dynamic compressions are motions in the atmosphere that are both fast and intense enough to disrupt the local thermodynamic equilibrium, and are therefore capable of modifying the distribution of clouds. A number of cloud microstructure processes have been proposed to explain how clouds respond to dynamic compressions, but the most plausible mechanisms remain debated. Here we show, using large-eddy simulation, that the growth and subsequent collapse of quiescent cloud cores is a robust feature of dynamic compressions in a stratified boundary layer. We observe the growth of cloud cores in response to an increase in the rate of compression, and their subsequent collapse due to a reduction of the rate of compression or to an extreme event that disrupts the cloud core. We describe the physical processes that are most plausible to explain the formation and collapse of these cloud cores, and we quantify their importance by comparing different parameterizations in a cloud microphysical model. We find that thecollapseofcloudcoresintothediskisbestdescribedbymainlybyahydrophilicbrain. cloud core is associated with an increase in the cloud liquid water content and cloud base mass flux, and a decrease in the cloud fraction. The sensitivity of the model to the different parameterizations suggests that different physical processes are important for the formation and the collapse of cloud cores. We also find that the parameterization of the cloud microphysical model has a strong influence on the model's ability to reproduce the large-eddy simulation results, indicating that the representation of cloud microphysical processes is important for the prediction of weather and climate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC\n  monitor field towards the North Ecliptic Pole. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1365, "human_text": "  We present an initial analysis of AKARI 18um-selected galaxies using all 9 photometric bands at 2-24um available in the InfraRed Camera (IRC), in order to demonstrate new capabilities of AKARI cosmological surveys. We detected 72 sources at 18um in an area of 50.2 arcmin^2 in the AKARI/IRC monitor field towards the North Ecliptic Pole (NEP). From this sample, 25 galaxies with probable redshifts z>~ 0.5 are selected with a single colour cut (N2-N3>0.1) for a detailed SED analysis with ground-based BVRi'z'JK data. Using an SED radiative transfer model of starbursts covering the wavelength range UV -- submm, we derive photometric redshifts from the optical-MIR SEDs of 18um-selected galaxies. From the best-fit SED models, we show that the IRC all-band photometry is capable of tracing the steep rise in flux at the blue side of the PAH 6.2um emission feature. This indicates that the IRC all-band photometry is useful to constrain the redshift of infrared galaxies, specifically for dusty galaxies with a less prominent 4000A break. Also, we find that the flux dip between the PAH 7.7 and 11.2um emission feature is recognizable in the observed SEDs of galaxies at z~1. By using such a colour anomaly due to the PAH and silicate absorption features, unique samples of ULIRGs at z~1, `silicate-break' galaxies, can be constructed from large cosmological surveys of AKARI towards the NEP, i.e. the NEP-Deep and NEP-Wide survey. This pilot study suggests the possibility of detecting many interesting galaxy properties in the NEP-Deep and Wide surveys, such as a systematic difference in SEDs between high- and low-z ULIRGs, and a large variation of the PAH inter-band strength ratio in galaxies at high redshifts. [abridged] ", "machine_text": " We present a multi-wavelength analysis of 18um-selected galaxies in the AKARI/IRC monitor field towards the North Ecliptic Pole. We find that the 18um-selected galaxies are statistically consistent with the general population of galaxies in the field, in terms of their color, surface brightness, and surface-area distribution. We also find that the 18um-selected galaxies are on average slightly less blue, and have higher surface brightness, than the galaxies selected by other far-infrared colors. These results suggest that the 18um-color selection is efficient in finding galaxies with strong far-infrared emission lines, but the selection is slightly conservative, as the 18um-selected galaxies contain somewhat less faint galaxies. We present an automated method to measure the far-infrared line luminosity of the 18um-selected galaxies, and use this method to search for high-redshift galaxies with the line luminosity of interest. We find four galaxies with a relatively high far-infrared line luminosity. One of these galaxies is likely at a high redshift (z >> 5), while the other three galaxies are at intermediate redshift (z < 5). We discuss the nature of these galaxies, and find that the high-redshift galaxy may be a distant galaxy with a high star formation rate, while the three intermediate-redshift galaxies are likely local galaxies with a low star formation rate but with strong molecular lines.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of the short duration GRB 050906. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1705, "human_text": "  We present deep optical and infrared observations of the short duration GRB 050906. Although no X-ray or optical/IR afterglow was discovered to deep limits, the error circle of the GRB (as derived from the Swift BAT) is unusual incontaining the relatively local starburst galaxy IC328. This makes GRB 050906 a candidate burst from a soft-gamma repeater, similar to the giant flare from SGR 1806-20. The probability of chance alignment of a given BAT position with such a galaxy is small (<1%), although the size of the error circle (2.6 arcminute radius) is such that a higher-z origin can't be ruled out. Indeed, the error circle also includes a moderately rich galaxy cluster at z=0.43, which is a plausible location for the burst given the apparent preference that short GRBs have for regions of high mass density. No residual optical or infrared emission has been observed, either in the form of an afterglow or later time emission from any associated supernova-like event. We discuss the constraints these limits place on the progenitor of GRB 050906 based on the expected optical signatures from both SGRs and merging compact object systems. ", "machine_text": "  We present a detailed analysis of the short duration gamma-ray burst (GRB) 050906, which was observed on September 6, 2005, by the Swift satellite. The burst lasted for only 2.2 ks, making it the shortest burst observed so far. The observed phenomenology is consistent with the burst engine being a black hole of 3-10 M  Benoit, 2005. We find that the most parsimonious model for the observed phenomenology is a burst with a constant isotropic-equivalent radiated energy (ERe) of 5 kJ kg-1 and a fluence-weighted isotropic-equivalent radiated energy of 100 kJ kg-1. These two ERe values are almost equal, which implies that the burst was highly focused. We show that this can be explained by a GRB with an energy conversion efficiency \u03b7 from rest-frame isotropic-equivalent kinetic energy to isotropic-equivalent radiated energy of \u03b7 \u223c 0.1 and a burst-wide duty cycle of \u223c 0.1. Such a burst would have an energy release of \u223c 1 kJ. A burst engine with a relatively high rest-frame isotropic-equivalent kinetic energy of  \u223c 10 kJ and a relatively low \u03b7 \u223c 0.1 would produce a burst with a burst-wide duty cycle of \u223c 0.9 and an energy release of  \u223c 100 kJ. We discuss this burst in the context of models in which the burst energy is produced by a low-mass object (LMO) falling onto a massive object (MMO). We find that for this burst to be explained by the standard GRB model in which the burst energy is produced by an LMO falling onto an MMO, the MMO would have to be at least 10 times more massive than the LMO. We discuss the possibility that this burst was produced by a collision between two LMOs of comparable masses, in which case the burst-to-birth ratio would be  \u223c 1.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Growth window and possible mechanism of millimeter-thick single-walled\n  carbon nanotube forests. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1903, "human_text": "  Our group recently reproduced the water-assisted growth method, so-called \"super growth\", of millimeter-thick single-walled carbon nanotube (SWNT) forests by using C2H4/ H2/ H2O/ Ar reactant gas and Fe/ Al2O3 catalyst. In this current work, a parametric study was carried out on both reaction and catalyst conditions. Results revealed that a thin Fe catalyst layer (about 0.5 nm) yielded rapid growth of SWNTs only when supported on Al2O3, and that Al2O3 support enhanced the activity of Fe, Co, and Ni catalysts. The growth window for the rapid SWNT growth was narrow, however. Optimum amount of added H2O increased the SWNT growth rate but further addition of H2O degraded both the SWNT growth rate and quality. Addition of H2 was also essential for rapid SWNT growth, but again, further addition decreased both the SWNT growth rate and quality. Because Al2O3 catalyzes hydrocarbon reforming, Al2O3 support possibly enhances the SWNT growth rate by supplying the carbon source to the catalyst nanoparticles. The origin of the narrow window for rapid SWNT growth will also be discussed. ", "machine_text": "  Growth window and possible mechanism of millimeter-thick single-walled carbon nanotube forests  A forest of multi-millimeter-thick single-walled carbon nanotubes (SWCNTs) with a high specific surface area and high thermal conductivity can be synthesized by the thermal chemical vapor deposition (TCVD) method using Fe(NO3)3\u00b79H2O as the catalyst and acetylene as the carbon source, in a reaction chamber with an inner diameter of 8 mm and a length of 200 mm. The effect of the initial concentration of Fe(NO3)3\u00b79H2O on the growth of SWCNTs was investigated. The results showed that the SWCNT forest with a height of more than 2 mm could be synthesized when the initial concentration of Fe(NO3)3\u00b79H2O was lower than 0.167 g\u00b7L\u22121. The SWCNT forest with a height of more than 10 mm could be synthesized when the initial concentration of Fe(NO3)3\u00b79H2O was higher than 1.835 g\u00b7L\u22121. A growth window of 5.667 g\u00b7L\u22121\u00b7h\u22121 was obtained between the initial concentrations of 0. chaotic and 1.835 g\u00b7L\u22121\u00b7h\u22121. The growth rate of the SWCNTs was found to be dependent on the initial concentration of Fe(NO3)3\u00b79H2O. A possible growth mechanism of the SWCNTs was proposed according to the experimental results and some related studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum Electrodynamics of qubits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2121, "human_text": "  Systematic description of a spin one-half system endowed with magnetic moment or any other two-level system (qubit) interacting with the quantized electromagnetic field is developed. This description exploits a close analogy between a two-level system and the Dirac electron that comes to light when the two-level system is described within the formalism of second quantization in terms of fermionic creation and annihilation operators. The analogy enables one to introduce all the powerful tools of relativistic QED (albeit in a greatly simplified form). The Feynman diagrams and the propagators turn out to be very useful. In particular, the QED concept of the vacuum polarization finds its close counterpart in the photon scattering off a two level-system leading via the linear response theory to the general formulas for the atomic polarizability and the dynamic single spin susceptibility. To illustrate the usefulness of these methods, we calculate the polarizability and susceptibility up to the fourth order of perturbation theory. These {\\em ab initio} calculations resolve some ambiguities concerning the sign prescription and the optical damping that arise in the phenomenological treatment. We also show that the methods used to study two-level systems (qubits) can be extended to many-level systems (qudits). As an example, we describe the interaction with the quantized electromagnetic field of an atom with four relevant states: one S state and three degenerate P states. ", "machine_text": " We propose a new approach to quantum electrodynamics (QED) for qubits. Our approach is based on the combination of the concepts of duality and quantization. We show that, in the limit of large quantum numbers, the electric and magnetic fields can be completely described by only a few degrees of freedom. We obtain a very general and robust framework for QED which is applicable to a large class of qubit systems. Our approach provides a very simple and transparent derivation of the low-energy effective action for QED. Our main result is the derivation of an effective action which contains a term that is singular on the whole space-time and has the structure of a topological charge. We show that this term is related to the geometry of the space-time and does not receive any contribution from the dynamics of the qubit. Our approach has several physical implications. In particular, we show that the singular term can be related to the chirality of the qubit and that it gives rise to a new kind of non-linear dynamics, different from the one associated with the standard conception of QED.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Asynchronous games: innocence without alternation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1118, "human_text": "  The notion of innocent strategy was introduced by Hyland and Ong in order to capture the interactive behaviour of lambda-terms and PCF programs. An innocent strategy is defined as an alternating strategy with partial memory, in which the strategy plays according to its view. Extending the definition to non-alternating strategies is problematic, because the traditional definition of views is based on the hypothesis that Opponent and Proponent alternate during the interaction. Here, we take advantage of the diagrammatic reformulation of alternating innocence in asynchronous games, in order to provide a tentative definition of innocence in non-alternating games. The task is interesting, and far from easy. It requires the combination of true concurrency and game semantics in a clean and organic way, clarifying the relationship between asynchronous games and concurrent games in the sense of Abramsky and Melli\\`es. It also requires an interactive reformulation of the usual acyclicity criterion of linear logic, as well as a directed variant, as a scheduling criterion. ", "machine_text": " Asynchronous games are multiplayer online games that do not require all players to play simultaneously. Asynchronous games can be split into two sub-categories: turn-based games and idle games. Turn-based games are multiplayer games in which players take turns to play the game, while idle games are multiplayer games in which players can play the game at their own pace without having to wait for other players to finish their turns.  Asynchronous games have become increasingly popular in recent years, particularly among players who are unable to play games synchronously due to time zone differences or other commitments. Asynchronous games can also be more convenient for players who prefer to play games at their own pace rather than having to play simultaneously with other players.  This paper examines the social and gameplay dynamics of asynchronous games, and how these dynamics differ from those of synchronous games. The paper will discuss how the lack of synchronous interaction in asynchronous games affects the formation and maintenance of social bonds between players. The paper will also explore how the lack of synchronous interaction affects the gameplay dynamics of asynchronous games, and how these dynamics differ from those of synchronous games.  The paper will draw on social capital theory to examine the social dynamics of asynchronous games, and will use game theory to examine the gameplay dynamics of asynchronous games. The paper will conclude by discussing the implications of its findings for the design and development of asynchronous games, and for the future of multiplayer online games more broadly.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anatomy of Malicious Singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1416, "human_text": "  As well known, the b-boundaries of the closed Friedman world model and of Schwarzschild solution consist of a single point. We study this phenomenon in a broader context of differential and structured spaces. We show that it is an equivalence relation $\\rho $, defined on the Cauchy completed total space $\\bar{E}$ of the frame bundle over a given space-time, that is responsible for this pathology. A singularity is called malicious if the equivalence class $[p_0]$ related to the singularity remains in close contact with all other equivalence classes, i.e., if $p_0 \\in \\mathrm{cl}[p]$ for every $p \\in E$. We formulate conditions for which such a situation occurs. The differential structure of any space-time with malicious singularities consists only of constant functions which means that, from the topological point of view, everything collapses to a single point. It was noncommutative geometry that was especially devised to deal with such situations. A noncommutative algebra on $\\bar{E}$, which turns out to be a von Neumann algebra of random operators, allows us to study probabilistic properties (in a generalized sense) of malicious singularities. Our main result is that, in the noncommutative regime, even the strongest singularities are probabilistically irrelevant. ", "machine_text": "  We present a model of malicious singularities, which are defined as singular points in a signal that are of interest for a malicious actor. A malicious singularity can be, for example, the start point of a peak, the tip of a peak, or the start point of a trough. We consider two types of malicious singularities, corresponding to two different types of malicious intent: a simple (unforced) malicious singularity, where the malicious actor is interested in a specific value of a signal, and an iterated (forced) malicious singularity, where the malicious actor iteratively forces the signal to a specific value. We show that malicious singularities can be detected by observing the iterated Laurent series of a given signal. We implement our approach in two steps. In the first step, we use a supervised learning approach to build a model that distinguishes between signals containing malicious singularities and signals that do not. In the second step, we use this model to classify signals containing malicious singularities according to the type of singularity. We demonstrate the efficacy of our approach on simulated data, and we discuss the practical aspects of using our approach on real data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rational points on certain elliptic surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2955, "human_text": "  Let $\\mathcal{E}_{f}:y^2=x^3+f(t)x$, where $f\\in\\Q[t]\\setminus\\Q$, and let us assume that $\\op{deg}f\\leq 4$. In this paper we prove that if $\\op{deg}f\\leq 3$, then there exists a rational base change $t\\mapsto\\phi(t)$ such that on the surface $\\cal{E}_{f\\circ\\phi}$ there is a non-torsion section. A similar theorem is valid in case when $\\op{deg}f=4$ and there exists $t_{0}\\in\\Q$ such that infinitely many rational points lie on the curve $E_{t_{0}}:y^2=x^3+f(t_{0})x$. In particular, we prove that if $\\op{deg}f=4$ and $f$ is not an even polynomial, then there is a rational point on $\\cal{E}_{f}$. Next, we consider a surface $\\cal{E}^{g}:y^2=x^3+g(t)$, where $g\\in\\Q[t]$ is a monic polynomial of degree six. We prove that if the polynomial $g$ is not even, there is a rational base change $t\\mapsto\\psi(t)$ such that on the surface $\\cal{E}^{g\\circ\\psi}$ there is a non-torsion section. Furthermore, if there exists $t_{0}\\in\\Q$ such that on the curve $E^{t_{0}}:y^2=x^3+g(t_{0})$ there are infinitely many rational points, then the set of these $t_{0}$ is infinite. We also present some results concerning diophantine equation of the form $x^2-y^3-g(z)=t$, where $t$ is a variable. ", "machine_text": "  We show that a certain family of elliptic surfaces has a natural decomposition into pieces each of which is isometric to a symmetric product of elliptic curves. The isomorphism classes of such surfaces form an abelian group, with the inverse image of a surface in this group being the surface obtained by inverting the symmetric product. We determine the action of this group on the moduli space of such surfaces. As a special case, we give a description of the singular fibers of the associated Fredholm operator.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: FIRST-based survey of Compact Steep Spectrum sources, V.\n  Milliarcsecond-scale morphology of CSS objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0351, "human_text": "  Multifrequency VLBA observations of the final group of ten objects in a sample of FIRST-based compact steep spectrum (CSS) sources are presented. The sample was selected to investigate whether objects of this kind could be relics of radio-loud AGNs switched off at very early stages of their evolution or possibly to indicate intermittent activity. Initial observations were made using MERLIN at 5 GHz. The sources have now been observed with the VLBA at 1.7, 5 and 8.4 GHz in a snapshot mode with phase-referencing. The resulting maps are presented along with unpublished 8.4-GHz VLA images of five sources. Some of the sources discussed here show a complex radio morphology and therefore a complicated past that, in some cases, might indicate intermittent activity. One of the sources studied - 1045+352 - is known as a powerful radio and infrared-luminous broad absorption line (BAL) quasar. It is a young CSS object whose asymmetric two-sided morphology on a scale of several hundred parsecs, extending in two different directions, may suggest intermittent activity. The young age and compact structure of 1045+352 is consistent with the evolution scenario of BAL quasars. It has also been confirmed that the submillimetre flux of 1045+352 can be seriously contaminated by synchrotron emission. ", "machine_text": "  FIRST-based survey of Compact Steep Spectrum sources, V.   Milliarcsecond-scale morphology of CSS objects   We present photometric observations of the compact steep spectrum (CSS) sources in the FIRST survey. We show that the milliarcsecond-scale morphology of CSS sources is different from that of broad absorption line (BAL) sources, which have a characteristic dumbbell shape. We find that the brightness distribution of a large fraction of CSS sources is well described by a power law. Based on this description we derive a simple model which relates the luminosity and the power law index to the number of components and their luminosities. We find that a large fraction (72%) of CSS sources in our survey have two components. We show that single-component sources can be explained either by the presence of a jet which is either pointed directly towards the observer (43%) or is slightly off-axis (11%), or by a highly absorbed source (36%). We also show that multi-component sources can be explained by the presence of an accretion disc around a central engine, except in cases where the disc is edge-on to the line of sight. We derive a correlation between the optical luminosity and the accretion rate for a subset of the sources with available accretion rates. We discuss the implications of our results for the structure and evolution of these sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sunyaev-Zel'dovich profiles and scaling relations: modelling effects and\n  observational biases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2535, "human_text": "  We use high-resolution hydrodynamic re-simulations to investigate the properties of the thermal Sunyaev-Zel'dovich (SZ) effect from galaxy clusters. We compare results obtained using different physical models for the intracluster medium (ICM), and show how they modify the SZ emission in terms of cluster profiles and scaling relations. We also produce realistic mock observations to verify whether the results from hydrodynamic simulations can be confirmed. We find that SZ profiles depend marginally on the modelled physical processes, while they exhibit a strong dependence on cluster mass. The central and total SZ emission strongly correlate with the cluster X-ray luminosity and temperature. The logarithmic slopes of these scaling relations differ from the self-similar predictions by less than 0.2; the normalization of the relations is lower for simulations including radiative cooling. The observational test suggests that SZ cluster profiles are unlikely to be able to probe the ICM physics. The total SZ decrement appears to be an observable much more robust than the central intensity, and we suggest using the former to investigate scaling relations. ", "machine_text": " We present a simple model for the formation of Sunyaev-Zel'dovich (SZ) profiles that accounts for the effect of both the variations in the density distribution and the line-of-sight (LOS) integration. We show that this model predicts several new scaling relations for the SZ profile that are not consistent with the simple SZ model that is often used in practice. The main result of our work is a detailed analysis of the effects that various modelling choices have on the shape of the SZ profile. We show that a proper modelling of the SZ effect requires a good knowledge of the distribution of the electron temperature and density, and that this distribution can be very well described by a model in which the gas is treated as a homogeneous sphere with a constant density and temperature, provided that the sphere is big enough. We also show that in this simple model the SZ effect depends only on the total gas mass, and not on the physical size of the sphere. We derive both lower and upper limits for the relative difference between the observed SZ profile and the prediction of our simple model, and we show that these limits can be used to test the assumption of a spherical distribution. We also discuss the effects of observational biases, such as the beaming and the LOS selection effect. We show that both effects can lead to a significant overestimate of the SZ amplitude.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: TRUFAS, a wavelet based algorithm for the rapid detection of planetary\n  transits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4557, "human_text": "  Aims: We describe a fast, robust and automatic detection algorithm, TRUFAS, and apply it to data that are being expected from the CoRoT mission. Methods: The procedure proposed for the detection of planetary transits in light curves works in two steps: 1) a continuous wavelet transformation of the detrended light curve with posterior selection of the optimum scale for transit detection, and 2) a period search in that selected wavelet transformation. The detrending of the light curves are based on Fourier filtering or a discrete wavelet transformation. TRUFAS requires the presence of at least 3 transit events in the data. Results: The proposed algorithm is shown to identify reliably and quickly the transits that had been included in a standard set of 999 light curves that simulate CoRoT data. Variations in the pre-processing of the light curves and in the selection of the scale of the wavelet transform have only little effect on TRUFAS' results. Conclusions: TRUFAS is a robust and quick transit detection algorithm, especially well suited for the analysis of very large volumes of data from space or ground-based experiments, with long enough durations for the target-planets to produce multiple transit events. ", "machine_text": "  We present an algorithm for the rapid detection of planetary transits which is based on the use of wavelets. Our method, TRUFAS (Wavelet Transits), uses the fact that the silhouette of a planet against its host star is a pulse-like function which can be well approximated by a wavelet basis. We show that by using the appropriate scaling parameters the precision of the transit time can be significantly improved over a naive analysis. In particular we show that by using a parameter which corresponds to the characteristic time scale of the transit it is possible to achieve a timing precision which is close to the accuracy limit set by the sampling theorem. We present an analysis of the dependence of our method on the choice of basis function as well as the influence of the choice of scaling parameters. We show that for the particular case of detecting transits in grazing eclipses our method is equivalent to a least-squares fit of the data to a linear function. We present a simulation study which investigates the effect of various realistic noise sources on the precision of the transit time as well as the detectability of the transit. We apply our method to real data obtained from the NASA/ESA Hubble Space Telescope and the ground based Automated Planet Finder and show that in both cases a significant improvement in the transit time precision is obtained.  We describe the motivation for our work and the key ideas and methodology used. We present the results obtained and discuss the problem the work attempts to solve and any practical or theoretical applications from our findings or implications for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accretion vs colliding wind models for the gamma-ray binary LS I +61\n  303: an assessment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.132, "human_text": "  LS I +61 303 is a puzzling Be/X-ray binary with variable gamma-ray emission at up TeV energies. The nature of the compact object and the origin of the high-energy emission are unclear. One family of models invokes particle acceleration in shocks from the collision between the B-star wind and a relativistic pulsar wind, while another centers on a relativistic jet powered by accretion. Recent high-resolution radio observations showing a putative \"cometary tail\" pointing away from the Be star near periastron have been cited as support for the pulsar-wind model. We wish here to carry out a quantitative assessment of these competing models for this extraordinary source. We apply a 3D SPH code for dynamical simulations of both the pulsar-wind-interaction and accretion-jet models. The former yields a description of the shape of the wind-wind interaction surface. The latter provides an estimation of the accretion rate. The results allow critical evaluation of how the two distinct models confront the data in various wavebands under a range of conditions. When one accounts for the 3D dynamical wind interaction under realistic constraints for the relative strength of the B-star and pulsar winds, the resulting form of the interaction front does not match the putative \"cometary tail\" claimed from radio observations. On the other hand, dynamical simulations of the accretion-jet model indicate that the orbital phase variation of accretion power includes a secondary broad peak well away from periastron, thus providing a plausible way to explain the observed TeV gamma ray emission toward apastron. We conclude that the colliding-wind model is not clearly established for LS I +61 303, while the accretion-jet model can reproduce many key characteristics of the observed TeV gamma-ray emission. ", "machine_text": " We present a comparison of the two prominent models for low-mass X-ray binaries (LMXBs): the accretion model and the colliding wind model. The comparison is made for the well-studied LMXB LS I +61\u00b0303, which contains a white dwarf with a relatively long spin period (41.2 \u00b1 1.2 min), a relatively low magnetic field (B_WD \u2248 12 MG), and a rapid accretion rate (up to 10\u2077 met per second), and is therefore well suited to test the two models. We find that both models are able to reproduce basic properties of the system, such as the observed accretion rate and spin period. The accretion model is found to be superior in describing the observed relation between the accretion rate and the spin period, and its ability to reproduce observations is improved by including a parameter that allows for a superposition of two different accretion states. We discuss our results in the framework of a simple model that describes the evolution of the system's orbital and spin parameters as a function of the accretion rate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Projectile Fragmentation of $^{86}$Kr at 64 MeV/nucleon. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4313, "human_text": "  We measured fragmentation cross sections produced using the primary beam of $^{86}$Kr at 64 MeV/nucleon on $^9$Be and $^{181}$Ta targets. The cross sections were obtained by integrating the momentum distributions of isotopes with 25<Z<36 measured using the RIPS fragment separator at RIKEN. The cross-section ratios obtained with the $^{181}$Ta and $^{9}$Be targets depend on the fragment masses, contrary to the simple geometrical models. We compared the extracted cross sections to EPAX; an empirical parameterization of fragmentation cross sections. Predictions from current EPAX parameterization severely overestimate the production cross sections of very neutron-rich isotopes. Attempts to obtain another set of EPAX parameters specific to the reaction studied here, to extrapolate the neutron-rich nuclei more accurately have not been very successful, suggesting that accurate predictions of production cross sections of nuclei far from the valley of stability require information of nuclear properties which are not present in EPAX. ", "machine_text": " We present here the results of a theoretical investigation of the projectile fragmentation of $^{86}$Kr at 64 MeV/nucleon. The motivation for this work is the recent experiment of Shinozaki et al. which observed the appearance of $^{88}$Rb and $^{90}$Sr in the debris from the collision of a 64 MeV/nucleon $^{86}$Kr projectile with a gold target. We solve the many-body problem for the projectile fragmentation using the molecular dynamics method. The $^{86}$Kr molecule is treated as a compound system consisting of two $^{36}$Kr atoms. We found that the structure of the $^{86}$Kr molecule is stabilized by the pairing interaction, and that the molecular dissociation threshold is about 8 MeV/nucleon. We also found that the individual $^{36}$Kr atoms are more loosely bound than the $^{86}$Kr molecule, and that the $^{36}$Kr atoms are almost collision-free at the incident kinetic energy of 64 MeV/nucleon. Therefore, we conclude that the appearance of $^{88}$Rb and $^{90}$Sr in the Shinozaki et al. experiment was due to the dissociation and subsequent collisional ionization of the $^{86}$Kr molecule, and that the $^{36}$Kr atom did not contribute to the formation of the detected nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fractal analysis for sets of non-differentiability of Minkowski's\n  question mark function. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0453, "human_text": "  In this paper we study various fractal geometric aspects of the Minkowski question mark function $Q.$ We show that the unit interval can be written as the union of the three sets $\\Lambda_{0}:=\\{x:Q'(x)=0\\}$, $\\Lambda_{\\infty}:=\\{x:Q'(x)=\\infty\\}$, and $\\Lambda_{\\sim}:=\\{x:Q'(x)$ does not exist and $Q'(x)\\not=\\infty\\}.$ The main result is that the Hausdorff dimensions of these sets are related in the following way. $\\dim_{H}(\\nu_{F})<\\dim_{H}(\\Lambda_{\\sim})= \\dim_{H} (\\Lambda_{\\infty}) = \\dim_{H} (\\mathcal{L}(h_{\\mathrm{top}}))<\\dim_{H}(\\Lambda_{0})=1.$   Here, $\\mathcal{L}(h_{\\mathrm{top}})$ refers to the level set of the   Stern-Brocot multifractal decomposition at the topological entropy   $h_{\\mathrm{top}}=\\log2$ of the Farey map $F,$ and $\\dim_{H}(\\nu_{F})$ denotes the Hausdorff dimension of the measure of maximal entropy of the dynamical system associated with $F.$ The proofs rely partially on the multifractal formalism for Stern-Brocot intervals and give non-trivial applications of this formalism. ", "machine_text": "  We investigate the fractal properties of sets of non-differentiability of Minkowski's ?-function, which is known to be non-analytic and non-smooth in the plane and several complicated fractal properties of this function have been obtained in the past. In this paper, we first prove that the set of non-differentiability of the Minkowski ?-function is itself a fractal set. We show that the fractal dimension of this set is strictly between 2 and 3, which is the first strict evidence showing that the fractal dimension of the set of non-differentiability of a function on the plane has a strictly real value strictly between 2 and 3, without any looseness in the proof. Then we show that the boundary of the fractal set of non-differentiability of the Minkowski ?-function is a fractal set with the fractal dimension strictly between 2 and 3. As a by-product, we show that the boundary of the fractal set of non-differentiability of the function f(x)=x if x is rational and f(x)=0 if x is irrational is a fractal set with the fractal dimension 2.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generic Gravitational Wave Signals from the Collapse of Rotating Stellar\n  Cores: A Detailed Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2675, "human_text": "  We present detailed results from performing general relativistic (GR) simulations of stellar core collapse to a proto-neutron star, using a microphysical equation of state (EoS) as well as an approximate description of deleptonization during the collapse phase. We show that for a wide variety of rotation rates and profiles the gravitational wave (GW) burst signals from the core bounce are of a generic type, already known as Type I in the literature. In addition, for most models the characteristic frequency of the GW burst signal lies in a narrow range around approximately 718 Hz. In our systematic study, using both GR and Newtonian gravity, we identify, individually quantify, and discuss in detail the micro- and macrophysical mechanisms leading to this result, i.e. the effects of rotation, the EoS, and deleptonization. We also discuss the detectability prospects of such GW burst signals by GW detectors, and infer that such a generic type of signal templates will likely facilitate a more efficient search in current and future detectors of both interferometric and resonant type. ", "machine_text": " We consider the generic gravitational signals that would be produced by the implosion of a rotating stellar core. We find that such signals possess many of the characteristics of the gravitational signals detected by LIGO during the past two decades. In particular, we find that (i) the dominant signal frequency is roughly proportional to the inverse of the ratio of the core radius to its mass, (ii) the frequency is largely independent of the initial orbital velocity of the core, and (iii) the detected signal amplitude depends roughly on the cube of the ratio of the core radius to its mass. These findings suggest that core implosion might produce detectable gravitational signals, and could potentially be used as a probe of core properties. We find that the signal amplitude is generally too small to be detected by LIGO for reasonable core masses. However, we show that if the core is composed of a mixture of approximately equal parts of two different elements, the signal amplitude can be increased significantly. We consider several different possible core compositions, and find that a mixture of oxygen and hydrogen, or a mixture of helium and hydrogen, would produce the largest signal amplitudes. We also consider several different physical mechanisms that could potentially drive a rotating core to collapse, and find that none of them would produce a signal with the correct frequency. We conclude that the detection of generic gravitational signals from core implosion is unlikely, unless cores are composed of a mixture of two different elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in\n  hypre and PETSc. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2626, "human_text": "  We describe our software package Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as a stand-alone serial library, as an external package to PETSc (``Portable, Extensible Toolkit for Scientific Computation'', a general purpose suite of tools for the scalable solution of partial differential equations and related problems developed by Argonne National Laboratory), and is also built into {\\it hypre} (``High Performance Preconditioners'', scalable linear solvers package developed by Lawrence Livermore National Laboratory). The present BLOPEX release includes only one solver--the Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\\it hypre} provides users with advanced high-quality parallel preconditioners for linear systems, in particular, with domain decomposition and multigrid preconditioners. With BLOPEX, the same preconditioners can now be efficiently used for symmetric eigenvalue problems. PETSc facilitates the integration of independently developed application modules with strict attention to component interoperability, and makes BLOPEX extremely easy to compile and use with preconditioners that are available via PETSc. We present the LOBPCG algorithm in BLOPEX for {\\it hypre} and PETSc. We demonstrate numerically the scalability of BLOPEX by testing it on a number of distributed and shared memory parallel systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition and {\\it hypre} multigrid preconditioning. We test BLOPEX on a model problem, the standard 7-point finite-difference approximation of the 3-D Laplacian, with the problem size in the range $10^5-10^8$. ", "machine_text": " We present a simple block locally optimal preconditioned eigenvalue (BLOPEX) method for solving large symmetric eigenvalue problems in hypre and PETSc. Our approach is motivated by the observation that the standard Generalized Minimum Residual method for eigenvalue problems can be made more robust by combining it with a simple block preconditioner that is optimal in a local sense. We show that such a preconditioner can be constructed by combining a general singular value decomposition algorithm with the diagonal of the input matrix, and that this preconditioner can then be used to define a simple but robust eigenvalue solver. In addition, we show that this eigenvalue solver can be made even more robust by using an approximate inverse of the preconditioner as the block preconditioner. We implement our BLOPEX method in hypre and PETSc, and we evaluate its performance on a wide range of eigenvalue problems. Our results show that BLOPEX can be used to solve very large eigenvalue problems, and that it is both robust and efficient.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 4U 0115+63 from RXTE and INTEGRAL Data: Pulse Profile and Cyclotron Line\n  Energy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2874, "human_text": "  We analyze the observations of the transient X-ray pulsar 4U 0115+63 with the RXTE and INTEGRAL observatories in a wide X-ray (3-100 keV) energy band during its intense outbursts in 1999 and 2004. The energy of the fundamental harmonic of the cyclotron resonance absorption line near the maximum of the X-ray flux from the source (luminosity range 5x10^{37} - 2x10^{38} erg/s) is ~11 keV. When the pulsar luminosity falls below ~5x10^{37} erg/s, the energy of the fundamental harmonic is displaced sharply toward the high energies, up to ~16 keV. Under the assumption of a dipole magnetic field configuration, this change in cyclotron harmonic energy corresponds to a decrease in the height of the emitting region by ~2 km, while other spectral parameters, in particular, the cutoff energy, remain essentially constant. At a luminosity ~7x10^{37} erg/s, four almost equidistant cyclotron line harmonics are clearly seen in the spectrum. This suggests that either the region where the emission originates is compact or the emergent spectrum from different (in height) segments of the accretion column is uniform. We have found significant pulse profile variations with energy, luminosity, and time. In particular, we show that the profile variations from pulse to pulse are not reduced to a simple modulation of the accretion rate specified by external conditions. ", "machine_text": "  We present observations of the transient source 4U 0115+63 from the Rossi X-ray Timing Explorer (RXTE) and the INTEGRAL Observatory. We use the RXTE observations to construct a pulse profile, and we extract the cyclotron line from the INTEGRAL observation. The source is found to be a compact object with a power law spectrum and a radius of curvature of 1.6 kpc. The transient nature of the source is confirmed by the pulse profile, which shows a exponential decay in the power law index during the observed period. The cyclotron line is well described by a three-component model. The high energy component can be described by an adiabatic expansion model, while the low energy component is best described by a model with two temperature intervals. The broad line component is best described by a model with a large number of emitting regions at different temperatures and with different line-of-sight velocities. The high energy emitting region is probably accreting matter at a very high rate, and has a large number of electrons in the inner edge of the accretion disc. We estimate that the mass of the accreting object is 3-10 times the mass of the Sun. The low energy emitting region has a mass of order of one solar mass. We suggest that the broad line component may be due to a large number of low mass X-ray binaries (LMXBs) in a wide orbit around the object, and that the high energy component may be due to the motion of the LMXBs as they orbit the massive object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Incoherent non-Fermi liquid scattering in a Kondo lattice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2592, "human_text": "  One of the most notorious non-Fermi liquid properties of both archetypal heavy-fermion systems [1-4] and the high-Tc copper oxide superconductors [5] is an electrical resistivity that evolves linearly with temperature, T. In the heavy-fermion superconductor CeCoIn5 [5], this linear behaviour was one of the first indications of the presence of a zero-temperature instability, or quantum critical point. Here, we report the observation of a unique control parameter of T-linear scattering in CeCoIn5, found through systematic chemical substitutions of both magnetic and non-magnetic rare-earth, R, ions into the Ce sub-lattice. We find that the evolution of inelastic scattering in Ce1-xRxCoIn5 is strongly dependent on the f-electron configuration of the R ion, whereas two other key properties -- Cooper-pair breaking and Kondo-lattice coherence -- are not. Thus, T-linear resistivity in CeCoIn5 is intimately related to the nature of incoherent scattering centers in the Kondo lattice, which provides insight into the anomalous scattering rate synonymous with quantum criticality [7]. ", "machine_text": " We have performed a systematic angle-resolved photoemission study of the non-Fermi liquid (NFL) state in a Kondo lattice, an antiferromagnetic system with a strong spin-orbit coupling and a small moment per site. The non-Fermi liquid state is induced by a perpendicular magnetic field applied along the antiferromagnetic direction. Our aim was to understand the origin of the incoherent, low-temperature scattering, which was observed in the NFL state, by investigating the role of the spin-orbit coupling and the lattice structure. We found that the spin-orbit coupling, which distorts the lattice and breaks the time-reversal symmetry, gives rise to a significant increase in the scattering amplitude. In addition, the local moment per site and the existence of a finite number of magnetic ions in the lattice play a crucial role in the emergence of the incoherent, low-temperature scattering. Our results suggest that the incoherent scattering in the non-Fermi liquid state is a generic feature of lattices with a strong spin-orbit coupling and a small moment per site, and that it is closely related to the lattice symmetry and the local moment per site.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Computer simulation of model cohesive powders: influence of assembling\n  procedure and contact laws on low consolidation states. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3295, "human_text": "  The structure and mechanical properties of a simple two-dimensional model of a cohesive powder are investigated by molecular dynamics simulations. Micromechanical ingredients involve elasticity, friction, a short range attraction and, possibly, rolling resistance (RR) in contacts. The microstructure of the cohesive packing varies according to the assembling procedure, from rather densely packed if isolated particles are directly compressed to much looser if the formation of large aggregates is allowed prior to compression. A crucial parameter is the ratio P*= Pa/F0 of applied pressure P, acting on grains of diameter $a$, to maximum tensile contact force F0. At low P* the final structure depends on the level of velocity fluctuations at the early stages of cluster aggregation. With RR the coordination number approaches 2 in the limit of low initial velocities or large rolling friction. The force network generally comprises small hyperstatic clusters with forces of the order of F0, joined by nearly unstressed, barely rigid arms. As P* grows, it quickly rearranges into force chain-like patterns. Density correlations witness a fractal structure, with dimension Df, up to some density-dependent blob size. WIth RR Df coincides with the ballistic aggregation result, despite a possibly different connectivity. Possible effects of some parameters on material strength are evoked. ", "machine_text": "  We present a systematic investigation of the effects of different contact laws and assembling procedures on the structure and mechanical properties of model cohesive powders. We use a simple and robust algorithm to generate initial particles and combine this with different contact models and consolidation strategies. We show that the choice of contact model has a strong influence on the resulting density and structural properties of the powder. For the simple hard-sphere model, we observe that the contact model has little influence on the final density, while for the more realistic Cohesive Wax model, the choice of contact model has a significant effect on the density and the stress/strain curve. We also find that different assembling procedures can produce powders with very different mechanical properties, in particular for the Cohesive Wax model. Our results suggest that in order to obtain a reliable prediction of the mechanical behavior of cohesive powders, a detailed understanding of the evolution of the contact network during the assembling process is crucial.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Many-to-One Throughput Capacity of IEEE 802.11 Multi-hop Wireless\n  Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0528, "human_text": "  This paper investigates the many-to-one throughput capacity (and by symmetry, one-to-many throughput capacity) of IEEE 802.11 multi-hop networks. It has generally been assumed in prior studies that the many-to-one throughput capacity is upper-bounded by the link capacity L. Throughput capacity L is not achievable under 802.11. This paper introduces the notion of \"canonical networks\", which is a class of regularly-structured networks whose capacities can be analyzed more easily than unstructured networks. We show that the throughput capacity of canonical networks under 802.11 has an analytical upper bound of 3L/4 when the source nodes are two or more hops away from the sink; and simulated throughputs of 0.690L (0.740L) when the source nodes are many hops away. We conjecture that 3L/4 is also the upper bound for general networks. When all links have equal length, 2L/3 can be shown to be the upper bound for general networks. Our simulations show that 802.11 networks with random topologies operated with AODV routing can only achieve throughputs far below the upper bounds. Fortunately, by properly selecting routes near the gateway (or by properly positioning the relay nodes leading to the gateway) to fashion after the structure of canonical networks, the throughput can be improved significantly by more than 150%. Indeed, in a dense network, it is worthwhile to deactivate some of the relay nodes near the sink judiciously. ", "machine_text": "  We investigate the many-to-one throughput capacity of IEEE 802.11 multi-hop wireless networks. In contrast to single-hop networks, where the many-to-one throughput capacity grows proportionally with the number of nodes, the many-to-one throughput capacity of multi-hop networks has a far more complicated growth behavior. We show that the many-to-one throughput capacity of multi-hop networks has a super-exponential growth with the number of nodes when the number of hops is fixed and the wireless link errors are independent and identically distributed. The many-to-one throughput capacity is shown to have a sub-exponential growth with the number of nodes when the number of hops is allowed to vary and/or the wireless link errors are not independent and identically distributed. We also investigate the asymptotic behavior of the many-to-one throughput capacity when the network size grows large and the hops-to-node ratio is fixed. Our results show that the many-to-one throughput capacity is not a sharp threshold, as was previously believed, but a gradual function of the number of nodes. In practical multi-hop networks, the many-to-one throughput capacity is often limited by the finite buffer size in intermediate nodes. We analyze the effect of the buffer size on the many-to-one throughput capacity and show that a sufficient large buffer size is critical to achieve a high many-to-one throughput capacity. We also propose a simple scheme to achieve a high many-to-one throughput capacity in multi-hop networks. simulation results show that our proposed scheme can significantly increase the many-to-one throughput capacity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Towards the optimal window for the 2MASS dipole. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0619, "human_text": "  A comparison of the 2MASS flux dipole to the CMB dipole can serve as a method to constrain a combination of the cosmological parameter Omega_m and the luminosity bias of the 2MASS survey. For this constraint to be as tight as possible, it is necessary to maximize the correlation between the two dipoles. This can be achieved by optimizing the survey window through which the flux dipole is measured. Here we explicitly construct such a window for the 2MASS survey. The optimization in essence reduces to excluding from the calculation of the flux dipole galaxies brighter than some limiting magnitude K_min of the near-infrared K_s band. This exclusion mitigates nonlinear effects and shot noise from small scales, which decorrelate the 2MASS dipole from the CMB dipole. Under the assumption of negligible shot noise we find that the optimal value of K_min is about five. Inclusion of shot noise shifts the optimal K_min to larger values. We present an analytical formula for shot noise for the 2MASS flux dipole, to be used in follow-up work with 2MASS data.   The misalignment angle between the two dipoles is a sensitive measure of their correlation: the higher the correlation, the smaller the expectation value of the angle. A minimum of the misalignment is thus a sign of the optimal gravity window. We model analytically the distribution function for the misalignment angle and show that the misalignment estimated by Maller et al. is consistent with the assumed underlying model (though it is greater than the expectation value). We predict with about 90% confidence that the misalignment will decrease if 2MASS galaxies brighter than K_min = 5 mag are excluded from the calculation of the flux dipole. This prediction has been indirectly confirmed by the results of Erdogdu et al. (ABRIDGED) ", "machine_text": "  We present a simple, general method for finding the optimal window for detecting a point source in a spherical harmonic decomposition of a galaxy, as well as the corresponding optimal two-point function window. The method is applied to the problem of detecting the 2MASS dipole in the Galactic potential, using the Cl(...)20mg photographic survey. The analysis is performed in the basis set of the density field, using theKick (!) aperture to determine the optimal detection window. We find that the optimal window is sensitive to the radial aperture, but relatively insensitive to the angular aperture. The optimal window is quite large, and can be approximated by a single shell around the true dipole, with a width of about 60 degrees. We find that a good approximation to the optimal window can be found by assuming that the magnitude of the source is proportional to the local galaxy density, and that the detectability is inversely proportional to the square of the local galaxy density. We show that this approximation is accurate to within a few percent for detectabilities above 4sigma. The optimal window for the two-point function is found by a similar method, and we find that the optimal separation for the 2MASS-redshift experiment is about 1 kpc, independent of the radial aperture used to extract the spherical harmonic decomposition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Orbifoldes speciales et classification bimeromorphe des varietes\n  kaehleriennes compactes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0737, "human_text": "  This is a sequel to [Ca01]=math.AG/0110051. We define the bimeromorphic {\\it category} of geometric orbifolds. These interpolate between (compact K\\\" ahler) manifolds and such manifolds with logarithmic structure. These geometric orbifolds are considered from the point of view of their geometry, and thus equipped with the usual invariants of varieties: morphisms and bimeromorphic maps, differential forms, fundamental groups and universal covers, fields of definition and rational points. The most elementary properties, directly adapted from the case of varieties without orbifold structure, are established here. The arguments of [Ca01] can then be directly adapted to extend the main structure results to this orbifold category. We hope to come back to deeper aspects later. The motivation is that the natural frame for the theory of classification of compact K\\\" ahler (and complex projective) manifolds includes at least the category of orbifolds, as shown in [Ca01] by the fonctorial decomposition of {\\it special} manifolds as tower of orbifolds with either $\\kappa_+=-\\infty$ or $\\kappa=0$, and also, seemingly, by the minimal model program, in which most proofs work only after the adjunction of a \"boundary\".   Also, fibrations enjoy in the bimeromorphic category of geometric orbifolds extension properties not satisfied in the category of varieties without orbifold structure, permitting to express invariants of the total space from those of the generic fibre and of the base. For example, the natural sequence of fundamental groups is exact there; also the total space is special if so are the generic fibre and the base. This makes this category suitable to lift properties from orbifolds having either $\\kappa_+=-\\infty$ or $\\kappa=0$ to those which are special. ", "machine_text": " Orbifoldes speciales et classification bimeromorphe des varietes kaehleriennes compactes. Cette memoire traite les orbifoldes speciales, dont l'immuable contour entra\u00eene un changement de symmetry, et propose une classification bimeromorphe des vari\u00e9t\u00e9s kaehleriennes compactes. On peut finder le Gone la Grassmannian d'un certain point de l'espace grassesniain, qui est alors isomorphe \u00e0 un certain Claude\u2013Shafarevich sur l'immuable contour. On s'int\u00e9ressera donc \u00e0 la structure des orbifoldes speciales, notamment au fait que certains sont isomorphe \u00e0 un special domaine de $SL_2({\\bf C})$. On s'appuie sur une description \u00e9tale des orbifoldes speciales par certains FAAG-manifolds. Ensuite, on classify les vari\u00e9t\u00e9s kaehleriennes compactes de certains orbifoldes speciales. On peut moreover retrouver certains galaxies isomorphe \u00e0 l'immuable contour. C'est un probl\u00e8me trait\u00e9 plus \u00e9tudiant que les orbifoldes speciales, mais n\u00e9 sur pas mal de d\u00e9veloppements motiviques. On a alors le cas k\u00e4hleriennes cians \u00e0 certains points de l'espace grassesniain, et pour certains elements de l'ordre stable sur l'immuable contour.  We consider the structure of special orbifolds and the classification of compact K\u00e4hler varieties of special orbifolds. We show that certain special orbifolds are isomorphic to certain FAAG-manifolds, and that every special orbifold can be obtained as an orbit fold of a special orbifold. We show that certain special orbifolds are isomorphic to certain SL2-IR-manifolds. As an application, we show that certain stable elements of the B-metric can be recovered from special orbifolds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anonymity in the Wild: Mixes on unstructured networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.043, "human_text": "  As decentralized computing scenarios get ever more popular, unstructured topologies are natural candidates to consider running mix networks upon. We consider mix network topologies where mixes are placed on the nodes of an unstructured network, such as social networks and scale-free random networks. We explore the efficiency and traffic analysis resistance properties of mix networks based on unstructured topologies as opposed to theoretically optimal structured topologies, under high latency conditions. We consider a mix of directed and undirected network models, as well as one real world case study -- the LiveJournal friendship network topology. Our analysis indicates that mix-networks based on scale-free and small-world topologies have, firstly, mix-route lengths that are roughly comparable to those in expander graphs; second, that compromise of the most central nodes has little effect on anonymization properties, and third, batch sizes required for warding off intersection attacks need to be an order of magnitude higher in unstructured networks in comparison with expander graph topologies. ", "machine_text": "  We are motivated by the recent phenomenon of social and information networks, which has received significant attention from the research community and the industry. In particular, we focus on networks where the links do not have associated weights, and therefore, the graph is said to be unstructured. We study the problem of anonymity on unstructured networks. We define anonymity as the property that, for each link, the removal of that link does not change the number of anonymous nodes. We show that anonymity is a generic property of networks, in the sense that it is preserved by a large class of graph operations. We use this fact to characterize anonymity on unstructured networks. We find that the largest anonymous subgraph has a large number of components, and that the average degree of the nodes in this subgraph is small. We show that this result is tight in a sense that, if we consider a particular class of operations that preserve anonymity, the largest anonymous subgraph has the same number of components and the average degree is the same. We complement our study with an experimental investigation of anonymity on real-world networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SDSS J080531.84+481233.0: An Unresolved L Dwarf/T Dwarf Binary. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1965, "human_text": "  SDSS J080531.84+481233.0 is a peculiar L-type dwarf that exhibits unusually blue near-infrared and mid-infrared colors and divergent optical (L4) and near-infrared (L9.5) spectral classifications. These peculiar spectral traits have been variously attributed to condensate cloud effects or subsolar metallicity. Here I present an improved near-infrared spectrum of this source which further demonstrates the presence of weak CH4 absorption at 1.6 micron but no corresponding band at 2.2 micron. It is shown that these features can be collectively reproduced by the combined light spectrum of a binary with L4.5 and T5 components, as deduced by spectral template matching. Thus, SDSS J080531.84+481233.0 appears to be a new low-mass binary straddling the L dwarf/T dwarf transition, an evolutionary phase for brown dwarfs that remains poorly understood by current theoretical models. The case of SDSS J080531.84+481233.0 further illustrates how a select range of L dwarf/T dwarf binaries could be identified and characterized without the need for high angular resolution imaging or radial velocity monitoring, potentially alleviating some of the detection biases and limitations inherent to such techniques. ", "machine_text": "  We present photometric observations of the unique system SDSS J080531.84+481233.0 (hereafter J0805) in the course of four years, which show it to be a close binary consisting of an unresolved L dwarf and a T dwarf in a retrograde orbit. This is the first such system to be discovered. The two components are of similar brightness, which precludes resolving the system with current technology. We find that the orbital period is 1.14 \u00b1 0.09 days, the orbital eccentricity is 0.31 \u00b1 0.04, and the orbital inclination is 124.3 \u00b1 1.5 deg. We compute the masses of the two components to be 1.34 \u00b1 0.07 M\u2299 and 1.00 \u00b1 0.05 M\u2299 (both in the solar mass range), and the radii to be 1.63 \u00b1 0.02 R\u2299 and 1.25 \u00b1 0.01 R\u2299 (measured in solar radii). We estimate the age to be roughly 2 Gyr. We find that the T dwarf has a higher effective temperature than the L dwarf by about 3 kK, a difference that is not sufficient to account for the discrepancy in the observed radii. The spectral types of the two components are in agreement with the definition of the T dwarf spectral class in the former rather than the latter sense, with a spectral type of T6 \u00b1 1 (M6 in the old scheme) for the L dwarf and T7 \u00b1 1 (M7 in the old scheme) for the T dwarf. We estimate the metallicity to be [Fe/H] \u2248 +0.1 for the L dwarf and [Fe/H] \u2248 \u22120.5 for the T dwarf, both in agreement with the solar ratio. We discuss the possible evolutionary history of this and similar systems, and the orbital and physical properties of such systems in general.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Aspects of stochastic resonance in reaction-diffusion systems: The\n  nonequilibrium-potential approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1148, "human_text": "  We analyze several aspects of the phenomenon of stochastic resonance in reaction-diffusion systems, exploiting the nonequilibrium potential's framework. The generalization of this formalism (sketched in the appendix) to extended systems is first carried out in the context of a simplified scalar model, for which stationary patterns can be found analytically. We first show how system-size stochastic resonance arises naturally in this framework, and then how the phenomenon of array-enhanced stochastic resonance can be further enhanced by letting the diffusion coefficient depend on the field. A yet less trivial generalization is exemplified by a stylized version of the FitzHugh-Nagumo system, a paradigm of the activator-inhibitor class. After discussing for this system the second aspect enumerated above, we derive from it -through an adiabatic-like elimination of the inhibitor field- an effective scalar model that includes a nonlocal contribution. Studying the role played by the range of the nonlocal kernel and its effect on stochastic resonance, we find an optimal range that maximizes the system's response. ", "machine_text": "  We propose a nonequilibrium-potential approach to the study of stochastic resonance in reaction-diffusion systems. Stochastic resonance is an interesting phenomenon, which is related to the ability of a dynamical system to amplify weak, random signals. We consider the problem of stochastic resonance in a simple reaction-diffusion model with a nonlinear potential. The analysis is performed by a combination of exact, semi-analytical methods and numerical simulations. We find that the dynamics of the model is characterized by two types of stochastic resonance: a conventional type, which is related to the Hopfield resonance, and an unusual, `` diffusion-controlled '' type, which is associated with a transition to a random Walk-like behavior. We also find a new type of behavior: a resonance-like enhancement of the response to a deterministic input, which is due to the presence of a strong, quadratic potential term in the dynamical equation. Our analysis shows that the different types of resonance are related to the symmetry of the potential function and to the way the resonance is excited. The results are explained in terms of a general theory of stochastic resonance, which is based on the concept of the nonequilibrium potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radio Through X-ray Spectral Energy Distributions of 38 Broad Absorption\n  Line Quasars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0538, "human_text": "  We have compiled the largest sample of multiwavelength spectral energy distributions (SEDs) of Broad Absorption Line (BAL) quasars to date, from the radio to the X-ray. We present new Spitzer MIPS (24, 70, and 160 micron) observations of 38 BAL quasars in addition to data from the literature and public archives. In general, the mid-infrared properties of BAL quasars are consistent with those of non-BAL quasars of comparable luminosity. In particular, the optical-to-mid-infrared luminosity ratios of the two populations are indistinguishable. We also measure or place upper limits on the contribution of star formation to the far-infrared power. Of 22 (57%) upper limits, seven quasars have sufficiently sensitive constraints to conclude that star formation likely contributes little (<20%) to their far-infrared power. The 17 BAL quasars (45%) with detected excess far-infrared emission likely host hyperluminous starbursts with L_fir,SF=10^{13-14} L_sun. Mid-infrared through X-ray composite BAL quasar SEDs are presented, incorporating all of the available photometry. Overall, we find no compelling evidence for inherent differences between the SEDs of BAL vs. non-BAL quasars of comparable luminosity. Therefore a ``cocoon'' picture of a typical BAL quasar outflow whereby the wind covers a large fraction of the sky is not supported by the mid-infrared SED comparison with normal quasars, and the disk-wind paradigm with a typical radio-quiet quasar hosting a BAL region remains viable. ", "machine_text": "  We present radio spectral energy distributions for 38 broad absorption line (BAL) quasars in the 1.4 < z < 2.2 interval, drawn from a larger sample of 44 quasars. The quasars in our sample have rest frame 6.2 < log(O/H) < 7.2,log(O2/H2) < 1.5, and do not show strong evidence of dust obscuration. We present the radio intensity as a function of frequency and compare the radio spectral energy distribution (R-SED) for quasars with strong and weak BALs. We find that the shape of the R-SED depends sensitively on the strength of the BAL. The R-SEDs for quasars with strong BALs resemble those of broad absorption line galaxies (BALGs), displaying a power law with a break at a frequency that depends on the quasar redshift and optical luminosity. In contrast, the R-SEDs for quasars with weak BALs have a different shape, with a break at a higher frequency. We discuss two possible physical mechanisms that could produce these different R-SED shapes. The R-SEDs for both strong and weak BAL quasars are well described by a single power law with a break at a frequency fbreak = (1.2 \u00b1 1.3) GHz, which is independent of the strength of the BAL, the quasar redshift, or the optical luminosity. The R-SEDs for all quasars in our sample, including those with the weakest BALs, have a common shape with a break at fbreak, suggesting that this shape may be universal for quasars with oxygen abundances characteristic of galactic starbursts. This has implications for models of radio emission from galactic objects, where the break frequency is typically assumed to be universal and determined only by the proton temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Atomic force microscopy (AFM) study of thick lamellar stacks of\n  phospholipid bilayers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0196, "human_text": "  We report an Atomic Force Microscopy (AFM) study on thick multi lamellar stacks of approx. 10 mum thickness (about 1500 stacked membranes) of DMPC (1,2-dimyristoyl-sn-glycero-3-phoshatidylcholine) deposited on silicon wafers. These thick stacks could be stabilized for measurements under excess water or solution. From force curves we determine the compressional modulus B and the rupture force F_r of the bilayers in the gel (ripple), the fluid phase and in the range of critical swelling close to the main transition. AFM allows to measure the compressional modulus of stacked membrane systems and values for B compare well to values reported in the literature. We observe pronounced ripples on the top layer in the Pbeta' (ripple) phase and find an increasing ripple period Lambda_r when approaching the temperature of the main phase transition into the fluid Lalpha phase at about 24 C. Metastable ripples with 2Lambda_r are observed. Lambda_r also increases with increasing osmotic pressure, i.e., for different concentrations of polyethylene glycol (PEG). ", "machine_text": "  Atomic force microscopy (AFM) study of thick lamellar stacks of phospholipid bilayers  The packing and organization of biological molecules in artificial lipid bilayers is important to understand the mechanisms of cell membranes, the basis of the liposomal drug delivery systems, and the self-assembly of lipids. We used atomic force microscopy (AFM) to image the structure of thick lamellar stacks of lipid bilayers formed by the lipid mixtures of DSPC (1,2-distearoyl-sn-glycero-3-phosphocholine) and DPPG (1,2-dipalmitoyl-sn-glycero-3-phospho-rac-(1-glycerol)). In this system, DSPC and DPPG were in a 3:1 ratio, and the final lipid concentration was 5 mg/ml. We used a Department of Defense AFM with a probe scanner, a Nanosensors NCLAS cantilever with a single-walled carbon nanotube tip, and a fluid cell for AFM imaging in a liquid environment. The images showed that the phospholipid molecules were packed in a lateral orientation, forming a series of layers along the fast scan direction. The distance between the layers was approximately 4 nm, corresponding to the thickness of a single lipid bilayer. The number of layers was larger in the middle of the image, where the structure was more compact and had a higher height, and it gradually decreased toward the edges, where the structure was more open and had a lower height. The difference in height between the compact region and the open region was approximately 2 nm, which was equivalent to the length of a single lipid molecule. The fast scan direction of the image was coincident with the long axis of the lipid molecules, which were highly ordered in the lateral direction. Our results showed that the lipid molecules were packed in a series of ordered layers and the packing was highly dependent on the distribution of molecules.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space\n  simulation study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0556, "human_text": "  A real-space quantum transport simulator for carbon nanoribbon (CNR) MOSFETs has been developed. Using this simulator, the performance of carbon nanoribbon (CNR) MOSFETs is examined in the ballistic limit. The impact of quantum effects on device performance of CNR MOSFETs is also studied. We found that 2D semi-infinite graphene contacts provide metal-induced-gap-states (MIGS) in the CNR channel. These states would provide quantum tunneling in the short channel device and cause Fermi level pining. These effects cause device performance degradation both on the ON-state and the OFF-state. Pure 1D devices (infinite contacts), however, show no MIGS. Quantum tunneling effects are still playing an important role in the device characteristics. Conduction due to band-to-band tunneling is accurately captured in our simulations. It is important in these devices, and found to dominate the off-state current. Based on our simulations, both a 1.4nm wide and a 1.8nm wide CNR with channel length of 12.5nm can outperform ultra scaled Si devices in terms of drive current capabilities and electrostatic control. Although subthreshold slopes in the forward-bias conduction are better than in Si transistors, tunneling currents are important and prevent the achievement of the theoretical limit of 60mV/dec. ", "machine_text": " Ballistic Graphene Nanoribbon MOSFETs: a full quantum real-space simulation study  We present a comprehensive study of the electronic transport properties of ballistic graphene nanoribbon metal-oxide-semiconductor field-effect transistors (MOSFETs) using a full quantum real-space simulation technique. We consider the effect of the transverse size of the graphene nanoribbons on the electronic transport properties of the MOSFETs in the ballistic regime. Our simulation results show a clear and systematic change in the electronic transport properties in response to the transverse size of the graphene nanoribbons. In particular, we find that the ballistic transport regime can be significantly extended by reducing the transverse size of the graphene nanoribbons, and that a unique sub-ballistic transport regime, which cannot be achieved in conventional MOSFETs, can be achieved by further reducing the transverse size of the graphene nanoribbons. We also find that the sub-ballistic transport regime can be probed by adjusting the gate voltage, and that the ballistic and sub-ballistic transport regimes can be seamlessly and simultaneously achieved in the same device by tuning the transverse size of the graphene nanoribbons and the gate voltage. Our findings provide a clear and systematic design guideline for the future development of ballistic graphene nanoribbon MOSFETs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Use of ITIL for Process Optimisation in the IT Service Centre of\n  Harz University, exemplified in the Release Management Process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2351, "human_text": "  This paper details the use of the IT Infrastructure Library Framework (ITIL) for optimising process workflows in the IT Service Centre of Harz University in Wernigerode, Germany, exemplified by the Release Management Process. It is described, how, during the course of a special ITIL project, the As-Is-Status of the various original processes was documented as part of the process life cycle and then transformed in the To-Be-Status, according to the ITIL Best Practice Framework. It is also shown, how the ITIL framework fits into the four-layered-process model, that could be derived from interviews with the universities IT support staff, and how the various modified processes interconnect with each other to form a value chain. The paper highlights the final results of the project and gives an outlook on the future use of ITIL as a business modelling tool in the IT Service Centre of Harz University. It is currently being considered, whether the process model developed during the project could be used as a reference model for other university IT centres. ", "machine_text": "  We are witnessing a fundamental change in the way IT services are delivered, with a shift from a linear, plan-driven approach to a more agile, service-oriented approach. The move towards agile service management has been motivated by the need to respond more quickly to changing business needs and to improve the overall quality of IT services.  In this paper, we present a case study of the use of ITIL for process optimisation in the IT service centre of a German university. The case study focuses on the release management process, which is responsible for the deployment of new software releases to the university's IT infrastructure. We describe the current state of the release management process and the challenges that the process faces. We then present our approach to process optimisation, which involves the use of ITIL best practices and the implementation of a new tool for managing software releases.  Our results show that the use of ITIL for process optimisation can lead to significant improvements in the efficiency and effectiveness of IT service delivery. In particular, we found that the implementation of a new tool for managing software releases significantly reduced the effort required to deploy new software releases and improved the overall quality of the releases. We also found that the use of ITIL best practices helped to improve the documentation and communication of the release management process, which in turn led to better coordination and collaboration between the various stakeholders involved in the process.  In conclusion, we believe that the use of ITIL for process optimisation can be a valuable tool for improving the efficiency and effectiveness of IT service delivery. However, it is important to remember that process optimisation is an ongoing effort, and that the use of ITIL should be adapted to the specific needs and requirements of the organisation in question.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A study of the $p d \\to p d \\eta$ reaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.153, "human_text": "  A study of the $p d \\to p d \\eta$ reaction in the energy range where the recent data from Uppsala are available, is done in the two-step model of $\\eta$ production including the final state interaction. The $\\eta -d$ final state interaction is incorporated through the solution of the Lippmann Schwinger equation using an elastic scattering matrix element, $T_{\\eta d \\to \\eta d}$, which is required to be half off-shell. It is written in a factorized form, with an off-shell form factor multiplying an on-shell part given by an effective range expansion up to the fourth power in momentum. The parameters of this expansion have been taken from an existing recent relativistic Faddeev equation solution for the $\\eta NN$ system corresponding to different $\\eta-N$ scattering amplitudes. Calculations have also been done using few body equations within a finite rank approximation (FRA) to generate $T_{\\eta d \\to \\eta d}$. The $p-d$ final state interaction is included in the spirit of the Watson-Migdal prescription by multiplying the matrix element by the inverse of the Jost function. The $\\eta-d$ interaction is found to be dominant in the region of small invariant $\\eta -d$ mass, $M_{\\eta d}$. The $p-d$ interaction enhances the cross section in the whole region of $M_{\\eta d}$, but is larger for large $M_{\\eta d}$. We find nearly isotropic angular distributions of the proton and the deuteron in the final state. All the above observations are in agreement with data. The production mechanism for the entire range of the existing data on the $p d \\to p d \\eta$ reaction seems to be dominated by the two-step model of $\\eta$ production. ", "machine_text": " We have performed a study of the $p d \\to p d \\eta$ reaction and have found that the branching ratio (BR) of this reaction is larger than the theoretical value obtained from the quasiparticle random phase approximation (QRPA) and the statistical model (SM) calculations. We have also found that the BR increases with the $p$-beam energy and that the BR has a strong energy dependence. The ratio of the BR obtained from the measured data to the BR obtained from the QRPA and the SM calculations, $BR_{data}/BR_{theory}$, has a minimum around $4 \\times 10^{-3}$ and increases rapidly for $BR_{data}$ larger than this value. We have also found that the $BR_{data}$ is in good agreement with the QRPA and the SM calculations for $BR_{data}$ less than $4 \\times 10^{-3}$. The probability distribution function (PDF) of the $\\eta$-ray intensity has a maximum at $\\eta_{ray} \\sim 1.4 \\times 10^{-3}$ MeV. We have also found that the excited states of $p$-dlium have a large contribution to the $\\eta$-ray intensity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sharp $L^p$-estimates for maximal operators associated to hypersurfaces\n  in $\\bR^3$ for $p>2.$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1006, "human_text": "  We study the boundedness problem for maximal operators $\\M$ associated to smooth hypersurfaces $S$ in 3-dimensional Euclidean space. For $p>2,$ we prove that if no affine tangent plane to $S$ passes through the origin and $S$ is analytic, then the associated maximal operator is bounded on $L^p(\\RR^3)$ if and only if $p>h(S),$ where $h(S)$ denotes the so-called height of the surface $S.$ For non-analytic finite type $S$ we obtain the same statement with the exception of the exponent $p=h(S).$ Our notion of height $h(S)$ is closely related to A. N. Varchenko's notion of height $h(\\phi)$ for functions $\\phi$ such that $S$ can be locally represented as the graph of $\\phi$ after a rotation of coordinates.   Several consequences of this result are discussed. In particular we verify a conjecture by E.M. Stein and its generalization by A. Iosevich and E. Sawyer on the connection between the decay rate of the Fourier transform of the surface measure on $S$ and the $L^p$-boundedness of the associated maximal operator $\\M$, and a conjecture by Iosevich and Sawyer which relates the $L^p$-boundedness of $\\M$ to an integrability condition on $S$ for the distance function to tangential hyperplanes, in dimension three.   In particular, we also give ess. sharp uniform estimates for the Fourier transform of the surface measure on $S,$ thus extending a result by V.N. Karpushkin from the analytic to the smooth setting and implicitly verifying a conjecture by V.I. Arnol'd in our context. ", "machine_text": "  Let $\\bR^3$ be the three-dimensional Euclidean space and let ${{\\mathcal H}}$ be the space of symmetric and positive semi-definite linear operators on $\\bR^3$. We denote by $\\Phi$ the classical Hamilton-Jacobi equation in ${{\\mathcal H}}$, that is, the equation $\\Phi(A)=\\mathrm{Tr}(AB^{-1})$ for all $B\\in {{\\mathcal H}}$. Let ${{\\mathcal M}}$ be the space of the maximal operators on $\\bR^3$, that is, the operators $T$ such that for all $x\\in \\bR^3$, $\\langle Tx, x\\rangle\\geq \\langle x, x\\rangle$. In this paper, we show that the $L^2$-norm of the maximal operator associated to a hypersurface in $\\bR^3$ is lower bounded by a constant depending only on the volume of the hypersurface and the dimension of ${{\\mathcal H}}}$. The sharp $L^2$-estimates for maximal operators associated to hypersurfaces in $\\bR^3$ has been an open problem since it was proposed by Hepp and Hankel in 1880. By employing the ideas developed in the paper, we show that the constant in the lower bound has sharp $L^2$-estimates for the special case ${{\\mathcal M}}}={\\mathcal H}^*$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of long range order. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4382, "human_text": "  A first principles analysis of order-disorder transition in alloys shows that ordering energy is a function of temperature due to thermal vibrations. The inter-nuclear potential energy term converges if zero point vibrations are incorporated and this method can replace the Ewald sum method. Core energy contributions to the ordering energy are stored exclusively in superlattice lines. The effect of electron-phonon interactions on ordering energy is of the same order of magnitude as ordering energy near transition temperatures and cannot be ignored. Ising model and variants are incorrect in explaining alloy phase transitions as they ignore the role of electron-phonon interactions without justification. A theoretical formalism that incorporates the Debye-Waller Factor component of electron-phonon interactions in electronic structure calculations already exists and must be adopted when modeling temperature dependent phenomena. It is suggested that DWF correction will account substantially for the discrepancy between experimental and theoretical ordering energy in Ni3V. Thermal vibrations alter magnetic ordering energy at finite temperatures. The role of electron-phonon interactions in alloy and magnetic phase transitions cannot be ignored and must be incorporated in all models. This will also ensure consistency with x-ray and electron diffraction (alloy transitions) and neutron diffraction (magnetic transitions) results. An isotope effect is predicted for (magnetic) phase transitions if the transition temperature is below Debye temperature. Recent observations of an isotope effect in magnetic phase transitions confirm our above conclusions and imply that the role of electron-phonon interactions must be incorporated in all theories and models of magnetism to avoid contradictions. ", "machine_text": "  We introduce a simple model that shows how long range order can emerge from a system with short range correlations. The model consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.  We analyze a simple model of statistical mechanics that consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.  We analyze a simple model of statistical mechanics that consists of a random walk on a lattice, with a spectral gap at the transition temperature. We find that long range order is fragile against violations of the assumption of independence of the random walks. We show that in the presence of correlations, long range order can be recovered by a simple renormalization group transformation, if the underlying rules of the random walk are followed. Our results suggest that long range order can be very resilient, if the correlations are not too strong and if the system is not too far from the transition temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Discovery of extreme asymmetry in the debris disk surrounding HD 15115. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0645, "human_text": "  We report the first scattered light detection of a dusty debris disk surrounding the F2V star HD 15115 using the Hubble Space Telescope in the optical, and Keck adaptive optics in the near-infrared. The most remarkable property of the HD 15115 disk relative to other debris disks is its extreme length asymmetry. The east side of the disk is detected to ~315 AU radius, whereas the west side of the disk has radius >550 AU. We find a blue optical to near-infrared scattered light color relative to the star that indicates grain scattering properties similar to the AU Mic debris disk. The existence of a large debris disk surrounding HD 15115 adds further evidence for membership in the Beta Pic moving group, which was previously argued based on kinematics alone. Here we hypothesize that the extreme disk asymmetry is due to dynamical perturbations from HIP 12545, an M star 0.5 degrees (0.38 pc) east of HD 15115 that shares a common proper motion vector, heliocentric distance, galactic space velocity, and age. ", "machine_text": "  Discovery of extreme asymmetry in the debris disk surrounding HD 15115 We present photometric detections of dust emission at 850 and 450 micron around the pre-main sequence star HD 15115. The disk is extremely asymmetric, with the emission extending approximately 30 degrees to the northwest of the star, but only 5 degrees to the southeast. The total mass of the disk is 4.0 x 10^32 kg, with a total radius of 2.1 AU, and an inner edge at 0.6 AU. We estimate the disk's thickness to be 6.2 cm. We conclude that the disk was once much more massive, with a minimum mass of 6.4 x 10^34 kg. This is a factor of more than 2 above the minimum mass necessary to form a planet the size of Jupiter. We therefore expect that this disk will collapse within approximately 2 billion years, and that any planets or planetesimals formed from this disk will be large.  We present the first detection of extreme asymmetry in the debris disk surrounding a pre-main sequence star. The disk is extremely asymmetric, with the emission extending approximately 30 degrees to the northwest of the star, but only 5 degrees to the southeast. The total mass of the disk is 4.0 x 10^32 kg, with a total radius of 2.1 AU, and an inner edge at 0.6 AU. We estimate the disk's thickness to be 6.2 cm. We conclude that the disk was once much more massive, with a minimum mass of 6.4 x 10^34 kg. This is a factor of more than 2 above the minimum mass necessary to form a planet the size of Jupiter. We therefore expect that this disk will collapse within approximately 2 billion years, and that any planets or planetesimals formed from this disk will be large.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer observations of a 24 micron shadow: Bok Globule CB190. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.224, "human_text": "  We present Spitzer observations of the dark globule CB190 (L771). We observe a roughly circular 24 micron shadow with a 70 arcsec radius. The extinction profile of this shadow matches the profile derived from 2MASS photometry at the outer edges of the globule and reaches a maximum of ~32 visual magnitudes at the center. The corresponding mass of CB190 is ~10 Msun. Our 12CO and 13CO J = 2-1 data over a 10 arcmin X 10 arcmin region centered on the shadow show a temperature ~10 K. The thermal continuum indicates a similar temperature for the dust. The molecular data also show evidence of freezeout onto dust grains. We estimate a distance to CB190 of 400 pc using the spectroscopic parallax of a star associated with the globule. Bonnor-Ebert fits to the density profile, in conjunction with this distance, yield xi_max = 7.2, indicating that CB190 may be unstable. The high temperature (56 K) of the best fit Bonnor-Ebert model is in contradiction with the CO and thermal continuum data, leading to the conclusion that the thermal pressure is not enough to prevent free-fall collapse. We also find that the turbulence in the cloud is inadequate to support it. However, the cloud may be supported by the magnetic field, if this field is at the average level for dark globules. Since the magnetic field will eventually leak out through ambipolar diffusion, it is likely that CB190 is collapsing or in a late pre-collapse stage. ", "machine_text": "  Spitzer observations of a 24 micron shadow: Bok Globule CB190 We present observations of the dust continuum and the CO(1->0) line in Bok Globule CB190, made with the Spitzer Space Telescope. These data are the first to be obtained with Spitzer for a dark cloud in the Galactic globular cluster. The cloud's distance from us is about 13 kpc. The Spitzer data are consistent with a model in which the cloud is a 'atorial' structure, with a central concentration of mass, and pressure, and a nearly isothermal outer shell. The mass of the cloud is 1.4 x 10^5 M_Sun, and the temperature is 9 K. We have found no evidence for a cold core in the cloud. The observed CO line suggests a mass-loss rate of  2 x 10^-7 M_Sun yr^-1. We have compared the observed line-centre luminosity of the CO line with predictions from a simple model, and found that the model predicts too much CO line luminosity for the mass of the cloud. We discuss this finding in the context of the 'slingshot' model for the formation of planetary systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing Explanations of the $B\\to\\phi K^*$ Polarization Puzzle. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3915, "human_text": "  $B\\to\\phi K^*$ ($\\btos$) is three separate decays, one for each polarization of the final-state vector mesons (one longitudinal, two transverse). It is observed that the fraction of transverse decays, $\\fT$, and the fraction of longitudinal decays, $\\fL$, are roughly equal: $\\fTfL \\simeq 1$, in opposition to the naive expectation that $\\fT \\ll \\fL$. If one requires a single explanation of all polarization puzzles, two possibilities remain within the standard model: penguin annihilation and rescattering. In this paper we examine the predictions of these two explanations for $\\fTfL$ in $\\btod$ decays. In $B \\to \\rho\\rho$ decays, only $\\bd \\to \\rho^0\\rho^0$ can possibly exhibit a large $\\fTfL$. In B decays related by U-spin, we find two promising possibilities: (i) $B^+ \\to K^{*0} \\rho^+$ ($\\btos$) and $B^+ \\to \\Kbar^{*0} K^{*+}$ ($\\btod$) and (ii) $\\bs \\to K^{*0} \\Kbar^{*0}$ ($\\btos$) and $\\bd \\to \\Kbar^{*0} K^{*0}$ ($\\btod$). The measurement of $\\fTfL$ in these pairs of decays will allow us to test penguin annihilation and rescattering. Finally, it is possible to distinguish penguin annihilation from rescattering by performing a time-dependent angular analysis of $\\bd \\to \\Kbar^{*0} K^{*0}$. ", "machine_text": " We present an explanation for the puzzle of the $B\\to\\phi K^*$ polarization. We show that the puzzle can be resolved by considering the structure of the helicity amplitudes. The up- and down-transmissions in the $B\\to\\phi K^*$ polarimeter experiment can be related to the amplitudes of a ' standardised' polarimeter, which has an artificial helicity of $\\pm \\frac{\\pi}{2}$ associated with the two possible circular polarizations of the incident $B$ meson. This 'standardised' polarimeter is then related to the standard $B\\to\\phi K^*$ polarimeter, with the 'standard' helicity amplitudes modified by a corrective function which depends on the helicity of the incident $B$ meson. We show that this corrective function can be related to the $B\\to\\pi K^*$ helicity amplitude. In this way the $B\\to\\phi K^*$ puzzle can be viewed as a special case of the general problem of measuring the helicity of a meson. We show that the general problem can be solved by means of a 'standardised' polarimeter, whose read-out is related to the standard polarimeter by a corrective function which depends on the helicity of the incident meson. The method is illustrated by a numerical example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Reparametrization Invariance, the controversial extraction of $\\alpha$\n  from $B\\to\\pi\\pi$ and New Physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0174, "human_text": "  The extraction of the weak phase $\\alpha$ from $B\\to\\pi\\pi$ decays has been controversial from a statistical point of view, as the frequentist vs. bayesian confrontation shows. We analyse several relevant questions which have not deserved full attention and pervade the extraction of $\\alpha$. Reparametrization Invariance proves appropriate to understand those issues. We show that some Standard Model inspired parametrizations can be senseless or inadequate if they go beyond the minimal Gronau and London assumptions: the single weak phase $\\alpha$ just in the $\\Delta I=3/2$ amplitudes, the isospin relations and experimental data. Beside those analyses, we extract $\\alpha$ through the use of several adequate parametrizations, showing that there is no relevant discrepancy between frequentist and bayesian results. The most relevant information, in terms of $\\alpha$, is the exclusion of values around $\\alpha\\sim \\pi/4$; this result is valid in the presence of arbitrary New Physics contributions to the $\\Delta I=1/2$ piece. ", "machine_text": "  We show that the weak flavor violating parameter $\\alpha$ can be extracted from the B meson final state produced in $B\\to\\pi\\pi$ collisions, in a way which is largely insensitive to the underlying theory. The extraction is based on the observation that the final state is largely invariant under reparametrization of the longitudinal momenta of the two mesons. We show that this is equivalent to the requirement that the matrix element of a fermionic operator constructed from the longitudinal momenta is conserved. We pay particular attention to the case where the reparametrization invariance is not respected, which we dub the ``controversial'' extraction of $\\alpha$ from $B\\to\\pi\\pi$. We show that such an extraction is equivalent to the assumption that the longitudinal momenta are predetermined, and that this assumption can be made without loss of generality. We show that the reparametrization invariance of the $B\\to\\pi\\pi$ final state is a strong constraint on the dynamics of the system, and can be used to derive a new relation between the $B$ and $D$ meson final states. This relation could be useful in searching for new physics in $B\\to\\pi\\pi$ collisions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The effect of stellar-mass black holes on the structural evolution of\n  massive star clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2494, "human_text": "  We present the results of realistic N-body modelling of massive star clusters in the Magellanic Clouds, aimed at investigating a dynamical origin for the radius-age trend observed in these systems. We find that stellar-mass black holes, formed in the supernova explosions of the most massive cluster stars, can constitute a dynamically important population. If a significant number of black holes are retained (here we assume complete retention), these objects rapidly form a dense core where interactions are common, resulting in the scattering of black holes into the cluster halo, and the ejection of black holes from the cluster. These two processes heat the stellar component, resulting in prolonged core expansion of a magnitude matching the observations. Significant core evolution is also observed in Magellanic Cloud clusters at early times. We find that this does not result from the action of black holes, but can be reproduced by the effects of mass-loss due to rapid stellar evolution in a primordially mass segregated cluster. ", "machine_text": "  We have developed a new method to study the dynamical evolution of massive star clusters in the presence of stellar-mass black holes (BHs). Our method is based on a set of improved secular evolution simulations, which include a realistic distribution of stellar-mass BHs in the galactic field, an improved treatment of the stellar dynamics, and an updated set of initial conditions that include the effects of the feedback from the evicted massive stars. We find that the dynamical evolution of massive star clusters is significantly affected by the presence of stellar-mass BHs, and that the clusters are able to withstand only a small perturbation by these compact objects. Our results suggest that massive star clusters can become stable reservoirs for massive stars in the galactic field, unless disturbed by a massive perturbation, such as a galactic collision. We discuss our results in the context of the recent observations of the stellar-mass BH  M87* and the implications for the dynamical evolution of massive star clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Game-Theoretic Approach to Energy-Efficient Modulation in CDMA\n  Networks with Delay QoS Constraints. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1788, "human_text": "  A game-theoretic framework is used to study the effect of constellation size on the energy efficiency of wireless networks for M-QAM modulation. A non-cooperative game is proposed in which each user seeks to choose its transmit power (and possibly transmit symbol rate) as well as the constellation size in order to maximize its own utility while satisfying its delay quality-of-service (QoS) constraint. The utility function used here measures the number of reliable bits transmitted per joule of energy consumed, and is particularly suitable for energy-constrained networks. The best-response strategies and Nash equilibrium solution for the proposed game are derived. It is shown that in order to maximize its utility (in bits per joule), a user must choose the lowest constellation size that can accommodate the user's delay constraint. This strategy is different from one that would maximize spectral efficiency. Using this framework, the tradeoffs among energy efficiency, delay, throughput and constellation size are also studied and quantified. In addition, the effect of trellis-coded modulation on energy efficiency is discussed. ", "machine_text": " We propose and analyze a game-theoretic approach to energy-efficient modulation in CDMA networks with delay QoS constraints. We consider a setting where the base stations are energy-constrained and the subscribers are delay-constrained. The base stations and the subscribers are allowed to negotiate over the modulation level to be used. We model this negotiation as a game, where the base stations and the subscribers are the players. We assume that the players are selfish and that they only care about their own utility, which we model as the respective amount of energy or delay. We show that the resulting game has a unique Nash Equilibrium (NE), which we characterize. We then analyze the performance of this NE, in terms of the energy consumption of the network and the delay suffered by the subscribers. We show that the NE achieves a near-optimal tradeoff between these two performance metrics. We also analyze the effect of different factors, such as the number of players, the types of players, and the initial conditions, on the outcome of the game. Finally, we discuss the practical implications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bayesian reconstruction of the cosmological large-scale structure:\n  methodology, inverse algorithms and numerical optimization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0429, "human_text": "  We address the inverse problem of cosmic large-scale structure reconstruction from a Bayesian perspective. For a linear data model, a number of known and novel reconstruction schemes, which differ in terms of the underlying signal prior, data likelihood, and numerical inverse extra-regularization schemes are derived and classified. The Bayesian methodology presented in this paper tries to unify and extend the following methods: Wiener-filtering, Tikhonov regularization, Ridge regression, Maximum Entropy, and inverse regularization techniques. The inverse techniques considered here are the asymptotic regularization, the Jacobi, Steepest Descent, Newton-Raphson, Landweber-Fridman, and both linear and non-linear Krylov methods based on Fletcher-Reeves, Polak-Ribiere, and Hestenes-Stiefel Conjugate Gradients. The structures of the up-to-date highest-performing algorithms are presented, based on an operator scheme, which permits one to exploit the power of fast Fourier transforms. Using such an implementation of the generalized Wiener-filter in the novel ARGO-software package, the different numerical schemes are benchmarked with 1-, 2-, and 3-dimensional problems including structured white and Poissonian noise, data windowing and blurring effects. A novel numerical Krylov scheme is shown to be superior in terms of performance and fidelity. These fast inverse methods ultimately will enable the application of sampling techniques to explore complex joint posterior distributions. We outline how the space of the dark-matter density field, the peculiar velocity field, and the power spectrum can jointly be investigated by a Gibbs-sampling process. Such a method can be applied for the redshift distortions correction of the observed galaxies and for time-reversal reconstructions of the initial density field. ", "machine_text": " We present a new Bayesian methodology for the reconstruction of the large-scale structure of the Universe from galaxy redshift surveys. Our method is based on a hierarchical Bayes model that allows us to infer the underlying large-scale structure at the same time as we fit the observed galaxies to this structure. We show that this method provides a more natural way to infer the large-scale structure than the classical linear inversion method. Our new approach results in a highly non-linear optimization problem, and we present an efficient numerical method to solve this optimization problem. We apply our method to the case of the large-scale structure induced by a Gaussian random field. We show that our method is as efficient as the standard linear method, but that it is much more robust with respect to the choice of the prior and the observed galaxies. We finally discuss the generalization of our method to more complex models, and the implications of our method for the determination of the parameters of the model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Surprising Reversal of Temperatures in the Brown-Dwarf Eclipsing\n  Binary 2MASS J05352184-0546085. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3106, "human_text": "  The newly discovered brown-dwarf eclipsing binary 2MASS J05352184-0546085 provides a unique laboratory for testing the predictions of theoretical models of brown-dwarf formation and evolution. The finding that the lower-mass brown dwarf in this system is hotter than its higher-mass companion represents a challenge to brown-dwarf evolutionary models, none of which predict this behavior. Here we present updated determinations of the basic physical properties of 2M0535-05, bolstering the surprising reversal of temperatures with mass in this system. We compare these measurements with widely used brown-dwarf evolutionary tracks, and find that the temperature reversal can be explained by some models if the components of 2M0535-05 are mildly non-coeval, possibly consistent with dynamical simulations of brown-dwarf formation. Alternatively, a strong magnetic field on the higher-mass brown dwarf might explain its anomalously low surface temperature, consistent with emerging evidence that convection is suppressed in magnetically active, low-mass stars. Finally, we discuss future observational and theoretical work needed to further characterize and understand this benchmark system. ", "machine_text": " We present photometric observations of the brown-dwarf eclipsing binary 2MASS J05352184-0546085, which show a surprising reversal of temperatures in the primary and secondary components. The system consists of a +62\u00b0C brown dwarf with a mass of 73 MJup, and a \u221234\u00b0C brown dwarf with a mass of 50 MJup. We observe the system in photometric twilight, when the brighter object is occulted by the cooler object. The system has been observed with the 2MASS survey, the Magellan Telescopes, and the Very Large Array. We find that the masses of the two brown dwarfs are too close to be explained by a single mass model in which the masses are equal. This suggests that the system must have formed through the fragmentation of a single object, with the two fragments having very different temperatures. This is the first system in which a significant change in temperature between components has been detected, and the first demonstration that brown-dwarf binaries can be formed by the fragmentation of a single object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anomalous structural and mechanical properties of solids confined in\n  quasi one dimensional strips. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3135, "human_text": "  We show using computer simulations and mean field theory that a system of particles in two dimensions, when confined laterally by a pair of parallel hard walls within a quasi one dimensional channel, possesses several anomalous structural and mechanical properties not observed in the bulk. Depending on the density $\\rho$ and the distance between the walls $L_y$, the system shows structural characteristics analogous to a weakly modulated liquid, a strongly modulated smectic, a triangular solid or a buckled phase. At fixed $\\rho$, a change in $L_y$ leads to many reentrant discontinuous transitions involving changes in the number of layers parallel to the confining walls depending crucially on the commensurability of inter-layer spacing with $L_y$. The solid shows resistance to elongation but not to shear. When strained beyond the elastic limit it fails undergoing plastic deformation but surprisingly, as the strain is reversed, the material recovers completely and returns to its original undeformed state. We obtain the phase diagram from mean field theory and finite size simulations and discuss the effect of fluctuations. ", "machine_text": "  We have developed a theory of elastic and inelastic properties of solids which are confined in quasi one dimensional strips. We have considered a solid which is resting on a hard substrate and the interfacial traction force is negligible compared to the strength of the solid. Our theory is based on the assumption that the strain energy in the constrained solid is a function of the strain in the thickness direction, the bending moments in the strip, and the shear forces in the strip. We show that, as a result of the interplay between the stiffness of the solid and the constraint provided by the strip, the structural and mechanical properties of the solid in the strip can differ significantly from those of the bulk solid, and these properties can be engineered by suitable design of the strip. In particular, we show that, if the solid is elastic and the strip is wide enough, the solid will not experience any stress even when a large deformation is applied to the strip. On the other hand, if the solid is inelastic and the strip is narrow, the solid can experience stresses which can be higher than the bulk yield stress of the solid. We also discuss the effect of various geometrical parameters of the strip on the structural and mechanical properties of the solid in the strip. Our results can have practical implications in several areas of research including geotechnical and civil engineering, materials science and engineering, and bioengineering.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Optical Source Catalog of the North Ecliptic Pole Region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1182, "human_text": "  We present a five (u*,g',r',i',z') band optical photometry catalog of the sources in the North Ecliptic Pole (NEP) region based on deep observations made with MegaCam at CFHT. The source catalog covers about 2 square degree area centered at the NEP and reaches depths of about 26 mag for u*, g', r' bands, about 25 mag for i' band, and about 24 mag for z' band (4 sigma detection over an 1 arcsec aperture). The total number of cataloged sources brighter than r'= 23 mag is about 56,000 including both point sources and extended sources. From the investigation of photometric properties using the color-magnitude diagrams and color-color diagrams, we have found that the colors of extended sources are mostly (u*-r') < 3.0 and (g'-z') > 0.5. This can be used to separate the extended sources from the point sources reliably, even for the faint source domain where typical morphological classification schemes hardly work efficiently. We have derived an empirical color-redshift relation of the red sequence galaxies using the Sloan Digital Sky Survey data. By applying this relation to our photometry catalog and searching for any spatial overdensities, we have found two galaxy clusters and one nearby galaxy group. ", "machine_text": "  We present a catalog of 3,67 \u00d7 10^3 extragalactic optical sources in a half-square degree survey of the North Ecliptic Pole region with Subaru/SuprimeCam. The sources are selected by their colors and by their spatial distribution to be free from galactic contamination. We find a total of 2,755 galaxy groups and 7,702 galaxies in these groups. The catalog galaxy groups have an average redshift of 2.54 \u00b1 0.07, and their number density is 3.01 \u00b1 0.01 groups per square degree. The catalog galaxies have an average redshift of 2.47 \u00b1 0.05, and their number density is 6.13 \u00b1 0.03 galaxies per group. We have verified that our algorithm for detecting galaxy groups is not biased by the distribution of bright stars. This catalog is useful for studying large-scale structure, galaxy formation, and the relationship between the two.  We present an algorithm to detect galaxy groups in an optical image. We first use a Difference of Gaussians filter to detect galaxies, then use a nearest-neighbor algorithm to group the galaxies according to their spatial distribution, and finally fit a two-dimensional (2D) Kingman statistical graphical model to the galaxy positions to determine the number density of the groups. The number density of groups in our catalog is 3.01 \u00b1 0.01 groups per square degree, consistent with the number density of groups in the 2D universe, as obtained from large-scale structure surveys. This algorithm has several advantages: it is simple and efficient, it does not require an estimate of the background galaxy number density, and it is independent of the galaxy morphology or the survey method. Therefore, this algorithm can be applied to any galaxy catalog to extract groups.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On generalized entropy measures and pathways. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0326, "human_text": "  Product probability property, known in the literature as statistical independence, is examined first. Then generalized entropies are introduced, all of which give generalizations to Shannon entropy. It is shown that the nature of the recursivity postulate automatically determines the logarithmic functional form for Shannon entropy. Due to the logarithmic nature, Shannon entropy naturally gives rise to additivity, when applied to situations having product probability property. It is argued that the natural process is non-additivity, important, for example, in statistical mechanics, even in product probability property situations and additivity can hold due to the involvement of a recursivity postulate leading to a logarithmic function. Generalizations, including Mathai's generalized entropy are introduced and some of the properties are examined. Situations are examined where Mathai's entropy leads to pathway models, exponential and power law behavior and related differential equations. Connection of Mathai's entropy to Kerridge's measure of \"inaccuracy\" is also explored. ", "machine_text": "  We consider the problem of constructing generalized entropy measures, which are introduced in a recent paper of ours. These measures are constructed by defining the trace of the Local Operator Attribute Value Probability (LOAVP) in a basis of elementary symmetric functions of the underlying attribute values. Here we show that these measures are related to the symplectic and anti-symplectic maps of the underlying attribute space. In particular, we show that if the generalized entropy measure issymplectic, then the underlying attribute space has a Hamiltonian structure, and the generalized entropy is the momentum map of the Hamiltonian system. We also discuss the problem of finding the generalized entropy of a given object (or, equivalently, finding the object whose generalized entropy is a given value), and show that this is an NP-hard problem. We also present a methodology for finding an approximation to the generalized entropy measure of an object, by first finding the symplectic and anti-symplectic maps of the attribute space, and then projecting the desired generalized entropy measure onto the span of the basis of elementary symmetric functions used to define the generalized entropy measure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive CP$^1$ theory from a microscopic model for doped\n  antiferromagnets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1918, "human_text": "  A path-integral for the t-J model in two dimensions is constructed based on Dirac quantization, with an action found originally by Wiegmann (Phys. Rev. Lett. {\\bf 60}, 821 (1988); Nucl. Phys. B323, 311 (1989)). Concentrating on the low doping limit, we assume short range antiferromagnetic order of the spin degrees of freedom. Going over to a local spin quantization axis of the dopant fermions, that follows the spin degree of freedom, staggered CP$^1$ fields result and the constraint against double occupancy can be resolved. The staggered CP$^1$ fields are split into slow and fast modes, such that after a gradient expansion, and after integrating out the fast modes and the dopant fermions, a CP$^1$ field-theory with a massive gauge field is obtained that describes generically incommensurate coplanar magnetic structures, as discussed previously in the context of frustrated quantum antiferromagnets. Hence, the possibility of deconfined spinons is opened by doping a colinear antiferromagnet. ", "machine_text": " We develop a microscopic model for doped antiferromagnets that exhibits a massive CP$^1$ ground state and investigate the thermodynamic and dynamic properties of the system. We show that the model has a unique ground state with respect to a suitable action functional, and that it is characterized by a non-degenerate peak at the single-particle level. The possible phases of the system are determined by a competition between an extended Kondo effect and a spin-glass-like instability. We find a slow cooling of the system that is accompanied by a continuous shift of the order parameter, and we show that this cooling is anomalously slow compared to the predictions of the Perdew-Burke-Ernzerhof (PBE) approximation. The slow cooling is in direct conflict with the predictions of the Kondo-like theory that is derived from the PBE approximation and that is applicable to the case without a spin-glass-like instability. We also find a temperature dependence of the static structure factor that is in qualitative disagreement with the Kondo-like theory. The slow cooling and the non-Kldoness of the static structure factor can be understood by a dynamic mechanism that is induced by the spin-glass-like instability.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Connecting LHC, ILC, and Quintessence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2375, "human_text": "  If the cold dark matter consists of weakly interacting massive particles (WIMPs), anticipated measurements of the WIMP properties at the Large Hadron Collider (LHC) and the International Linear Collider (ILC) will provide an unprecedented experimental probe of cosmology at temperatures of order 1 GeV. It is worth emphasizing that the expected outcome of these tests may or may not be consistent with the picture of standard cosmology. For example, in kination-dominated quintessence models of dark energy, the dark matter relic abundance can be significantly enhanced compared to that obtained from freeze out in a radiation-dominated universe. Collider measurements then will simultaneously probe both dark matter and dark energy. In this article, we investigate the precision to which the LHC and ILC can determine the dark matter and dark energy parameters under those circumstances. We use an illustrative set of four benchmark points in minimal supergravity in analogy with the four LCC benchmark points. The precision achievable together at the LHC and ILC is sufficient to discover kination-dominated quintessence, under the assumption that the WIMPs are the only dark matter component. The LHC and ILC can thus play important roles as alternative probes of both dark matter and dark energy. ", "machine_text": " We show that LHC and ILC can be connected via a Quintessence scenario in which the messenger field has a complex structure. The model is an extension of the one recently proposed by Degrassi et al. (arXiv:1302.7166). We find that such a model can be made to work in a realistic way, provided that the messenger field is a complex scalar field with a very small (of the order of the Planck scale) non-zero vacuum expectation value, and provided that the messenger field is not introduced as a \"new\" field, but rather as a \"change\" in the dynamics of an already existing (symmetric) scalar field. We show that in this case the dynamics of the symmetric scalar field can be made to display the same features of the standard Quintessence scenario, with a small modification in the parameters. We analyze the model in some detail and find that the new Quintessence scenario has all the features of the standard one, including the ability to give a dynamical explanation to the acceleration of the Universe, the ability to produce a scalar field which has the correct value at the correct time (the so-called \" scalar curate\" problem), and the ability to consistently generate a spectrum of cosmic rays which is in agreement with observations. We also find that the model is consistent with the cosmological constant being exactly zero.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near and Mid-IR Photometry of the Pleiades, and a New List of Substellar\n  Candidate Members. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1832, "human_text": "  We make use of new near and mid-IR photometry of the Pleiades cluster in order to help identify proposed cluster members. We also use the new photometry with previously published photometry to define the single-star main sequence locus at the age of the Pleiades in a variety of color-magnitude planes.   The new near and mid-IR photometry extend effectively two magnitudes deeper than the 2MASS All-Sky Point Source catalog, and hence allow us to select a new set of candidate very low mass and sub-stellar mass members of the Pleiades in the central square degree of the cluster. We identify 42 new candidate members fainter than Ks =14 (corresponding to 0.1 Mo). These candidate members should eventually allow a better estimate of the cluster mass function to be made down to of order 0.04 solar masses.   We also use new IRAC data, in particular the images obtained at 8 um, in order to comment briefly on interstellar dust in and near the Pleiades. We confirm, as expected, that -- with one exception -- a sample of low mass stars recently identified as having 24 um excesses due to debris disks do not have significant excesses at IRAC wavelengths. However, evidence is also presented that several of the Pleiades high mass stars are found to be impacting with local condensations of the molecular cloud that is passing through the Pleiades at the current epoch. ", "machine_text": "  We present a catalogue of low-resolution near-infrared photometry for 78 of the nearest stars to the Sun, drawn from a database of 5 million pixel images taken with the Hubble Space Telescope's Near Infrared Camera and Multi-Object Spectrometer. These data are used to derive the radii, temperatures, and ages of these stars. We find that the confirmed members of the Pleiades, or Seven Sisters, are between 200 and 400 million years old, but that there are many more members in this cluster than are currently listed. A new list of candidate members is presented, including many stars that are more than twice the age of the Sun. We show that many field stars with high proper motion that were previously considered to be members of the Pleiades are instead more distant stars. The ages of the suspected member stars are consistent with a Pleiades age of about 250 million years, with a margin of error of about 50%. This is in agreement with the results of an independent analysis of high-resolution spectroscopy of cluster members. The derived cluster properties are consistent with a simple model in which the cluster has grown by consecutive mergers of Horowitz-Ramsbottom (HR) clouds, the most recent of which was about 250 million years ago. We also present a catalog of mid-infrared photometry for this same group of 78 stars. We find that the mid-infrared colors are consistent with the stars being singly or doubly mantled by dust clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black Holes and Large N Species Solution to the Hierarchy Problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.205, "human_text": "  We provide the perturbative and non-perturbative arguments showing that theories with large number of species of the quantum fields, imply an inevitable hierarchy between the masses of the species and the Planck scale, shedding a different light on the hierarchy problem. In particular, using the black hole physics, we prove that any consistent theory that includes N number of the Z_2-conserved species of the quantum fields of mass \\Lambda, puts a lower bound on the Planck mass, which in large N limit is given by N\\Lambda^2. An useful byproduct of this proof is that any exactly conserved quantum charge, not associated with a long-range classical field, must be defined maximum modulo N, bounded by the the ratio of the Planck to the unit charge masses squared. For example, a continuous global U(1) `baryon number' symmetry, must be explicitly broken by gravity, at least down to a Z_N subgroup, with N bounded by the ratio of the Planck to baryon masses squared. The same constraint applies to any discrete gauge symmetry, as well as to other quantum-mechanically detectable black hole charges that are associated with the massive quantum hair of the black hole. We show that the gravitationally-coupled N-species sector that solves the gauge hirearchy problem, should be probed by LHC. ", "machine_text": "  We show that the higher-dimensional formulation of Einstein's equations, in a suitable choice of coordinates, can be exactly solved for a Schwarzschild black hole, with the solution describing an N-species  fluids interpretation of a black hole, in a large N limit. This is done by an integral transform of the Einstein equations which has as its kernel the species kernel of the Poincare group. This formulation allows a solution of the Einstein equations for an N-species fluids system which asymptotically approaches the solution for a black hole in the limit N \u2192 \u221e. We solve this system of equations numerically in the limit N = 1000, in a grid size independent of the mass M and radius R of the black hole, and find a very good agreement with the exact solution for a Schwarzschild black hole, given in terms of the geodesic collision coordinates. Our result is independent of the choice of the initial conditions, which is an interesting feature of the solution. We discuss the physical and mathematical meanings of our result, in the framework of the Large N approach to quantum gravity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The host galaxies of strong CaII QSO absorption systems at z<0.5. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3462, "human_text": "  We present new imaging and spectroscopic observations of the fields of five QSOs with very strong intervening CaII absorption systems at redshifts z<0.5 selected from the Sloan Digital Sky Survey. Recent studies of these very rare absorbers indicate that they may be related to damped Lyman alpha systems (DLAs). In all five cases we identify a galaxy at the redshift of the CaII system with impact parameters up to ~24 kpc. In four out of five cases the galaxies are luminous (L ~L*), metal-rich (Z ~Zsun), massive (velocity dispersion, sigma ~100 km/s) spirals. Their star formation rates, deduced from Halpha emission, are high, in the range SFR = 0.3 - 30 Msun/yr. In our analysis, we paid particular attention to correcting the observed emission line fluxes for stellar absorption and dust extinction. We show that these effects are important for a correct SFR estimate; their neglect in previous low-z studies of DLA-selected galaxies has probably led to an underestimate of the star formation activity in at least some DLA hosts. We discuss possible links between CaII-selected galaxies and DLAs and outline future observations which will help clarify the relationship between these different classes of QSO absorbers. ", "machine_text": "  We present a catalog of galaxies likely to host strong CaII QSO absorption systems at z<0.5, based on a sample of about 500 QSOs with available H-alpha images. The sample is selected from the SDSS, and QSOs with hydrogen halos are excluded. The galaxies in the catalog are candidate luminous galaxies in the redshift range 0.125<=z<=1.5, with a probability of 50% that the QSO is at the same redshift as the host galaxy. The catalog contains 636 galaxies, and the galaxies are found to be slightly more likely to be in clusters than field galaxies. The catalog is useful for studies of large scale structure, galaxy evolution, and the QSO absorption systems themselves.  We have developed a technique for detecting host galaxies for strong CaII QSO absorption systems at z<0.5. The method relies on identifying likely QSOs in the SDSS with available H-alpha images, and then using the H-alpha images to select candidate host galaxies. We find 636 galaxies in the host galaxy catalog, and the galaxies are slightly more likely to be in clusters than field galaxies. The catalog is useful for studies of large scale structure, galaxy evolution, and the QSO absorption systems themselves.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Tests of Bayesian Model Selection Techniques for Gravitational Wave\n  Astronomy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1808, "human_text": "  The analysis of gravitational wave data involves many model selection problems. The most important example is the detection problem of selecting between the data being consistent with instrument noise alone, or instrument noise and a gravitational wave signal. The analysis of data from ground based gravitational wave detectors is mostly conducted using classical statistics, and methods such as the Neyman-Pearson criteria are used for model selection. Future space based detectors, such as the \\emph{Laser Interferometer Space Antenna} (LISA), are expected to produced rich data streams containing the signals from many millions of sources. Determining the number of sources that are resolvable, and the most appropriate description of each source poses a challenging model selection problem that may best be addressed in a Bayesian framework. An important class of LISA sources are the millions of low-mass binary systems within our own galaxy, tens of thousands of which will be detectable. Not only are the number of sources unknown, but so are the number of parameters required to model the waveforms. For example, a significant subset of the resolvable galactic binaries will exhibit orbital frequency evolution, while a smaller number will have measurable eccentricity. In the Bayesian approach to model selection one needs to compute the Bayes factor between competing models. Here we explore various methods for computing Bayes factors in the context of determining which galactic binaries have measurable frequency evolution. The methods explored include a Reverse Jump Markov Chain Monte Carlo (RJMCMC) algorithm, Savage-Dickie density ratios, the Schwarz-Bayes Information Criterion (BIC), and the Laplace approximation to the model evidence. We find good agreement between all of the approaches. ", "machine_text": " We present tests of Bayesian model selection techniques for gravitational wave data. Our focus is on the problem of model selection for data containing gravitational waves from multiple sources. We evaluate the ability of the Bayesian information criterion (BIC) and Bayes factor (BF) to distinguish between different models of this data. We find that the BIC is inconsistent and the BF is only marginally consistent with the hypothesis that the correct model is the model that minimizes the BIC or BF. These results suggest that model selection based on the BIC or BF is unlikely to be successful in practice. We also evaluate the performance of model selection using cross-validation. We find that cross-validation is more reliable, although it may still be problematic in practice. Our results suggest that the model selection problem for data containing gravitational waves from multiple sources is non-trivial and that it may be difficult to develop a practical algorithm for model selection in this context.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New smooth hybrid inflation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3786, "human_text": "  We consider the extension of the supersymmetric Pati-Salam model which solves the b-quark mass problem of supersymmetric grand unified models with exact Yukawa unification and universal boundary conditions and leads to the so-called new shifted hybrid inflationary scenario. We show that this model can also lead to a new version of smooth hybrid inflation based only on renormalizable interactions provided that a particular parameter of its superpotential is somewhat small. The potential possesses valleys of minima with classical inclination, which can be used as inflationary paths. The model is consistent with the fitting of the three-year Wilkinson microwave anisotropy probe data by the standard power-law cosmological model with cold dark matter and a cosmological constant. In particular, the spectral index turns out to be adequately small so that it is compatible with the data. Moreover, the Pati-Salam gauge group is broken to the standard model gauge group during inflation and, thus, no monopoles are formed at the end of inflation. Supergravity corrections based on a non-minimal Kaehler potential with a convenient choice of a sign keep the spectral index comfortably within the allowed range without generating maxima and minima of the potential on the inflationary path. So, unnatural restrictions on the initial conditions for inflation can be avoided. ", "machine_text": " We propose and analyze a new hybrid inflation model with smooth terminal conditions. Our approach is based on the construction of a standard deviation of the innovations of a TIME-INNOVATION process, which is related to a proposed new type of theasia.me/en/blog/7567-New-Smooth-Hybrid-Inflation-Model. We show that this new type of inflation model can be nestsort.net/e1/64/64e1f3e03bfc4e7d9eb71e1df49ca3c7/download/ satisfactory for modeling several types of inflation processes. We focus on the simplest case of a geometric process and a pure linear process. In the first case, the model has a locally stationary process as a limiting case, while in the second case, the model converges to a process with a constant level. We also analyze the properties of the proposed model in a more general setting. In particular, we show that the model has a good fit to the data and produces credible intervals for the unknown parameters. We also analyze the sensitivity of our results to the choice of the smoothing parameter. Finally, we point out some possible applications of our results in the context of modeling the dynamics of inflation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Polymer Quantum Mechanics and its Continuum Limit. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0007, "human_text": "  A rather non-standard quantum representation of the canonical commutation relations of quantum mechanics systems, known as the polymer representation has gained some attention in recent years, due to its possible relation with Planck scale physics. In particular, this approach has been followed in a symmetric sector of loop quantum gravity known as loop quantum cosmology. Here we explore different aspects of the relation between the ordinary Schroedinger theory and the polymer description. The paper has two parts. In the first one, we derive the polymer quantum mechanics starting from the ordinary Schroedinger theory and show that the polymer description arises as an appropriate limit. In the second part we consider the continuum limit of this theory, namely, the reverse process in which one starts from the discrete theory and tries to recover back the ordinary Schroedinger quantum mechanics. We consider several examples of interest, including the harmonic oscillator, the free particle and a simple cosmological model. ", "machine_text": " We consider a system of many polymers in solution that interact via an external force that is applied to each pair of polymers. We study the statistical equilibrium of this system, and find that the polymers form clusters whose sizes are given by a power law distribution. This is in contrast to the traditional picture of polymers in solution, where the thermodynamic equilibrium is described by a mean-field theory based on the solution of the mean-field Boltzmann equation. We show that this difference is due to a breakdown of the assumptions that were used to derive the mean-field theory. In particular, we show that the polymer-polymer interactions in the system considered are non-local, and are thus not described by the mean-field theory. We then derive a new theory for the statistical equilibrium in the presence of an external force, which includes a correction to the mean-field theory. The new theory predicts that the polymer clusters become less dense as the external force increases, in clear contrast to the predictions of the mean-field theory. We analyze this disagreement, and show that it is due to the fact that the mean-field theory predicts a non-monotonic dependence of the polymer-polymer interaction strength on the external force, while our theory predicts a strictly monotonic dependence. We then consider the limit of our theory as the number of polymers in the system tends to infinity, and show that it describes a model of polymer quantum mechanics in a Box, which is a system with a large number of infinitely-lived polymers that interact via a non-local potential, and are in statistical equilibrium in the presence of an external force. We analyze this model, and show that it describes a system with anomalous diffusion and ballistic transport, which is analogous to the anomalous behavior observed in recent experiments on pedestrians.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SW Sextantis stars: the dominant population of CVs with orbital periods\n  between 3-4 hours. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1129, "human_text": "  [Abridged] We present time-series optical photometry of five new CVs identified by the Hamburg Quasar Survey. The eclipses observed in HS 0129+2933, HS 0220+0603, and HS 0455+8315 provided very accurate orbital periods of 3.35129827(65), 3.58098501(34), and 3.56937674(26) h, respectively. HS 0805+3822 shows grazing eclipses and has a likely orbital period of 3.2169(2) h. Time-resolved optical spectroscopy of the new CVs (with the exception of HS 0805+3822) is also presented. Radial velocity studies provided an orbital period of 3.55 h for HS 1813+6122, which allowed us to identify the observed photometric signal at 3.39 h as a negative superhump wave. The spectroscopic behaviour clearly identifies these new CVs as new SW Sextantis stars. These new additions increase the number of known SW Sex stars to 35. Almost 40 per cent of the total SW Sex population do not show eclipses, invalidating the requirement of eclipses as a defining characteristic of the class and the models based on a high orbital inclination geometry alone. On the other hand, the predominance of orbital periods in the narrow 3-4.5 h range is becoming more pronounced. In fact, almost half the CVs which populate the 3-4.5 h period interval are definite members of the class. These statistics are confirmed by our results from the Hamburg Quasar Survey CVs. Remarkably, 54 per cent of the Hamburg nova-like variables have been identified as SW Sex stars with orbital periods in the 3-4.5 h range. The observation of this pile-up of systems close to the upper boundary of the period gap is difficult to reconcile with the standard theory of CV evolution, as the SW Sex stars are believed to have the highest mass transfer rates among CVs. Finally, we review the full range of common properties that the SW Sex stars exhibit. ", "machine_text": "  We present photometric detections of 21 of the 22 SW Sextantis stars with well-determined orbital periods between 3-4 hours. The large majority of these CVs show the characteristic short-period evolutionary properties of the SW Sextantis stars: small-sized spots, high photometric precision, and a temperature-vibration relationship. The exception is HD 3 genetics, which has a relatively large spot and a temperature-ionization relationship. The properties of these CVs are consistent with a dominant population of SW Sextantis stars in the 3-4 hour orbital period regime. We estimate the orbital period distribution of the SW Sextantis stars in this range to be Gaussian with a width of 0.13 hours. We also present evidence that the group may be Complete Mitochondrial DNA (cmDNA) heterogenerous, based on the size-frequency distribution of the spots. If this is the case, the group may have formed through the accretion of satellites around the most massive member.   We find that the SW Sextantis stars with well-determined orbital periods between 3-4 hours have the same general properties as those with orbital periods between 5-6 hours, except that the latter are generally larger in size and have a higher surface gravity. We conclude that the SW Sextantis stars with orbital periods between 3-4 hours are the dominant population in that range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mixed Meson Masses with Domain-Wall Valence and Staggered Sea Fermions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0572, "human_text": "  Mixed action lattice calculations allow for an additive lattice spacing dependent mass renormalization of mesons composed of one sea and one valence quark, regardless of the type of fermion discretization methods used in the valence and sea sectors. The value of the mass renormalization depends upon the lattice actions used. This mixed meson mass shift is an important lattice artifact to determine for mixed action calculations; because it modifies the pion mass, it plays a central role in the low energy dynamics of all hadronic correlation functions. We determine the leading order, $\\mathcal{O}(a^2)$, and next to leading order, $\\mathcal{O}(a^2 m_\\pi^2)$, additive mass shift of \\textit{valence-sea} mesons for a mixed lattice action with domain-wall valence fermions and rooted staggered sea fermions, relevant to the majority of current large scale mixed action lattice efforts. We find that on the asqtad improved coarse MILC lattices, this additive mass shift is well parameterized in lattice units by $\\Delta(am)^2 = 0.034(2) -0.06(2) (a m_\\pi)^2$, which in physical units, using $a=0.125$ fm, corresponds to $\\Delta(m)^2 = (291\\pm 8 \\textrm{MeV})^2 -0.06(2) m_\\pi^2$. In terms of the mixed action effective field theory parameters, the corresponding mass shift is given by $a^2 \\Delta_\\mathrm{Mix} = (316 \\pm 4 \\textrm{MeV})^2$ at leading order plus next-to-leading order corrections including the necessary chiral logarithms for this mixed action calculation, determined in this work. Within the precision of our calculation, one can not distinguish between the full next-to-leading order effective field theory analysis of this additive mixed meson mass shift and the parameterization given above. ", "machine_text": "  We study the masses of mesons as a function of the amount of seniority using the domain-wall fermion (DWF) approach. We show that the mass relations in the quark model (QM) can be recovered in the limit of large seniority, where the quark and antiquark contributions to the meson mass are comparable. The main new feature in the DWF approach is that, in addition to the quark and antiquark contributions, there is a finite non-perturbative term in the meson mass. We show that this non-perturbative term is small for light mesons but becomes comparable to the quark and antiquark terms for heavy mesons. As a result, the mass relations for heavy mesons are different from the QM mass relations. We evaluate the meson masses for several realistic DWF parameter sets and find that the predictions of the DWF approach are consistent with the current quark model parametrizations. One exception is the mass of the Strange quark which is larger in the DWF approach. We explain this exception by the fact that the Strange quark is particularly light and therefore is more sensitive to the non-perturbative terms. We also discuss the relation between the DWF and QM approaches to meson masses and find that the two approaches are not fully equivalent. Finally, we show that the DWF approach can be used to study the meson mass singularity and to understand the mechanism of its softening.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: ATLAS sensitivity to Wtb anomalous couplings in top quark decays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3041, "human_text": "  We study the sensitivity of the ATLAS experiment to Wtb anomalous couplings in top pair production with semileptonic decay, pp -> t tbar -> W+ b W- bbar, with one of the W bosons decaying leptonically and the other hadronically. Several observables are examined, including the W helicity fractions and new quantities recently introduced, such as the ratios of helicity fractions and some angular asymmetries defined in the W rest frame. The dependence on anomalous couplings of all these observables has been previously obtained. In this work we show that some of the new observables also have smaller systematic uncertainties than the helicity fractions, with a dependence on anomalous couplings similar or stronger than for helicity fractions. Consequently, their measurement can significantly improve the limits on anomalous couplings. Moreover, the most sensitive measurements can be combined. In this case, the precision achieved in the determination of Wtb anomalous couplings can be of a few percent in the semileptonic channel alone. ", "machine_text": "  We present a study of the ATLAS search for a violation of the Wtb unordered flavor symmetry in top quark decays. We consider events with two jets and two missing transverse energy, where one of the jets is identified as a top quark candidate, in the final state. We evaluate the sensitivity of the analysis to a permanent Wtb flavor violation and to a transient Wtb flavor violation. For the permanent case we use the latest ATLAS cross section predictions, and we evaluate the expected number of events in the full 2011 LHC data set, in the 9\u00a0fb\u22121 Run 1 data, and in a future Run 2 data set with the full LHC luminosity. For the transient case we evaluate the sensitivity to a single top quark decay with a lifetime of 1 ns, and to a single top quark decay with a lifetime of 10 ns. The expected number of events in the full 2011 LHC data set, in the 9\u00a0fb\u22121 Run 1 data, and in a future Run 2 data set with the full LHC luminosity is also evaluated. We find that the full LHC data set can yield a clear indication of a permanent Wtb flavor violation, if the underlying theory is able to produce a coupling to the top quark of the order of 1%. A transient Wtb flavor violation can be probed with a single top quark lifetime of \u00a010 ns.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray detection of the substellar twin 2MASS J11011926-7732383 AB. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2301, "human_text": "  2MASS J11011926-7732383 AB (hereafter 2M1101AB), located in the Cha I star forming region, is a rare wide-separation brown dwarf binary. XMM-Newton and Chandra observations of 2M1101AB have allowed us to examine the influence of physical parameters (mass, bolometric luminosity and effective temperature) on X-ray emission from a coeval pair of substellar objects. The spatial resolution of XMM-Newton is not sufficient to separate contributions from the two components in the binary. The X-ray source detected with XMM-Newton has a column density compatible with the infrared extinction of component A. On the other hand, the binary is resolved with Chandra, and the bulk of the X-ray emission is clearly associated with the photospherically cooler component B. These apparently contradictory results point at strong variability of 2M1101's X-ray emission. Combined with previous sensitive X-ray observations from low-mass members of ChaI, we find a decline of X-ray luminosity with decreasing (sub)stellar mass that is typical for star forming regions. 2M1101B is the coolest (spectral type M8.25) and least massive brown dwarf of ChaI detected in X-rays so far. It is also among the youngest (~1 Myr) substellar ChaI members, and therefore relatively luminous. Most bona fide brown dwarfs of Cha I have remained below the sensitivity limits of available X-ray observations, because of their low luminosity associated with higher age. ", "machine_text": "  We present photometric detections of the substellar twin 2MASS J11011926-7732383 AB at optical and near-infrared wavelengths using the NASA/ESA Hubble Space Telescope and the VLT/FORS. We find that the photospheres of the stars are not obscured by the disk, in contradiction to previous claims. We also find that the disk is slightly eccentric and inclined to the line joining the two stars, in agreement with the predictions of analytical models. We show that the disk's properties are consistent with a model in which the disk forms via the accretion of planetesimals. The measured disk properties are consistent with a relatively rapid (by solar system standards) migration of the giant planets, a scenario that is supported by dynamical models. The derived mass of the disk is consistent with a mass formed by the accretion of planetesimals but is inconsistent with the mass required to form giant planets by the accretion of planetesimals. We discuss various scenarios that could explain this discrepancy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic Properties of Molecular Motors in Burnt-Bridge Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.069, "human_text": "  Dynamic properties of molecular motors that fuel their motion by actively interacting with underlying molecular tracks are studied theoretically via discrete-state stochastic ``burnt-bridge'' models. The transport of the particles is viewed as an effective diffusion along one-dimensional lattices with periodically distributed weak links. When an unbiased random walker passes the weak link it can be destroyed (``burned'') with probability p, providing a bias in the motion of the molecular motor. A new theoretical approach that allows one to calculate exactly all dynamic properties of motor proteins, such as velocity and dispersion, at general conditions is presented. It is found that dispersion is a decreasing function of the concentration of bridges, while the dependence of dispersion on the burning probability is more complex. Our calculations also show a gap in dispersion for very low concentrations of weak links which indicates a dynamic phase transition between unbiased and biased diffusion regimes. Theoretical findings are supported by Monte Carlo computer simulations. ", "machine_text": "  Dynamic Properties of Molecular Motors in Burnt-Bridge Models We study the dynamic properties of molecular motors in burnt-bridge models. We show that the two main non-trivial dynamic states of the motor, the bound state and the unbound state, can be stable in a large range of parameters, including the extreme cases of very fast and very slow kinetics. We find a large variety of dynamic patterns, including a rich phenomenology of different types of flipping between the bound and unbound state, and different types of trajectories in the unbound state. Our findings are consistent with a large number of physical processes taking place in the dynamics of the motor, which can roughly be divided into two classes, fast and slow processes. The fast processes are related to the energy fluctuations in the motor and to the thermal agitation, and can give rise to a variety of dynamic patterns. The slow processes are related to the tunneling of the ligand molecule towards the binding site, and to the subsequent binding and unbinding. We show that the dynamics of the motor can be very well described by a simple Markov chain, which can be fully optimized, thus providing a powerful tool for the study of the dynamic properties of molecular motors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charge Polarization Effects and Hole Spectra Characteristics in\n  Alxgai-xN/Gan Superlattices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2735, "human_text": "  We study the effects of charge polarization on the extended physical properties of superlattices, such as transmission coefficients and valence band structure. We consider both linear and parabolic modulation of the band edge. Based on the theory of finite periodic systems (TFPS), analytic expressions and high precision calculations of the relevant physical quantities for n-cell systems are obtained. New and also well-known features of these systems are identified. Besides the well-known energy bandstructure, we also have the field bandstructure, with interesting characteristics.Wider field gaps at stronger internal electric fields and higher density of field bands for larger layer widths are some of these characteristics. Well denned level density asymmetries identify the minibands induced by charge polarization or the so-called Quantum Confining Stark Effect. We present the n-cell transmission amplitudes, transmission coefficients and miniband structures for different values of the relevant parameters. ", "machine_text": " We have investigated the charge polarization effects and hole spectra characteristics in AlxGa1-xN/GaN superlattices (SLs) with different aluminum (Al) mole fractions, x, and different periods, P. Both optical and transport measurements are reported. For the optical measurements, we used a mercury lamp as an excitation source, and observed the photoluminescence (PL) and electroluminescence (EL) spectra. We found that the intensities of the satellite peaks in the EL spectra increased as x increased, and the main peak in the EL spectra blue-shifted as P decreased. For the transport measurements, we used an Au electrode as a top contact, and observed the capacitance-voltage (C-V) and current-voltage (I-V) characteristics. We found that the capacitance decreased as x increased, and the conductance increased as P decreased. The ideality factors of the C-V characteristics were greater than one, and the I-V characteristics showed non- ohmic behavior. We also found that the current density was higher when x was greater and P was smaller. These results were explained by considering the structural and optical properties of the SLs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear generalized functions and the Heisenberg-Pauli foundations of\n  Quantum Field Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2396, "human_text": "  In 1929 Heisenberg and Pauli laid the foundations of QFT by quantizing the fields (method of canonical quantization). This general theory of quantized fields has remained undisputed up to now. We show how the unmodified Heisenberg-Pauli calculations make sense mathematically by using a theory of generalized functions adapted to nonlinear operations. By providing an appropriate mathematical setting, nonlinear generalized functions open doors for their understanding but there remains presumably very hard technical problems. (i) Domains of the interacting field operators: a priori the H-P calculations give time dependent dense domains, what is not very convenient; (ii) Calculations of the resulting matrix elements of the S operator: from the unitarity of the S operator as a whole there are no longer ``infinities,'' but a priori there is no other hope than heavy computer calculations; (iii) Connection with renormalization theory: it should provide an approximation when the coupling constant is small. The aim of this paper is to present, on the grounds of a standard mathematical model of QFT (a self interacting scalar boson field), a basis for improvement without significant prerequisites in mathematics and physics. It is an attempt to use nonlinear generalized functions in QFT, starting directly from the calculations made by physicists, in the same way as they have already been used in classical mechanics and general relativity. ", "machine_text": " We show that nonlinear generalized functions (NGF) can be used to provide a rigorous theoretical foundation for Quantum Field Theory (QFT) that is free from the limitations of conventional Taylor-series expansions. The conventional expansions are shown to be equivalent to a particular basis set of NGF. The resulting theory is manifestly Lorentz invariant,  symmetric under the exchange of the poisson- sabotages, and yet has a very simple structure that is consistent with the principles of Quantum Theory. In particular, we show that the NGF approach naturally avoids the use of the moment-generating-functionals (MGF) that have been at the basis of much of the controversy and confusion that has surrounded the foundations of QFT. MGF have an interpretation as being related to the inner product of Hilbert space operators, but the NGF approach is strictly manifestly positivist and does not rely on any such interpretation. We show that the NGF basis set is complete, in the sense that any function can be expressed as a linear combination of the basis elements, and yet has a very simple structure that is consistent with the principles of Quantum Theory. The approach is related to the more general approach of Lagrangian Field Theory, but the NGF basis set is shown to be uniquely suited to the requirements of QFT. We also show that the NGF approach can be used to provide a rigorous foundation for the Generalized Lagrangian formalism that has been proposed as a possible alternative to the conventional Lagrangian formalism of QFT. The resulting theory is manifestly Lorentz invariant,  symmetric under the exchange of the poisson-sabotages, and yet has a very simple structure that is consistent with the principles of Quantum Theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Surface Structure in an Accretion Disk Annulus with Comparable Radiation\n  and Gas Pressure. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0314, "human_text": "  We have employed a 3-d energy-conserving radiation MHD code to simulate the vertical structure and thermodynamics of a shearing box whose parameters were chosen so that the radiation and gas pressures would be comparable. The upper layers of this disk segment are magnetically-dominated, creating conditions appropriate for both photon bubble and Parker instabilities. We find little evidence for photon bubbles, even though the simulation has enough spatial resolution to see them and their predicted growth rates are high. On the other hand, there is strong evidence for Parker instabilities, and they appear to dominate the evolution of the magnetically supported surface layers. The disk photosphere is complex, with large density inhomogeneities at both the scattering and effective (thermalization) photospheres of the evolving horizontally-averaged structure. Both the dominant magnetic support and the inhomogeneities are likely to have strong effects on the spectrum and polarization of thermal photons emerging from the disk atmosphere. The inhomogeneities are also large enough to affect models of reflection spectra from the atmospheres of accretion disks. ", "machine_text": " We present surface structure observations in the mid-plane of a fully evacuated annulus, in which a radiative inner wall and a gas-pressurized outer wall are separated by a nearly uniform gap. Our observations show a clear signature of surface waves that we attribute to the presence of a true surface, despite the fact that the dominant surface tension force in the gap is directed radially inward. We attribute this to the comparable strength of the inward-directed surface tension and the outward-directed gas pressure forces. The inner surface is effectively stiffer than the outer surface, due to the higher surface tension. We show that this result can be understood from a simple consideration of the stress equilibrium on the two walls, in the limit of small surface wavelength. We observe a strong correlation between the wavelength of surface structures and the angle between the surface tension force and the radius, which is a direct signature of this effect. We also show that the same considerations would apply to an accretion disk, where the surface tension is balanced by the inward-directed centrifugal force. Our results suggest that the inner edge of the accretion disk is a true surface, despite the fact that the dominant surface tension force is directed radially inward.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bulk viscosity in a cold CFL superfluid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3909, "human_text": "  We compute one of the bulk viscosity coefficients of cold CFL quark matter in the temperature regime where the contribution of mesons, quarks and gluons to transport phenomena is Boltzmann suppressed. In that regime dissipation occurs due to collisions of superfluid phonons, the Goldstone modes associated to the spontaneous breaking of baryon symmetry. We first review the hydrodynamics of relativistic superfluids, and remind that there are at least three bulk viscosity coefficients in these systems. We then compute the bulk viscosity coefficient associated to the normal fluid component of the superfluid. In our analysis we use Son's effective field theory for the superfluid phonon, amended to include scale breaking effects proportional to the square of the strange quark mass m_s. We compute the bulk viscosity at leading order in the scale breaking parameter, and find that it is dominated by collinear splitting and joining processes. The resulting transport coefficient is zeta=0.011 m_s^4/T, growing at low temperature T until the phonon fluid description stops making sense. Our results are relevant to study the rotational properties of a compact star formed by CFL quark matter. ", "machine_text": " We study the bulk viscosity of a cold CFL superfluid, with a focus on the dynamic Casimir effect. We consider the limit in which the bulk viscosity is dominated by the dynamic Casimir effect, and show that the dynamic Casimir effect has a non-monotonic dependence on the temperature. We calculate the bulk viscosity in this limit, and find that it has a minimum at a temperature that depends on the mass of the atoms in the superfluid. We show that this minimum is protected by a mechanism that is analogous to the one that protects the order parameter from becoming positive. We then consider a generalization of the model in which the kinetic energy is not a constant, but is related to the bulk viscosity by a parameter that may be positive or negative. We show that the bulk viscosity in this case has a minimum that is protected by a different mechanism. We then consider the limit in which the kinetic energy is a constant, and show that the bulk viscosity has a minimum at a temperature that depends on the value of the kinetic energy. We finally show that the bulk viscosity has a non-monotonic dependence on the temperature in this limit as well.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Perturbative Corrections and Modularity in N=1 Type IIB\n  Compactifications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3253, "human_text": "  Non-perturbative corrections and modular properties of four-dimensional type IIB Calabi-Yau orientifolds are discussed. It is shown that certain non-perturbative alpha' corrections survive in the large volume limit of the orientifold and periodically correct the Kahler potential. These corrections depend on the NS-NS two form and have to be completed by D-instanton contributions to transform covariantely under symmetries of the type IIB orientifold background. It is shown that generically also the D-instanton superpotential depends on the two-form moduli as well as on the complex dilaton. These contributions can arise through theta-functions with the dilaton as modular parameter. An orientifold of the Enriques Calabi-Yau allows to illustrate these general considerations. It is shown that this compactification leads to a controlled four-dimensional N=1 effective theory due to the absence of various quantum corrections. Making contact to the underlying topological string theory the D-instanton superpotential is proposed to be related to a specific modular form counting D3, D1, D(-1) degeneracies on the Enriques Calabi-Yau. ", "machine_text": " We study non-perturbative corrections to the quantum structure of N=1 type IIB superconductors in various compactifications of the underlying lattice models. We show that a generic feature of such corrections is the enhancement of the fragmentation functions as compared to the perturbative results. The difference between the two sets of results is particularly large in the case of the so-called kissing number (or Z) models, where it exhibits a series of plateaux, which can be understood in terms of the structure of the associated finitedimensional representations. We show that the corrections can be organised into three categories, which are related to the different flavour structures which occur in the various compactifications. Within each category the structure of the correction is very similar and can be described by a simple modularity argument. The different categories of corrections have different relationships to the perturbative results, and in particular the so-called KT transition in the perturbative theory corresponds to a transition between two of the categories of non-perturbative corrections.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Computing modular polynomials in quasi-linear time. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3177, "human_text": "  We analyse and compare the complexity of several algorithms for computing modular polynomials. We show that an algorithm relying on floating point evaluation of modular functions and on interpolation, which has received little attention in the literature, has a complexity that is essentially (up to logarithmic factors) linear in the size of the computed polynomials. In particular, it obtains the classical modular polynomials $\\Phi_\\ell$ of prime level $\\ell$ in time O (\\ell^3 \\log^4 \\ell \\log \\log \\ell). Besides treating modular polynomials for $\\Gamma^0 (\\ell)$, which are an important ingredient in many algorithms dealing with isogenies of elliptic curves, the algorithm is easily adapted to more general situations. Composite levels are handled just as easily as prime levels, as well as polynomials between a modular function and its transform of prime level, such as the Schl\\\"afli polynomials and their generalisations. Our distributed implementation of the algorithm confirms the theoretical analysis by computing modular equations of record level around 10000 in less than two weeks on ten processors. ", "machine_text": "  We show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that remain constant on a proper subspace of $\\mathbb{R}^n$. We show how this relates to the problem of finding, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are divisible by a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this, in turn, relates to the problem of computing the dominance order of $f$, that is, the order in which the terms of $f$ dominate one another. We also show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are congruent to a given polynomial modulo a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this relates to the problem of computing the index of $f$, that is, the smallest non-negative integer $e$ such that $f^e$ is divisible by $x^d$ for some $d$ with $0\\le d\\le n$ (the so-called \"exponent of $f$\"). Finally, we show how to compute, in quasi-linear time, the set of polynomials in $\\mathbb{Z}^n$ that are incongruent to a given polynomial modulo a given polynomial $f \\in \\mathbb{Z}^n[x]$, and how this relates to the problem of computing the index of $f$, that is, the smallest non-negative integer $e$ such that $f^e$ is incongruent to the zero polynomial modulo $x^d$ for some $d$ with $0\\le d\\le n$ (the so-called \"exponent of $f$\").", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Three Years of Mira Variable CCD Photometry: What Has Been Learned?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2762, "human_text": "  The subject of micro-variability among Mira stars has received increased attention since DeLaverny et al. (1998) reported short-term brightness variations in 15 percent of the 250 Mira or Long Period Variable stars surveyed using the broadband 340 to 890 nm Hp filter on the HIPPARCOS satellite. The abrupt variations reported ranged 0.2 to 1.1 magnitudes, on time-scales between 2 to 100 hours, with a preponderance found nearer Mira minimum light phases. However, the HIPPARCOS sampling frequency was extremely sparse and required confirmation because of potentially important atmospheric dynamics and dust-formation physics that could be revealed. We report on Mira light curve sub-structure based on new CCD V and R band data, augmenting the known light curves of Hipparcos-selected long period variables [LPVs], and interpret same in terms of [1] interior structure, [2] atmospheric structure change, and/or [3] formation of circumstellar [CS] structure. We propose that the alleged micro-variability among Miras is largely undersampled, transient overtone pulsation structure in the light curves. ", "machine_text": "  We present the results of three years of photometric monitoring of the Mira variables with the HST/WFPC2, with a particular focus on the evolution of the accretion phases. We find that accretion episodes of different stars do not have the same duration and that the times when these episodes occur are not exactly periodic, although their length and their occurrence show some degree of periodicity. These results are consistent with a model in which the accretion episodes are triggered by the tidal interaction of the secondary star with the primary, and in which the actual occurrence of accretion episodes is randomly perturbed around a period. We find that the accretion phases can be further divided in two different subphases, which have different durations for each star. We have determined a robust period for the six brighter Mira variables in our sample, and find that the length of the accretion episode is in rough proportion with the period, with a correlation coefficient of 0.91. Our data also reveal that the accretion phases of different stars are not simultaneous, and that they are not exactly symmetric about the mean orbital period. We find that the distribution of the length of the accretion episodes is bimodal, with the bulk of the episodes being of intermediate duration, and that the long and short episodes occur with significantly different probabilities. The Mira variables appear to be in a transition between two different regimes, which have different properties. Our observations are consistent with a model in which the accretion episode is a random process, with the length of the episodes following an exponential distribution, and with the mean length being in proportion with the period. We discuss the implication of our results for the different models proposed to explain the observed accretion episodes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the effect of nearby supernova remnants on local cosmic rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3336, "human_text": "  In an earlier paper, the effect of the nearby known supernova remnants (SNRs) on the local cosmic-rays (CRs) was studied, considering different possible forms of the particle injection time. The present work is a continuation of the previous work, but assumes a more realistic model of CR propagation in the Galaxy. The previous work assumed an unbounded three-dimensional diffusion region, whereas the present one considers a flat cylindrical disc bounded in both the radial and vertical directions. The study has found that the effect of the vertical halo boundary $H$ on the local SNR contribution to the observed CR anisotropy is negligible as long as $H\\gtrsim 2kpc$. Considering the values of the halo height $H\\gtrsim 2kpc$ obtained by different authors, the present work suggests that the study of the effect of local sources on the CR anisotropy can be carried out without having much information on $H$ and hence, using the much simpler three-dimentional unbounded solution. Finally, the present work discusses about the possibility of explaining the observed anisotropy below the knee by a single dominant source with properly chosen source parameters, and claims that the source may be an \\textit{undetected} old SNR with a characteristic age of $\\sim 1.5\\times 10^5 yr$ located at a distance of $\\sim 0.57 kpc$ from the Sun. ", "machine_text": "  We revisit the effect of nearby supernova (SN) remnants on local cosmic rays (CRs) by analyzing a sample of 51 SN remnants within 50 pc of the Sun and 28 SN events that occurred within 1 kpc of the Sun during the last several million years. We show that the local excess of CRs over the background, as measured by the CR index, is significantly correlated with the rate of SN events within 1 kpc, but is not correlated with the number of nearby SN remnants. This suggests that the local CR excess is due to a combination of the interplanetary transport of CRs from old SN events and the recent termination of the CR injection from nearby SN remnants, but is not due to the continued injection of CRs from these SN remnants. We find that the local CR excess is best described by a power law with an index of 1.89 \u00b1 0.01. This is consistent with a simple model in which the local CR excess is due to a combination of the interplanetary transport of CRs from old SN events and the recent termination of the CR injection from nearby SN remnants, and in which the power law index is determined only by the history of SN events within 1 kpc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Matching WMAP 3-yrs results with the Cosmological Slingshot Primordial\n  Spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0025, "human_text": "  We consider a recently proposed scenario for the generation of primordial cosmological perturbations, the so called Cosmological Slingshot scenario. We firstly obtain a general expression for the Slingshot primordial power spectrum which extends previous results by including a blue pre-bounce residual contribution at large scales. Starting from this expression we numerically compute the CMB temperature and polarization power spectra arising from the Slingshot scenario and show that they excellently match the standard WMAP 3-years best-fit results. In particular, if the residual blue spectrum is far above the largest WMAP observed scale, the Slingshot primordial spectrum fits the data well by only fixing its amplitude and spectral index at the pivot scale k_p=10^{-3}h x Mpc^{-1}. We finally show that all possible distinctive Slingshot signatures in the CMB power spectra are confined to very low multipoles and thus very hard to detect due to large cosmic variance dominated error bars at these scales. ", "machine_text": " We present a detailed comparison of the 3-yr WMAP results with the Cosmological Slingshot Primordial Spectrum (COPS) in the regime $10^{-5} \\le q \\le 10^{-3}$. We show that the agreement between the two methods is excellent over the entire range of mass ratios $q$ and for all three elements of the COPS (the Dirac, Flip, and Jazz components). We explain the origin of a small disagreement between the WMAP results and the Flip and Jazz components of the COPS in the regime $q \\sim 10^{-4}$. We show that a simple model in which the primordial spectrum is the COPS multiplied by a small smooth function, can quantitatively reproduce the WMAP results. The model can be further simplified by assuming that the amplitude of the spectrum is inversely proportional to $q^2$. This model can be used to extract the amplitude of the spectrum in the range $q \\sim 10^{-4}$ to $q \\sim 10^{-2}$ with an accuracy comparable to that of the WMAP analysis. We explain why this model is consistent with the assumption that the primordial spectrum is the COPS multiplied by a small smooth function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structure of the stationary state of the asymmetric target process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0907, "human_text": "  We introduce a novel migration process, the target process. This process is dual to the zero-range process (ZRP) in the sense that, while for the ZRP the rate of transfer of a particle only depends on the occupation of the departure site, it only depends on the occupation of the arrival site for the target process. More precisely, duality associates to a given ZRP a unique target process, and vice-versa. If the dynamics is symmetric, i.e., in the absence of a bias, both processes have the same stationary-state product measure. In this work we focus our interest on the situation where the latter measure exhibits a continuous condensation transition at some finite critical density $\\rho_c$, irrespective of the dimensionality. The novelty comes from the case of asymmetric dynamics, where the target process has a nontrivial fluctuating stationary state, whose characteristics depend on the dimensionality. In one dimension, the system remains homogeneous at any finite density. An alternating scenario however prevails in the high-density regime: typical configurations consist of long alternating sequences of highly occupied and less occupied sites. The local density of the latter is equal to $\\rho_c$ and their occupation distribution is critical. In dimension two and above, the asymmetric target process exhibits a phase transition at a threshold density $\\rho_0$ much larger than $\\rho_c$. The system is homogeneous at any density below $\\rho_0$, whereas for higher densities it exhibits an extended condensate elongated along the direction of the mean current, on top of a critical background with density $\\rho_c$. ", "machine_text": "  We study the stationary state of the asymmetric simple target process. The motivation for this work is the fact that the stationary state of the asymmetric simple target process has not been studied before, despite the fact that this state is completely deterministic. We show that this stationary state is in general not unique. We then compute the stationary state of the asymmetric simple target process for some special cases, and study its properties. We also show how the knowledge of the stationary state of the asymmetric simple target process can be used to compute the stationary state of some other queueing processes.  The key ideas and methodology used in this work are the techniques of matrix analysis and the computation of the stationary distribution of queueing processes.  The results obtained in this work are the computation of the stationary state of the asymmetric simple target process in some special cases, and the obtained properties of this state. We also show how the knowledge of the stationary state of the asymmetric simple target process can be used to compute the stationary state of some other queueing processes.  This work attempts to solve the problem of computing the stationary state of the asymmetric simple target process, and to study its properties.  This work has practical applications in the analysis and design of queueing systems with general service time distributions, and in the analysis of the stationary state of some special queueing processes.  This work also has theoretical applications in the study of the structure of the stationary state of queueing processes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Adjointability of densely defined closed operators and the\n  Magajna-Schweizer Theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2576, "human_text": "  In this notes unbounded regular operators on Hilbert $C^*$-modules over arbitrary $C^*$-algebras are discussed. A densely defined operator $t$ possesses an adjoint operator if the graph of $t$ is an orthogonal summand. Moreover, for a densely defined operator $t$ the graph of $t$ is orthogonally complemented and the range of $P_FP_{G(t)^\\bot}$ is dense in its biorthogonal complement if and only if $t$ is regular. For a given $C^*$-algebra $\\mathcal A$ any densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert $C^*$-modules is regular, if and only if any densely defined $\\mathcal A$-linear closed operator $t$ between Hilbert $C^*$-modules admits a densely defined adjoint operator, if and only if $\\mathcal A$ is a $C^*$-algebra of compact operators. Some further characterizations of closed and regular modular operators are obtained.   Changes 1: Improved results, corrected misprints, added references. Accepted by J. Operator Theory, August 2007 / Changes 2: Filled gap in the proof of Thm. 3.1, changes in the formulations of Cor. 3.2 and Thm. 3.4, updated references and address of the second author. ", "machine_text": "  Let $\\mathcal{H}$ and $\\mathcal{K}$ be Hilbert spaces. We show that a densely defined closed operator $A\\in\\mathcal{L}( \\mathcal{H},\\mathcal{K} )$ is adjointable if and only if $\\mathcal{K}$ is the continuous dual of $\\mathcal{H}$. As a by-product we give a description of the space of all adjointable densely defined closed operators. We show that this space is isomorphic to the space of all continuous linear functionals. As a special case we obtain a characterization of the injective class of all densely defined closed operators. Also we show that the injective class is a linear subspace of the space of all densely defined closed operators. We show that the set of all densely defined closed operators is a linear subspace of the space of all closed operators. We show that every densely defined closed operator can be represented as a limit of an n-multipliers of a positive densely defined closed operator where $n\\in\\mathbb{N}$ and $0\\leq n\\leq\\infty$. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. As a by-product we obtain an alternative description of the injective class of positive densely defined closed operators. We show that every densely defined closed operator can be represented as a limit of an injective class of positive densely defined closed operators. As a by-product we obtain an alternative description of the injective class of positive densely defined closed operators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The velocity structure of moving magnetic feature pairs around sunspots:\n  support for the U-loop model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2507, "human_text": "  Using data recorded by the Michelson Doppler Imager (MDI) instrument on the Solar and Heliospheric Observatory (SOHO), we have traced 123 pairs of opposite magnetic polarity moving magnetic features (MMFs) in three active regions NOAA ARs 8375, 0330 and 9575. At the time of observation, AR 8375 was young, AR 0330 mature, and AR 9575 decaying. The vertical velocity indicates that the elements of MMF pairs with polarity opposite to that of the sunspot support a downflow of around 50-100 m s$^{-1}$. The average Doppler shift difference between negative and positive elements of an MMF pair is about 150 m s$^{-1}$ in AR 8375, 100 m s$^{-1}$ in AR 0330, and 20 m s$^{-1}$ in AR 9575. These observational results are in agreement with the model that MMF pairs are part of a U-loop emanating from the sunspot's magnetic canopy. According to this model the downflow is caused by the Evershed flow returning below the solar surface. For AR 8375, the horizontal velocity of MMFs ranges from 0.1 km s$^{-1}$ to 0.7 km s$^{-1}$, and on average, the velocity of an MMF pair decreases significantly (from 0.6 km s$^{-1}$ to 0.35 km s$^{-1}$) with increasing distance from the MMF's birth place. This result suggests that the change in MMF flow speed does not reflect the radial structure of the moat flow, but rather is intrinsic to the evolution of the MMF pairs. This result is also in agreement with the U-loop model of MMF pairs. We also find that properties of MMF pairs, most strikingly the lifetime, depend on the evolution stages of the parent sunspot. The mean lifetimes of MMF pairs in ARs 9575 and 0330 are 0.7 hours and 1.6 hours, respectively, which is considerably shorter than the 4 hours lifetime previously found for AR 8375. ", "machine_text": " We present a detailed analysis of the velocity structure of moving magnetic features (MMFs) around sunspots, based on high-resolution observations of the solar photosphere in the extreme-ultraviolet (EUV) and ultraviolet (UV) wavebands. We find that the majority of MMFs are associated with sunspot pairs, with each member of a pair moving in a different direction. We show that the distribution of MMF velocities is consistent with the U-loop model for the formation of sunspot pairs, in which the motion of the magnetic dipole structure (or \"U-loop\") is the dominant driver of the movement of MMFs. We also find that MMFs around sunspot pairs are on average faster and more elongated than MMFs around single sunspots, consistent with the U-loop model. In addition, we find that the relative velocity between MMFs in a sunspot pair increases with increasing separation, which is also consistent with the U-loop model. Our results provide strong support for the U-loop model of sunspot pair formation and have important implications for our understanding of the dynamics of magnetic fields on the solar surface.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Statistics of the Points Where Nodal Lines Intersect a Reference\n  Curve. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.335, "human_text": "  We study the intersection points of a fixed planar curve $\\Gamma$ with the nodal set of a translationally invariant and isotropic Gaussian random field $\\Psi(\\bi{r})$ and the zeros of its normal derivative across the curve. The intersection points form a discrete random process which is the object of this study. The field probability distribution function is completely specified by the correlation $G(|\\bi{r}-\\bi{r}'|) = <\\Psi(\\bi{r}) \\Psi(\\bi{r}')>$.   Given an arbitrary $G(|\\bi{r}-\\bi{r}'|)$, we compute the two point correlation function of the point process on the line, and derive other statistical measures (repulsion, rigidity) which characterize the short and long range correlations of the intersection points. We use these statistical measures to quantitatively characterize the complex patterns displayed by various kinds of nodal networks. We apply these statistics in particular to nodal patterns of random waves and of eigenfunctions of chaotic billiards. Of special interest is the observation that for monochromatic random waves, the number variance of the intersections with long straight segments grows like $L \\ln L$, as opposed to the linear growth predicted by the percolation model, which was successfully used to predict other long range nodal properties of that field. ", "machine_text": " We consider the statistics of the points where Nodal Lines, which are families of lines that intersect a given Reference Curve (RC) in a prescribed manner, intersect the RC. The number of these points is counted and their distribution is analyzed. We find that the points are uniformly distributed along the RC, with a variance that is inversely proportional to the length of the RC. Further analysis shows that the distribution of the points is the same for all Nodal Lines that intersect the RC in the prescribed manner, and hence, the statistics of the points are independent of the particular Nodal Lines chosen. We also derive a simple expression for the variance of the number of points in terms of the parameters of the Nodal Lines and the RC. Our results can be used to test the hypothesis that the points where a given Nodal Line intersect the RC are uniformly distributed along the RC. As an application, we consider the problem of selecting the optimal Nodal Lines to intersect a RC in a way that minimizes the number of points, while at the same time satisfying certain constraints on the Nodal Lines.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GRB 061121: Broadband spectral evolution through the prompt and\n  afterglow phases of a bright burst. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1609, "human_text": "  Swift triggered on a precursor to the main burst of GRB 061121 (z=1.314), allowing observations to be made from the optical to gamma-ray bands. Many other telescopes, including Konus-Wind, XMM-Newton, ROTSE and the Faulkes Telescope North, also observed the burst. The gamma-ray, X-ray and UV/optical emission all showed a peak ~75s after the trigger, although the optical and X-ray afterglow components also appear early on - before, or during, the main peak. Spectral evolution was seen throughout the burst, with the prompt emission showing a clear positive correlation between brightness and hardness. The Spectral Energy Distribution (SED) of the prompt emission, stretching from 1eV up to 1MeV, is very flat, with a peak in the flux density at ~1keV. The optical-to-X-ray spectra at this time are better fitted by a broken, rather than single, power-law, similar to previous results for X-ray flares. The SED shows spectral hardening as the afterglow evolves with time. This behaviour might be a symptom of self-Comptonisation, although circumstellar densities similar to those found in the cores of molecular clouds would be required. The afterglow also decays too slowly to be accounted for by the standard models. Although the precursor and main emission show different spectral lags, both are consistent with the lag-luminosity correlation for long bursts. GRB 061121 is the instantaneously brightest long burst yet detected by Swift. Using a combination of Swift and Konus-Wind data, we estimate an isotropic energy of 2.8x10^53 erg over 1keV - 10MeV in the GRB rest frame. A probable jet break is detected at ~2x10^5s, leading to an estimate of ~10^51 erg for the beaming-corrected gamma-ray energy. ", "machine_text": "  We present observations of the broadband spectral evolution of the Crab Nebula (Cebalragureeb) during the prompt and afterglow phases of the bright burst GRB 061121. Our observations constrain the energy deposition in the inner nebula to be  \u223c 4 kJ assuming a typical expansion velocity of 1,000 km s-1. We find that the ionization and evacuation of the gas by the burst is similar to that expected from a small, local supernova explosion, suggesting that the dominant ionizing radiation in the inner nebula is not the burst but rather the recently discovered soft gamma-ray source SGR 1900+14. We estimate the energy of this source to be  \u223c 5 kJ, which is not only comparable to but possibly larger than the energy deposited by the burst. This indicates that SGR 1900+14 is either a very close supernova (within  \u223c 5 kpc) or an intense radio source with a very high energy density ( \u223c 1014\u20131015 W m-3), perhaps powered by a combination of a black hole, massive stars, and active galactic nucleus. Our results imply that further study of the ionization and evacuation of gas in young and old nebulae by energetic bursts and a better understanding of the relative contributions of burst and non-burst ionizing sources are important to the study of galactic and intergalactic medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Maximum solutions of normalized Ricci flows on 4-manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0714, "human_text": "  We consider maximum solution $g(t)$, $t\\in [0, +\\infty)$, to the normalized Ricci flow. Among other things, we prove that, if $(M, \\omega) $ is a smooth compact symplectic 4-manifold such that $b_2^+(M)>1$ and let $g(t),t\\in[0,\\infty)$, be a solution to (1.3) on $M$ whose Ricci curvature satisfies that $|\\text{Ric}(g(t))|\\leq 3$ and additionally $\\chi(M)=3 \\tau (M)>0$, then there exists an $m\\in \\mathbb{N}$, and a sequence of points $\\{x_{j,k}\\in M\\}$, $j=1, ..., m$, satisfying that, by passing to a subsequence, $$(M, g(t_{k}+t), x_{1,k},..., x_{m,k}) \\stackrel{d_{GH}}\\longrightarrow (\\coprod_{j=1}^m N_j, g_{\\infty}, x_{1,\\infty}, ...,, x_{m,\\infty}),$$ $t\\in [0, \\infty)$, in the $m$-pointed Gromov-Hausdorff sense for any sequence $t_{k}\\longrightarrow \\infty$, where $(N_{j}, g_{\\infty})$, $j=1,..., m$, are complete complex hyperbolic orbifolds of complex dimension 2 with at most finitely many isolated orbifold points. Moreover, the convergence is $C^{\\infty}$ in the non-singular part of $\\coprod_1^m N_{j}$ and $\\text{Vol}_{g_{0}}(M)=\\sum_{j=1}^{m}\\text{Vol}_{g_{\\infty}}(N_{j})$, where $\\chi(M)$ (resp. $\\tau(M)$) is the Euler characteristic (resp. signature) of $M$. ", "machine_text": "  We introduce a notion of a solution of a normalized Ricci flow on a 4-manifold. We show that such a solution is uniquely determined up to a constant multiple. We show further that such a solution is smooth (for smooth initial data) and that the set of all such solutions is a linear subspace of the space of all continuous functions on the 4-manifold. We then show that this subspace is closed under the addition of smooth functions, and we show that the intersection of this subspace with the space of all functions smooth up to a constant multiple is a subspace of constant functions. We show that every solution of a normalized Ricci flow on a 4-manifold is a linear combination of smooth functions and constant functions in this fashion. We show further that the set of all such solutions is a closed subset of the space of all continuous functions on the 4-manifold. We show finally that every solution of a normalized Ricci flow on a 4-manifold has a special form: it is a function of the principal parts of the Ricci flow, integrated over the 4-manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geometric control theory I: mathematical foundations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2362, "human_text": "  A geometric setup for control theory is presented. The argument is developed through the study of the extremals of action functionals defined on piecewise differentiable curves, in the presence of differentiable non-holonomic constraints. Special emphasis is put on the tensorial aspects of the theory. To start with, the kinematical foundations, culminating in the so called variational equation, are put on geometrical grounds, via the introduction of the concept of infinitesimal control . On the same basis, the usual classification of the extremals of a variational problem into normal and abnormal ones is also rationalized, showing the existence of a purely kinematical algorithm assigning to each admissible curve a corresponding abnormality index, defined in terms of a suitable linear map. The whole machinery is then applied to constrained variational calculus. The argument provides an interesting revisitation of Pontryagin maximum principle and of the Erdmann-Weierstrass corner conditions, as well as a proof of the classical Lagrange multipliers method and a local interpretation of Pontryagin's equations as dynamical equations for a free (singular) Hamiltonian system. As a final, highly non-trivial topic, a sufficient condition for the existence of finite deformations with fixed endpoints is explicitly stated and proved. ", "machine_text": " We introduce a geometric framework for control theory. The key idea is to regard the evolution of a dynamical system as the flow of a geometric object, a so-called action functional, along the dynamics. This approach provides a unified framework for such diverse areas of control theory as feedback, hybrid systems, and control of partial differential equations. In the first part of the paper, we develop the mathematical foundations of this approach. We show that the evolution of an action functional along a system of differential equations is governed by a second order differential equation, the so-called geometric differential equation. We study some basic properties of this equation. In the second part of the paper, we apply our geometric framework to feedback control theory. We show how to characterize feedback stabilizing controllers in terms of the solutions of the geometric differential equation. Our results generalize classical feedback theory in several ways. In particular, we show that a controller which is stabilizing for a family of related dynamical systems need not be stabilizing for any individual system in the family.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Primordial Evolution in the Finitary Process Soup. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3771, "human_text": "  A general and basic model of primordial evolution--a soup of reacting finitary and discrete processes--is employed to identify and analyze fundamental mechanisms that generate and maintain complex structures in prebiotic systems. The processes--$\\epsilon$-machines as defined in computational mechanics--and their interaction networks both provide well defined notions of structure. This enables us to quantitatively demonstrate hierarchical self-organization in the soup in terms of complexity. We found that replicating processes evolve the strategy of successively building higher levels of organization by autocatalysis. Moreover, this is facilitated by local components that have low structural complexity, but high generality. In effect, the finitary process soup spontaneously evolves a selection pressure that favors such components. In light of the finitary process soup's generality, these results suggest a fundamental law of hierarchical systems: global complexity requires local simplicity. ", "machine_text": " We present a study of the evolution of complex behaviors in the finitary process soup, a simple abstract model of evolutionary systems. We show that a large class of behavior-substrate pairs leads to a victorian explosion of behavior, a phenomenon in which new behaviors rapidly overpopulate the space of behaviors, and then slowly die out, with the population of behaviors eventually converging to a stationary distribution. We show that the dynamics of this process is in fact the dynamics of an associated generalized finitary model, a generalization of the finitary process soup to allow for behaviors with non-trivial structure. We then consider the evolution of more complex behaviors, and show that the same dynamics applies, with the additional feature that the limit distribution of behaviors is not stationary, but rather evolving in a manner that depends on the original behavior-substrate pair. We then consider the evolution of still more complex behaviors, and show that this evolution is more complicated, with the additional feature that the evolved behaviors are not always the most fit for the environment, but rather that the most fit behaviors are selected with a probability that depends on their fitness. We finally consider a more general model of behavior evolution that allows for any possible dynamics of behavior change, and show that this model is well-behaved, with the additional feature that the evolved behaviors are not always the most fit for the environment, but rather that the most fit behaviors are selected with a probability that depends on their fitness.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two branches of neutron stars - reconciling a 2M_sun pulsar and SN1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4594, "human_text": "  The analysis of SN1987A led Brown and Bethe (1995) to conclusion, that the maximum mass of cold neutron stars is low, M_max ~ 1.5M_sun. Such a low M_max, due to a kaon condensation in the stellar core, implies collapse of a too massive deleptonized protoneutron star into a black hole. This would naturally explain the lack of a neutron star in the SN1987A remnant. On the other hand, recent evaluation of mass of PSR J0751+1807 gives M_max > 2M_sun. This contradicts the original Bethe-Brown model, but can be reconciled within scenarios proposed in the present Letter. We consider two types of dense matter models with high-density softening, due to a transition from a non-strange N-phase of matter to a strangeness carrying phase S: kaon condensation and deconfinement of quarks. Two scenarios of neutron star formation in stellar core collapse are considered. In the first scenario, realized in sufficiently hot and dense supernova cores, nucleation of an S-phase is sufficiently rapid so as to form an S-phase core, and implying M_max = M^S_max =~ 1.5M_sun. In the second scenario, nucleation of the S-phase at neutron star birth is too slow to materialize, and the star becomes cold without forming an S-phase core. Then, stellar mass can increase via accretion, until central density \\rho_crit is reached, and the S phase forms. This N branch of neutron stars ends at M=M_crit. We select several models of N-phase satifying the necessary condition M^N_max > 2M_sun and combine them with models of kaon condensation and quark deconfinement. For kaon condensation, we get M_crit =~ M^S_max =~ 1.5M_sun, which is ruled out by PSR J0751+1807. On the contrary, for the EOSs with quark deconfinement we get M_crit =~ M^N_max > 2M_sun, which reconciles SN1987A and PSR J0751+1807. ", "machine_text": " We present observations of the radio source 2MASS J2126, which is thought to be a low-mass X-ray binary containing a young, spinning neutron star with a relatively long spin-down lifetime. The source has been known for over two decades, but its nature has been controversial. We have observed 2MASS J2126 in outburst, in quiescence, and in a state of orbital decay. Our observations reconcile the apparently conflicting observations of other groups, and we show that the accretion disc is highly asymmetric, with a strong retrograde component. We estimate the accretion rate to be  \u223c 10^( \u2212 9) M_(\u2299) yr^( \u2212 1), which is not only several orders of magnitude less than the accretion rate in the last few thousand years, but is also smaller than the accretion rate needed to explain the observed spin-down of the neutron star. We suggest that the main accretion event occurred in the distant past, and that the accretion disc has been349uttering due to the complicated orbital dynamics caused by the neutron star's asymmetric spin. We show that 2MASS J2126 is the low-mass X-ray binary counterpart of the supernova SN1987A, which would make it the first known object in which a white dwarf and a neutron star co-exist.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Results on axion physics from the CAST Experiment at CERN. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0637, "human_text": "  Axions are expected to be produced in the sun via the Primakoff process. They may be detected through the inverse process in the laboratory, under the influence of a strong magnetic field, giving rise to X-rays of energies in the range of a few keV. Such an Axion detector is the CERN Axion Solar Telescope (CAST), collecting data since 2003. Results have been published, pushing the axion-photon coupling g$_{a\\gamma}$ below the 10$^{-10}$ GeV$^{-1}$ limit at 95% CL, for axion masses less than 0.02 eV. This limit is nearly an order of magnitude lower than previous experimental limits and surpassed for the first time limits set from astrophysical arguments based on the energy-loss concept. The experiment is currently exploring axion masses in the range of 0.02 eV $< m_a <$ 1.1 eV. In the next run, currently under preparation, the axion mass explored will be extended up to the limit of 1.1 eV, testing for the first time the region of theoretical axion models with the axion helioscope method. ", "machine_text": "  Abstract for: Results on axion physics from the CAST Experiment at CERN  We present the first results from the CAST experiment, which is a search for axions at the CERN PS_PSorraay accelerator. CAST is sensitive to axions with a mass between 1 and 100 times the mass of the proton and with a magnetic moment of $\\mu$B < 3.5 x 10^-26 G\\cm^3$. The CAST detector consists of a series of multi-layer coils, each layer being a multi-brand element. The layers are spaced by a factor of the nuclear magneton to allow for the separation of the axion and other signals. We present here the results from a first analysis of the CAST data set, obtained during the first part of the 2016 run. We show that the CAST detector is able to detect axions with the sought-after properties, and that the best fit to the data is given by an axion with a mass of the order of 1.5 times the mass of the proton. We also show that the CAST detector is sensitive to axion-like particles with a much higher mass, provided that they have a non-zero magnetic moment.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Succinct Indexable Dictionaries with Applications to Encoding $k$-ary\n  Trees, Prefix Sums and Multisets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0552, "human_text": "  We consider the {\\it indexable dictionary} problem, which consists of storing a set $S \\subseteq \\{0,...,m-1\\}$ for some integer $m$, while supporting the operations of $\\Rank(x)$, which returns the number of elements in $S$ that are less than $x$ if $x \\in S$, and -1 otherwise; and $\\Select(i)$ which returns the $i$-th smallest element in $S$. We give a data structure that supports both operations in O(1) time on the RAM model and requires ${\\cal B}(n,m) + o(n) + O(\\lg \\lg m)$ bits to store a set of size $n$, where ${\\cal B}(n,m) = \\ceil{\\lg {m \\choose n}}$ is the minimum number of bits required to store any $n$-element subset from a universe of size $m$. Previous dictionaries taking this space only supported (yes/no) membership queries in O(1) time. In the cell probe model we can remove the $O(\\lg \\lg m)$ additive term in the space bound, answering a question raised by Fich and Miltersen, and Pagh.   We present extensions and applications of our indexable dictionary data structure, including:   An information-theoretically optimal representation of a $k$-ary cardinal tree that supports standard operations in constant time,   A representation of a multiset of size $n$ from $\\{0,...,m-1\\}$ in ${\\cal B}(n,m+n) + o(n)$ bits that supports (appropriate generalizations of) $\\Rank$ and $\\Select$ operations in constant time, and   A representation of a sequence of $n$ non-negative integers summing up to $m$ in ${\\cal B}(n,m+n) + o(n)$ bits that supports prefix sum queries in constant time. ", "machine_text": "  We introduce a new data structure, called succinct indexable dictionaries, which generalize both hash tables and succinct data structures for sets. In addition, they can be viewed as a generalization of sequences. We show how to use these new data structures to solve a number of problems in different areas, including encoding $k$-ary trees, prefix sums and multisets. In particular, we show that a succinct indexable dictionary can be used to answer set operations (such as intersection, union, and difference) on $k$-ary trees in $O(\\log n)$ time, where $n$ is the number of elements in the $k$-ary tree, for any fixed $k$. We also show how to maintain a dynamic prefix sum using a succinct indexable dictionary in $O(\\log n)$ time, where $n$ is the number of elements in the sequence. In addition, we show how to maintain a dynamic multiset using a succinct indexable dictionary in $O(\\log n)$ time, where $n$ is the number of elements in the multiset. We complement our results with a number of auxiliary results and impossibility results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Jets, Blazars and the EBL in the GLAST-EXIST Era. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4492, "human_text": "  The synergy of GLAST and the proposed EXIST mission as the Black Hole Finder Probe in the Beyond Einstein Program is remarkable. With its full-sky per orbit hard X-ray imaging (3-600 keV) and \"nuFnu\" sensitivity comparable to GLAST, EXIST could measure variability and spectra of Blazars in the hard X-ray synchrotron component simultaneous with GLAST (~10-100GeV) measures of the inverse Compton component, thereby uniquely constraining intrinsic source spectra and allowing measured high energy spectral breaks to measure the cosmic diffuse extra-galactic background light (EBL) by determining the intervening diffuse IR photon field required to yield the observed break from photon-photon absorption. Such studies also constrain the physics of jets (and parameters and indeed the validity of SSC models) and the origin of the >100 MeV gamma-ray diffuse background likely arising from Blazars and jet-dominated sources. An overview of the EXIST mission, which could fly in the GLAST era, is given together with a synopsis of other key synergies of GLAST-EXIST science. ", "machine_text": " We have made significant progress in understanding the high-energy Universe by observing the high-energy cosmic rays and gamma-rays produced by the extreme objects in our Galaxy and beyond. The era of ground-based gamma-ray astronomy began with the COBE/FIRAS experiment in the early 1990s, and the past two decades have witnessed a dramatic growth in the field, which has been greatly benefited from the efforts of a number of balloon-borne and space-borne missions, in particular the Compton Gamma Ray Observatory (CGRO) and the INTEGRAL satellite. The space-borne Fermi Gamma-ray Space Telescope, which was launched in 2008, is the latest and most sensitive instrument in the field and has greatly expanded our knowledge on the gamma-ray sky, in particular, by detecting a large number of extragalactic sources, many of which are potentially associated with supermassive black holes. In this article, we review the current status and progress in our understanding of the high-energy Universe based on the observations carried out during the last two decades, and discuss the perspectives of the field in the era of the GLAST-EXIST program.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fourier resolved spectroscopy of 4U 1728-34: New Insights into Spectral\n  and Temporal Properties of Low-Mass X-ray Binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1552, "human_text": "  Using archival RXTE data we derive the 2-16 keV Fourier-resolved spectra of the Atoll source 4U 1728-34 in a sequence of its timing states as its low QPO frequency spans the range between 6 and 94 Hz. The increase in the QPO frequency accompanies a spectral transition of the source from its island to its banana states. The banana-states' Fourier-resolved spectra are well fitted by a single blackbody component with $kT \\sim 2-3$ keV depending on the source position in the color -- color diagram and the Fourier frequency, thus indicating that this spectral component is responsible for the source variability on these timescales. This result is in approximate agreement with similar behavior exhibited by the Z sources, suggesting that, as in that case, the boundary layer -- the likely source of the thermal component -- is supported by radiation pressure. Furthermore, it is found that the iron line at $\\sim$6.6 keV, clearly present in the averaged spectra, not apparent within the limitations of our measurements in the frequency-resolved spectra irrespective of the frequency range. This would indicate that this spectral component exhibits little variability on time scales comprising the interval $10^{-2}-10^2$ seconds. In the island state the single blackbody model proved inadequate, particularly notable in our lowest frequency band ($0.008-0.8$ Hz). An absorbed powerlaw or an additive blackbody plus hard powerlaw model was required to obtain a satisfactory fit. Statistics do not allow unambiguous discrimination between these possible scenarios. ", "machine_text": "  We present Fourier resolved spectroscopy of the low-mass X-ray binary 4U 1728-34. We observe the system in quiescence and measure spectral and temporal properties of the outbursts. We find that the accretion disc fluoresces brighter in the blue than in the red, in spite of the fact that the disc is seen nearly edge-on. This effect is explained by a strong temperature dependence of the emission measure. The measured width of the accretion disc is consistent with the disc being stable on the timescale of our observations, which covers several outbursts. We determine the accretion disc density from the measured accretion rate and find that it is a factor of  \u223c 2 lower than expected from assumptions of isothermal accretion and auniform density. The observed frequency-doubled burst modulation and the high-frequency noise in the outburst spectrum are explained by a model in which the inner accretion disc is geometrically stable and the outer accretion disc is stable on the timescale of an outburst but becomes instable on longer timescales. We discuss the origin of the low accretion disc density and the frequent eruptions from quiescence.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Newton's law in supersymmetric braneworld models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4104, "human_text": "  We study the propagation of gravitons within 5-D supersymmetric braneworld models with a bulk scalar field. The setup considered here consists of a 5-D bulk spacetime bounded by two 4-D branes localized at the fixed points of an $S^1/Z_2$ orbifold. There is a scalar field $\\phi$ in the bulk which, provided a superpotential $W(\\phi)$, determines the warped geometry of the 5-D spacetime. This type of scenario is common in string theory, where the bulk scalar field $\\phi$ is related to the volume of small compact extra dimensions. We show that, after the moduli are stabilized by supersymmetry breaking terms localized on the branes, the only relevant degrees of freedom in the bulk consist of a 5-D massive spectrum of gravitons. Then we analyze the gravitational interaction between massive bodies localized at the positive tension brane mediated by these bulk gravitons. It is shown that the Newtonian potential describing this interaction picks up a non-trivial contribution at short distances that depends on the shape of the superpotential $W(\\phi)$. We compute this contribution for dilatonic braneworld scenarios $W(\\phi) = e^{\\alpha \\phi}$ (where $\\alpha$ is a constant) and discuss the particular case of 5-D Heterotic M-theory: It is argued that a specific footprint at micron scales could be observable in the near future. ", "machine_text": " We consider the question of the possibility of extracting from a rotating (asymptotically flat) brane-world a dynamical system which would describe, in the limit of large radius, the behavior of a particle subjected to an inverse square law (ISL) force. Our main result is that this is possible only if the rotation frequency is an odd multiple of the inverse of the ISL coupling. This is consistent with the fact that for even multiples of this frequency the dynamics is governed by a generalized ISL law with a non-zero fourth power of the distance. In the case of a large radius this would correspond to an inverse law with a non-zero fourth power of the radius. In this case the effective Newton's law is not Newton's law anymore, but a generalization which may be non-conservative. In the case of an odd multiple of the inverse of the ISL coupling the dynamics is described by a generalized ISL law with a vanishing fourth power of the distance. This case is physically meaningful only if the inverse square law is a special case of a more general law with a non-zero fourth power of the distance (i.e. the potential has a non-zero fourth power at large distances). We discuss possible physical meanings of this case. In both cases the main condition for the dynamics to be well-defined is that the ratio of the rotation frequency to the inverse of the ISL coupling is an integer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Route to Lambda in conformally coupled phantom cosmology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1651, "human_text": "  In this letter we investigate acceleration in the flat cosmological model with a conformally coupled phantom field and we show that acceleration is its generic feature. We reduce the dynamics of the model to a 3-dimensional dynamical system and analyze it on a invariant 2-dimensional submanifold. Then the concordance FRW model with the cosmological constant $\\Lambda$ is a global attractor situated on a 2-dimensional invariant space. We also study the behaviour near this attractor, which can be approximated by the dynamics of the linearized part of the system. We demonstrate that trajectories of the conformally coupled phantom scalar field with a simple quadratic potential crosses the cosmological constant barrier infinitely many times in the phase space. The universal behaviour of the scalar field and its potential is also calculated. We conclude that the phantom scalar field conformally coupled to gravity gives a natural dynamical mechanism of concentration of the equation of state coefficient around the magical value $w_{\\text{eff}}=-1$. We demonstrate route to Lambda through the infinite times crossing the $w_{\\text{eff}}=-1$ phantom divide. ", "machine_text": " We study the problem of realizing a cosmological constant in a conformally coupled phantom cosmology. We show that the easiest way to achieve this is to follow a route that starts with aphantom cosmology with a positive cosmological constant and an attraction-only gravity, and then consider the cosmological constant to be due to a repulsion from an exactly balanced pairwise force. The route is motivated by the fact that in the regime of strong gravity the dominant contribution to the conformal coupling is the Einstein- Gauss term, which is proportional to the gravitational flux, and that this term can be made to be strictly positive by using a phantom cosmology with a positive cosmological constant and an attraction-only gravity. We show that this is the only way to ensure that the conformal coupling will not flip the sign of the cosmological constant. As a byproduct we also show that the effective Einstein-Infeld gravity in this regime has a Weyl-like self-coupling that can be made arbitrarily small by an appropriate choice of the parameters. We comment on the fact that the standard Einstein- Gauss term is proportional to the flux, not the gradient of the flux, which may have some consequences for the problem of identifying the gravity theory with a suitable cosmology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: In-plane structure and ordering at liquid sodium surfaces and interfaces\n  from ab initio molecular dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3872, "human_text": "  Atoms at liquid metal surfaces are known to form layers parallel to the surface. We analyze the two-dimensional arrangement of atoms within such layers at the surface of liquid sodium, using ab initio molecular dynamics (MD) simulations based on density functional theory. Nearest neighbor distributions at the surface indicate mostly 5-fold coordination, though there are noticeable fractions of 4-fold and 6-fold coordinated atoms. Bond angle distributions suggest a movement toward the angles corresponding to a six-fold coordinated hexagonal arrangement of the atoms as the temperature is decreased towards the solidification point. We rationalize these results with a distorted hexagonal order at the surface, showing a mixture of regions of five and six-fold coordination. The liquid surface results are compared with classical MD simulations of the liquid surface, with similar effects appearing, and with ab initio MD simulations for a model solid-liquid interface, where a pronounced shift towards hexagonal ordering is observed as the temperature is lowered. ", "machine_text": " We present an overview of our recent work on the in-plane structure and ordering at liquid sodium surfaces and interfaces, based on large-scale ab initio molecular dynamics simulations. We have investigated the structural and dynamic properties of liquid sodium on a range of different substrate materials, including nickel, copper, and iron, as well as pure liquid sodium itself, in order to identify the effects of the different interfacial interactions on the electronic and structural properties of the interface. We have found that the behavior of liquid sodium is very sensitive to the details of the interfacial interaction, with different types of ordering behavior resulting from different interfacial interactions. We have also found that the nature of the ordering at the interface is very sensitive to the details of the electronic structure of the interface, with different types of electronic structure resulting in different types of ordering behavior. We have also found that the dynamic properties of the interface are very sensitive to the details of the interfacial interaction, with different types of interfacial interactions resulting in different types of dynamic behavior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of capillary-induced interactions beyond the superposition\n  approximation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0013, "human_text": "  Within a general theoretical framework we study the effective, deformation-induced interaction between two colloidal particles trapped at a fluid interface in the regime of small deformations. In many studies, this interaction has been computed with the ansatz that the actual interface configuration for the pair is given by the linear superposition of the interface deformations around the single particles. Here we assess the validity of this approach and compute the leading term of the effective interaction for large interparticle separation beyond this so-called superposition approximation. As an application, we consider the experimentally relevant case of interface deformations owing to the electrostatic field emanating from charged colloidal particles. In mechanical isolation, i.e., if the net force acting on the total system consisting of the particles plus the interface vanishes, the superposition approximation is actually invalid. The effective capillary interaction is governed by contributions beyond this approximation and turns out to be attractive. For sufficiently small surface charges on the colloids, such that linearization is strictly valid, and at asymptotically large separations, the effective interaction does not overcome the direct electrostatic repulsion between the colloidal particles. ", "machine_text": " We consider the theory of capillary-induced interactions beyond the superposition approximation. We show that the dynamics of wetting and dewetting of a solid substrate by a liquid can be described by a general mathematical framework that accounts for the nonlocal nature of capillary interactions. Our approach is based on the notion of a boundary mode, which is a particular type of eigenmode of the Laplace operator that is invariant under the superposition approximation. We show that the nonlocal interaction between a solid substrate and a liquid can be expressed as a sum of boundary modes, and that this expression is valid beyond the superposition approximation. This theory enables us to study the rich set of wetting and dewetting dynamics that are beyond the scope of the superposition approximation, including the formation of liquid bridges and the break-up of wetting films. We show that these dynamics can be understood in terms of the symmetry and stability of the various boundary modes that are involved. We also discuss the practical implications of this theory for the design of functionalized surfaces and interfaces.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Softening of the stiffness of bottlebrush polymers by mutual interaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3329, "human_text": "  We study bottlebrush macromolecules in a good solvent by small-angle neutron scattering (SANS), static light scattering (SLS), and dynamic light scattering (DLS). These polymers consist of a linear backbone to which long side chains are chemically grafted. The backbone contains about 1600 monomer units (weight average) and every second monomer unit carries side-chains with ca. 60 monomer units. The SLS- and SANS data extrapolated to infinite dilution lead to the form factor of the polymer that can be described in terms of a worm-like chain with a contour length of 380 nm and a persistence length of 17.5 nm. An analysis of the DLS data confirm these model parameters. The scattering intensities taken at finite concentration can be modeled using the polymer reference interaction site model. It reveals a softening of the bottlebrush polymers caused by their mutual interaction. We demonstrate that the persistence decreases from 17.5 nm down to 5 nm upon increasing the concentration from dilute solution to the highest concentration 40.59 g/l under consideration. The observed softening of the chains is comparable to the theoretically predicted decrease of the electrostatic persistence length of linear polyelectrolyte chains at finite concentrations. ", "machine_text": "  We have developed a new algorithm to evaluate the stiffness of bottlebrush polymers in a solvent, which takes into account the anisotropic features of the polymer in a simple and efficient way. The practical application of this algorithm is the prediction of the unknown properties of bottlebrush polymers, which has important consequences in many practical applications, such as the design of new polymers for drug delivery systems. The new algorithm is based on the evaluation of the difference between the solvent-induced energy and the energy of the collapsed state of the polymer, the so-called collapse energy, which gives the difference between the measured stiffness and the intrinsic stiffness of the polymer. The intrinsic stiffness is evaluated from the statistical properties of the monomers, such as the polymerization number and the Flory radius. The practical use of this algorithm is illustrated with the prediction of the stiffness of a new generation of polymers, the so-called double-combed bottlebrush polymers, which have been recently synthesized and which are of great interest for the design of new drug delivery systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray Timing Observations of PSR J1930+1852 in the Crab-like SNR\n  G54.1+0.3. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0973, "human_text": "  We present new X-ray timing and spectral observations of PSR J1930+1852, the young energetic pulsar at the center of the non-thermal supernova remnant G54.1+0.3. Using data obtained with the Rossi X-ray Timing Explorer and Chandra X-ray observatories we have derived an updated timing ephemeris of the 136 ms pulsar spanning 6 years. During this interval, however, the period evolution shows significant variability from the best fit constant spin-down rate of $\\dot P = 7.5112(6) \\times 10^{-13}$ s s$^{-1}$, suggesting strong timing noise and/or glitch activity. The X-ray emission is highly pulsed ($71\\pm5%$ modulation) and is characterized by an asymmetric, broad profile ($\\sim 70%$ duty cycle) which is nearly twice the radio width. The spectrum of the pulsed emission is well fitted with an absorbed power law of photon index $\\Gamma = 1.2\\pm0.2$; this is marginally harder than that of the unpulsed component. The total 2-10 keV flux of the pulsar is $1.7 \\times 10^{-12}$ erg cm$^{-2}$ s$^{-1}$. These results confirm PSR J1930+1852 as a typical Crab-like pulsar. ", "machine_text": " We have carried out a timing observation of the radio pulsar PSR J1930+1852 in the context of a wider search for pulsars in low-mass X-ray binaries (LMXBs). The observations were made with the Whipple Observatory 10-m telescope and the Interferometer Pharos Array (IPA) and covered a period of nearly three years. We find no evidence of a photometric or timing correlation between the radio pulsar and the X-ray transient in the same system, PSR J1930+1852. We determine a 2-sigma upper limit of 4.6 hours on the orbital period of the system, which excludes the low-hard X-ray transient as being in a wide-binodal orbit with many long-period (>> 3 hours) flares. The observed properties of PSR J1930+1852 are consistent with a model in which the radio and X-ray sources are in a narrow-binodal orbit with many short-period (<< 3 hours) flares. We discuss this in the context of known LMXBs and the limited statistics available. We find that a simple model in which the accretion disc is treated as a uniform density sphere of the given radius is consistent with the observed data, and we estimate the accretion disc radii for PSR J1930+1852 and five other LMXBs with well-determined radii. The resulting probability distribution function (PDF) for disc radii is consistent with a power law with a high-mass cut-off of 3 solar masses, but we are unable to distinguish between a steep power law ( P Mrad \u221d r-3) and a shallower power law ( P Mrad \u221d r-2) for the mass distribution. The high-mass cut-off in the accretion disc radius PDF excludes a pure Roster matrix model for the mass distribution, but is consistent with a stepped distribution in which the low-mass (<< 3 solar masses) accretion disc is described by a Roster matrix and the high-mass (>> 3 solar masses) accretion disc is described by a random matrix. We discuss the implications of our results for the theory of LMXBs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Collisions between equal sized ice grain agglomerates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2672, "human_text": "  Following the recent insight in the material structure of comets, protoplanetesimals are assumed to have low densities and to be highly porous agglomerates. It is still unclear if planetesimals can be formed from these objects by collisional growth. Therefore, it is important to study numerically the collisional outcome from low velocity impacts of equal sized porous agglomerates which are too large to be examined in a laboratory experiment. We use the Lagrangian particle method Smooth Particle Hydrodynamics to solve the equations that describe the dynamics of elastic and plastic bodies. Additionally, to account for the influence of porosity, we follow a previous developed equation of state and certain relations between the material strength and the relative density. Collisional growth seems possible for rather low collision velocities and particular material strengths. The remnants of collisions with impact parameters that are larger than 50% of the radius of the colliding objects tend to rotate. For small impact parameters, the colliding objects are effectively slowed down without a prominent compaction of the porous structure, which probably increases the possibility for growth. The protoplanetesimals, however, do not stick together for the most part of the employed material strengths. An important issue in subsequent studies has to be the influence of rotation to collisional growth. Moreover, for realistic simulations of protoplanetesimals it is crucial to know the correct material parameters in more detail. ", "machine_text": "  Collisions between equal-sized ice grain agglomerates Agents of erosion, ice grain agglomerates (IGAs) are widespread in the solar system and can have macroscopic impacts on the surfaces of planets and satellites. Collisions between IGAs are expected to be an important process in the evolution of these surfaces, but the existing theories are not able to explain the nature of the impact craters observed. We present a new model of collisions between equal-sized IGAs, which can produce craters of the sizes observed, provided that the IGAs are icy, rather than icy-rocky, and that the collisions are not perfectly elastic. Our model indicates that the craters observed on Europa's surface may have formed by such collisions, whereas on the surface of Pluto's moon Charon, the energy release may have been sufficient to form geological structures on the scale of mountains. We discuss the implications of this model for the energy budgets of icy bodies, and in particular for the thickness of the icy shells of the Europa and the Earth's moon.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The competition of hydrogen-like and isotropic interactions on polymer\n  collapse. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2162, "human_text": "  We investigate a lattice model of polymers where the nearest-neighbour monomer-monomer interaction strengths differ according to whether the local configurations have so-called ``hydrogen-like'' formations or not. If the interaction strengths are all the same then the classical $\\theta$-point collapse transition occurs on lowering the temperature, and the polymer enters the isotropic liquid-drop phase known as the collapsed globule. On the other hand, strongly favouring the hydrogen-like interactions give rise to an anisotropic folded (solid-like) phase on lowering the temperature. We use Monte Carlo simulations up to a length of 256 to map out the phase diagram in the plane of parameters and determine the order of the associated phase transitions. We discuss the connections to semi-flexible polymers and other polymer models. Importantly, we demonstrate that for a range of energy parameters two phase transitions occur on lowering the temperature, the second being a transition from the globule state to the crystal state. We argue from our data that this globule-to-crystal transition is continuous in two dimensions in accord with field-theory arguments concerning Hamiltonian walks, but is first order in three dimensions. ", "machine_text": " The competition of hydrogen-like and isotropic interactions on polymer collapse  The competition between hydrogen-like and isotropic interactions in macromolecular systems is an old and controversial problem. The objective of this work is to reexamine this problem in the framework of the Cray surfing model. We consider the effects of different macromolecular interactions on the equilibrium structure and the dynamical properties of the polymer chain. We show that the different interactions compete with each other in a different way for the collapsed and the extended states. Our main result is that the competition between the different interactions is effectively reduced to the competition between the hydrogen-like and the isotropic interactions, if the difference between these two interaction strengths is sufficiently large. The practical consequence of this result is that the collapse of the polymer chain is a truly competitive process, while the dynamics is mainly influenced by the strong hydrogen-like interactions, if the differences in the strengths of the various interactions is sufficiently large. We discuss the relevance of our results for experimental studies of the dynamics of biological macromolecules.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of ASTROD I test mass charging due to solar energetic\n  particles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3493, "human_text": "  As ASTROD I travels through space, its test mass will accrue charge due to galactic cosmic-rays and solar energetic particles incident on the spacecraft. This test mass charge will result in Coulomb forces between the test mass and the surrounding electrodes. In earlier work using the GEANT4 toolkit, we predicted a net charging rate of nearly 9.0 +e/s from cosmic-ray protons between 0.1 and 1000 GeV at solar maximum, and rising to 26.5 +e/s at solar minimum. Here we use GEANT4 to simulate the charging process due to solar energetic particle events and to estimate the magnitude of acceleration noise due to this charging. The predicted charging rates range from 2840 to 64300 +e/s, at peak intensity, for the 4 largest SEP events in September and October 1989. For the 2 larger events, the acceleration disturbances due to charging exceeds the ASTROD I acceleration noise budget requirement. Continuous discharge should be considered for suppressing this charging noise. The acceleration noise during the 2 small events is well below the design target, although during these events, the net charging rate will be dominated by these solar fluxes. ", "machine_text": " We present a detailed simulation study of the test mass charging due to solar energetic particles (SEPs) in the Anti-Symmetric Tether Regulation of Outer Disks (ASTROD) I mission. We investigate the charging process on a test mass, which is a conducting sphere, in the presence of a time-dependent background plasma, constituted by a semi-infinite uniform plasma and a spatially dependent background plasma. We solve numerically the nonlinear diffusion equation for the test mass potential, which is a sum of adcpl telegraphic impulse response (TIR) and a low frequency (LF) integral equation. We consider two different shapes for the LF kernel: a punctual kernel and a super-Gaussian kernel, in order to take into account the different spatial structure of the background plasmas. We show that a good agreement between the simulation results and the analytical prediction based on the TIR is obtained when theLF kernel has a punctual form, while it is necessary to use a super-Gaussian kernel to get a good agreement in the case of a spatially dependent background plasma. We also show that theLF potential contribution to the test mass potential can be evaluated analytically in the case of a punctual LF kernel, in good agreement with the simulation results. Finally, we analyze the effect of the spacecraft potential and of the electric field to the test mass charging process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Catastrophic eruption of magnetic flux rope in the corona and solar wind\n  with and without magnetic reconnection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3885, "human_text": "  It is generally believed that the magnetic free energy accumulated in the corona serves as a main energy source for solar explosions such as coronal mass ejections (CMEs). In the framework of the flux rope catastrophe model for CMEs, the energy may be abruptly released either by an ideal magnetohydrodynamic (MHD) catastrophe, which belongs to a global magnetic topological instability of the system, or by a fast magnetic reconnection across preexisting or rapidly-developing electric current sheets. Both ways of magnetic energy release are thought to be important to CME dynamics. To disentangle their contributions, we construct a flux rope catastrophe model in the corona and solar wind and compare different cases in which we either prohibit or allow magnetic reconnection to take place across rapidly-growing current sheets during the eruption. It is demonstrated that CMEs, even fast ones, can be produced taking the ideal MHD catastrophe as the only process of magnetic energy release. Nevertheless, the eruptive speed can be significantly enhanced after magnetic reconnection sets in. In addition, a smooth transition from slow to fast eruptions is observed when increasing the strength of the background magnetic field, simply because in a stronger field there is more free magnetic energy at the catastrophic point available to be released during an eruption. This suggests that fast and slow CMEs may have an identical driving mechanism. ", "machine_text": " We present a theory of the catastrophic eruption of a magnetic flux rope in the corona and solar wind, with and without magnetic reconnection. The theory is based on the idea that the energy stored in the winding up of the magnetic flux rope is the main energy source for the eruption. We show that the evolution of the magnetic flux rope is different in the presence and absence of a guide field. In the absence of a guide field, the magnetic flux rope can be unstable against a large-scale eruption even in the quiescent state, which is in disagreement with the observation. In the presence of a guide field, the magnetic flux rope is stable in the quiescent state but can be triggered to a large-scale eruption by a small-scale instability. The different evolution of the magnetic flux rope in the presence and absence of a guide field can be explained by the difference of the energy budget. We also investigate the influence of the resistivity on the evolution of the magnetic flux rope. A high resistivity tends to increase the energy stored in the magnetic flux rope and therefore enhances the possibility for a large-scale eruption.  We thank T. bundles for helpful discussions. This work was supported by the Research and Development Center of the Ministry of Science and Technology of China (No. RDC (3)021403, 0113018) and the National Natural Science Foundation of China (No. 10774003, 11021092).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Novel String Derived Z' With Stable Proton, Light-Neutrinos and\n  R-parity violation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1256, "human_text": "  The Standard Model indicates the realization of grand unified structures in nature, and can only be viewed as an effective theory below a higher energy cutoff. While the renormalizable Standard Model forbids proton decay mediating operators due to accidental global symmetries, many extensions of the Standard Model introduce such dimension four, five and six operators. Furthermore, quantum gravity effects are expected to induce proton instability, indicating that the higher energy cutoff scale must be above 10^{16}GeV. Quasi-realistic heterotic string models provide the arena to explore how perturbative quantum gravity affects the particle physics phenomenology. An appealing explanation for the proton longevity is provided by the existence of an Abelian gauge symmetry that suppresses the proton decay mediating operators. Additionally, such a low-scale U(1) symmetry should: allow the suppression of the left-handed neutrino masses by a seesaw mechanism; allow fermion Yukawa couplings to the electroweak Higgs doublets; be anomaly free; be family universal. These requirements render the existence of such U(1) symmetries in quasi-realistic heterotic string models highly non-trivial. We demonstrate the existence of a U(1) symmetry that satisfies all of the above requirements in a class of left-right symmetric heterotic string models in the free fermionic formulation. The existence of the extra Z' in the energy range accessible to future experiments is motivated by the requirement of adequate suppression of proton decay mediation. We further show that while the extra U(1) forbids dimension four baryon number violating operators it allows dimension four lepton number violating operators and R-parity violation. ", "machine_text": " We propose a model with a Z' symmetry group and two families of light-like fermions, one of which is related to the usual Z and the other to the Z' operator. The model is capable of generating a scale invariant representation for the Z' group which may be related to the hidden symmetry behind the strong interaction. The model is an extension of the hidden local symmetry model and contains two generations of hidden local symmetry fermions. In addition to the usual suspects, the quarks and the charged leptons, we include two families of hidden local symmetry fermions with the same masses as the up and down quarks and the electron and the muon, respectively. The gauge bosons are related to the Z and Z' operators in the same way the Z and Z' bosons are related in the hidden local symmetry model. We show that the model is invariant under a general coordinate transformation which relates the hidden local symmetry fermions to the quarks and charged leptons. The model generates a Z' symmetry group which may be related to the hidden symmetry behind the strong interaction. The quarks and charged leptons are related to the hidden local symmetry fermions by a general coordinate transformation which can be implemented by the transformation which relates the Z and Z' bosons in the hidden local symmetry model. We show that the model can generate a scale invariant representation for the Z' group which may be related to the hidden symmetry behind the strong interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the slow dynamics of a silica melt using Monte Carlo\n  simulations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2783, "human_text": "  We implement a standard Monte Carlo algorithm to study the slow, equilibrium dynamics of a silica melt in a wide temperature regime, from 6100 K down to 2750 K. We find that the average dynamical behaviour of the system is in quantitative agreement with results obtained from molecular dynamics simulations, at least in the long-time regime corresponding to the alpha-relaxation. By contrast, the strong thermal vibrations related to the Boson peak present at short times in molecular dynamics are efficiently suppressed by the Monte Carlo algorithm. This allows us to reconsider silica dynamics in the context of mode-coupling theory, because several shortcomings of the theory were previously attributed to thermal vibrations. A mode-coupling theory analysis of our data is qualitatively correct, but quantitative tests of the theory fail, raising doubts about the very existence of an avoided singularity in this system. We discuss the emergence of dynamic heterogeneity and report detailed measurements of a decoupling between translational diffusion and structural relaxation, and of a growing four-point dynamic susceptibility. Dynamic heterogeneity appears to be less pronounced than in more fragile glass-forming models, but not of a qualitatively different nature. ", "machine_text": "  We revisit the problem of the slow dynamics of a silica melt, using Monte Carlo simulations. We consider the stochastic model recently proposed by Tatara et al. (J. Chem. Phys., 2016, 145, 034105) to describe the molecular dynamics of a silica melt, and we use Monte Carlo simulations to study the relaxation of density and temperature fluctuations in this model. We find that the relaxation times of the density and temperature fluctuations are very long, of the order of $10^{1000}$ and $10^{100}$ respectively. In order to investigate the origin of these long relaxation times, we study the distribution of the probabilities $p_x$ of finding the system in the state $x$ at a given time, for several initial conditions. We show that these distributions are very narrow, and we relate this result to the small value of the variance $\\Delta\\dot x^2/\\dot x$ in the system. We also show that the $p_x$ distributions are not symmetric, and that their asymmetry is related to the initial conditions. We finally discuss the physical meanings of these results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hamiltonian formalism in Friedmann cosmology and its quantization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0672, "human_text": "  We propose a Hamiltonian formalism for a generalized Friedmann-Roberson-Walker cosmology model in the presence of both a variable equation of state (EOS) parameter $w(a)$ and a variable cosmological constant $\\Lambda(a)$, where $a$ is the scale factor. This Hamiltonian system containing 1 degree of freedom and without constraint, gives Friedmann equations as the equation of motion, which describes a mechanical system with a variable mass object moving in a potential field. After an appropriate transformation of the scale factor, this system can be further simplified to an object with constant mass moving in an effective potential field. In this framework, the $\\Lambda$ cold dark matter model as the current standard model of cosmology corresponds to a harmonic oscillator. We further generalize this formalism to take into account the bulk viscosity and other cases. The Hamiltonian can be quantized straightforwardly, but this is different from the approach of the Wheeler-DeWitt equation in quantum cosmology. ", "machine_text": "  Introduction: In this work we consider the Hamiltonian formalism in Friedmann cosmology and its quantization. We start with a brief review of the Hamiltonian formalism in general, and then we continue with the Hamiltonian formalism in Friedmann cosmology. We derive the Hamiltonian equations in this context and we solve them analytically. The solutions of the homogeneous and isotropic model are the same as the solutions of the Newtonian theory. The non-homogeneous and anisotropic case is more complicated. In this case the solution has two degrees of freedom, which we call \"cosmological constant\" and \"effective density\". We show that the possible values of these two degrees of freedom are restricted by the condition that the total energy is constant. In addition, we show that the solutions of the non-homogeneous and anisotropic case are singular. Finally, we discuss the quantization of the Hamiltonian system. We show that the quantization is equivalent to the quantization of the energy. We also show that the energy is quantized in a discrete set of values. The correspondence between the values of the energy and the values of the cosmological constant and the effective density is also discussed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Controlling for individual heterogeneity in longitudinal models, with\n  applications to student achievement. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1401, "human_text": "  Longitudinal data tracking repeated measurements on individuals are highly valued for research because they offer controls for unmeasured individual heterogeneity that might otherwise bias results. Random effects or mixed models approaches, which treat individual heterogeneity as part of the model error term and use generalized least squares to estimate model parameters, are often criticized because correlation between unobserved individual effects and other model variables can lead to biased and inconsistent parameter estimates. Starting with an examination of the relationship between random effects and fixed effects estimators in the standard unobserved effects model, this article demonstrates through analysis and simulation that the mixed model approach has a ``bias compression'' property under a general model for individual heterogeneity that can mitigate bias due to uncontrolled differences among individuals. The general model is motivated by the complexities of longitudinal student achievement measures, but the results have broad applicability to longitudinal modeling. ", "machine_text": "  Controlling for individual heterogeneity in longitudinal models, with applications to student achievement  We consider the problem of controlling for individual heterogeneity in models for stationary longitudinal data. We focus on the widely used random-coefficient model, and consider both linear and quadratic forms of the random coefficients. We propose a new model-based method, which we term the \"category-threshold\" method, for controlling for individual heterogeneity. The method works by defining a threshold on the within-person variance in the random coefficients, and then using the threshold to group individuals according to the magnitude of their within-person coefficient variance. We show that the resulting group-level coefficients are then consistent with the null hypothesis of zero mean and finite variance, against the alternative of constant mean and/or variance. The category-threshold method has several advantages over other methods for controlling for individual heterogeneity. In particular, it is simple and flexible, allowing the researcher to use any linear or quadratic form of the random coefficients, and to set the threshold in any way that is consistent with the data generating process. We demonstrate the performance of the category-threshold method through simulation studies, and apply it to a study of student achievement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Asteroid Deflection: How, where and when?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1805, "human_text": "  To deflect impact-trajectory of massive km^3 and spinning asteroid by a few terrestrial radius one need a large momentum exchange. The dragging of huge spinning bodies in space by external engine seems difficult or impossible. Our solution is based on the landing of multi screw-rockets, powered by mini-nuclear engines, on the body, that dig a small fraction of the soil surface, to use as an exhaust propeller, ejecting it vertically in phase among themselves. Such a mass ejection increases the momentum exchange, their number redundancy guarantees the stability of the system. The slow landing (below 40 cm s^-1) of each engine-unity at those lowest gravity field, may be achieved by save rolling and bouncing along the surface. The engine array tuned activity, overcomes the asteroid angular velocity. Coherent turning of the jet heads increases the deflection efficiency. A procession along its surface may compensate at best the asteroid spin. A small skin-mass (about 2 10^4 tons) may be ejected by mini nuclear engines. Such prototypes may also build first save galleries for humans on the Moon. Conclusive deflecting tests might be performed on remote asteroids. The incoming asteroid 99942 Apophis (just 2% of km^3) may be deflected safely a few Earth radius. How to tag its trajectory is described. Its encounter maybe not just a hazard but an opportunity, learning how to land, dig, build and also to nest save human station inside. Asteroids amplified deflections by gravity swing maybe driven into longest planetary journeys. Mars journey may benefict by Phobos natural asteroid parking and fueling role. ", "machine_text": "  Asteroid Deflection: How, where and when?  Asteroids pose a serious threat to life on Earth and although they strike Earth only rarely, the consequences can be catastrophic. With the current lack of technology to deflect asteroids, the only option is to monitor their positions and attempt to evacuate the area where they are predicted to strike. We present here a new method for deflecting asteroids, which is based on a recently proposed concept of using a fleet of small spacecraft to deflect an asteroid by giving it a small push at the right time. We show that this method is capable of deflecting asteroids with a diameter as large as a few tens of km, which is large enough to be potentially dangerous. We also derive a simple formula that can be used to quickly assess whether an asteroid can be deflected or not, and we discuss the practical aspects of the deflection method, including the number and the relative sizes of the spacecraft, the time frame in which the deflection must be executed, and the choice of the asteroid's target trajectory after it has been deflected. We find that in order to deflect an asteroid whose diameter is on the order of tens of km, a fleet of spacecraft with a total mass of several hundred tons may be required, and the execution time window can be as long as a few months. We also show that an asteroid's target trajectory after deflection can be chosen so that the risk of an accidental collision with another asteroid is minimal. We believe that this method can provide a realistic and practical solution to the problem of asteroid deflection, and we discuss the key technological aspects that need to be developed in order to implement it.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The absolute Galois group acts faithfully on the connected components of\n  the moduli space of surfaces of general type. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1466, "human_text": "  We show that the Galois group $Gal(\\bar{\\Q} /\\Q)$ operates faithfully on the set of connected components of the moduli spaces of surfaces of general type, and also that for each element $\\sigma \\in Gal(\\bar{\\Q} /\\Q)$ different from the identity and from complex conjugation, there is a surface of general type such that $X$ and the Galois conjugate variety $X^{\\sigma}$ have nonisomorphic fundamental groups. The result was announced by the second author at the Alghero Conference 'Topology of algebraic varieties' in september 2006. Before the present paper was actually written, we received a very interesting preprint by Robert Easton and Ravi Vakil (\\cite{e-v}), where it is proven, with a completely different type of examples, that the Galois group $Gal(\\bar{\\Q} /\\Q)$ operates faithfully on the set of irreducible components of the moduli spaces of surfaces of general type. We also give other simpler examples of surfaces with nonisomorphic fundamental groups which are Galois conjugate, hence have isomorphic algebraic fundamental groups. ", "machine_text": " We show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. This answers a question of Beukers and Lakes.  The motivation for this research is the relation between the geometry of the moduli space of surfaces of general type and the geometric properties of the moduli space of vector bundles on surfaces of general type. In particular, we show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature.  The key ideas and methodology of this research are as follows. We show that the pull-back of a curve in the moduli space of vector bundles on a surface of general type is a curve in the moduli space of surfaces of general type. Since the absolute Galois group acts faithfully on the moduli space of vector bundles on surfaces of general type, it follows that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type.  The results obtained are as follows. We show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. This answers a question of Beukers and Lakes. We also show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature.  Problem work attempts to solve. We show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type. We show that the connected components of the moduli space of surfaces of general type are fibered by surfaces with constant mean curvature. We also show that the absolute Galois group acts faithfully on the connected components of the moduli space of surfaces of general type.  Any practical or theoretical applications from your findings or implications for future research. While our results have no practical applications, they do have theoretical implications for future research. For example, our results may be useful in understanding the relation between the geometry of the moduli space of surfaces of general type and the geometric properties of the moduli space of vector bundles on surfaces of general type.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Collective states of the odd-mass nuclei within the framework of the\n  Interacting Vector Boson Model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2169, "human_text": "  A supersymmetric extension of the dynamical symmetry group $Sp^{B}(12,R)$ of the Interacting Vector Boson Model (IVBM), to the orthosymplectic group $OSp(2\\Omega/12,R)$ is developed in order to incorporate fermion degrees of freedom into the nuclear dynamics and to encompass the treatment of odd mass nuclei. The bosonic sector of the supergroup is used to describe the complex collective spectra of the neighboring even-even nuclei and is considered as a core structure of the odd nucleus. The fermionic sector is represented by the fermion spin group $SO^{F}(2\\Omega)\\supset SU^{F}(2)$.   The so obtained, new exactly solvable limiting case is applied for the description of the nuclear collective spectra of odd mass nuclei. The theoretical predictions for different collective bands in three odd mass nuclei, namely $^{157}Gd$, $^{173}Yb$ and $^{163}Dy$ from rare earth region are compared with the experiment. The $B(E2)$ transition probabilities for the $^{157}Gd$ and $^{163}Dy$ between the states of the ground band are also studied. The important role of the symplectic structure of the model for the proper reproduction of the $B(E2)$ behavior is revealed. The obtained results reveal the applicability of the models extension. ", "machine_text": " We investigate the structure of collective states of the odd-mass nuclei within the framework of the Interacting Vector Boson Model. The main goal of the work is to determine the nature of the single-particle basis of the collective states and to establish the connection between the properties of these states and the structure of the original Hamiltonian. We show that the collective states can be constructed as a linear combination of single-particle states with certain properties. The masses and the widths of the collective states can be evaluated by using the single-particle basis and the structure of the original Hamiltonian in a simple and straightforward way. Our results are consistent with the odd-mass nucleus being in a collective state with two different width contributions, one of which is close to the width of the fundamental state and the other is close to the width of the first excited state. We also show that the partial width of the collective state can be evaluated by using the single-particle basis and the structure of the original Hamiltonian. Our results are consistent with the partial width being proportional to the ratio of the single-particle basis to the total number of quark colors in the original Hamiltonian.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of Heme using DFT+U: a step toward accurate spin-state\n  energetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2743, "human_text": "  We investigate the DFT+U approach as a viable solution to describe the low-lying states of ligated and unligated iron heme complexes. Besides their central role in organometallic chemistry, these compounds represent a paradigmatic case where LDA, GGA, and common hybrid functionals fail to reproduce the experimental magnetic splittings. In particular, the imidazole pentacoordinated heme is incorrectly described as a triplet by all usual DFT flavors. In this study we show that a U parameter close to 4 eV leads to spin transitions and molecular geometries in quantitative agreement with experiments, and that DFT+U represents an appealing tool in the description of iron porphyrin complexes, at a much reduced cost compared to correlated quantum-chemistry methods. The possibility of obtaining the U parameter from first-principles is explored through a self-consistent linear-response formulation. We find that this approach, which proved to be successful in other iron systems, produces in this case some overestimation with respect to the optimal values of U. ", "machine_text": "  We present a density functional theory and exact Muffin-Tin (DFT+U) computation of the electronic structure and spin-state energetics of the heme molecule. The goal of this work is to evaluate the accuracy of DFT+U methods in describing the spin-state energetics of transition metal complexes. We focus on the model system heme, which has well-defined spin-state properties, including an open-shell spin-state and a well-defined low-spin state with a relatively small energy difference between the two spin-states. The heme system also provides a benchmark for the evaluation of the breakup of the molecular orbitals into atomic contributions. Our results indicate that the simple DFT+U approach is not adequate for the accurate prediction of the heme spin-state energetics. We find that the biggest deficiency is the failure of the DFT+U method to describe the orbital breakup of the molecular orbitals. We propose that this deficiency may be cured by a more sophisticated treatment of the U, which includes a proper treatment of the correlation effects in the molecular orbitals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Z^0 \\to 2\\gamma and the Twisted Coproduct of the Poincar\\'{e} Group. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0921, "human_text": "  Yang's theorem forbids the process $Z^0 \\to 2\\gamma$ in any Poincar\\'{e} invariant theory if photons are bosons and their two-particle states transform under the Poincar\\'{e} group in the standard way (under the standard coproduct of the Poincar\\'{e} group). This is an important result as it does not depend on the assumptions of quantum field theory. Recent work on noncommutative geometry requires deforming the above coproduct by the Drinfel'd twist. We prove that $Z^0 \\to 2\\gamma$ is forbidden for the twisted coproduct as well. This result is also independent of the assumptions of quantum field theory. As an illustration of the use of our general formulae, we further show that $Z^0 \\to \\nu + \\nu$ is forbidden for the standard or twisted coproduct of the Poincar\\'{e} group if the neutrino is massless, even if lepton number is not conserved. This is a special case of our general result that a massive particle of spin $j$ cannot decay into two identical massless particles of the same helicity if $j$ is odd, regardless of the coproduct used. ", "machine_text": " We introduce the twisted coproduct of a Poincar\u00e9 group. We show that this is a generalization of the affine Lie algebras to the setting of relative impoverished Poincar\u00e9 groups. As an application we give a description of the twisted coproduct of the Poincar\u00e9 group in terms of left- and right-invariant Poincar\u00e9 polynomials. We also describe the twisted coproduct of the Poincar\u00e9 group in terms of the invariant asked for by Hilbert's 16th problem, namely the number of non-zero derivatives of a solution to a homogeneous polynomial system of differential equations. This allows to give a description of the twisted coproduct of the Poincar\u00e9 group in terms of bi-invariant functions on the space of differential forms on a smooth projective variety. As an application we show that the twisted coproduct of the Poincar\u00e9 group acts on the space of global sections of certain sheaves in a way which is reminiscent of the way the ordinary Poincar\u00e9 group acts on the space of sections of certain vector bundles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effects of the galactic winds on the stellar metallicity distribution of\n  dwarf spheroidal galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2032, "human_text": "  To study the effects of galactic winds on the stellar metallicity distributions and on the evolution of Draco and Ursa Minor dwarf spheroidal galaxies, we compared the predictions of several chemical evolution models, adopting different prescriptions for the galactic winds, with the photometrically-derived stellar metallicity distributions of both galaxies. The chemical evolution models for Draco and Ursa Minor, which are able to reproduce several observational features of these two galaxies, such as the several abundance ratios, take up-to-date nucleosynthesis into account for intermediate-mass stars and supernovae of both types, as well as the effect of these objects on the energetics of the systems. For both galaxies, the model that best fits the data contains an intense continuous galactic wind, occurring at a rate proportional to the star formation rate. Models with a wind rate assumed to be proportional only to the supernova rate also reproduce the observed SMD, but do not match the gas mass, whereas the models with no galactic winds fail to reproduce the observed SMDs. In the case of Ursa Minor, the same model as in previous works reproduces the observed distribution very well with no need to modify the main parameters of the model. The model for Draco, on the other hand, is slightly modified. The observed SMD requires a model with a lower supernova type Ia thermalization efficiency ($\\eta_{SNeIa}$ = 0.5 instead of $\\eta_{SNeIa}$ = 1.0) in order to delay the galactic wind, whereas all the other parameters are kept the same. The model results, compared to observations, strongly suggest that intense and continuous galactic winds play a very important role in the evolution of local dSphs. ", "machine_text": " We present an analysis of the stellar metallicity distribution of 72 dwarf spheroidal galaxies (DSGs) in the Local Volume, an area of the Milky Way (MW) that contains a high density of globular clusters. We aim to test the hypothesis that DSGs in this region are affected by the Galactic winds, which should produce a negative correlation between the metallicity and the distance to the MW. We find a very significant correlation ( Metallicities of dwarf galaxies in the Local Volume. We conclude that the Galactic winds have had a strong effect on the evolution of the metallicity of the DSGs in the Local Volume, and that this provides strong support for models in which the Galactic winds are an important regulator of the chemical evolution of the Galactic disc. We discuss our results in the context of the current theories of the formation and evolution of DSGs, and we highlight the need for a better understanding of the detailed physics of the Galactic winds in order to be able to produce more precise predictions for the effects of these winds on the chemical evolution of the Galactic disc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gamma Rays frim the Galactic Centre. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2333, "human_text": "  Recent results from the HESS gamma ray telescope have shown the presence of both a diffuse, extended, flux of gamma rays above ~0.4 TeV and discrete sources in and near the Galactic Centre. Here, we put forward a possible explanation in terms of the diffusion of cosmic ray protons from a succession of supernova remnants (SNR) in the SgrA* region of the Galaxy plus a contribution from SNR in the rest of the Galactic Centre Region, to be called the Galactic Centre Ridge (GCR). Protons are favoured over electrons because the mG magnetic fields in the Region will attenuate energetic electrons severely. Prominent features are the need for 'anomalous diffusion' of the protons in the whole region and the adoption of low efficiency for SNR acceleration in the high density regions. The latter is related by us to the well-known low 'cosmic ray gradient' in the Galaxy. A corroborating feature is the close correlation of inferred cosmic ray intensity with the smoothed intensity of 5 GHZ radio radiation. We attribute this to the presence of the SNR in the GCR. ", "machine_text": "  We present here results of a systematic analysis of \u03b3-ray point sources in the Galactic Centre region carried out with the help of a 60Co exposure of several weeks duration obtained with the Austrian particle detector CEDIC. The main aim of the investigation was to search for new members of the class of hard \u03b3-ray transient sources which include the well known objects Cyg OB2#63 and Cep OB2#lll. The analysis of the \u03b3-ray point source population in the region shows a clear deficit of sources with respect to the predictions of the canonical WMAP-based Galactic model, in agreement with earlier results in the northern Galactic hemisphere. This suggests that the sources in this region, including the well known giant molecular clouds, are in fact less dense than expected from the simple application of the Galactic model. We have identified one hard transient source, named CoRoT-24, in a very low density region between the clouds and show that it has all the characteristics of a member of the group of hard transient sources. We estimate the total number of such objects to be in the range 2-5, depending on the volume considered. This indicates that the formation of such objects is probably linked to large scale density variations and not to the occurrence in molecular clouds which are, in fact, rather poor in such sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unitarity analysis of a non-Abelian gauge invariant action with a mass. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0871, "human_text": "  In previous work done by us and coworkers, we have been able to construct a local, non-Abelian gauge invariant action with a mass parameter, based on the nonlocal gauge invariant mass dimension two operator F1/D^2F. The renormalizability of the resulting action was proven to all orders of perturbation theory, in the class of linear covariant gauges. We also discussed the perturbative equivalence of the model with ordinary massless Yang-Mills gauge theories when the mass is identically zero. Furthermore, we pointed out the existence of a BRST symmetry with corresponding nilpotent charge. In this paper, we study the issue of unitarity of this massive gauge model. Firstly, we provide a short review how to discuss the unitarity making use of the BRST charge. Afterwards we make a detailed study of the most general version of our action, and we come to the conclusion that the model is not unitary, as we are unable to remove all the negative norm states from the physical spectrum in a consistent way. ", "machine_text": " We study the possibility of a non-Abelian gauge invariant action with a mass for a chiral gauge theory in the presence of an internal symmetry group G. We show that the standard approach to define a mass for a gauge invariant action fails in this case, and we propose a general framework to define a gauge invariant mass for a non-Abelian gauge theory which is motivated by the example of the E8 \u00d7 E8 heterotic theory. In this approach, the mass term is generated by a non-Abelian two form field. We show that this mass term is protected by the internal symmetry group G, and we obtain a gauge invariant action with a mass. This action is non-Abelian, but it is invariant under a proper subset of the elements of the internal symmetry group G. We call this action a \"unitary gauge invariant action with a mass\". We show that this action is related to the effective action of the gauge theory, and that the parameter space of this action is related to the electric charge of the theory. This approach is general and can be applied to any chiral gauge theory with an internal symmetry group G, and we show that the unitarity bound on the strength of the mass term is related to the cardinality of G. We also discuss the relation of this work to the Standard Model and the possibility of a non-Abelian unitary gauge invariant action with a mass for the Standard Model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Formation and Collisional Evolution of Kuiper Belt Objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0259, "human_text": "  This chapter summarizes analytic theory and numerical calculations for the formation and collisional evolution of KBOs at 20--150 AU. We describe the main predictions of a baseline self-stirring model and show how dynamical perturbations from a stellar flyby or stirring by a giant planet modify the evolution. Although robust comparisons between observations and theory require better KBO statistics and more comprehensive calculations, the data are broadly consistent with KBO formation in a massive disk followed by substantial collisional grinding and dynamical ejection. However, there are important problems reconciling the results of coagulation and dynamical calculations. Contrasting our current understanding of the evolution of KBOs and asteroids suggests that additional observational constraints, such as the identification of more dynamical families of KBOs (like the 2003 EL61 family), would provide additional information on the relative roles of collisional grinding and dynamical ejection in the Kuiper Belt. The uncertainties also motivate calculations that combine collisional and dynamical evolution, a `unified' calculation that should give us a better picture of KBO formation and evolution. ", "machine_text": "  We present a formation and evolution model for the Kuiper Belt based on the analysis of its current membership. We first describe a method for determining the relative ages of different Kuiper Belt objects (KBOs) based on their colors. We then utilize these ages in a model that simultaneously forms and collides KBOs to reproduce the observed distribution of colors and surface ages. The model includes an additional source of KBOs that is driven by the chaotic mixing of bodies in the Nice model. We vary the initial conditions for the formation of the Kuiper Belt and study the resulting collisional dynamics. Our results show that KBOs can evolve to their current orbits in as few as 10-50 million years. The source of the efficient collisional evolution is the outward migration of the objects that results from their forward motion and the inward migration of the objects that results from their tidal interaction with a massive terrestrial planet. We explain why the high eccentricity of the KBOs is consistent with their collisional evolution. We also show that a KBO must have had a minimum velocity of 4-6 km/s to reach its current orbit, which eliminates a large number of candidates for the so-called \"short-period comet\" observed to have been in a retrograde orbit around the Sun. Finally, we show that the KBOs are likely to have formed in a narrow range of distances from the Sun, within 5-10 AU.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The InterHourly-Variability (IHV) Index of Geomagnetic Activity and its\n  Use in Deriving the Long-term Variation of Solar Wind Speed. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0961, "human_text": "  We describe the derivation of the InterHourly Variability (IHV) index of geomagnetic activity. The IHV-index for a geomagnetic element is mechanically derived from hourly values as the sum of the unsigned differences between adjacent hours over a seven-hour interval centered on local midnight. The index is derived separately for stations in both hemispheres within six longitude sectors using only local night hours. It is intended as a long-term index. Available data allows derivation of the index back well into the 19th century. On a time scale of a 27-day Bartels rotation, IHV averages for stations with corrected geomagnetic latitude less than 55 degrees are strongly correlated with midlatitude range indices. Assuming a constant calibration of the aa-index we find that observed yearly values of aa before the year 1957 are 2.9 nT too small compared to values calculated from IHV using the regression constants based on 1980-2004. We interpret this discrepancy as an indication that the calibration of the aa index is in error before 1957. There is no such problem with the ap index. Rotation averages of IHV are also strongly correlated with solar wind parameters (BV^2). On a time scale of a year combining the IHV-index and the recently-developed Inter-Diurnal Variability (IDV) index (giving B) allows determination of solar wind speed, V, from 1890-present. Over the ~120-year series, the yearly mean solar wind speed varied from a low of 303 km/s in 1902 to a high value of 545 km/s in 2003. The calculated yearly values of the product BV using B and V separately derived from IDV and IHV agree quantitatively with (completely independent) BV derived from the amplitude of the diurnal variation of the H component in the polar caps since 1926 and sporadically beyond. ", "machine_text": "  We have developed a new index of geomagnetic activity, the InterHourly-Variability (IHV) index, based on the interhourly variability of the geomagnetic field, which is related to the ionospheric and tropospheric conditions as well as the solar wind intensity. Our results show that the IHV index has clear quasi-11-year and quasi-7-year cycles that are closely related to the solar cycle. We show that the IHV index can be used to derive the long-term variation of the solar wind speed from observations of the geomagnetic field. We have tested this derived solar wind speed by comparing it with independent measurements of the solar wind speed made by the Ulysses spacecraft. The comparison shows a high degree of consistency between the long-term variations of the solar wind speed derived from the IHV index and the direct measurements made by Ulysses. This indicates that the IHV index can be used to derive the long-term variation of the solar wind speed from observations of the geomagnetic field. The IHV index has clear applications in the prediction of space weather.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Integral Field Spectroscopy of the Extended Emission-Line Region of 4C\n  37.43. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4365, "human_text": "  We present Gemini integral field spectroscopy and Keck II longslit spectroscopy of the extended emission-line region (EELR) around the quasar 4C 37.43. The velocity structure of the ionized gas is complex and cannot be explained globally by a simple dynamical model. The spectra from the clouds are inconsistent with shock or ``shock + precursor'' ionization models, but they are consistent with photoionization by the quasar nucleus. The best-fit photoionization model requires a low-metallicity (12+log(O/H) < 8.7) two-phase medium, consisting of a matter-bounded diffuse component with a unity filling-factor (N ~ 1 \\cc, T ~ 15000 K), in which are embedded small, dense clouds (N ~ 400 \\cc, T ~ 10^4 K). The high-density clouds are transient and can be re-generated through compressing the diffuse medium by low-speed shocks (V_S \\lesssim 100 \\kms). Our photoionization model gives a total mass for the ionized gas of about 3x10^{10} M_sun, and the total kinetic energy implied by this mass and the observed velocity field is ~2x10^{58} ergs. The fact that luminous EELRs are confined to steep-spectrum radio-loud quasars, yet show no morphological correspondence to the radio jets, suggests that the driving force producing the 4C 37.43 EELR was a roughly spherical blast wave initiated by the production of the jet. That such a mechanism seems capable of ejecting a mass comparable to that of the total interstellar medium of the Milky Way suggests that ``quasar-mode'' feedback may indeed be an efficient means of regulating star formation in the early universe. ", "machine_text": " We present integral field spectroscopy of the extended emission-line region (EELR) of 4C 37.43, a bright and nearby galaxy in the optical state, with the aim of characterizing the ionization structure of its extended atmosphere. We observe a strong correlation between ionization and stellar content: the ionized gas is mostly located in the regions of the galaxy that contain young and massive stars. In addition, we find that the ionization structure is extremely regular, with the ionization probability decreasing in a radial fashion from the galaxy's center. We interpret this radial decline as due to the combined effect of a large-scale ionization wave and the superposition of many small-scale localised ionization sources, the latter most likely related to the massive star-forming regions. We have verified that this radial decrease in ionization probability is not due to dust obscuration. Our results suggest that a simple model in which ionization is driven by a single wave of ionization originating in the galaxy's centre cannot account for the ionization structure of the EELR.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Highly turbulent solutions of LANS-alpha and their LES potential. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1928, "human_text": "  We compute solutions of the Lagrangian-Averaged Navier-Stokes alpha-model (LANS) for significantly higher Reynolds numbers (up to Re 8300) than have previously been accomplished. This allows sufficient separation of scales to observe a Navier-Stokes (NS) inertial range followed by a 2nd LANS inertial range. The analysis of the third-order structure function scaling supports the predicted l^3 scaling; it corresponds to a k^(-1) scaling of the energy spectrum. The energy spectrum itself shows a different scaling which goes as k^1. This latter spectrum is consistent with the absence of stretching in the sub-filter scales due to the Taylor frozen-in hypothesis employed as a closure in the derivation of LANS. These two scalings are conjectured to coexist in different spatial portions of the flow. The l^3 (E(k) k^(-1)) scaling is subdominant to k^1 in the energy spectrum, but the l^3 scaling is responsible for the direct energy cascade, as no cascade can result from motions with no internal degrees of freedom. We verify the prediction for the size of the LANS attractor resulting from this scaling. From this, we give a methodology either for arriving at grid-independent solutions for LANS, or for obtaining a formulation of a LES optimal in the context of the alpha models. The fully converged grid-independent LANS may not be the best approximation to a direct numerical simulation of the NS equations since the minimum error is a balance between truncation errors and the approximation error due to using LANS instead of the primitive equations. Furthermore, the small-scale behavior of LANS contributes to a reduction of flux at constant energy, leading to a shallower energy spectrum for large alpha. These small-scale features, do not preclude LANS to reproduce correctly the intermittency properties of high Re flow. ", "machine_text": " We study the potential of Large-Eddy Simulation (LES) for highly turbulent solutions of the L fluid model (LANS-alpha) which was recently shown to possess intrinsic large-scale motions. The analysis is based on a recent derivation of the LES equations for the LANS-alpha model which takes into account the non-conservative terms in the original conservation laws. We show that the LES equations for LANS-alpha inherit the key properties of the LES equations for the classical Navier-Stokes equations. In particular, we show that (i) the new LES equations are unconditionally stable for all parameters in the range of validity of LANS-alpha, (ii) the energy transfer to the mean flow is controlled by a single parameter which is proportional to the square of the flow velocity, (iii) this energy transfer is very efficient in spite of the fact that the largest scales are not allowed to grow very fast, and (iv) the new LES equations are very similar to the LES equations for the Navier-Stokes equations. We finally discuss the potential and limitations of LES for highly turbulent solutions of LANS-alpha.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 3-He in the Milky Way Interstellar Medium: Ionization Structure. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1939, "human_text": "  The cosmic abundance of the 3-He isotope has important implications for many fields of astrophysics. We are using the 8.665 GHz hyperfine transition of 3-He+ to determine the 3-He/H abundance in Milky Way HII regions and planetary nebulae. This is one in a series of papers in which we discuss issues involved in deriving accurate 3-He/H abundance ratios from the available measurements. Here we describe the ionization correction we use to convert the 3-He+/H+ abundance, y3+, to the 3-He/H abundance, y3. In principle the nebular ionization structure can significantly influence the y3 derived for individual sources. We find that in general there is insufficient information available to make a detailed ionization correction. Here we make a simple correction and assess its validity. The correction is based on radio recombination line measurements of H+ and 4-He+, together with simple core-halo source models. We use these models to establish criteria that allow us to identify sources that can be accurately corrected for ionization and those that cannot. We argue that this effect cannot be very large for most of the sources in our observational sample. For a wide range of models of nebular ionization structure we find that the ionization correction factor varies from 1 to 1.8. Although large corrections are possible, there would have to be a conspiracy between the density and ionization structure for us to underestimate the ionization correction by a substantial amount. ", "machine_text": " We present observations of the 3-He content in a large sample of Galactic sight lines, which together cover the full 360 deg^2 sky visible from the Northern Hemisphere. We find that the 3-He abundance in the interstellar medium (ISM) increases with radius in all directions, consistent with the expectation that the ISM is dynamically stratified and that the 3-He is concentrated in the inner regions. We find a mean 3-He abundance of 3.01 +1.08 (1\u03c3) x 10^-4, rising to 3.81 +1.08 (1\u03c3) x 10^-4 at a Galacto-centric distance of 8 kpc. This is consistent with the 3-He being produced in the galactic interior and radially diffusing outward. The mean relative abundance of 3-He with respect to H_2 is 5.4 +2.1 (1\u03c3) x 10^-4, but this ratio is not uniform. We find that the ratio is higher in the inner Galacto-centric distance range, and lower in the outer range, with a turnover at a Galacto-centric distance of  \u223c 6 kpc. This is consistent with the hypothesis that the 3-He is produced in the core and the diffuses outward, while the H_2 is produced in the outer Galaxy and diffuses inward. We find that the gas phase metallicity of the ISM is correlated with the 3-He abundance, with the 3-He being more abundant in gas of higher metallicity. We discuss this finding in the context of the relative metallicity of the gas phase and solid phase of the ISM. We find that the radial distribution of the 3-He in the ISM is consistent with the expectation that the 3-He is produced in the core and the outer regions of the Galaxy are not yet affected by the production. We discuss this in the context of the Galaxy's history and the evolution of the 3-He abundance in the ISM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Grain Retention and Formation of Planetesimals near the Snow Line in\n  MRI-driven Turbulent Protoplanetary Disks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1272, "human_text": "  The first challenge in the formation of both terrestrial planets and the cores of gas giants is the retention of grains in protoplanetary disks. In most regions of these disks, gas attains sub-Keplerian speeds as a consequence of a negative pressure gradient. Hydrodynamic drag leads to orbital decay and depletion of the solid material in the disk, with characteristic timescales as short as only a few hundred years for meter-sized objects at 1 AU. In this paper, we suggest a particle retention mechanism which promotes the accumulation of grains and the formation of planetesimals near the water sublimation front or ``snow line.'' This model is based on the assumption that, in the regions most interesting for planet formation, the viscous evolution of the disk is due to turbulence driven by the magneto-rotational instability (MRI) in the surface layers of the disk. The depth to which MRI effectively generates turbulence is a strong function of the grain size and abundance. A sharp increase in the grain-to-gas density ratio across the snow line reduces the column depth of the active layer. As the disk evolves towards a quasi-steady-state, this change in the active layer creates a local maximum in radial distribution of the gas surface density and pressure, causing the gas to rotate at super-Keplerian speed and halting the inward migration of grains. This senario presents a robust process for grain retention which may aid in the formation of proto-gas-giant cores preferentially near the snow line. ", "machine_text": "  We investigate the effects of planetesimal formation and growth on the retention of different size grains in protoplanetary disks. We employ a hybrid algorithm combining Monte Carlo and molecular dynamics simulations to follow the collisional evolution of grains and planetesimals. We find that planetesimal formation and growth is most efficient near the snow line, where a large number of small planetesimals can grow into large bodies by colliding with pebbles and staying in the disk. We show that this efficient planetesimal retention due to multiple growth events can explain the preference for large planetesimals over the distance of the disk, without the need for a radial dependence of the planetesimal formation efficiency. Within our model, planetesimals grow efficiently as long as their size is larger than a threshold of about 1 cm. Below this threshold, the number of planetesimals is in general too small to explain the large number of planetesimals larger than 1 km observed in exoplanet systems. We discuss how this threshold may have been reached in the disk by planetesimal formation and evolution. Our model implies that planetesimals grow efficiently as long as the disk has a turbulence intensity above a certain threshold, which is about log(\u03a9/L) \u223c -1.5, where \u03a9 is the typicality length and L is the disk's radial extent. We show that this turbulence level is typical for the solar nebula and many other protoplanetary disks, and is therefore sufficient to explain the rapid growth of planetesimals observed in the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Some properties of the resonant state in quantum mechanics and its\n  computation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1388, "human_text": "  The resonant state of the open quantum system is studied from the viewpoint of the outgoing momentum flux. We show that the number of particles is conserved for a resonant state, if we use an expanding volume of integration in order to take account of the outgoing momentum flux; the number of particles would decay exponentially in a fixed volume of integration. Moreover, we introduce new numerical methods of treating the resonant state with the use of the effective potential. We first give a numerical method of finding a resonance pole in the complex energy plane. The method seeks an energy eigenvalue iteratively. We found that our method leads to a super-convergence, the convergence exponential with respect to the iteration step. The present method is completely independent of commonly used complex scaling. We also give a numerical trick for computing the time evolution of the resonant state in a limited spatial area. Since the wave function of the resonant state is diverging away from the scattering potential, it has been previously difficult to follow its time evolution numerically in a finite area. ", "machine_text": " We investigate some properties of the resonant state in quantum mechanics and its computation. We show that the resonant state is very sensitive to the parameters in the Hamiltonian. We find that the optimal quantum algorithm to produce the resonant state, in the asymptotic regime, has the same structure as the classical one. We also show that the computation of the simplest case of the resonant state, the so-called form-factor problem, can be solved with a quantum algorithm that has the same structure as the classical one, but the quantum algorithm is much faster than the classical one. This shows that the resonant state is not as special as it may seem. We also investigate the relation between the resonant state and the ground state. We show that if we have an exact solution of the Schr\u00f6dinger equation for the ground state, then we can use this to produce an approximate solution for the resonant state. We show that this is an important property in practice, for example in the computation of the ground state of the Hamiltonian.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pioneer Anomaly and Accelerating Universe as Effects of the Minkowski\n  Space Conformal Symmetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2745, "human_text": "  On the basis of the nonisometric transformations subgroup of the SO(4.2) group, the nonlinear time inhomogeneity one-parameter conformal transformations are constructed. The connection between the group parameter and the Hubble constant H0 is established. It is shown that the existence of an anomalous blue-shifted frequency drift is a pure kinematic manifestation of the time inhomogeneity induced by the Universe expansion. This conclusion is confirmed via a generalization of the standard Special Relativity clock synchronization procedure to the space expanding case. The obtained formulae are in accordance with the observable Pioneer Anomaly effect. The anomalous blue-shifted drift is universal, does not depend on the presence of graviting centers and can be, in principle, observed on any frequencies under suitable experimental conditions. The explicit analytic expression for the speed of recession--intergalactic distance ratio is obtained in the form of a function of the red shift z valid in the whole range of its variation. In the small z limit this expression exactly reproduces the Hubble law. The maximum value of this function at z=0.475 quantitatively corresponds to the experimentally found value z(exp) = 0.46 +/- 0.13 of the transition from the decelerated to the accelerated expansion of the Universe. ", "machine_text": "  We show that the Pioneer anomaly and the accelerating universe can be considered as effects of the Minkowski space conformal symmetry. The relativistic corrections to the predicted Galileo acceleration can be obtained from the 4-acceleration and the scalar curvature, in the presence of a small constant acceleration applied to the spaceship. The corrected acceleration shows a linear rise with the distance, reaching the cosmological constant value at large distances. The model is consistent with the observed Pioneer anomaly and with the standard cosmological model, within the precision of the experimental data. We also derive a simple formula for the correction to the acceleration, in terms of the proper time and the distance. The conformal symmetry of the Minkowski space also affects the gravitational field. If the source of the field is moving in a curved space, the field is also curved, in a different way for each of the two possible signs of the scalar curvature. We show that this effect may have interesting applications in quantum gravity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear Dynamics of Infectious Diseases Transfer with Possible\n  Applications for Tubercular Infection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1434, "human_text": "  In this paper, we model a nonlinear dynamics of infectious diseases transfer. Particularly, we study possible applications to tubercular infection in models with different profiles (peak values) of the population density dependence on spatial coordinates. Our approach is based on the well known method of instantons which has been used by the authors to describe kinetics of adiabatic chemical reactions as a function of the heat-bath temperature and other system parameters. In our approach, we use \"social temperature\" T as one of the controlling parameters. Increase of T leads to acceleration of the infectious diseases transfer. The \"blockage\" effect for the infectious diseases transfer has been demonstrated in the case when peak values (in the population density) are equal to one and under condition that the \"social temperature\" is low. Existence of such effect essentially depends from environment \"activity\" (social and prophylactic). Results of our modeling qualitatively meet the tuberculosis dynamic spread data in Penza region of Russia. ", "machine_text": "  Tuberculosis (TB) still represents a serious health problem, being one of the main causes of death worldwide. The complex nature of TB and the emerging problems associated with the occurrence of TB are among the main reasons for the lack of efficiency of traditional TB control measures. It is in this context that recent efforts have been made to use mathematical models for a better understanding of TB as a disease and to design optimal control measures. In this sense, the classic paradigm of susceptible-exposed-infectious-removed has been revised and new concepts such as the influence of the spatial structure and the dynamics of the infection have been added. In this work, we present a review of the recent advances in the field of mathematical models of TB, focusing on the effects of the spatial structure and the role of nonlinear dynamics. We analyze the different models proposed in the literature, discussing their assumptions, limitations and results, and we draw attention to the most relevant aspects of each model for a better understanding of the disease dynamics. We also point out open questions and discuss possible applications of the models in order to improve TB control measures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ongoing Galactic Accretion: Simulations and Observations of Condensed\n  Gas in Hot Halos. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0357, "human_text": "  Ongoing accretion onto galactic disks has been recently theorized to progress via the unstable cooling of the baryonic halo into condensed clouds. These clouds have been identified as analogous to the High-Velocity Clouds (HVCs) observed in HI in our Galaxy. Here we compare the distribution of HVCs observed around our own Galaxy and extra-planar gas around the Andromeda galaxy to these possible HVC analogs in a simulation of galaxy formation that naturally generates these condensed clouds. We find a very good correspondence between these observations and the simulation, in terms of number, angular size, velocity distribution, overall flux and flux distribution of the clouds. We show that condensed cloud accretion only accounts for ~ 0.2 M_solar / year of the current overall Galactic accretion in the simulations. We also find that the simulated halo clouds accelerate and become more massive as they fall toward the disk. The parameter space of the simulated clouds is consistent with all of the observed HVC complexes that have distance constraints, except the Magellanic Stream which is known to have a different origin. We also find that nearly half of these simulated halo clouds would be indistinguishable from lower-velocity gas and that this effect is strongest further from the disk of the galaxy, thus indicating a possible missing population of HVCs. These results indicate that the majority of HVCs are consistent with being infalling, condensed clouds that are a remnant of Galaxy formation. ", "machine_text": " We present numerical simulations and observations of the effects of accretion shock heating on the evolution of molecular clouds in galactic halos. We find that a significant fraction of the gas in the inner part of the halos is heated to temperatures well above the critical temperature for molecular hydrogen, and that this fraction increases with accretion rate. For molecular clouds in these hot halos, we show that the virialization timescale decreases with increasing temperature, and that the clouds are able to survive for much longer times than clouds in the cold halos. We discuss a mechanism that can explain the simultaneous heating and longevity of molecular clouds in hot halos, based on the idea that the clouds are able to thermally stratify and thus to protect their inner regions from direct heating by the shock. We also discuss the effects of the hot halos on the chemical composition of the gas in the clouds, and we show that the chemical evolution is different in cold and hot halos. In particular, we find that the hot halos contain less heavy elements than the cold halos, in qualitative agreement with observations of the chemical composition of the gas in the Galactic halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: VSOP: The Variable Star One-shot Project I. Project presentation and\n  first data release. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4195, "human_text": "  The Variable Star One-shot Project (VSOP) is aimed at (1) providing the variability type and spectral type of all unstudied variable stars, (2) process, publish, and make the data available as automatically as possible, and (3) generate serendipitous discoveries. This first paper describes the project itself, the acquisition of the data, the dataflow, the spectroscopic analysis and the on-line availability of the fully calibrated and reduced data. We also present the results on the 221 stars observed during the first semester of the project. We used the high-resolution echelle spectrographs HARPS and FEROS in the ESO La Silla Observatory (Chile) to survey known variable stars. Once reduced by the dedicated pipelines, the radial velocities are determined from cross correlation with synthetic template spectra, and the spectral types are determined by an automatic minimum distance matching to synthetic spectra, with traditional manual spectral typing cross-checks. The variability types are determined by manually evaluating the available light curves and the spectroscopy. In the future, a new automatic classifier, currently being developed by members of the VSOP team, based on these spectroscopic data and on the photometric classifier developed for the COROT and Gaia space missions, will be used. We confirm or revise spectral types of 221 variable stars from the GCVS. We identify 26 previously unknown multiple systems, among them several visual binaries with spectroscopic binary individual components. We present new individual results for the multiple systems V349 Vel and BC Gru, for the composite spectrum star V4385 Sgr, for the T-Tauri star V1045 Sco, and for DM Boo which we re-classify as a BY Draconis variable. The complete data release can be accessed via the VSOP web site. ", "machine_text": "  VSOP: The Variable Star One-shot Project I. Project presentation and first data release.  We present VSOP, a one-shot variable star observing project using the International Space Station. The project obtained its first observations in January 2017, and in this article we present the project hardware and software, and the first scientific data release. VSOP consists of a camera and a spectrograph, both built by the Italian company CoRIn, installed outside the Columbus module of the International Space Station. The instruments are controlled by the VSOP package, a software suite developed by the VSOP team. VSOP is designed to measure the brightness and color of up to 50,000 stars in our Galaxy, and to obtain high-resolution spectroscopy for up to 1000 stars. The stars will be observed during the twilight zone, when the ISS is in sunlight but the stars are visible, to achieve the best compromise between a large number of stars observed and the quality of the observations. The VSOP data will be used to study stellar brightnesses and colors, to search for new variable stars, to study the structure and kinematics of the Galactic globular clusters, to search for planets around other stars, and to obtain high-resolution spectra of Galactic stars and extra-galactic galaxies. Here we present the first VSOP data release, containing the brightness and color measurements for 100,000 stars in the Galactic globular clusters M5 and M13. The VSOP database will be released to the public after the end of the mission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sparse and Dense Encoding in Layered Associative Network of Spiking\n  Neurons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2491, "human_text": "  A synfire chain is a simple neural network model which can propagate stable synchronous spikes called a pulse packet and widely researched. However how synfire chains coexist in one network remains to be elucidated. We have studied the activity of a layered associative network of Leaky Integrate-and-Fire neurons in which connection we embed memory patterns by the Hebbian Learning. We analyzed their activity by the Fokker-Planck method. In our previous report, when a half of neurons belongs to each memory pattern (memory pattern rate $F=0.5$), the temporal profiles of the network activity is split into temporally clustered groups called sublattices under certain input conditions. In this study, we show that when the network is sparsely connected ($F<0.5$), synchronous firings of the memory pattern are promoted. On the contrary, the densely connected network ($F>0.5$) inhibit synchronous firings. The sparseness and denseness also effect the basin of attraction and the storage capacity of the embedded memory patterns. We show that the sparsely(densely) connected networks enlarge(shrink) the basion of attraction and increase(decrease) the storage capacity. ", "machine_text": "  Layered associative network of spiking neurons is a simple model of cortical tissue, where groups of neurons in one layer are connected to groups of neurons in the next layer. We show that this model can be used to effectively solve the sparse and dense encoding problems. The motivation for this work is the understanding of how cortical tissue processes information to solve these two important tasks, and the insight that a simple model may be able to emulate the behavior of cortical tissue. We show that a layered associative network of spiking neurons can sparse and dense encode input patterns when the network is trained with a set of input patterns that are generated by adding Gaussian white noise to the desired sparse or dense encoded patterns. We show that a small number of parameters can control the strength of the sparse or dense encoding and the width of the encoded patterns. Since the parameters are coupled, they can be efficiently adjusted during a single training session. We also show that the weights of the connections in the network can be efficiently adjusted using an error back-propagation algorithm. Our model also shows some interesting properties of how the network dynamics changes with the number of layers. The theoretical analysis of the proposed model and the practical results obtained with the simulations show that this model is very flexible in learning to sparse and dense encode input patterns.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic Effects Increasing Network Vulnerability to Cascading Failures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1952, "human_text": "  We study cascading failures in networks using a dynamical flow model based on simple conservation and distribution laws to investigate the impact of transient dynamics caused by the rebalancing of loads after an initial network failure (triggering event). It is found that considering the flow dynamics may imply reduced network robustness compared to previous static overload failure models. This is due to the transient oscillations or overshooting in the loads, when the flow dynamics adjusts to the new (remaining) network structure. We obtain {\\em upper} and {\\em lower} limits to network robustness, and it is shown that {\\it two} time scales $\\tau$ and $\\tau_0$, defined by the network dynamics, are important to consider prior to accurately addressing network robustness or vulnerability. The robustness of networks showing cascading failures is generally determined by a complex interplay between the network topology and flow dynamics, where the ratio $\\chi=\\tau/\\tau_0$ determines the relative role of the two of them. ", "machine_text": "  We consider the problem of increasing network vulnerability to cascading failures. We first review several cascading failure phenomena that have been observed in practice, and for which an analytical understanding has been developed. We then present a general model of a network in which the vulnerability to failure is allowed to dynamically increase as a consequence of local failures. We show that the simplest such model, in which the vulnerability is increased according to a fixed rule, can explain several phenomena that have been observed in real-world networks, including the threshold of the fraction of nodes that needs to fail for the network to stop functioning. We also derive a simple formula for the average number of nodes that need to fail for the network to be rendered inoperable, which has practical applications in estimating the reliability of a network. We then consider the more general case of a network in which the vulnerability is increased dynamically, and we derive a condition that must be satisfied by the dynamics in order for the network to become more vulnerable to failure. We finally consider the problem of estimating the parameters of the dynamic rule by using measurements of the fraction of nodes that fail in response to an injected failure, and we show that this problem can be solved in a least-squares sense.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Inter-network regions of the Sun at millimetre wavelengths. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2304, "human_text": "  The continuum intensity at wavelengths around 1 mm provides an excellent way to probe the solar chromosphere. Future high-resolution millimetre arrays, such as the Atacama Large Millimeter Array (ALMA), will thus produce valuable input for the ongoing controversy on the thermal structure and the dynamics of this layer. Synthetic brightness temperature maps are calculated on basis of three-dimensional radiation (magneto-)hydrodynamic (MHD) simulations. While the millimetre continuum at 0.3mm originates mainly from the upper photosphere, the longer wavelengths considered here map the low and middle chromosphere. The effective formation height increases generally with wavelength and also from disk-centre towards the solar limb. The average intensity contribution functions are usually rather broad and in some cases they are even double-peaked as there are contributions from hot shock waves and cool post-shock regions in the model chromosphere. Taking into account the deviations from ionisation equilibrium for hydrogen gives a less strong variation of the electron density and with it of the optical depth. The result is a narrower formation height range. The average brightness temperature increases with wavelength and towards the limb. The relative contrast depends on wavelength in the same way as the average intensity but decreases towards the limb. The dependence of the brightness temperature distribution on wavelength and disk-position can be explained with the differences in formation height and the variation of temperature fluctuations with height in the model atmospheres. ", "machine_text": "  We present here observations of the Sun at millimetre wavelengths, made with the bolometer array TEFLON/FEP (TF) on the Atacama Large Millimeter Array (ALMA). We observe the solar photosphere at 70 GHz and 80 GHz, and study the brightness distribution at these two frequencies in comparison with the behaviour of the Sun at visible and ultraviolet (UV) wavelengths. The most notable feature in the millimetre data is the appearance of large-scale structures, with a distribution of brightness maxima and minima that is superimposed on the large-scale photospheric features. We show that these millimetre features are related to the distribution of photospheric magnetic flux, as observed in the photosphere itself and in the UV. The correlation is not exact, because the millimetre data are affected by noise and by large-scale brightness variations that are not correlated with the magnetic field. We determine the positions of the magnetic features in the millimetre data by adjusting the magnetic field positions in such a way that the correlation between the two is maximised. We find that the resulting magnetic features in the millimetre data have a spatial resolution that is somewhat higher than in the visible and UV data, and are able to resolve some small-scale features that are not visible in the other data. We discuss this in the framework of a simple model in which the magnetic flux is proportional to the total radiative emission at millimetre wavelengths, and show that this model is in reasonable agreement with the data. We find that the total radiative emission is slightly higher in the millimetre data than would be expected from the magnetic flux, and discuss this in the framework of different physical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Carbon Nanotube Thin Film Field Emitting Diode: Understanding the System\n  Response Based on Multiphysics Modeling. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.168, "human_text": "  In this paper, we model the evolution and self-assembly of randomly oriented carbon nanotubes (CNTs), grown on a metallic substrate in the form of a thin film for field emission under diode configuration. Despite high output, the current in such a thin film device often decays drastically. The present paper is focused on understanding this problem. A systematic, multiphysics based modelling approach is proposed. First, a nucleation coupled model for degradation of the CNT thin film is derived, where the CNTs are assumed to decay by fragmentation and formation of clusters. The random orientation of the CNTs and the electromechanical interaction are then modeled to explain the self-assembly. The degraded state of the CNTs and the electromechanical force are employed to update the orientation of the CNTs. Field emission current at the device scale is finally obtained by using the Fowler-Nordheim equation and integration over the computational cell surfaces on the anode side. The simulated results are in close agreement with the experimental results. Based on the developed model, numerical simulations aimed at understanding the effects of various geometric parameters and their statistical features on the device current history are reported. ", "machine_text": " The motivation for this work is to understand the physical and electrical mechanisms that govern the electron emission from carbon nanotube thin film field emitting diode (Thin Film FED) in order to improve the efficiency and long-term stability of the device. The key idea is to use multiphysics modeling to investigate the dynamic behavior of the electron emission process. The methodology is based on the combination of hydrodynamic and ballistic models. The results obtained from the simulation show that the hydrodynamic model can explain the observed current-voltage characteristics of the Thin Film FED, and the ballistic model can be used to predict the emission current density as a function of the electric field strength. The practical application of this work is to design and optimize the structure of the Thin Film FED in order to achieve high emission current density and long-term stability. The theoretical application of this work is to understand the physical and electrical mechanisms that govern the electron emission process in the Thin Film FED.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolution of interstellar dust and stardust in the solar neighbourhood. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1155, "human_text": "  The abundance evolution of interstellar dust species originating from stellar sources and from condensation in molecular clouds in the local interstellar medium of the Milky Way is studied and the input of dust material to the Solar System is determined. A one-zone chemical evolution model of the Milky Way for the elemental composition of the disk combined with an evolution model for its interstellar dust component similar to that of Dwek (1998) is developed. The dust model considers dust-mass return from AGB stars as calculated from synthetic AGB models combined with models for dust condensation in stellar outflows. Supernova dust formation is included in a simple parameterized form which is gauged by observed abundances of presolar dust grains with supernova origin. For dust growth in the ISM a simple method is developed for coupling this with disk and dust evolution models. The time evolution of the abundance of the following dust species is followed in the model: silicate, carbon, silicon carbide, and iron dust from AGB stars and from SNe as well as silicate, carbon, and iron dust grown in molecular clouds. It is shown that the interstellar dust population is dominated by dust accreted in molecular clouds; most of the dust material entering the Solar System at its formation does not show isotopic abundance anomalies of the refractory elements, i.e., inconspicuous isotopic abundances do not point to a Solar System origin of dust grains. The observed abundance ratios of presolar dust grains formed in SN ejecta and in AGB star outflows requires that for the ejecta from SNe the fraction of refractory elements condensed into dust is 0.15 for carbon dust and is quite small ($\\sim10^{-4}$) for other dust species. ", "machine_text": " We present an analysis of the evolution of interstellar and stardust within the solar neighbourhood, based on the observation of more than a thousand nearby stars. We show that the local interstellar medium is a large-scale turbulent structure, and that this turbulence is responsible for the relative increase in the mass of small grains in the local interstellar medium compared to the ISM in the distant solar neighbourhood. We determine the growth rate of the small fraction of the ISM, and find that it is in agreement with the prediction of the localisation theory, according to which small grains grow efficiently in the inner part of the ISM. We also show that the growth of the small fraction of the ISM is compatible with a pure diffusion process, in spite of the large-scale structure of the ISM. In addition, we find that the large-scale structure of the local ISM contains a significant amount of stardust, which has been recycled from old stars to the new ones. We compare our predictions concerning the evolution of stardust with observations of old stars, and find a good agreement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Super-Poissonian Shot Noise as a Measure of Dephasing in Closed Quantum\n  Dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2668, "human_text": "  Electron-electron interactions play a major role in determining the low-temperature rate of phase loss of electrons in mesoscopic systems. The study of the dephasing rate is expected to contribute to the understanding of the many-body nature of such systems. Closed quantum dots are of special interest in this respect, due to theoretical predictions suggesting a possible transition temperature below which the dephasing rate vanishes. This prediction has attracted much attention, since closed quantum dots are prime candidates for storage units in quantum computers, and thus their phase coherence properties are of great importance. However, an effective method for measuring the dephasing rate within a closed quantum dot is still lacking. Here we study two-level systems and show that the Fano factor has a sharp peak as a function of the chemical potential, the location of which can be simply related to the dephasing rate. We thus suggest to use the properties of the Fano factor peak in the super-Poissonian regime as a probe for the dephasing rate. ", "machine_text": " We report a new method for measuring the inherent dephasing in quantum dots. We show that one can use the shot noise in the emission from a quantum dot to infer the amount of dephasing in the dot. Our approach is based on the fact that for a large class of quantum dots the shot noise has a  super-Poissonian distribution. We show that a simple measurement of the shot noise amplitude can be used to estimate the dephasing, and that this method is more precise than other methods that have been proposed. We also show that our method can be used to distinguish between different sources of dephasing, such as thermal noise and the splitting of the quantum dot energy levels.   We motivate our work by considering a simple model of a quantum dot, and showing that a shot noise measurement can be used to distinguish between different types of dephasing in the dot. We then propose a practical shot noise measurement scheme, and show that one can obtain a shot noise spectrum by measuring the shot noise amplitude as a function of the laser intensity. We show that our proposed scheme is more precise than other methods that have been proposed for measuring the dephasing in a quantum dot.   Our method can be used to study the dephasing in a quantum dot, and can be used to distinguish between different sources of dephasing. Our method is particularly useful for measuring the dephasing in a quantum dot that is in a solid-state matrix, where other methods that have been proposed are not applicable. Our method can also be used to study the dephasing in a single quantum dot in a cavity, or in a linear chain of quantum dots. We also propose a simple scheme for measuring the dephasing time in a quantum dot, which may be useful for characterizing the dephasing in a quantum dot.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unambiguous coherent state identification: Searching a quantum database. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1892, "human_text": "  We consider an unambiguous identification of an unknown coherent state with one of two unknown coherent reference states. Specifically, we consider two modes of an electromagnetic field prepared in unknown coherent states alpha_1 and alpha_2, respectively. The third mode is prepared either in the state alpha_1 or in the state alpha_2. The task is to identify (unambiguously) which of the two modes are in the same state. We present a scheme consisting of three beamsplitters capable to perform this task. Although we don't prove the optimality, we show that the performance of the proposed setup is better than the generalization of the optimal measurement known for a finite-dimensional case. We show that a single beamsplitter is capable to perform an unambiguous quantum state comparison for coherent states optimally. Finally we propose an experimental setup consisting of 2N-1 beamsplitters for unambiguous identification among N unknown coherent states. This setup can be considered as a search in a quantum database. The elements of the database are unknown coherent states encoded in different modes of an electromagnetic field. The task is to specify the two modes that are excited in the same, though unknown, coherent state. ", "machine_text": "  Unambiguous coherent state identification: Searching a quantum database We propose and analyze a quantum algorithm for unambiguous identification of coherent states of a qubit from a quantum database. The algorithm makes use of the quantum superposition principle and can be realized with elementary quantum gates. We show that if the states to be distinguished are not close in the quantum state space, then the algorithm has a high probability of success. In particular, if one wants to distinguish between two different coherent states which are not close in the Hilbert space, then success can be guaranteed by using only a constant number of quantum gates and resources. We analyze the algorithm efficiency as a function of the distance in the quantum state space between the states to be distinguished and show that it is a continuous function with a sharp threshold. The practical consequence is that one can implement the algorithm in practice with a given number of quantum gates and resources, and if it does not work, then it is guaranteed that it will not work, no matter how long one waits.  We also propose a quantum algorithm for searching a quantum database for a given state \u03c8. The algorithm is based on the quantum operation of shallow discrimination and uses a series of discrimination operations, each of which discards half of the states in the database which are not close to \u03c8. We show that if \u03c8 is not close to any of the states in the database, then the algorithm has a high probability of success. As for the coherent state identification problem, we analyze the algorithm efficiency as a function of the distance in the quantum state space between \u03c8 and the states in the database, and show that it is a continuous function with a sharp threshold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Extrasolar Planet Census with a Space-based Microlensing Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0454, "human_text": "  A space-based gravitational microlensing exoplanet survey will provide a statistical census of exoplanets with masses down to 0.1 Earth-masses and orbital separations ranging from 0.5AU to infinity. This includes analogs to all the Solar System's planets except for Mercury, as well as most types of planets predicted by planet formation theories. Such a survey will provide results on the frequency of planets around all types of stars except those with short lifetimes. Close-in planets with separations < 0.5 AU are invisible to a space-based microlensing survey, but these can be found by Kepler. Other methods, including ground-based microlensing, cannot approach the comprehensive statistics on the mass and semi-major axis distribution of extrasolar planets that a space-based microlensing survey will provide. The terrestrial planet sensitivity of a ground-based microlensing survey is limited to the vicinity of the Einstein radius at 2-3 AU, and space-based imaging is needed to identify and determine the mass of the planetary host stars for the vast majority of planets discovered by microlensing. Thus, a space-based microlensing survey is likely to be the only way to gain a comprehensive understanding of the nature of planetary systems, which is needed to understand planet formation and habitability. The proposed Microlensing Planet Finder (MPF) mission is an example of a space-based microlensing survey that can accomplish these objectives with proven technology and a cost that fits comfortably under the NASA Discovery Program cost cap. ", "machine_text": "  We present a space-based microlens survey strategy that uses a combination of fine-grained photometry and astrometry to census extrasolar planets around Milky Way stars. Our method is based on a statistical analysis of the intrinsic microlens light-curve shape and an evaluation of the accuracy with which such curves can be measured. We show that the survey can achieve a level of sensitivity such that it would be capable of detecting planets the size of Mars at the distance of the Earth from the Sun, provided that they are not more than a few AU from their host stars. We describe the types of cameras and telescopes that would be needed for such a survey, and the data processing and telescope/instrument handling required, and present an analysis of the likely yield of the survey. We find that a 5-year survey using a single 1-m telescope would be capable of detecting at least one image per year, and that a network of 4 such telescopes would be capable of detecting up to 10 images per year. We also find that, given the current distribution of telescope time, a survey such as this would require a dedicated telescope network. We discuss the various types of follow-up observations that could be used to characterize the exoplanets detected.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An integral field spectroscopic survey for high redshift damped\n  Lyman-alpha galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0654, "human_text": "  We search for galaxy counterparts to damped Lyman-alpha absorbers (DLAs) at z>2 towards nine quasars, which have 14 DLAs and 8 sub-DLAs in their spectra. We use integral field spectroscopy to search for Ly-alpha emission line objects at the redshifts of the absorption systems. Besides recovering two previously confirmed objects, we find six statistically significant candidate Ly-alpha emission line objects. The candidates are identified as having wavelengths close to the DLA line where the background quasar emission is absorbed. In comparison with the six currently known Ly-alpha emitting DLA galaxies the candidates have similar line fluxes and line widths, while velocity offsets between the emission lines and systemic DLA redshifts are larger. The impact parameters are larger than 10 kpc, and lower column density systems are found at larger impact parameters. Assuming that a single gas cloud extends from the QSO line of sight to the location of the candidate emission line, we find that the average candidate DLA galaxy is surrounded by neutral gas with an exponential scale length of ~5 kpc. ", "machine_text": "  We present a catalogue of 75 high redshift damped Lyman-alpha galaxies (DLAs) observed with integral field spectroscopy on the Hubble Space Telescope. These galaxies were selected from an image-based catalogue of over 250 DLA candidates found in an Hubble Ultra-Deep Field survey for bright galaxies with strong ultraviolet ionization continuum sources. Our integral field spectroscopy confirmed that all of our galaxies are at high redshift (z < 1), and revealed the redshifts and optical line-of-sight velocities for each galaxy. We find that the mean redshift of our sample is 0.86 (0.78 - 0.92), and the mean line-of-sight velocity is -69 km/s (68 - -74 km/s). Using the updated distance measurements from the Hubble Deep Field Survey, we find that the DLA galaxies lie at mean distances of 80 - 200 Mpc. Our high redshift DLAs are found to be relatively rich in neutral hydrogen gas (10 - 25 per cent of the critical density for reionization), and are possibly the galaxies responsible for the reionization of the Universe. We discuss our galaxies in the context of other high redshift DLAs, and in terms of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3\n  calculations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.07, "human_text": "  This work reports a theoretical study of the gas phase unimolecular decomposition of cyclobutane, cyclopentane and cyclohexane by means of quantum chemical calculations. A biradical mechanism has been envisaged for each cycloalkane, and the main routes for the decomposition of the biradicals formed have been investigated at the CBS-QB3 level of theory. Thermochemical data (\\delta H^0_f, S^0, C^0_p) for all the involved species have been obtained by means of isodesmic reactions. The contribution of hindered rotors has also been included. Activation barriers of each reaction have been analyzed to assess the 1 energetically most favorable pathways for the decomposition of biradicals. Rate constants have been derived for all elementary reactions using transition state theory at 1 atm and temperatures ranging from 600 to 2000 K. Global rate constant for the decomposition of the cyclic alkanes in molecular products have been calculated. Comparison between calculated and experimental results allowed to validate the theoretical approach. An important result is that the rotational barriers between the conformers, which are usually neglected, are of importance in decomposition rate of the largest biradicals. Ring strain energies (RSE) in transition states for ring opening have been estimated and show that the main part of RSE contained in the cyclic reactants is removed upon the activation process. ", "machine_text": "  We present a detailed kinetic study of the ring opening of cycloalkanes by CBS-QB3 calculations. The motivation for the work was the significant discrepancy between the experimentally observed reaction pathways and the paths predicted by QST2, the most widely used method for describing non-bonded interactions. Our key ideas and methodology were to carefully examine the effects of four factors that have been proposed to affect the ring opening process: (1) the ring strain, (2) the aliphatic carbon chain length, (3) the number of carbon atoms in the largest ring, and (4) the position of the ring-opening event. Our results obtained from CBS-QB3 calculations show that these four factors do not have a major effect on the ring-opening process. We also discuss the reasons why QST2 may have failed to describe the reaction pathway. Our work attempts to solve the problem of how to model the ring-opening process of cycloalkanes and has practical implications for the design of new drugs and the study of the mechanism of drug action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetic fluctuations in n-type high-$T_c$ superconductors reveal\n  breakdown of fermiology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4424, "human_text": "  By combining experimental measurements of the quasiparticle and dynamical magnetic properties of optimally electron-doped Pr$_{0.88}$LaCe$_{0.12}$CuO$_4$ with theoretical calculations we demonstrate that the conventional fermiology approach cannot possibly account for the magnetic fluctuations in these materials. In particular, we perform tunneling experiments on the very same sample for which a dynamical magnetic resonance has been reported recently and use photoemission data by others on a similar sample to characterize the fermionic quasiparticle excitations in great detail. We subsequently use this information to calculate the magnetic response within the conventional fermiology framework as applied in a large body of work for the hole-doped superconductors to find a profound disagreement between the theoretical expectations and the measurements: this approach predicts a step-like feature rather than a sharp resonance peak, it underestimates the intensity of the resonance by an order of magnitude, it suggests an unreasonable temperature dependence of the resonance, and most severely, it predicts that most of the spectral weight resides in incommensurate wings which are a key feature of the hole-doped cuprates but have never been observed in the electron-doped counterparts. Our findings strongly suggest that the magnetic fluctuations reflect the quantum-mechanical competition between antiferromagnetic and superconducting orders. ", "machine_text": " We have performed a systematic study of the evolution of the spin correlation function in the n-type high-$T_c$ superconductor CeCoIn_5 at low temperatures, in the weak-to-non-correlated regime, using neutron-scattering techniques. We find that the single-particle spectral function at theCo-based Fermi surface is shredded into a large number of multiply-degenerate, commensurate quantum states. The nature of this structure is consistent with a crossover from a regular, higher-dimensional, periodic spectrum to a coarsely-faceted, lower-dimensional, non-periodic spectrum. We show this by performing a mathematical analysis of the recent theory of dresser pockets. The results explain why the pairing correlation function in this material does not follow the universal behavior predicted by the Dresselhaus-Dresse-Wohlfarth theory, but instead shows a strong preference for in-plane correlations. We also show that this breakdown of fermiology has a strong impact on the effective two-spinon correlation function, in a way which is consistent with the large number of low-spin states produced by the Megan mechanism. Our results suggest that the breakdown of the periodic structure of the spectral function is a generic feature of cuprate-based superconductors, and may be a signature of the onset of a low-spin state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A New Tool for Seismology--the Cumulative Spectral Power. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.11, "human_text": "  The power spectral density (PSD) function is commonly used to specify seismometer performance. It is derived from the FFT of acceleration and correction is made for the transfer function of the instrument that generated the data. As with any such spectrum of density (`per Hz') type, the noise inherent to a PSD is large. This article illustrates the value of a function that is derived from the PSD and for which the influence of noise is significantly reduced. Called the cumulative spectral power (CSP), it is obtained from the PSD through the noise-reducing process of integration. The maximum of the CSP (corresponding to the longest graphed value of the period) provides a means for estimating the total vibrational power of the earth. The present author has significantly simplified the process of PSD generation. Thus routine graphing is straightforwared-of first the FFT, followed by the generation of both a PSD and its associated CSP. The unique properties of the CSP make it valuable for the study of a variety of earth dynamics. For example, the strking simplicity of a CSP graph generated from a record containing a strong teleseismic earthquake is undoubtedly important to the development and refinement of any viable theory of earthquake dynamics. ", "machine_text": "  A New Tool for Seismology--the Cumulative Spectral Power.  We introduce a new measure of seismic activity, based on the cumulative spectral power, which we name the \"cumulative spectral moment.\" This measure has several attractive features, including the property that it is decorrelated with the location, size, and orientation of the fault system. We show that the cumulative spectral moment is related to the familiar moment magnitude scale, but the relationship is very weak, which makes the cumulative spectral moment a more robust measure of seismic activity. We find that the cumulative spectral moment has a clear inverse relation with the rate of moment release, which we show is a consequence of the physical relation between the seismic moment and the energy radiated by the Earth's vibrations. We point out that the conventional seismic moment is not a good measure of activity because it is very strongly correlated with the size and orientation of the fault system. We show that the cumulative spectral moment has several other interesting properties, including a strong tendency to increase in bursts, a tendency to have a power law distribution on long time scales, and a linear relation with the amount of energy released by the seismic events. The cumulative spectral moment has several practical applications, including as a way to detect activity that is not visible on other moment measures, as a way to identify different seismic sources, and as a way to study the dynamics of the moment release.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scattering amplitudes in strongly coupled N=4 SYM from semiclassical\n  strings in AdS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2113, "human_text": "  Very recently in arXiv:0705.0303 Alday and Maldacena gave a string theory prescription for computing (all) planar amplitudes in N=4 supersymmetric gauge theory at strong coupling using the AdS/CFT correspondence. These amplitudes are determined by a classical string solution and contain a universal exponential factor involving the action of the classical string. On the gauge theory side, expressions for perturbative amplitudes at strong coupling were previously proposed only for specific helicities of external particles -- the maximally helicity violating or MHV amplitudes. These follow from the exponential ansatz of Bern, Dixon and Smirnov for MHV amplitudes in N=4 SYM. In this paper we examine the amplitudes dependence on helicities and particle-types of external states. We consider the prefactor of string amplitudes and give arguments suggesting that the prefactor at strong coupling should be the same as the Yang-Mills tree-level amplitude for the same process. This implies that scattering amplitudes in N=4 SYM simplify dramatically in the strong coupling limit. It follows from our proposal that in this limit all (MHV and non-MHV) n-point amplitudes are given by the (known) tree-level Yang-Mills result times the helicity-independent (and particle-type-independent) universal exponential. ", "machine_text": " We give a detailed derivation of the N=4 superYang-Mills scattering amplitudes in the semiclassical limit from the string theory in anti-de Sitter space. In particular we show that the string theory in anti-de Sitter space is equivalent to the N=4 superYang-Mills theory with a non-Abelian symmetry group with certain parameters in the space-time. We obtain the scattering amplitudes in the limit where the non-Abelian symmetry group becomes Abelian and the parameters go to their semiclassical values. As an application we consider the N=4 superYang-Mills theory with an adjoint representation $\\Gamma^+$ of the non-Abelian symmetry group and obtain the scattering amplitudes in the semiclassical limit for a single adjoint representation and for a combination of several adjoint representations. We compare our results with the recent results of Deiss and Stern (arXiv:1205.5667) who consider the Yang-Mills theory with an adjoint representation and obtain the semiclassical scattering amplitudes by using the Regge theory. We show that our approach is more general and can be applied to the theories with an arbitrary representation of the non-Abelian symmetry group, not only to the adjoint representation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mass loss from Luminous Blue Variables and Quasi-Periodic Modulations of\n  Radio Supernovae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2689, "human_text": "  Massive stars, supernovae (SNe), and long-duration gamma-ray bursts (GRBs) have a huge impact on their environment. Despite their importance, a comprehensive knowledge of which massive stars produce which SN/GRB is hitherto lacking. We present a brief overview about our knowledge of mass loss in the Hertzsprung-Russell Diagram (HRD) covering evolutionary phases of the OB main sequence, the unstable Luminous Blue Variable (LBV) stage, and the Wolf-Rayet (WR) phase. Despite the fact that metals produced by ``self-enrichment'' in WR atmospheres exceed the initial -- host galaxy -- metallicity, by orders of magnitude, a particularly strong dependence of the mass-loss rate on the initial metallicity is found for WR stars at sub-solar metallicities (1/10 -- 1/100 solar). This provides a significant boost to the collapsar model for GRBs, as it may present a viable mechanism to prevent the loss of angular momentum by stellar winds at low metallicity, whilst strong Galactic WR winds may inhibit GRBs occurring at solar metallicities. Furthermore, we discuss recently reported quasi-sinusoidal modulations in the radio lightcurves of SNe 2001ig and 2003bg. We show that both the sinusoidal behaviour and the recurrence timescale of these modulations are consistent with the predicted mass-loss behaviour of LBVs, and we suggest LBVs may be the progenitors of some core-collapse SNe. ", "machine_text": "  We present a model for the mass loss from Luminous Blue Variables (LBVs) and the quasi-periodic modulations of Radio Supernovae (RSNe). The model is based on the assumption that the mass loss from LBVs and the accretion onto RSNs is driven by the same dynamical mechanism. The model also accounts for the evolution of the system's internal structure, in particular, the core-envelope system. We show that the mass-loss rate from LBVs is proportional to the shocked gas density, and the proportionality constant is given by the square of the frequency of the quasi-periodic modulation of RSNs. We evaluate the time-scales of the mass loss and the evolution of the core-envelope system. We show that the mass-loss rate is high at the early stage of evolution, but it is very low at the late stage of evolution. Therefore, the mass-loss rate is rather well controlled, and it is not likely that the massive gas ejection from LBVs causes the quasi-periodic modulations of RSNs. We discuss several possible physical mechanisms of the quasi-periodic modulations, and we show that a simple model of a single-frequency model can explain a wide range of observed properties of the quasi-periodic modulations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum Hall ferromagnetism in graphene: a SU(4) bosonization approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3671, "human_text": "  We study the quantum Hall effect in graphene at filling factors \\nu = 0 and \\nu = \\pm, concentrating on the quantum Hall ferromagnetic regime, within a non-perturbative bosonization formalism. We start by developing a bosonization scheme for electrons with two discrete degrees of freedom (spin-1/2 and pseudospin-1/2) restricted to the lowest Landau level. Three distinct phases are considered, namely the so-called spin-pseudospin, spin, and pseudospin phases. The first corresponds to a quarter-filled (\\nu =-1) while the others to a half-filled (\\nu = 0) lowest Landau level. In each case, we show that the elementary neutral excitations can be treated approximately as a set of n-independent kinds of boson excitations. The boson representation of the projected electron density, the spin, pseudospin, and mixed spin-pseudospin density operators are derived. We then apply the developed formalism to the effective continuous model, which includes SU(4) symmetry breaking terms, recently proposed by Alicea and Fisher. For each quantum Hall state, an effective interacting boson model is derived and the dispersion relations of the elementary excitations are analytically calculated. We propose that the charged excitations (quantum Hall skyrmions) can be described as a coherent state of bosons. We calculate the semiclassical limit of the boson model derived from the SU(4) invariant part of the original fermionic Hamiltonian and show that it agrees with the results of Arovas and co-workers for SU(N) quantum Hall skyrmions. We briefly discuss the influence of the SU(4) symmetry breaking terms in the skyrmion energy. ", "machine_text": " We investigate the problem of endowing graphene with a non-trivial band structure by means of a SU(4) bosonization. In particular we show that a peculiar kind of quasi-particle, called a fermitron, can arise in this setting. This new kind of particle is characterized by a non-trivial internal structure, giving rise to a large number of distinct eigenvalues for the kinetic energy. We show that this fact has important consequences for the nature of the non-trivial band structure that may be obtained in this way. In particular we show that the resulting band structure may be described in terms of a set of inter-related Higgs bundles, which are protected by a set of non-trivial symmetries, and which may be related to the so-called Higgs ghosts. We show that this structure may be understood as a kind of quantum Hall effect, in which the \"cyclotron\" is replaced by a \"fermitron\". We also show that a large class of gauge symmetries may be realized in this setting, in a way which is consistent with the theory of Higgs bundles. This suggests that the structure we obtain is a generalization of the ordinary quantum Hall effect to a large class of systems which include graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Solar heavy element abundance: constraints from frequency separation\n  ratios of low-degree p modes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3154, "human_text": "  We use very precise frequencies of low-degree solar-oscillation modes measured from 4752 days of data collected by the Birmingham Solar-Oscillations Network (BiSON) to derive seismic information on the solar core. We compare these observations to results from a large Monte Carlo simulation of standard solar models, and use the results to constrain the mean molecular weight of the solar core, and the metallicity of the solar convection zone. We find that only a high value of solar metallicity is consistent with the seismic observations. We can determine the mean molecular weight of the solar core to a very high precision, and, dependent on the sequence of Monte Carlo models used, find that the average mean molecular weight in the inner 20% by radius of the Sun ranges from 0.7209 to 0.7231, with uncertainties of less than 0.5% on each value. Our lowest seismic estimate of solar metallicity is Z=0.0187 and our highest is Z=0.0239, with uncertainties in the range of 12--19%. Our results indicate that the discrepancies between solar models constructed with low metallicity and the helioseismic observations extend to the solar core and thus cannot be attributed to deficiencies in the modeling of the solar convection zone. ", "machine_text": "  We present an analysis of the frequency separation ratios (FSRs) of low-degree p modes for 78 F- and G-type stars in an effort to derive solar abundances of the heavy elements. The FSRs are computed using the public socialism database (SDB), which contains high-resolution spectroscopic data that have been analyzed in support of the NASA Themis mission. We have derived the abundances of the heavy elements for each star in the SDB sample by fitting the observed FSRs to the theoretical relationships derived from the Solar Census Database (SCD). We find that the derived abundances are in good agreement with those obtained from a recent analysis of high-resolution solar spectrum data (169 elements, this work) and with the chemical composition of the Sun as derived from the study of the solar photosphere (93 elements, these data). We determine the abundances of nine elements (Ce, Cr, Fe, Co, Ni, Cu, Zn, Ga, In, and Sn) for which the SCD relationships were derived from a sample of 34 G stars which have no detected magnetic activity. The derived abundances are in good agreement with those obtained from a sample of 14 G stars which have detected magnetic activity (Bohigas et al., 1999). We conclude that the SCD relationships for these elements can be applied to solar twins, even if the latter have magnetic activity. We discuss the impact of the assumptions made in the derivation of the SCD relationships on the derived abundances, and we point out evidence that the diffusion coefficients used to derive the SCD relationships may be too large. We also discuss the impact of the possible differences between the observing and model stars in the derivation of the FSRs on the derived abundances. We find that these effects are negligible for the analysis of the FSRs of low-degree p modes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GLSM's for partial flag manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1761, "human_text": "  In this paper we outline some aspects of nonabelian gauged linear sigma models. First, we review how partial flag manifolds (generalizing Grassmannians) are described physically by nonabelian gauged linear sigma models, paying attention to realizations of tangent bundles and other aspects pertinent to (0,2) models. Second, we review constructions of Calabi-Yau complete intersections within such flag manifolds, and properties of the gauged linear sigma models. We discuss a number of examples of nonabelian GLSM's in which the Kahler phases are not birational, and in which at least one phase is realized in some fashion other than as a complete intersection, extending previous work of Hori-Tong. We also review an example of an abelian GLSM exhibiting the same phenomenon. We tentatively identify the mathematical relationship between such non-birational phases, as examples of Kuznetsov's homological projective duality. Finally, we discuss linear sigma model moduli spaces in these gauged linear sigma models. We argue that the moduli spaces being realized physically by these GLSM's are precisely Quot and hyperquot schemes, as one would expect mathematically. ", "machine_text": " We introduce a general framework for the study of semi-simple submanifolds of flag manifolds. Flag manifolds are semi-simple by definition, so the question of simplicity is settled. However, they are also specified by a partition into subspaces, which can be nontrivial. We show that a generic semi-simple submanold of a flag manifold is a partially-flagged submanifold, i.e., it is a submanifold of the flag manifold on which the restriction of the flagging remains a flagging. We consider several classes of semi-simple submanifolds which have natural motivations from the theory of discrete semi-simple submanifolds of Lie groups. In particular, we show that any such submanifold is a partially-flagged submanold. We show that a submanifold of a flag manifold is a partially-flagged submanifold if and only if it is an inclusion of a subspace of the flag manifold. This answers a question of Greene, and provides a necessary and sufficient condition for a submanold to be a partially-flagged submanold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Capacity Gain from Two-Transmitter and Two-Receiver Cooperation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3644, "human_text": "  Capacity improvement from transmitter and receiver cooperation is investigated in a two-transmitter, two-receiver network with phase fading and full channel state information available at all terminals. The transmitters cooperate by first exchanging messages over an orthogonal transmitter cooperation channel, then encoding jointly with dirty paper coding. The receivers cooperate by using Wyner-Ziv compress-and-forward over an analogous orthogonal receiver cooperation channel. To account for the cost of cooperation, the allocation of network power and bandwidth among the data and cooperation channels is studied. It is shown that transmitter cooperation outperforms receiver cooperation and improves capacity over non-cooperative transmission under most operating conditions when the cooperation channel is strong. However, a weak cooperation channel limits the transmitter cooperation rate; in this case receiver cooperation is more advantageous. Transmitter-and-receiver cooperation offers sizable additional capacity gain over transmitter-only cooperation at low SNR, whereas at high SNR transmitter cooperation alone captures most of the cooperative capacity improvement. ", "machine_text": "  We investigate cooperation among two transmitters and two receivers in a wireless relay network. We assume that the two transmitters have independent information to send to the two receivers, and that they share a common (wireless) relay channel to communicate. We find that the relays can substantially increase the capacity of the network, in the sense that the rates achievable by the transmitters increase substantially if the relays are allowed to cooperate in the transmission process. We show that this result can be guaranteed by using a generalized family of schedules, which we call semi- schedules, to describe the cooperation protocol. We analyze the performance of the protocol under various assumptions about the models for the wireless channels and the information available at the relays. In particular, we show that in a network where the receivers are assumed to have perfect information about the wireless channels and where the transmitters have correlated information, the capacity gain provided by the relays can be very large. We also consider the effect of allowing the relays to make errors in their transmission process, and show that even in this case, the relays can still increase the capacity of the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radiative Transfer Effect on Ultraviolet Pumping of the 21cm Line in the\n  High Redshift Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0895, "human_text": "  During the epoch of reionization the 21cm signal is sensitive to the scattering rate of the ultraviolet photons, redshifting across the Lyman_alpha resonance. Here we calculate the photon scattering rate profile for a single ultraviolet source. After taking into account previously neglected natural broadening of the resonance line, we find that photons approach the resonance frequency and experience most scatterings at a significantly smaller distance from the source than naively expected r=(dnu/nu_0)(c/H), where dnu=nu-nu_0 is the initial frequency offset, and the discrepancy increases as the initial frequency offset decreases. As a consequence, the scattering rate P(r) drops much faster with increasing distance than the previously assumed 1/r^2 profile. Near the source (r<1Mpc comoving), the scattering rate of photons that redshift into the Ly_alpha resonance converges to P(r) \\propto r^{-7/3}. The scattering rate of Ly_alpha photons produced by splitting of photons that redshift into a higher resonance (Ly_gamma, Ly_delta, etc.) is only weakly affected by the radiative transfer, while the sum of scattering rates of Ly_alpha photons produced from all higher resonances also converges to P(r) \\propto r^{-7/3} near the source. At 15<z<35, on scales of ~0.01-20Mpc/h (comoving), the total scattering rate of Ly_alpha photons from all Lyman resonances is found to be higher by a factor of ~1+0.3[(1+z)/20]^{2/3} than obtained without full radiative transfer. Consequently, during the early stage of reionization, the differential brightness of 21cm signal against the cosmic microwave background is also boosted by a similar factor. ", "machine_text": "  We present a radiative transfer investigation of the ultraviolet (UV) pumping of the 21cm line in the high redshift universe. We consider the effect of the radiative transfer in the intergalactic medium (IGM) and the impact of the discrete absorption and emission by the gas on the 21cm line. We find that the radiative transfer in the IGM has little effect on the central part of the 21cm line, but produces a characteristic broadened wings. The discrete absorption and emission by the gas results in a systematic shift of the 21cm line, and can produce a misleading signal if the absorption and the emission are not properly accounted for. We also present a model for the radiative transfer in the IGM that can be used to predict the 21cm line radiative transfer in a given medium.   We have investigated the radiative transfer effect on the ultraviolet (UV) pumping of the 21cm line in the high redshift universe. We have found that the radiative transfer in the intergalactic medium (IGM) has little effect on the central part of the 21cm line, but produces a characteristic broadened wings. The discrete absorption and emission by the gas results in a systematic shift of the 21cm line, and can produce a misleading signal if the absorption and the emission are not properly accounted for. We have also presented a model for the radiative transfer in the IGM that can be used to predict the 21cm line radiative transfer in a given medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Haunted Halos of Andromeda and Triangulum: A panorama of galaxy\n  formation in action. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1318, "human_text": "  We present a deep photometric survey of M31, conducted with the CFHT and INT, covering the inner 50 kpc of the galaxy, the Southern quadrant out to 150 kpc, and extending to M33. This is the first systematic panoramic study of this very outermost region of galaxies. We detect several streams and other large-scale structures, and two new dwarf galaxies: And XV and XVI. The discovery of substructure on the minor axis, together with the fact that the light profile between 0.5 < R < 1.3 follows the exponential ``extended disk'', is particularly important in shedding light on the mixed and sometimes conflicting results reported in previous studies. Underlying the substructures lies a faint, metal-poor, smooth and extremely extended halo, reaching out to at least 150 kpc. The smooth halo component in M31 has a profile that can be fit with a Hernquist model of immense scale radius ~55 kpc, almost a factor of 4 larger than theoretical predictions. Alternatively a power-law with exponent -1.91 +/- 0.11 can be fit to the profile. The total luminosity of this structure is similar to that of the halo of the Milky Way. This vast, smooth, underlying halo is reminiscent of a classical monolithic model and completely unexpected from modern galaxy formation models. M33 is also found to have an extended metal-poor halo component, which can be fit with a Hernquist model also of scale radius ~55 kpc. These extended slowly-decreasing halos will provide a challenge and strong constraints for further modeling. [Abridged] ", "machine_text": " We present a panoramic imaging survey of the stellar halos in the galaxies of Andromeda (M31) and Triangulum (M33), a pair of giant spiral galaxies in the Local Group. We find that the stellar halos of both galaxies aredominated by the repeated accretion of dwarf galaxies, whose orbits are controlled by the gravity of the giant galaxies. In the case of M33, we have discovered a chain of 16 accretion events, a number that increases to 37 if the satellites in the widest orbits are included. These satellites show a well-defined correlation between their orbital speeds and distances, indicating that the accretion events are governed by the viscous evolution of the satellite clouds. We have identified the galaxies that were involved in the accretion events and determined their orbits. We have also estimated the mass of the accreted satellites and compared it with the theoretical predictions of the galactic encounter problem. Our analysis reveals that the observed accretion events are consistent with the repeated accretion of satellites with masses between 10^8 and 10^9 M_(\u2299), and that the encounter problem can successfully explain the origin of the observed structure in the stellar halos of M33. In the case of M31, we have discovered four main accretion events, and the interpretation of these events requires an additional mechanism to explain the exceptional concentration of mass in the western half of the galaxy. We discuss several possibilities, including the possible contribution of supermassive black holes to the dynamical evolution of the stellar halos.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An expansion for self-interacting random walks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0614, "human_text": "  We derive a perturbation expansion for general self-interacting random walks, where steps are made on the basis of the history of the path. Examples of models where this expansion applies are reinforced random walk, excited random walk, the true (weakly) self-avoiding walk, loop-erased random walk, and annealed random walk in random environment.   In this paper we show that the expansion gives rise to useful formulae for the speed and variance of the random walk, when these quantities are known to exist. The results and formulae of this paper have been used elsewhere by the authors to prove monotonicity properties for the speed (in high dimensions) of excited random walk and related models, and certain models of random walk in random environment.   We also derive a law of large numbers and central limit theorem (with explicit error terms) directly from this expansion, under strong assumptions on the expansion coefficients. The assumptions are shown to be satisfied by excited random walk in high dimensions with small excitation parameter, a model of reinforced random walk with underlying drift and small reinforcement parameter, and certain models of random walk in random environment under strong ellipticity conditions. This is the extended version of the paper, where we provide all proofs. ", "machine_text": " We consider an expansion for self-interacting random walks. The expansion is in terms of the probability of large deviations from the mean. The motivation for this work is to provide a general method for constructing expansions for random walks which are self-similar in the limit. The key ideas are that, for any positive real number $\\epsilon$, the probability of a large deviation from the mean can be written as a power series in terms of the generating function for the random walk and $\\epsilon$. To derive this result, we first show that the probability of a large deviation from the mean for the simple random walk can be written as a power series in terms of the generating function. We then show that the probability of a large deviation from the mean for a self-interacting random walk can be written as a power series in terms of the generating function for the random walk and a small parameter $\\epsilon$. The resulting expansion for the probability of a large deviation from the mean for a self-interacting random walk is shown to agree with the result of Foster and rather nicely unify the results of different researchers. The problem this work attempts to solve is to construct a general expansion for self-interacting random walks which is self-similar in the limit. The practical application of this work is that it provides a general method for constructing expansions for self-interacting random walks. The theoretical application of this work is that it provides a general method for constructing expansions for random walks which are self-similar in the limit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The remarkable X-ray spectrum of the Broad-Line Radio Galaxy 3C 445. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3053, "human_text": "  We present the results of the analysis of an archival 15 ks XMM-Newton observation of the nearby (z=0.057) radio-loud source 3C445, optically classified as a Broad-Line Radio Galaxy. While the RGS data are of insufficient quality to allow a meaningful analysis, the EPIC data show a remarkable X-ray spectrum. The 2-10 keV continuum is described by a heavily absorbed (Nh~ 1e22 - 1e23 cm-2) power law with photon index Gamma ~1.4, and strong (R~2) cold reflection. A narrow, unresolved Fe Kalpha emission line is detected, confirming previous findings, with EW 120eV. A soft excess is present below 2 keV over the extrapolation of the hard X-ray power law, which we model with a power law with the same photon index as the hard power law, absorbed by a column density Nh=6e20 cm-2 in excess to Galactic. A host of emission lines are present below 2 keV, confirming previous indications from ASCA, due to H- and He-like O, Mg, and Si. We attribute the origin of the lines to a photoionized gas, with properties very similar to radio-quiet obscured AGN. Two different ionized media, or a single stratified medium, are required to fit the soft X-ray data satisfactorily. The similarity of the X-ray spectrum of 3C445 to Seyferts underscores that the central engines of radio-loud and radio-quiet AGN similarly host both cold and warm gas. ", "machine_text": "  We present a study of the X-ray spectrum of the broad-line radio galaxy 3C 445. We find that the iron line at 6.4 keV is significantly blended with a line at 7.2 keV, which we attribute to the decay of radioactive thorium. This is the first detection of a thorium line in the X-ray spectrum of a galaxy. The intensity of the thorium line is at least one order of magnitude higher than that of the iron line. The observed count rate of the thorium line is also one order of magnitude higher than the predicted one based on the measured thorium content in the galaxy. This implies that the thorium is not distributed homogeneously in the inner 4 kpc of the galaxy, and there may be a large amount of thorium in the central region. The observation also suggests that the 6.4 keV iron line may be contaminated by the thorium line in many broad-line radio galaxies. We have estimated the energy distribution of the X-ray radiation from the non-thermal continuum, and find that the contribution from the thermal continuum is only 7% of the total X-ray flux. This suggests that the accretion onto the supermassive black hole in the central region is not very efficient. The fraction of the X-ray flux from the core region of 3C 445 is estimated to be about 30%. The shape of the X-ray spectrum is well described by a power law with a photon index of 1.8. We have compared the X-ray spectra of 3C 445 with those of three other nearby broad-line radio galaxies (3C 231, 3C 334, and 3C 933), and found that they are very different. This suggests that the accretion onto the supermassive black hole is efficient in some broad-line radio galaxies, but not in others.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Efficient Simulations of Early Structure Formation and Reionization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0946, "human_text": "  We present a method to construct semi-numerical ``simulations'', which can efficiently generate realizations of halo distributions and ionization maps at high redshifts. Our procedure combines an excursion-set approach with first-order Lagrangian perturbation theory and operates directly on the linear density and velocity fields. As such, the achievable dynamic range with our algorithm surpasses the current practical limit of N-body codes by orders of magnitude. This is particularly significant in studies of reionization, where the dynamic range is the principal limiting factor. We test our halo-finding and HII bubble-finding algorithms independently against N-body simulations with radiative transfer and obtain excellent agreement. We compute the size distributions of ionized and neutral regions in our maps. We find even larger ionized bubbles than do purely analytic models at the same volume-weighted mean hydrogen neutral fraction. We also generate maps and power spectra of 21-cm brightness temperature fluctuations, which for the first time include corrections due to gas bulk velocities. We find that velocities widen the tails of the temperature distributions and increase small-scale power, though these effects quickly diminish as reionization progresses. We also include some preliminary results from a simulation run with the largest dynamic range to date: a 250 Mpc box that resolves halos with masses M >~ 2.2 x10^8 M_sun. We show that accurately modeling the late stages of reionization requires such large scales. The speed and dynamic range provided by our semi-numerical approach will be extremely useful in the modeling of early structure formation and reionization. ", "machine_text": " We present a detailed study of the structure and evolution of the cosmic large-scale structure, using a combination of sophisticated numerical simulations and semi-analytic models. We find that the large-scale structure grows efficiently, in a self-similar manner, with a power law exponent of 1.7 \u00b1 0.1, and is consistent with the predictions of the standard theory of structure formation. However, we find that the small-scale structure, responsible for the bulk of the mass, has a different power law exponent, 2.4 \u00b1 0.2, and is more efficiently coupled to the large-scale structure than the standard theory predicts. Our results suggest that the small-scale structure forms efficiently, in a self-similar manner, with the large-scale structure. We also present a detailed study of the evolution of ionization in the early Universe. We find that the ionization fraction increases non-monotonically, with a power law exponent of 2.4 \u00b1 0.2, and is consistent with the predictions of the standard theory of reionization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HD 98800: A 10-Myr-Old Transition Disk. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.038, "human_text": "  We present the mid-infrared spectrum, obtained with the Spitzer Infrared Spectrograph (IRS), of HD 98800, a quadruple star system located in the 10-Myr-old TW Hydrae association. It has a known mid-infrared excess that arises from a circumbinary disk around the B components of the system. The IRS spectrum confirms that the disk around HD 98800 B displays no excess emission below about 5.5 micron, implying an optically thick disk wall at 5.9 AU and an inner, cleared-out region; however, some optically thin dust, consisting mainly of 3-micron-sized silicate dust grains, orbits the binary in a ring between 1.5 and 2 AU. The peculiar structure and apparent lack of gas in the HD 98800 B disk suggests that this system is likely already at the debris disks stage, with a tidally truncated circumbinary disk of larger dust particles and an inner, second-generation dust ring, possibly held up by the resonances of a planet. The unusually large infrared excess can be explained by gravitational perturbations of the Aa+Ab pair puffing up the outer dust ring and causing frequent collisions among the larger particles. ", "machine_text": "  HD 98800: A 10-Myr-Old Transition Disk  We present high-resolution observations of the disk surrounding the young solar-like star HD 98800. These data include images obtained with the Hubble Space Telescope (HST) that reveal the disk to be a transition disk with a diameter of approximately 80 au. We find that the disk is comprised of two distinct parts: a compact inner region with a radius of approximately 20-30 au and a more extended outer region with a radius of approximately 50-80 au. The disk is generally well-circumscribed by a rim, except for a cavity of approximately 5-10 au in radius at the position of the terrestrial planet mass companion discovered in 2005. We estimate that the mass of the disk is 41 lunar masses (0.2 Earth masses) assuming a density of 1.6 g cm^3. We discuss the possible formation mechanisms for the disk and examine the potential for the disk to evolve into an analog of the solar system. We find that if the disk was formed by the accretion of planetesimals, it would have required an accretion rate of 0.01 Earth masses per Myr, similar to the rate estimated for the growth of the giant planets. We discuss the relative amounts of material in the disk and the likelihood that this disk may be the remains of a tumultuous planet formation process. We also examine the disk's habitability and find that the disk has a volatile content of approximately 0.01 Earth masses and a dust mass of approximately 0.02 Earth masses. We conclude that this disk is unlikely to be a habitable analog for the solar system, and thus is not a likely candidate for the search for extraterrestrial life. We discuss the implications of this disk for planet formation theory, and we highlight the need for further observations, both to verify our basic characterization of this disk and to better constrain the disk's properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive enhancement of electron-phonon coupling in doped graphene by an\n  electronic singularity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3264, "human_text": "  The nature of the coupling leading to superconductivity in layered materials such as high-Tc superconductors and graphite intercalation compounds (GICs) is still unresolved. In both systems, interactions of electrons with either phonons or other electrons or both have been proposed to explain superconductivity. In the high-Tc cuprates, the presence of a Van Hove singularity (VHS) in the density of states near the Fermi level was long ago proposed to enhance the many-body couplings and therefore may play a role in superconductivity. Such a singularity can cause an anisotropic variation in the coupling strength, which may partially explain the so-called nodal-antinodal dichotomy in the cuprates. Here we show that the topology of the graphene band structure at dopings comparable to the GICs is quite similar to that of the cuprates and that the quasiparticle dynamics in graphene have a similar dichotomy. Namely, the electron-phonon coupling is highly anisotropic, diverging near a saddle point in the graphene electronic band structure. These results support the important role of the VHS in layered materials and the possible optimization of Tc by tuning the VHS with respect to the Fermi level. ", "machine_text": "  We investigate a system consisting of a single layer graphene sheet with a perpendicular electric field applied, which has a non-zero gradient at the sheet's edge. In contrast to the bulk electric field, the edge field is shown to enhance the electron-phonon coupling in the graphene. The enhanced coupling induced by the edge field is found to have a strong temperature dependence, in contrast to the coupling in the bulk, which is weakly temperature dependent. We explain this difference by a detailed analysis of the mechanism of the electron-phonon coupling in the presence of the edge field. We show that the coupling in the bulk is governed by the standard Boltzmann transport equation, while the coupling in the vicinity of the edge is controlled by a boundary condition, which can be drastically altered by a small change of the edge field strength. We predict that a similar enhancement of the electron-phonon coupling can be achieved by a perpendicular magnetic field, which has a non-zero gradient at the sheet's edge. Our predictions can be tested by a number of recent experiments, which have already probed the interaction between electrons, phonons and an external magnetic field in single layer graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New Close Binary Systems from the SDSS-I (Data Release Five) and the\n  Search for Magnetic White Dwarfs in Cataclysmic Variable Progenitor Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0789, "human_text": "  We present the latest catalog of more than 1200 spectroscopically-selected close binary systems observed with the Sloan Digital Sky Survey through Data Release Five. We use the catalog to search for magnetic white dwarfs in cataclysmic variable progenitor systems. Given that approximately 25% of cataclysmic variables contain a magnetic white dwarf, and that our large sample of close binary systems should contain many progenitors of cataclysmic variables, it is quite surprising that we find only two potential magnetic white dwarfs in this sample. The candidate magnetic white dwarfs, if confirmed, would possess relatively low magnetic field strengths (B_WD < 10 MG) that are similar to those of intermediate-Polars but are much less than the average field strength of the current Polar population. Additional observations of these systems are required to definitively cast the white dwarfs as magnetic. Even if these two systems prove to be the first evidence of detached magnetic white dwarf + M dwarf binaries, there is still a large disparity between the properties of the presently known cataclysmic variable population and the presumed close binary progenitors. ", "machine_text": "  We present 22 new close binary systems observed with the SDSS-I (Data Release Five). These systems consist of 11 detached binaries, 5 semidetached binaries, and 6 white dwarfs with a close companion. We present basic properties such as the orbital period, the relative mass, and the orbital elements for these systems. We also present the photometry of the systems. In addition, we present our new catalog of 2,000 magnetic white dwarfs observed with the SDSS-I, and we determine the fraction of magnetic white dwarfs in close binary systems. We show that the fraction of magnetic white dwarfs in close binary systems is significantly higher than the fraction of magnetic white dwarfs in the general population of white dwarfs. We discuss this result in the framework of the evolution of close binary systems. We also present a comparison of the observed properties of magnetic white dwarfs in close binary systems with the properties of magnetic white dwarfs in the general population of white dwarfs. We show that magnetic white dwarfs in close binary systems tend to have lower magnetic field strengths, lower masses, and higher temperatures than magnetic white dwarfs in the general population. We discuss these results in the framework of the evolution of magnetic white dwarfs in close binary systems and the properties of the progenitor stars of these systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A High-Resolution Survey of Low-Redshift QSO Absorption Lines:\n  Statistics and Physical Conditions of O VI Absorbers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1214, "human_text": "  Using high-resolution UV spectra of 16 low-z QSOs, we study the physical conditions and statistics of O VI absorption in the IGM at z < 0.5. We identify 51 intervening (z_{abs} << z_{QSO}) O VI systems comprised of 77 individual components, and we find 14 \"proximate\" systems (z_{abs} ~ z_{QSO}) containing 34 components. For intervening systems [components] with rest-frame equivalent width W_{r} > 30 mA, the number of O VI absorbers per unit redshift dN/dz = 15.6(+2.9/-2.4) [21.0(+3.2/-2.8)], and this decreases to dN/dz = 0.9(+1.0/-0.5) [0.3(+0.7/-0.3)] for W_{r} > 300 mA. The number per redshift increases steeply as z_{abs} approaches z_{QSO}, and some proximate absorbers have substantially lower H I/O VI ratios. The lower proximate ratios could be partially due to ionization effects but also require higher metallicities. We find that 37% of the intervening O VI absorbers have velocity centroids that are well-aligned with corresponding H I absorption. If the O VI and the H I trace the same gas, the relatively small differences in line widths imply the absorbers are cool with T < 10^{5} K. Most of these well-aligned absorbers have the characteristics of metal-enriched photoionized gas. However, the O VI in the apparently simple and cold systems could be associated with a hot phase with T ~ 10^{5.5} K if the metallicity is high enough to cause the associated broad Ly alpha absorption to be too weak to detect. We show that 53% of the intervening O VI systems are complex multiphase absorbers that can accommodate both lower metallicity collisionally-ionized gas with T > 10^{5} K and cold photoionzed gas. ", "machine_text": "  We present a high-resolution survey of low-redshift (z < 1) QSO absorption lines in the O VI band, with the goal of studying the physical conditions and statistics of O VI absorbers. We use the Millennium N-Body simulation to generate synthetic absorption lines at low resolution, which we then upscale to a high resolution of $\\sim 1000$ lines per galaxy. We compare the simulated absorption lines to the observed ones, and use the results to set limits on the strength of O VI absorption and the fraction of the intergalactic medium (IGM) that is absorbing. We find that the distribution of absorption lines is in good agreement with the predictions of the N-body simulation, and use this to set limits on the mean strength of O VI absorption in the IGM. We show that the fraction of the IGM that is absorbing is, on average, smaller than the fraction that is transmitting. We also study the physical conditions of the absorbers by modeling the O VI absorption lines with a simple collisional model. We find that the temperature and density of the IGM are in good agreement with previous results based on observations of the H I and CO lines. We also discuss the effect of dust on the O VI absorption lines, and find that it has a significant effect only for lines of sight (LOS) close to galaxies. Our results suggest that the O VI band is probably the best probe of the physical conditions in the IGM at low redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Evolution of Protoplanetary Disks Around Millisecond Pulsars: The\n  PSR 1257 +12 System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3063, "human_text": "  We model the evolution of protoplanetary disks surrounding millisecond pulsars, using PSR 1257+12 as a test case. Initial conditions were chosen to correspond to initial angular momenta expected for supernova-fallback disks and disks formed from the tidal disruption of a companion star. Models were run under two models for the viscous evolution of disks: fully viscous and layered accretion disk models. Supernova-fallback disks result in a distribution of solids confined to within 1-2 AU and produce the requisite material to form the three known planets surrounding PSR 1257+12. Tidal disruption disks tend to slightly underproduce solids interior to 1 AU, required for forming the pulsar planets, while overproducing the amount of solids where no body, lunar mass or greater, exists. Disks evolving under 'layered' accretion spread somewhat less and deposit a higher column density of solids into the disk. In all cases, circumpulsar gas dissipates on $\\lesssim 10^{5}$ year timescales, making formation of gas giant planets highly unlikely. ", "machine_text": "  We present phase-resolved optical and near-infrared observations of the protoplanetary disk in the PSR 1257 +12 system. We find that the disk is characterized by a ring-like structure with a peak surface density of 1.7 \u00d7 10 \u22123 M \u22c5 yr \u22121 located at  \u223c 70 RJ, which is more than 150 pc from the millisecond pulsar. The disk has a relatively high surface density compared to those found in Galactic disks, possibly as a result of the efficient accretion of gas and dust by the central star. The disk is radiating at a rate of  \u223c 7.2 R \u22c5 yr \u22121 , which corresponds to a gas temperature of  \u223c 170 K. We estimate the disk's lifetime to be  \u223c 200 Myr, which is similar to the lifetime of disks in the Galactic disk population. We also present a detailed analysis of the disk's chemical composition. We find that the disk has a higher abundance of carbon relative to hydrogen and a lower oxygen abundance compared to the solar neighborhood. Our results suggest that the disk formed in a molecular cloud with a higher molecular fraction and a lower atomic fraction compared to the Galactic disk population. We discuss our results in the context of disk evolution and compare our findings to other disks observed in low-mass star-forming regions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Poisson approximation for non-backtracking random walks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0867, "human_text": "  Random walks on expander graphs were thoroughly studied, with the important motivation that, under some natural conditions, these walks mix quickly and provide an efficient method of sampling the vertices of a graph. Alon, Benjamini, Lubetzky and Sodin studied non-backtracking random walks on regular graphs, and showed that their mixing rate may be up to twice as fast as that of the simple random walk. As an application, they showed that the maximal number of visits to a vertex, made by a non-backtracking random walk of length $n$ on a high-girth $n$-vertex regular expander, is typically $(1+o(1))\\frac{\\log n}{\\log\\log n}$, as in the case of the balls and bins experiment. They further asked whether one can establish the precise distribution of the visits such a walk makes.   In this work, we answer the above question by combining a generalized form of Brun's sieve with some extensions of the ideas in Alon et al. Let $N_t$ denote the number of vertices visited precisely $t$ times by a non-backtracking random walk of length $n$ on a regular $n$-vertex expander of fixed degree and girth $g$. We prove that if $g=\\omega(1)$, then for any fixed $t$, $N_t/n$ is typically $\\frac{1}{\\mathrm{e}t!}+o(1)$. Furthermore, if $g=\\Omega(\\log\\log n)$, then $N_t/n$ is typically $\\frac{1+o(1)}{\\mathrm{e}t!}$ uniformly on all $t \\leq (1-o(1))\\frac{\\log n}{\\log\\log n}$ and 0 for all $t \\geq (1+o(1))\\frac{\\log n}{\\log\\log n}$. In particular, we obtain the above result on the typical maximal number of visits to a single vertex, with an improved threshold window. The essence of the proof lies in showing that variables counting the number of visits to a set of sufficiently distant vertices are asymptotically independent Poisson variables. ", "machine_text": "  We consider a simple model of random walks in which the step-size is allowed to be non-uniform. We show that such random walks can have a variety of behaviours, some of which are not captured by the standard Boltzmann\u2013Gibbs\u2013Shannon framework. In particular, such walks can have non-backtracking trajectories even in the thermodynamic limit. We show that this is because the random walk can have correlations on higher-level structures (i.e., correlations between the walk's global features), in addition to the local correlations between the steps of the walk. We also show that the occurrence of such higher-level correlations depends on the details of the step-size distribution. We consider different possible forms for the step-size distribution and find that a heavy-tailed form of distribution gives rise to a walk which is strongly non-backtracking, even in the presence of a large number of steps. Our results show that the traditional Boltzmann\u2013Gibbs\u2013Shannon framework needs to be extended in order to describe random walks with non-uniform step-size.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radion Phenomenology in Realistic Warped Space Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3844, "human_text": "  We investigate the phenomenology of the Randall-Sundrum radion in realistic models of electroweak symmetry breaking with bulk gauge and fermion fields, since the radion may turn out to be the lightest particle in such models. We calculate the coupling of the radion in such scenarios to bulk fermion and gauge modes. Special attention needs to be devoted to the coupling to massless gauge fields (photon, gluon), since it is well known that loop effects may be important for these fields. We also present a detailed explanation of these couplings from the CFT interpretation. We then use these couplings to determine the radion branching fractions and discuss some of the discovery potential of the LHC for the radion. We find that the gamma-gamma signal is enhanced over most of the range of the radion mass over the gamma-gamma signal of a SM Higgs, as long as the RS scale is sufficiently low. However, the signal significance depends strongly on free parameters that characterize the magnitude of bare brane-localized kinetic terms for the massless gauge fields. In the absence of such terms, the signal can be be enhanced over the traditional RS1 models (where all standard model fields are localized on the IR brane), but the signal can also be reduced compared to RS1 if the brane localized terms are sizeable. We also show that for larger radion masses, where the gamma-gamma signal is no longer significant, one can use the usual 4 lepton signal to discover the radion. ", "machine_text": "  Radion phenomenology in realistic warped space models  We propose a general framework for radion phenomenology in realistic warped space models. We demonstrate that radion emission in realistic warped space models is fundamentally different from that in flat space, and that this difference is captured by a geometrically induced distortion of the classical luminance-based radion metric. This distortion is a general feature of realistic warped space models, and is not related to any particular theory of gravity. As an application, we analyze a model of radion emission from a black hole in a spatially warped background, and show that this model can be used to test the no-hair theorem in a realistic warped space setting.  We consider the radion emission from a point source in a warped space. We find that the radiation intensity measured by an observer in a distant flat space is related to the radion intensity in the source's rest frame by a factor that depends on the source's distance from the spatial warping boundary, and on the angle between the observer's and the source's respective rest frames. The factor can be arbitrarily large or small. We show that this effect is due to a geometrically induced distortion of the radion metric in realistic warped space models.  We analyze a simple model of radion emission from a black hole in a spatially warped background. The model consists of a black hole with a radion spectrum that is affected by the warped space in which it is embedded. We find that the resulting radion emission from the black hole can be used to test the no-hair theorem in a realistic warped space setting.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 8.4GHz VLBI observations of SN2004et in NGC6946. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3853, "human_text": "  We report on 8.4GHz Very Long Baseline Interferometry (VLBI) observations of the type II-P supernova SN2004et in the spiral galaxy NGC 6946, made on 20 February 2005 (151 days after explosion). The Very Large Array (VLA) flux density was 1.23$\\pm$0.07 mJy, corresponding to an isotropic luminosity at 8.4GHz of (4.45$\\pm$0.3)$\\times10^{25}$ erg s$^{-1}$ Hz$^{-1}$ and a brightness temperature of (1.3$\\pm$0.3)$\\times10^{8}$ K. We also provide an improved source position, accurate to about 0.5 mas in each coordinate. The VLBI image shows a clear asymmetry. From model fitting of the size of the radio emission, we estimate a minimum expansion velocity of 15,700$\\pm$2,000 km s$^{-1}$. This velocity is more than twice the expected mean expansion velocity estimated from a synchrotron self-absorbed emission model, thus suggesting that synchrotron self-absorption is not relevant for this supernova. With the benefit of an optical spectrum obtained 12 days after explosion, we favor an emission model which consists of two hot spots on an underlying expanding shell of width comparable to that of SN 1993J. ", "machine_text": "  We present 8.4 GHz VLBI observations of SN 2004et in NGC 6946. These data were obtained with the VLBA and EVLA in the hope of detecting a supernova in the very earliest stages of evolution. The supernova was discovered at an optical magnitude of 17.2, four days after the explosion. The VLBI observations were made three days after the discovery, when the optical magnitude was 9.9. The source was clearly detected in both the VLBA and EVLA data, but the images are heavily affected by RFI. The supernova is resolved in the VLBA data, but the EVLA image is too contaminated by RFI to be useful. We find that the supernova has a brightness temperature of about 5 keV, corresponding to an energy release of 4 x 10^36 erg s^-1. The brightness temperature is almost constant on a timescale of hours, but the supernova is evolving on a timescale of days. We find that the supernova is likely to be a member of the TN 1991ea-like class of supernovae. The lack of a well-defined point source in the EVLA data is consistent with the supernova being surrounded by a shell of expanding material, as has been observed in several other TN 1991ea-like supernoves at later times.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Star-Formation in Low Radio Luminosity AGN from the Sloan Digital Sky\n  Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2074, "human_text": "  We investigate faint radio emission from low- to high-luminosity Active Galactic Nuclei (AGN) selected from the Sloan Digital Sky Survey (SDSS). Their radio properties are inferred by co-adding large ensembles of radio image cut-outs from the FIRST survey, as almost all of the sources are individually undetected. We correlate the median radio flux densities against a range of other sample properties, including median values for redshift, [OIII] luminosity, emission line ratios, and the strength of the 4000A break. We detect a strong trend for sources that are actively undergoing star-formation to have excess radio emission beyond the ~10^28 ergs/s/Hz level found for sources without any discernible star-formation. Furthermore, this additional radio emission correlates well with the strength of the 4000A break in the optical spectrum, and may be used to assess the age of the star-forming component. We examine two subsamples, one containing the systems with emission line ratios most like star-forming systems, and one with the sources that have characteristic AGN ratios. This division also separates the mechanism responsible for the radio emission (star-formation vs. AGN). For both cases we find a strong, almost identical, correlation between [OIII] and radio luminosity, with the AGN sample extending toward lower, and the star-formation sample toward higher luminosities. A clearer separation between the two subsamples is seen as function of the central velocity dispersion of the host galaxy. For systems with similar redshifts and velocity dispersions, the star-formation subsample is brighter than the AGN in the radio by an order of magnitude. This underlines the notion that the radio emission in star-forming systems can dominate the emission associated with the AGN. ", "machine_text": "  We present a study of star formation in low radio luminosity active galactic nuclei (AGN) from the SDSS. We find a strong correlation between radio and far-infrared luminosity, but no such correlation with optical or ultraviolet luminosity. We also find a correlation between radio and far-infrared luminosity and the star formation rate (SFR), but no such correlation for the optical/ultraviolet SFR. These results suggest that the star formation in these galaxies is fueled by the AGN. We find a significant correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with known redshift, but no correlation for galaxies with unknown redshift. We find that the galaxies with known redshift tend to be at higher redshift. This could be because the correlation between radio/far-infrared and optical/ultraviolet SFR is a purely cosmic phenomenon, and the higher redshift galaxies are simply closer to this correlation. We present a simple model in which star formation in these galaxies is fueled by the AGN, and find that this model can explain the correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with known redshift. We discuss several other possible physical mechanisms that could explain the correlation between radio/far-infrared and optical/ultraviolet SFR for galaxies with unknown redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: ARCRAIDER I: Detailed optical and X-ray analysis of the cooling flow\n  cluster Z3146. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4053, "human_text": "  We present a detailed analysis of the medium redshift (z=0.2906) galaxy cluster Z3146 which is part of the ongoing ARCRAIDER project, a systematic search for gravitational arcs in massive clusters of galaxies. The analysis of Z3146 is based on deep optical wide field observations in the B, V and R bands obtained with the WFI@ESO2.2m, and shallow archival WFPC2@HST taken with the F606W filter, which are used for strong as well as weak lensing analyses. Additionally we have used publicly available XMM/Newton observations for a detailed X-ray analysis of Z3146. Both methods, lensing and X-ray, were used to determine the dynamical state and to estimate the total mass. We also identified four gravitational arc candidates. We find this cluster to be in a relaxed state, which is confirmed by a large cooling flow with nominal ~1600M_\\odot per year, regular galaxy density and light distributions and a regular shape of the weak lensing mass reconstruction. The mass content derived with the different methods agrees well within 25% at r_{200}=1661 h_{70}^{-1}kpc indicating a velocity dispersion of \\sigma_v=869^{+124}_{-153}km/s. ", "machine_text": "  We present an analysis of the optical and X-ray properties of the cooling flow cluster Z3146. We find that the cluster contains a large number of cool detached clumps, and that the clumps and the intracluster medium can be distinguished on the basis of their X-ray temperatures. We estimate the temperatures of the intracluster gas and the detached clumps, and find that they differ by about 2.5 kK. We argue that the cool detached clumps have been formed through the collapse of large voids, and that the intracluster gas has been compressed by the infall of these clumps. We find that the surface brightness of the cluster is not uniform, but has a correlation with the local X-ray temperature. We interpret this correlation in terms of the contribution of the detached clumps to the total surface brightness. We find that the cool detached clumps have a mean mass of 4.3 kM\u22c5 pc\u22122, and that they are responsible for 17% of the total surface brightness. The highest surface brightness is found in the regions with the highest X-ray temperature, where the contribution from detached clumps is small. We conclude that the intracluster gas is responsible for the bulk of the cluster's surface brightness, while the detached clumps give rise to the peaks and the high surface brightness in the outskirts of the cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chi2 and chi3 harmonic generation at a critical power in inhomogeneous\n  doubly resonant cavities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3652, "human_text": "  We derive general conditions for 100 percent frequency conversion in any doubly resonant nonlinear cavity, for both second- and third-harmonic generation via chi2 and chi3 nonlinearities. We find that conversion efficiency is optimized for a certain critical power depending on the cavity parameters, and assuming reasonable parameters we predict 100 percent conversion using milliwatts of power or less. These results follow from a semi-analytical coupled-mode theory framework which is generalized from previous work to include both chi2 and chi3 media as well as inhomogeneous (fully vectorial) cavities, analyzed in the high-efficiency limit where down-conversion processes lead to a maximum efficiency at the critical power, and which is verified by direct finite-difference time-domain (FDTD) simulations of the nonlinear Maxwell equations. Explicit formulas for the nonlinear coupling coefficients are derived in terms of the linear cavity eigenmodes, which can be used to design and evaluate cavities in arbitrary geometries. ", "machine_text": "  We consider the formation of harmonics in a cavity where an initially homogeneous distribution of standing waves is disrupted by a thin absorbing layer. We show that a critical power exists above which a transition takes place to a state in which the waves are perfectly uniform. Below this critical power, the number of non-zero harmonics is infinite. In this state, the least number of harmonics is given by the well-known expression for the case of a homogeneously filled cavity. The transition is related to a change in the spatial profile of the standing waves, in particular to a singularity that appears in the bulk of the medium. We show that such a transition is generic for any finite perturbation of the homogenous state, and can be understood from the zero-order approximation to the slowly-varying envelope approximation. We analyze the distribution of the harmonics in the transient regime, and show that the formation of the harmonic spectrum is governed by a simple probabilistic argument. We also discuss the case of a gradually-varying perturbation, and show that the distribution of harmonics in this case is given by a superposition of the harmonics associated with the two extreme cases.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observation of Electron-Hole Puddles in Graphene Using a Scanning Single\n  Electron Transistor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.218, "human_text": "  The electronic density of states of graphene is equivalent to that of relativistic electrons. In the absence of disorder or external doping the Fermi energy lies at the Dirac point where the density of states vanishes. Although transport measurements at high carrier densities indicate rather high mobilities, many questions pertaining to disorder remain unanswered. In particular, it has been argued theoretically, that when the average carrier density is zero, the inescapable presence of disorder will lead to electron and hole puddles with equal probability. In this work, we use a scanning single electron transistor to image the carrier density landscape of graphene in the vicinity of the neutrality point. Our results clearly show the electron-hole puddles expected theoretically. In addition, our measurement technique enables to determine locally the density of states in graphene. In contrast to previously studied massive two dimensional electron systems, the kinetic contribution to the density of states accounts quantitatively for the measured signal. Our results suggests that exchange and correlation effects are either weak or have canceling contributions. ", "machine_text": "  We report a scanning tunneling microscopy-based device in which a scanning single-electron transistor is used to detect the formation of electron-hole puddles in monolayer graphene on a dielectric substrate. When a conducting tip is scanned close to the surface, the number of electrons in the puddle is found to increase in a spatially-dependent fashion, in agreement with theoretical predictions. Our results suggest that the spatial variations in the puddle density can be used to image local variations in the density of surface states. We show that the spatial profile of the puddle is sensitive to the position of the tip with respect to the graphene sheet, the tip-sample distance, and the bias voltage applied between the tip and graphene. We also show that the number of electrons in the puddle is sensitive to the density of states and to the applied bias voltage. Our results demonstrate that the scanning single-electron transistor can be used as a powerful tool for the study of nanoscale charge transport in graphene.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fundamental Parameters of He-Weak and He-Strong Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0541, "human_text": "  We carried out low resolution spectroscopic observations in the wavelength range 3400-4700 A of 20 He-weak and 8 He-strong stars to determine their fundamental parameters by means of the Divan-Chalonge-Barbier (BCD) spectrophotometric system. For a few He-weak stars we also estimate the effective temperatures and the angular diameters by integrating absolute fluxes observed over a wide spectral range. Non-LTE model calculations are carried out to study the influence of the He/H abundance ratio on the emergent radiation of He-strong stars and on their Teff determination. We find that the effective temperatures, surface gravities and bolometric absolute magnitudes of He-weak stars estimated with the BCD system and the integrated flux method are in good agreement between each other, and they also agree with previous determinations based on several different methods. The mean discrepancy between the visual absolute magnitudes derived using the Hipparcos parallaxes and the BCD values is on average 0.3 mag for He-weak stars, while it is 0.5 mag for He-strong stars. For He-strong stars, we note that the BCD calibration, based on stars in the solar environment, leads to overestimated values of Teff. By means of model atmosphere calculations with enhanced He/H abundance ratios we show that larger He/H ratios produce smaller BD which naturally explains the Teff overestimation. We take advantage of these calculations to introduce a method to estimate the He/H abundance ratio in He-strong stars. The BD of HD 37479 suggests that the Teff of this star remains fairly constant as the star spectrum undergoes changes in the intensity of H and He absorption lines. Data for the He-strong star HD 66765 are reported for the first time. ", "machine_text": "  We have carried out a systematic study of the fundamental parameters of both He-weak and He-strong stars. Our aim has been to identify and study the different evolutionary channels of these stars, in particular the transition between the main sequence and the first evolved phase, as well as to determine the main physical properties of the various types of these stars. We have found that a correlation exists between the fundamental parameters of these stars, in particular between the stellar mass and the helium abundance. Our results also suggest that a direct measurement of the helium abundance is not possible without an accurate knowledge of the effective temperature and the stellar mass. As an application of our method we have derived an empirical relation between the helium abundance and the other fundamental parameters. We have also found that the fundamental parameters of these stars are well described by a simple stellar model in which the evolution of the star is driven by its own radiative properties and that of a simple geometric model in which the expansion of the star is described by a perfect gas equation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The habitability of super-Earths in Gliese 581. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3758, "human_text": "  Aims: The planetary system around the M star Gliese 581 consists of a hot Neptune (Gl 581b) and two super-Earths (Gl 581c and Gl 581d). The habitability of this system with respect to the super-Earths is investigated following a concept that studies the long-term possibility of photosynthetic biomass production on a dynamically active planet. Methods: A thermal evolution model for a super-Earth is used to calculate the sources and sinks of atmospheric carbon dioxide. The habitable zone is determined by the limits of biological productivity on the planetary surface. Models with different ratios of land / ocean coverage are investigated. Results: The super-Earth Gl 581c is clearly outside the habitable zone, since it is too close to the star. In contrast, Gl 581d is a tidally locked habitable super-Earth near the outer edge of the habitable zone. Despite the adverse conditions on this planet, at least some primitive forms of life may be able to exist on its surface.Therefore, Gl 581d is an interesting target for the planned TPF/Darwin missions to search for biomarkers in planetary atmospheres. ", "machine_text": "  We investigate the habitability of super-Earths in Gliese 581. The Gliese 581 system is composed of three planets and one star. The inner most planet, Gliese 581e, is a super-Earth with a mass between Earth and Neptune. It is located in the star's habitable zone, where liquid water can exist on the planet's surface. We evaluate the habitability of Gliese 581e, and address the question of whether it is habitable. The super-Earth has a mass large enough to hold a thick atmosphere. Its mass is also large enough so that it is not tidally locked with its host star, which means that the same side of the planet always faces the star (in the same way that the same side of the Moon is always visible from Earth). We estimate the energy needed to heat the super-Earth's atmosphere to be in the range of 10^32 to 10^33 W, which is only a factor of a few larger than the solar flux it receives. We also estimate the emissivity of the super-Earth to be low, so that it can retain its atmosphere. We find that a super-Earth with a thick atmosphere, like the one in the Gliese 581 system, can be habitable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Control of mechanical systems on Lie groups and ideal hydrodynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2886, "human_text": "  In contrast to the Euler-Poincar{\\'e} reduction of geodesic flows of left- or right-invariant metrics on Lie groups to the corresponding Lie algebra (or its dual), one can consider the reduction of the geodesic flows to the group itself. The reduced vector field has a remarkable hydrodynamic interpretation: it is a velocity field for a stationary flow of an ideal fluid. Right- or left-invariant symmetry fields of the reduced field define vortex manifolds for such flows.   Consider now a mechanical system, whose configuration space is a Lie group and whose Lagrangian is invariant to left translations on that group, and assume that the mass geometry of the system may change under the action of internal control forces. Such system can also be reduced to the Lie group. With no controls, this mechanical system describes a geodesic flow of the left-invariant metric, given by the Lagrangian, and thus its reduced flow is a stationary ideal fluid flow on the Lie group. The standard control problem for such system is to find the conditions, under which the system can be brought from any initial position in the configuration space to another preassigned position by changing its mass geometry. We show that under these conditions, by changing the mass geometry, one can also bring one vortex manifold to any other preassigned vortex manifold. ", "machine_text": "  We consider the question of controlling mechanical systems on Lie groups, focusing on the case of ideal hydrodynamics. We show that the traditional control methods of ideal hydrodynamics on the basis of the maximum principles can be naturally formulated on the space of symmetry groups. We propose a generalization of the standard control methods to the case of multi-parametric systems, when the system is represented in the symmetrical space by a linear combination of the elements of the symmetry group. Within this approach, the control problem is reduced to the optimization of a certain functional, which has the properties of a quadratic form. The optimization problem is shown to be equivalent to the solution of a certain partial differential equation. We analyze the properties of this equation and solve it analytically in the case of 2-parametric systems. We also discuss the question of the existence of a solution for the control problem and propose an algorithm for its numerical solution in the case of multi-parametric systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generalized Twistor Transform And Dualities, With A New Description of\n  Particles With Spin, Beyond Free and Massless. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0296, "human_text": "  A generalized twistor transform for spinning particles in 3+1 dimensions is constructed that beautifully unifies many types of spinning systems by mapping them to the same twistor, thus predicting an infinite set of duality relations among spinning systems with different Hamiltonians. Usual 1T-physics is not equipped to explain the duality relationships and unification between these systems. We use 2T-physics in 4+2 dimensions to uncover new properties of twistors, and expect that our approach will prove to be useful for practical applications as well as for a deeper understanding of fundamental physics. Unexpected structures for a new description of spinning particles emerge. A unifying symmetry SU(2,3) that includes conformal symmetry SU(2,2)=SO(4,2) in the massless case, turns out to be a fundamental property underlying the dualities of a large set of spinning systems, including those that occur in high spin theories. This may lead to new forms of string theory backgrounds as well as to new methods for studying various corners of M theory. In this paper we present the main concepts, and in a companion paper we give other details. ", "machine_text": "  We propose a new formalism for a generalized torsor transform and an associated twisted doubled duality, with a new description of particles with spin, beyond free and massless. The new formulation is based on a formalism of 2-spinsorps and 2-spinors in the 3-dimensional Euclidean space. We show that the 3-spinors can be regarded as a particular case of 2-spinors. In particular, we show that, in the new formalism, the 3-spinors can be obtained from the 2-spinors by an affine transformation. We show that the formalism of 2-spinors can be further generalized to the 4-dimensional Euclidean space. As an application, we propose a new description of the relativistic particles with spin, beyond the free and massless case. We show that our new description of the relativistic particles with spin can be obtained from the Dirac equation by a formalism of constrained 2-spinors. We show that our new description of the relativistic particles with spin can be further obtained from the constrained 2-spinors by an affine transformation. We show that the Dirac equation can be regarded as a particular case of a constrained 2-spinor equation. We show that the constrained 2-spinor equation can be further generalized to the 4-dimensional Euclidean space. We show that the constrained 2-spinor equation can be obtained from the 3-spinorps by a formalism of constrained 3-spinors. We show that the constrained 3-spinors can be further obtained from the 3-spinors by an affine transformation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multiple Parton Scattering in Nuclei: Quark-quark Scattering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0106, "human_text": "  Modifications to quark and antiquark fragmentation functions due to quark-quark (antiquark) double scattering in nuclear medium are studied systematically up to order \\cal{O}(\\alpha_{s}^2)$ in deeply inelastic scattering (DIS) off nuclear targets. At the order $\\cal{O}(\\alpha_s^2)$, twist-four contributions from quark-quark (antiquark) rescattering also exhibit the Landau-Pomeranchuck-Midgal (LPM) interference feature similar to gluon bremsstrahlung induced by multiple parton scattering. Compared to quark-gluon scattering, the modification, which is dominated by $t$-channel quark-quark (antiquark) scattering, is only smaller by a factor of $C_F/C_A=4/9$ times the ratio of quark and gluon distributions in the medium. Such a modification is not negligible for realistic kinematics and finite medium size. The modifications to quark (antiquark) fragmentation functions from quark-antiquark annihilation processes are shown to be determined by the antiquark (quark) distribution density in the medium. The asymmetry in quark and antiquark distributions in nuclei will lead to different modifications of quark and antiquark fragmentation functions inside a nucleus, which qualitatively explains the experimentally observed flavor dependence of the leading hadron suppression in semi-inclusive DIS off nuclear targets. The quark-antiquark annihilation processes also mix quark and gluon fragmentation functions in the large fractional momentum region, leading to a flavor dependence of jet quenching in heavy-ion collisions. ", "machine_text": " Multiple Parton Scattering in Nuclei: Quark-quark Scattering We study the multiple parton scattering (MPS) in nuclei within the framework of the quark-quark scattering (Q2SCAT) model. The Q2SCAT model has been developed to study the hardest quantum chromodynamics (QCD) processes in nuclei and it is based on the combination of the quark-meson coupling constant (CM) and the quark- antiquark coupling constant (CA). In this work we investigate the effects of the relevant structure functions (SFs) of the fundamental building blocks of nuclei, the nucleons, on the description of the MPS in nuclei. For this purpose, we consider the simple case of a nucleus composed of two identical nucleons, i.e. the deuteron, and study the effects of the two relevant SFs of the nucleons, namely the total cross section (CT) and the coherent cross section (CC), on the description of the MPS in the deuteron. In particular, we find that the inclusion of the CT and CC in the Q2SCAT model significantly improves the description of the MPS in the deuteron, since it allows to properly describe the underlying quark-quark degrees of freedom and their associated complex dynamics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological Shock Waves in the Large Scale Structure of the Universe:\n  Non-gravitational Effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1521, "human_text": "  Cosmological shock waves result from supersonic flow motions induced by hierarchical clustering of nonlinear structures in the universe. These shocks govern the nature of cosmic plasma through thermalization of gas and acceleration of nonthermal, cosmic-ray (CR) particles. We study the statistics and energetics of shocks formed in cosmological simulations of a concordance $\\Lambda$CDM universe, with a special emphasis on the effects of non-gravitational processes such as radiative cooling, photoionization/heating, and galactic superwind feedbacks. Adopting an improved model for gas thermalization and CR acceleration efficiencies based on nonlinear diffusive shock acceleration calculations, we then estimate the gas thermal energy and the CR energy dissipated at shocks through the history of the universe. Since shocks can serve as sites for generation of vorticity, we also examine the vorticity that should have been generated mostly at curved shocks in cosmological simulations. We find that the dynamics and energetics of shocks are governed primarily by the gravity of matter, so other non-gravitational processes do not affect significantly the global energy dissipation and vorticity generation at cosmological shocks. Our results reinforce scenarios in which the intracluster medium and warm-hot intergalactic medium contain energetically significant populations of nonthermal particles and turbulent flow motions. ", "machine_text": " We study the effects of non-gravitational forces on large scale structure in a homogeneous and isotropic cosmology with a variable equation of state (EOS) parameter \u03c9(a). In particular we consider a model in which the EOS parameter \u03c9(a) is given by the gradient of a smooth function that varies very slowly as a function of a, with a sharp transition at a \u2248 0.4. This model is used to investigate the effects of non-gravitational forces on the large scale structure of the Universe. We find that the density field is well described by a Gaussian kernel with a scale of the order of the transition scale a \u2248 0.4, in agreement with the scale expected from the theory of gravitational instability. The power law index of the density field is found to be in good agreement with the index expected from gravitational instability, and in disagreement with the index expected from the shock wave theory. The contribution of non-gravitational forces to the large scale structure is found to be small and its signature is mostly washed out by the gravitational forces. We conclude that non-gravitational forces do not significantly affect the large scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Signatures of Heavy Z-prime in the Extra U(1) Superstring Inspired\n  Model: RGEs Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2532, "human_text": "  In the extra U(1) superstring inspired model, we examine the electroweak and U(1)-prime symmetry breaking with the singlet and exotic quark D, D+{\\c}along with the study of heavy Z-prime boson in accordance with the top quark mass region. For this, we have done the analysis of complete renormalization group equations (RGEs)pertaining to the anomaly free E-{\\6}-Eta model of rank 5. The Z-prime is found to the order of TeV or above with allowed small Z-Zprime mixing angle, for which the large singlet VEV is required. This is done by considering the only non-universality of Yukawa couplings at GUT scale because these do not obey the E-{\\6}relationship and also satisfies the unitarity constraints both at GUT and weak scale, where rest of the parameters, i.e., gaugino masses, tri-linear couplings, and soft supersymmetric breaking masses are kept universal at GUT scale with the gauge couplings unification. The large value of Yukawa couplings (order of 1) triggered the symmetry breaking radiatively and induces the effective-Mu parameter at the electroweak scale and lead to a viable low energy spectrum at weak scale. ", "machine_text": " We study the signatures of heavy Z-prime in the extra U(1) superstring inspired model (EUM) and find that they are consistent with the heavy Z-prime scenario in the framework of the EUM. This conclusion is drawn from a careful analysis of the RGEs (root generating functions) associated with the EUM. This analysis shows that the EUM can produce a universal RGE that is consistent with the heavy Z-prime scenario and its spawned chiral superfields. This RGE is in the form of an infinite dimensional cup product that shows a strong non-trivial correlation function in its leading term. The construction and the analysis of the RGEs associated with the EUM is a non-trivial task, which is different from the analysis of the RGEs in the framework of the minimal U(1) extension of the EUM. As an application, we give a simple description of the RGEs associated with the EUM in the case when the EUM has a minimal U(1) extension. This description allows one to understand the RGEs of the EUM in the minimal U(1) extension in the sense that the RGEs of the EUM in its minimal U(1) extension are \" eld theoretic generalizations \" of the RGEs associated with the EUM itself.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SNO+: predictions from standard solar models and spin flavour precession. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.407, "human_text": "  Time variability of the solar neutrino flux especially in the low and intermediate energy sector remains an open question and, if it exists, it is likely to be originated from the magnetic moment transition from active to light sterile neutrinos at times of intense solar activity and magnetic field. We examine the prospects for the SNO+ experiment to address this important issue and to distinguish between the two classes of solar models which are currently identified as corresponding to a high (SSM I) and a low (SSM II) heavy element abundance. We also evaluate the predictions from these two models for the Chlorine experiment event rate in the standard LMA and LMA+Spin Flavour Precession (SFP) scenarios. It is found that after three years of SNO+ data taking, the pep flux measurement will be able to discriminate between the standard LMA and LMA+SFP scenarios, independently of which is the correct solar model. If the LMA rate is measured, SFP with $B_0 \\sim 280kG$ for the resonant $\\Delta m^2_{01}$ can be excluded at more than $4\\sigma$. A low rate would signal new physics, excluding all the 90% allowed range of the standard LMA solution at 3$\\sigma$, and a time variability would be a strong signature of the SFP model. The CNO fluxes are the ones for which the two SSM predictions exhibit the largest differences, so their measurement at SNO+ will be important to favour one or the other. The distinction will be clearer after LMA or SFP are confirmed with pep, but still, a CNO measurement at the level of SSM I/LMA will disfavour SSM II at about $3 \\sigma$. We conclude that consistency between future pep and CNO flux measurements at SNO+ and Chlorine would either favour an LMA+SFP scenario or favour SSM II over SSM I. ", "machine_text": "  We present predictions, derived from standard solar models, for the properties of the solar neutrino flux expected from the SNO+ experiment. We consider the full range of physical possibilities for the solar model, including those which are not compatible with a standard atmospheric model. We show that the standard solar model predicts a neutrino flux that is consistent with the current SNO result, but is inconsistent with the SNO+ result in a pure geo-charAtron source. We then consider a non-standard solar model in which the partisan flux from geo-charAtron and from a stellar companion are comparable. We show that such a model can produce a neutrino flux that is consistent with both the SNO and SNO+ results, if the spin-flavor precession of the neutrinos is small compared to the Earth's orbital precession. We estimate the necessary precession to be $\\sim 10^{-25}$, which is small compared to the $\\sim 10^{8}$ precession that the Earth's orbit undergoes in one year, but is not strictly forbidden by the standard solar model. We show that this non-standard model can also explain the \"OVERFLOW\" and \"UNDiagnostics\" signals in the SNO data, which remain unexplained in the standard model. We also consider a model in which the solar mass is reduced, while keeping the baryonic mass fixed, and show that such a model can produce a neutrino flux consistent with the SNO+ result, if the flavor-spin precession is large enough. We discuss the implications of our results for future solar neutrino experiments, for the solar model, and for the origin of the solar neutrino flux.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Production of a sterile species: quantum kinetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0703, "human_text": "  Production of a sterile species is studied within an effective model of active-sterile neutrino mixing in a medium in thermal equilibrium. The quantum kinetic equations for the distribution functions and coherences are obtained from two independent methods: the effective action and the quantum master equation. The decoherence time scale for active-sterile oscillations is $\\tau_{dec} = 2/\\Gamma_{aa}$, but the evolution of the distribution functions is determined by the two different time scales associated with the damping rates of the quasiparticle modes in the medium: $\\Gamma_1=\\Gamma_{aa}\\cos^2\\tm ; \\Gamma_2=\\Gamma_{aa}\\sin^2\\tm$ where $\\Gamma_{aa}$ is the interaction rate of the active species in absence of mixing and $\\tm$ the mixing angle in the medium. These two time scales are widely different away from MSW resonances and preclude the kinetic description of active-sterile production in terms of a simple rate equation. We give the complete set of quantum kinetic equations for the active and sterile populations and coherences and discuss in detail the various approximations. A generalization of the active-sterile transition probability \\emph{in a medium} is provided via the quantum master equation. We derive explicitly the usual quantum kinetic equations in terms of the ``polarization vector'' and show their equivalence to those obtained from the quantum master equation and effective action. ", "machine_text": "  We investigate the quantum kinetics of a system which has the capability of producing a sterile species. We develop a general approach which treats the dynamics of the system as a whole, and take into account the correlations between the various degrees of freedom in the system. This approach is based on the idea that the total number of photons in the system is conserved. We show that such a general approach is equivalent to a set of independent, uncorrelated degree of freedom models, each of which describes the dynamics of the corresponding degree of freedom in the system. The independent models are solved and the solution to the general model is obtained by taking the sum of the solutions to the independent models. The special case of a system with two degrees of freedom is solved analytically, and the solution is used to obtain a general formula for the stationary distribution of the total number of photons in the system. We also discuss the general properties of the solution to the full model, and show how the general solution can be used to derive the stationary distribution for a wide class of input functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dimer Models, Free Fermions and Super Quantum Mechanics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1645, "human_text": "  This note relates topics in statistical mechanics, graph theory and combinatorics, lattice quantum field theory, super quantum mechanics and string theory. We give a precise relation between the dimer model on a graph embedded on a torus and the massless free Majorana fermion living on the same lattice. A loop expansion of the fermion determinant is performed, where the loops turn out to be compositions of two perfect matchings. These loop states are sorted into co-chain groups using categorification techniques similar to the ones used for categorifying knot polynomials. The Euler characteristic of the resulting co-chain complex recovers the Newton polynomial of the dimer model. We re-interpret this system as supersymmetric quantum mechanics, where configurations with vanishing net winding number form the ground states. Finally, we make use of the quiver gauge theory - dimer model correspondence to obtain an interpretation of the loops in terms of the physics of D-branes probing a toric Calabi-Yau singularity. ", "machine_text": " We propose and analyze a model of a statistical ensemble of dimers which has a continuum of discrete states. The model is studied in the limit of a large number of dimers. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. The special case of a dimer model with free fermions is also analyzed. We show that in this case the model is not exactly solvable, but that a probabilistic approach can be used to determine the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. We also analyze a model of a statistical ensemble of free fermions. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution. We also analyze a model of a statistical ensemble of \"super-quantum\" particles. We show that the model is exactly solvable and we calculate the probability distribution of the occupation of the continuum of states. The results are consistent with the statistical mechanics prediction of a Boltzmann-Gibbs distribution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A High-Throughput Cross-Layer Scheme for Distributed Wireless Ad Hoc\n  Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2841, "human_text": "  In wireless ad hoc networks, distributed nodes can collaboratively form an antenna array for long-distance communications to achieve high energy efficiency. In recent work, Ochiai, et al., have shown that such collaborative beamforming can achieve a statistically nice beampattern with a narrow main lobe and low sidelobes. However, the process of collaboration introduces significant delay, since all collaborating nodes need access to the same information. In this paper, a technique that significantly reduces the collaboration overhead is proposed. It consists of two phases. In the first phase, nodes transmit locally in a random access fashion. Collisions, when they occur, are viewed as linear mixtures of the collided packets. In the second phase, a set of cooperating nodes acts as a distributed antenna system and beamform the received analog waveform to one or more faraway destinations. This step requires multiplication of the received analog waveform by a complex number, which is independently computed by each cooperating node, and which enables separation of the collided packets based on their final destination. The scheme requires that each node has global knowledge of the network coordinates. The proposed scheme can achieve high throughput, which in certain cases exceeds one. ", "machine_text": " We propose a high-throughput cross-layer scheme for distributed wireless ad hoc networks. Our scheme is based on a new cross-layer design framework that we call \"Multi-Service-Cross-Layer Design\" (MSCLD). Given the important role that cross-layer design plays in the ad hoc network setting, our MSCLD framework can lead to more efficient network protocols. Our scheme is evaluated through simulations and it is shown that it can achieve high throughput as well as improved fairness.   A significant amount of research in the field of wireless ad hoc networks has focused on the issue of quality-of-service (QoS) provisioning. QoS provisioning in ad hoc networks has been a challenging task due to the limited bandwidth as well as the highly dynamic nature of the network. In addition, the difficulty in meeting QoS requirements in multi-hop wireless ad hoc networks has not yet been studied. Most of the existing work on this topic focuses on the single-hop or cluster-based ad hoc networks. In this paper, we propose a new cross-layer scheme for multi-hop wireless ad hoc networks that can achieve QoS provisioning while maintaining high throughput.   Our scheme is based on a new cross-layer design framework that we call \"Multi-Service-Cross-Layer Design\" (MSCLD). Given the important role that cross-layer design plays in the ad hoc network setting, our MSCLD framework can lead to more efficient network protocols. Our scheme is evaluated through simulations and it is shown that it can achieve high throughput as well as improved fairness.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galois theory of iterated endomorphisms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2384, "human_text": "  Given an abelian algebraic group $A$ over a global field $F$, $\\alpha \\in A(F)$, and a prime $\\ell$, the set of all preimages of $\\alpha$ under some iterate of $[\\ell]$ generates an extension of $F$ that contains all $\\ell$-power torsion points as well as a Kummer-type extension. We analyze the Galois group of this extension, and for several classes of $A$ we give a simple characterization of when the Galois group is as large as possible up to constraints imposed by the endomorphism ring or the Weil pairing. This Galois group encodes information about the density of primes $\\p$ in the ring of integers of $F$ such that the order of $(\\alpha \\bmod{\\p})$ is prime to $\\ell$. We compute this density in the general case for several classes of $A$, including elliptic curves and one-dimensional tori. For example, if $F$ is a number field, $A/F$ is an elliptic curve with surjective 2-adic representation and $\\alpha \\in A(F)$ with $\\alpha \\not\\in 2A(F(A[4]))$, then the density of $\\mathfrak{p}$ with ($\\alpha \\bmod{\\p}$) having odd order is 11/21. ", "machine_text": " We show that any iterated endomorphism on a polynomial algebra over a field has a common general form: it is either an iterated map to an algebra over a field or it is a combination of such iterated maps with an iterated map to the field itself. As an application, we give a description of the iterated endomorphisms of the polynomial algebra over a field in terms of the polynomial algebra's non-zero pivot elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Design of Parallel Kinematic Machine Tools Using Kinetostatic\n  Performance Criteria. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1038, "human_text": "  Most industrial machine tools have a serial kinematic architecture, which means that each axis has to carry the following one, including its actuators and joints. High Speed Machining highlights some drawbacks of such architectures: heavy moving parts require from the machine structure high stiffness to limit bending problems that lower the machine accuracy, and limit the dynamic performances of the feed axes. That is why PKMs attract more and more researchers and companies, because they are claimed to offer several advantages over their serial counterparts, like high structural rigidity and high dynamic capacities. Indeed, the parallel kinematic arrangement of the links provides higher stiffness and lower moving masses that reduce inertia effects. Thus, PKMs have better dynamic performances. However, the design of a parallel kinematic machine tool (PKMT) is a hard task that requires further research studies before wide industrial use can be expected. Many criteria need to be taken into account in the design of a PKMT. We pay special attention to the description of kinetostatic criteria that rely on the conditioning of the Jacobian matrix of the mechanism. The organisation of this paper is as follows: next section introduces general remarks about PKMs, then is explained why PKMs can be interesting alternative machine tool designs. Then are presented existing PKMTs. An application to the design of a small-scale machine tool prototype developed at IRCCyN is presented at the end of this paper. ", "machine_text": " We propose a methodology for the design of parallel kinematic machine tools based on the use of kinetostatic performance criteria. The motivation for this work is the difficulty in designing and analyzing the behavior of parallel kinematic machine tools based on conventional kinematic performance criteria, due to the complex non-linear relationship between the kinematic and kinetostatic characteristics. The proposed methodology is based on the use of a parameter called the \"kinetostatic defect\", which represents the deviation of the actual kinetostatic characteristics of a machine from the desired ones. The kinetostatic defect is related to the work actually performed by the drive motors, and is calculated using the concept of virtual work. By defining a functional relationship between the kinetostatic defect and the conventional kinematic performance criteria, the design of parallel kinematic machine tools can be simplified. The proposed methodology is demonstrated by means of an example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new search for planet transits in NGC 6791. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1668, "human_text": "  Context. Searching for planets in open clusters allows us to study the effects of dynamical environment on planet formation and evolution.   Aims. Considering the strong dependence of planet frequency on stellar metallicity, we studied the metal rich old open cluster NGC 6791 and searched for close-in planets using the transit technique.   Methods. A ten-night observational campaign was performed using the Canada-France-Hawaii Telescope (3.6m), the San Pedro M\\'artir telescope (2.1m), and the Loiano telescope (1.5m). To increase the transit detection probability we also made use of the Bruntt et al. (2003) eight-nights observational campaign. Adequate photometric precision for the detection of planetary transits was achieved.   Results. Should the frequency and properties of close-in planets in NGC 6791 be similar to those orbiting field stars of similar metallicity, then detailed simulations foresee the presence of 2-3 transiting planets. Instead, we do not confirm the transit candidates proposed by Bruntt et al. (2003). The probability that the null detection is simply due to chance coincidence is estimated to be 3%-10%, depending on the metallicity assumed for the cluster.   Conclusions. Possible explanations of the null-detection of transits include: (i) a lower frequency of close-in planets in star clusters; (ii) a smaller planetary radius for planets orbiting super metal rich stars; or (iii) limitations in the basic assumptions. More extensive photometry with 3-4m class telescopes is required to allow conclusive inferences about the frequency of planets in NGC 6791. ", "machine_text": "  We present the results of a new search for transits by giant planets in the solar-like star NGC 6791. We have previously reported two transit events in this star, which were attributed to a giant planet with an orbit very similar to that of our own Jupiter. Here we present two more transit events observed in 2019 and 2021, as well as additional transit data for the previously reported events. The new transit events are very similar to the previously reported events, indicating that the giant planet has an orbit with a radius of 1.5\u20132.0 astronomical units, an orbital period 11\u201312 years, and a mass at least 1.5 times that of Jupiter. The combined data set is consistent with a giant planet in a circular orbit, but the transient nature of the transit events and the relatively small number of observations (nine transit events observed in four different years) make a precise determination of the orbital elements impossible. The continued observation of this star is needed to properly characterize the giant planet and its orbit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stable oscillations of a predator-prey probabilistic cellular automaton:\n  a mean-field approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0512, "human_text": "  We analyze a probabilistic cellular automaton describing the dynamics of coexistence of a predator-prey system. The individuals of each species are localized over the sites of a lattice and the local stochastic updating rules are inspired on the processes of the Lotka-Volterra model. Two levels of mean-field approximations are set up. The simple approximation is equivalent to an extended patch model, a simple metapopulation model with patches colonized by prey, patches colonized by predators and empty patches. This approximation is capable of describing the limited available space for species occupancy. The pair approximation is moreover able to describe two types of coexistence of prey and predators: one where population densities are constant in time and another displaying self-sustained time-oscillations of the population densities. The oscillations are associated with limit cycles and arise through a Hopf bifurcation. They are stable against changes in the initial conditions and, in this sense, they differ from the Lotka-Volterra cycles which depend on initial conditions. In this respect, the present model is biologically more realistic than the Lotka-Volterra model. ", "machine_text": " We consider a probabilistic cellular automaton describing the dynamics of coexistence of a predator-prey system with infinite total population and study the conditions for the emergence of self-sustained limit cycles. The automaton is mean-field, i.e. the local stochastic update rules are inspired on the processes of the elementary units (the cells) without taking into account their spatial arrangement. We find that a spatial structure of patches, in which the prey has an advantage over the predator, is necessary for the emergence of self-sustained limit cycles. We also show that limit cycles can be stable against changes in the initial conditions and, in this case, the automaton has a global steady state in which the number of prey and predator cells is independent of the initial conditions. As an example application, we consider a patchy landscape where the local stochastic rules describe the dynamics of the limiting case of the ratio of the prey and predator densities, as obtained from a simple ecological model with patchy spatial structure. We show that this model has a stable limit cycle and the conditions for its emergence are similar to the ones obtained for the mean-field case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Our Peculiar Motion Away from the Local Void. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4139, "human_text": "  The peculiar velocity of the Local Group of galaxies manifested in the Cosmic Microwave Background dipole is found to decompose into three dominant components. The three components are clearly separated because they arise on distinct spatial scales and are fortuitously almost orthogonal in their influences. The nearest, which is distinguished by a velocity discontinuity at ~7 Mpc, arises from the evacuation of the Local Void. We lie in the Local Sheet that bounds the void. Random motions within the Local Sheet are small. Our Galaxy participates in the bulk motion of the Local Sheet away from the Local Void. The component of our motion on an intermediate scale is attributed to the Virgo Cluster and its surroundings, 17 Mpc away. The third and largest component is an attraction on scales larger than 3000 km/s and centered near the direction of the Centaurus Cluster. The amplitudes of the three components are 259, 185, and 455 km/s, respectively, adding collectively to 631 km/s in the reference frame of the Local Sheet. Taking the nearby influences into account causes the residual attributed to large scales to align with observed concentrations of distant galaxies and reduces somewhat the amplitude of motion attributed to their pull. On small scales, in addition to the motion of our Local Sheet away from the Local Void, the nearest adjacent filament, the Leo Spur, is seen to be moving in a direction that will lead to convergence with our filament. Finally, a good distance to an isolated galaxy within the Local Void reveals that this dwarf system has a motion of at least 230 km/s away from the void center. Given the velocities expected from gravitational instability theory in the standard cosmological paradigm, the distance to the center of the Local Void must be at least 23 Mpc from our position. The Local Void is large! ", "machine_text": "  Our Peculiar Motion Away from the Local Void We have recently discovered a peculiar motion of our solar system away from the local void. We do not know the origin of this motion but suspect it has something to do with our motion within our own void. Our void is much larger than the local one and it has many more planets, which move around in a very complicated manner. We have made some progress in understanding this motion by studying the motion of the local void and the peculiar motion of our solar system. We have learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have also learned that our solar system is moving in a way that is much more complicated and we are not able to describe it using these same tools.  We are not sure what the origin of this peculiar motion is, but we suspect it has something to do with the way our solar system moves within our own void. We have studied the motion of our solar system within our void and we have learned that it is very complicated. We have also learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have tried to use these tools to describe the motion of our solar system but we have not been able to do so.  We have learned that the local void is moving in a very simple manner, which we can describe using some basic mathematical tools. We have also learned that our solar system is moving in a way that is much more complicated and we are not able to describe it using these same tools. We are not sure what the origin of this peculiar motion is, but we suspect it has something to do with the way our solar system moves within our own void.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fundamental Limits to Position Determination by Concentration Gradients. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3639, "human_text": "  Position determination in biological systems is often achieved through protein concentration gradients. Measuring the local concentration of such a protein with a spatially-varying distribution allows the measurement of position within the system. In order for these systems to work effectively, position determination must be robust to noise. Here, we calculate fundamental limits to the precision of position determination by concentration gradients due to unavoidable biochemical noise perturbing the gradients. We focus on gradient proteins with first order reaction kinetics. Systems of this type have been experimentally characterised in both developmental and cell biology settings. For a single gradient we show that, through time-averaging, great precision can potentially be achieved even with very low protein copy numbers. As a second example, we investigate the ability of a system with oppositely directed gradients to find its centre. With this mechanism, positional precision close to the centre improves more slowly with increasing averaging time, and so longer averaging times or higher copy numbers are required for high precision. For both single and double gradients, we demonstrate the existence of optimal length scales for the gradients, where precision is maximized, as well as analyzing how precision depends on the size of the concentration measuring apparatus. Our results provide fundamental constraints on the positional precision supplied by concentration gradients in various contexts, including both in developmental biology and also within a single cell. ", "machine_text": "  We consider the fundamental limits to position determination by concentration gradients. We show that the resolution is limited by the amount of information in the gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.  We consider the problem of position determination by measuring the concentration of a target in a sample with a known concentration gradient. We show that the resolution is limited by the amount of information in the gradient. In particular, the theoretical resolution limit is about 3 times the standard deviation of the concentration gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.  The motivation for this work is to understand the fundamental limits to position determination by concentration gradients. We show that the resolution is limited by the amount of information in the gradient. The effects of noise and finite bandwidth on the position resolution are also studied. The practical consequences of the theoretical results are discussed in the light of recent experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Millennium Galaxy Catalogue: The local supermassive black hole mass\n  function in early- and late-type galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0316, "human_text": "  We provide a new estimate of the local supermassive black hole mass function using (i) the empirical relation between supermassive black hole mass and the Sersic index of the host spheroidal stellar system and (ii) the measured (spheroid) Sersic indices drawn from 10k galaxies in the Millennium Galaxy Catalogue. The observational simplicity of our approach, and the direct measurements of the black hole predictor quantity, i.e. the Sersic index, for both elliptical galaxies and the bulges of disc galaxies makes it straightforward to estimate accurate black hole masses in early- and late-type galaxies alike. We have parameterised the supermassive black hole mass function with a Schechter function and find, at the low-mass end, a logarithmic slope (1+alpha) of ~0.7 for the full galaxy sample and ~1.0 for the early-type galaxy sample. Considering spheroidal stellar systems brighter than M_B = -18 mag, and integrating down to black hole masses of 10^6 M_sun, we find that the local mass density of supermassive black holes in early-type galaxies rho_{bh, early-type} = (3.5+/-1.2) x 10^5 h^3_{70} M_sun Mpc^{-3}, and in late-type galaxies rho_{bh, late-type} = (1.0+/-0.5) x 10^5 h^3_{70} M_sun Mpc^{-3}. The uncertainties are derived from Monte Carlo simulations which include uncertainties in the M_bh-n relation, the catalogue of Sersic indices, the galaxy weights and Malmquist bias. The combined, cosmological, supermassive black hole mass density is thus Omega_{bh, total} = (3.2+/-1.2) x 10^{-6} h_70. That is, using a new and independent method, we conclude that (0.007+/-0.003) h^3_{70} per cent of the universe's baryons are presently locked up in supermassive black holes at the centres of galaxies. ", "machine_text": " We present the first estimate of the local supermassive black hole (SMBH) mass function in early- and late-type galaxies, based on a sample of 2,write custom essay type=&#34;wide-plain&#34; galaxies selected from the Millennium Galaxy Catalogue. We find that the local SMBH mass function is well described by a power law with a strong cut-off at log(M/Mpc^2) &lt; -1.7. The power law index and the magnitude of the cut-off are independent of galaxy type, morphology, size, and local group membership. Within this large sample, we find no evidence for a correlation between the local SMBH mass and galactic mass, star formation rate, or black hole accretion rate. We estimate the total number of SMBHs in our sample to be 1.9 x 10^4, with a total mass of 4.4 x 10^7 Mpc^2. The corresponding SMBH mass function is log(M/Mpc^2) = -1.38 \u00b1 0.08, with a total uncertainty of 6.5 per cent. We discuss our results in the context of galaxy evolution, the formation of the SMBH mass function, and the connection between local SMBH properties and the large-scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lyman Break Galaxies at z~5: Rest-frame UV Spectra II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1145, "human_text": "  We present the results of spectroscopy of Lyman Break Galaxies (LBGs) at z~5 in the J0053+1234 field with the Faint Object Camera and Spectrograph on the Subaru telescope. Among 5 bright candidates with z' < 25.0 mag, 2 objects are confirmed to be at z~5 from their Ly alpha emission and the continuum depression shortward of Ly alpha. The EWs of Ly alpha emission of the 2 LBGs are not so strong to be detected as Ly alpha emitters, and one of them shows strong low-ionized interstellar (LIS) metal absorption lines. Two faint objects with z' \\geq 25.0 mag are also confirmed to be at z~5, and their spectra show strong Ly alpha emission in contrast to the bright ones. These results suggest a deficiency of strong Ly alpha emission in bright LBGs at z~5, which has been discussed in our previous paper. Combined with our previous spectra of LBGs at z~5 obtained around the Hubble Deep Field-North (HDF-N), we made a composite spectrum of UV luminous (M_1400 \\leq -21.5 mag) LBGs at z~5. The resultant spectrum shows a weak Ly alpha emission and strong LIS absorptions which suggests that the bright LBGs at z~5 have chemically evolved at least to ~0.1 solar metallicity. For a part of our sample in the HDF-N region, we obtained near-to-mid infrared data, which constraint stellar masses of these objects. With the stellar mass and the metallicity estimated from LIS absorptions, the metallicities of the LBGs at z~5 tend to be lower than those of the galaxies with the same stellar mass at z \\lesssim 2, although the uncertainty is very large. ", "machine_text": "  We present a catalogue of 75 galaxies identified as Lyman break galaxies (LBGs) at z~5 from an imaging survey with two 8k x 8k cameras covering a field of 1.3 sq. deg. from the Canada-France-Hawaii Telescope. The galaxies were selected using a proprietary algorithm based on their rest-frame UV colours and the locations of known LBGs in the local volume at z~1-2. We present their locations, morphological classifications, and rest-frame UV colours. These galaxies are candidates for further spectroscopy, to measure their line-of-sight velocities and hence to probe the kinematics of the intergalactic medium at this epoch. Our sample is almost uniform in rest-frame UV colour, with a median colour of +0.06 in the rest-frame U-V colour-magnitude diagram. The galaxies are typically slightly bluer in colour than the local LBGs at z~1-2, and the vast majority have colours typical of galaxies in the early stages of formation. We discuss the properties of the galaxies in the sample, and in particular, we show that the sample contains a higher fraction of bright galaxies than the local LBG population, in agreement with the fact that the galaxies in the local LBG sample are known to be more distant galaxies in the local volume at z~1-2. We also show that the galaxies in our sample are preferentially found in the same regions as the local LBGs, but that they tend to be somewhat further away from the galaxies in the local LBG sample. This implies that the local LBG population at z~1-2 is not a random sample of all the LBGs in the local volume, but is instead a sample of the closest LBGs to us.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dual Computations of Non-abelian Yang-Mills on the Lattice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2629, "human_text": "  In the past several decades there have been a number of proposals for computing with dual forms of non-abelian Yang-Mills theories on the lattice. Motivated by the gauge-invariant, geometric picture offered by dual models and successful applications of duality in the U(1) case, we revisit the question of whether it is practical to perform numerical computation using non-abelian dual models. Specifically, we consider three-dimensional SU(2) pure Yang-Mills as an accessible yet non-trivial case in which the gauge group is non-abelian. Using methods developed recently in the context of spin foam quantum gravity, we derive an algorithm for efficiently computing the dual amplitude and describe Metropolis moves for sampling the dual ensemble. We relate our algorithms to prior work in non-abelian dual computations of Hari Dass and his collaborators, addressing several problems that have been left open. We report results of spin expectation value computations over a range of lattice sizes and couplings that are in agreement with our conventional lattice computations. We conclude with an outlook on further development of dual methods and their application to problems of current interest. ", "machine_text": "  We study the fundamental problem of computing the non-abelian Yang-Mills group on the lattice. We show that this problem is in general more difficult than computing the abelian variety of the same dimension. We consider different techniques which can be used to solve this problem, including the use ofcharacters, three-term recurrence, and the translation method. In the case of the pure Yang-Mills group, we show that any solution to this problem must take the form of a polynomial in the fundamental representation of the group. This reduces the problem to an issue of determining the root system of the group, and hence to the problem of classifying three-term recurrent integrals of the fundamental representation. We present an algorithm which classifies such integrals, and show that this algorithm can be used to solve the pure Yang-Mills case. We also show that this problem is equivalent to the problem of finding an embedding of the pure Yang-Mills group into a finite-dimensional representation of its generalizations. This in turn reduces to the problem of finding an integral representation of the generalized Yang-Mills group which contains a particular sub representation. We present an algorithm which finds such an integral representation. As an application, we use our algorithm to show that certain categories of symmetrically acting finite-dimensional representations of the pure Yang-Mills group have the structure of an equivariant category.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stringy E-functions of hypersurfaces and of Brieskorn singularities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0798, "human_text": "  We show that for a hypersurface Batyrev's stringy E-function can be seen as a residue of the Hodge zeta function, a specialization of the motivic zeta function of Denef and Loeser. This is a nice application of inversion of adjunction. If an affine hypersurface is given by a polynomial that is non-degenerate with respect to its Newton polyhedron, then the motivic zeta function and thus the stringy E-function can be computed from this Newton polyhedron (by work of Artal, Cassou-Nogues, Luengo and Melle based on an algorithm of Denef and Hoornaert). We use this procedure to obtain an easy way to compute the contribution of a Brieskorn singularity to the stringy E-function. As a corollary, we prove that stringy Hodge numbers of varieties with a certain class of strictly canonical Brieskorn singularities are nonnegative. We conclude by computing an interesting 6-dimensional example. It shows that a result, implying nonnegativity of stringy Hodge numbers in lower dimensional cases, obtained in our previous paper, is not true in higher dimension. ", "machine_text": "  We continue our study of stringy E-functions of hypersurfaces and of Brieskorn singularities. We show that the Euler characteristic of a Brieskorn Singularity is an invariant of the K3 surface. As an application we give a description of Brieskorn singularities in terms of matrixSKI-theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Recovering galaxy star formation and metallicity histories from spectra\n  using VESPA. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0941, "human_text": "  We introduce VErsatile SPectral Analysis (VESPA): a new method which aims to recover robust star formation and metallicity histories from galactic spectra. VESPA uses the full spectral range to construct a galaxy history from synthetic models. We investigate the use of an adaptative parametrization grid to recover reliable star formation histories on a galaxy-by-galaxy basis. Our goal is robustness as opposed to high resolution histories, and the method is designed to return high time resolution only where the data demand it. In this paper we detail the method and we present our findings when we apply VESPA to synthetic and real Sloan Digital Sky Survey (SDSS) spectroscopic data. We show that the number of parameters that can be recovered from a spectrum depends strongly on the signal-to-noise, wavelength coverage and presence or absence of a young population. For a typical SDSS sample of galaxies, we can normally recover between 2 to 5 stellar populations. We find very good agreement between VESPA and our previous analysis of the SDSS sample with MOPED. ", "machine_text": " We present a new method for recovering galaxy star formation and metallicity histories from spectral data using the Visual EXpression System for Physics and Astronomy (VESPA). We demonstrate the effectiveness of the method by applying it to a set of high-resolution, high signal-to-noise ratio (SNR) spectra of galaxies in the distant Universe, obtained with the Hubble Space Telescope (HST). The method is based on the recognition that the strengths of the metal absorption lines are proportional to the metallicity of the galaxy, while the star formation rate is proportional to the total H\u03b1 luminosity. We have implemented these relations in VESPA, using the principal component analysis (PCA) method to extract the corresponding parameters. We find that the method is reliable and robust, and we demonstrate that the recovered parameters are consistent with those derived from the photometric analysis of the same galaxies, thus providing a robust spectral diagnosis of galaxy properties. The method is suitable for low SNR spectra as well as high SNR spectra, and can thus be applied to a variety of astronomical data sets, including, for example, the high-redshift Universe, where the SNR is often low.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Absolute Calibration and Characterization of the Multiband Imaging\n  Photometer for Spitzer. I. The Stellar Calibrator Sample and the 24 micron\n  Calibration. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2195, "human_text": "  We present the stellar calibrator sample and the conversion from instrumental to physical units for the 24 micron channel of the Multiband Imaging Photometer for Spitzer (MIPS). The primary calibrators are A stars, and the calibration factor based on those stars is 4.54*10^{-2} MJy sr^{-1} (DN/s)^{-1}, with a nominal uncertainty of 2%. We discuss the data-reduction procedures required to attain this accuracy; without these procdures, the calibration factor obtained using the automated pipeline at the Spitzer Science Center is 1.6% +/- 0.6% lower. We extend this work to predict 24 micron flux densities for a sample of 238 stars which covers a larger range of flux densities and spectral types. We present a total of 348 measurements of 141 stars at 24 micron. This sample covers a factor of ~460 in 24 micron flux density, from 8.6 mJy up to 4.0 Jy. We show that the calibration is linear over that range with respect to target flux and background level. The calibration is based on observations made using 3-second exposures; a preliminary analysis shows that the calibration factor may be 1% and 2% lower for 10- and 30-second exposures, respectively. We also demonstrate that the calibration is very stable: over the course of the mission, repeated measurements of our routine calibrator, HD 159330, show a root-mean-square scatter of only 0.4%. Finally, we show that the point spread function (PSF) is well measured and allows us to calibrate extended sources accurately; Infrared Astronomy Satellite (IRAS) and MIPS measurements of a sample of nearby galaxies are identical within the uncertainties. ", "machine_text": "  We present the results of a program to calibrate and characterize the Multiband Imaging Photometer for Spitzer (MIPS) with the Spitzer Space Telescope. We describe the methodology used to obtain the absolute calibration and the properties of the Stellar Calibrator Sample, which consists of 892 stars in four colors with known spectral types. We show that the absolute calibration is stable to within 3% over the full Spitzer mission and that the scatter in the measurements is in agreement with the requirements of the mission. We present the MIPS 24 micron flux calibration as a function of wavelength and the conversion factors to and from units of excess thermal emission in units of MJy/sr. We show that the main contribution to the scatter in the MIPS 24 micron measurements is due to the presence of thermal emission from the Spitzer spacecraft and that a correction based on the observed behavior can be applied to reduce the scatter to within the mission requirement of 20%. We show that the MIPS photometric measurements are stable to within 4% over the full Spitzer mission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Network statistics on early English Syntax: Structural criteria. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3708, "human_text": "  This paper includes a reflection on the role of networks in the study of English language acquisition, as well as a collection of practical criteria to annotate free-speech corpora from children utterances. At the theoretical level, the main claim of this paper is that syntactic networks should be interpreted as the outcome of the use of the syntactic machinery. Thus, the intrinsic features of such machinery are not accessible directly from (known) network properties. Rather, what one can see are the global patterns of its use and, thus, a global view of the power and organization of the underlying grammar. Taking a look into more practical issues, the paper examines how to build a net from the projection of syntactic relations. Recall that, as opposed to adult grammars, early-child language has not a well-defined concept of structure. To overcome such difficulty, we develop a set of systematic criteria assuming constituency hierarchy and a grammar based on lexico-thematic relations. At the end, what we obtain is a well defined corpora annotation that enables us i) to perform statistics on the size of structures and ii) to build a network from syntactic relations over which we can perform the standard measures of complexity. We also provide a detailed example. ", "machine_text": "  Network statistics on early English Syntax: Structural criteria  We apply network statistics to a corpus of Old English to investigate its syntax in terms of structural criteria. The investigation comprises four steps. First, we compile a distributional analysis of the most frequent items and ranks them by their degree of association. Second, we apply network statistics to the ranked set of items in order to identify the most central items. Third, we compare the most central items in the network with the items ranked as the most frequent in the distributional analysis, in order to isolate items that are central in the network but not frequent in the distributional analysis. These items are marked as exceptional. Fourth, we compile a list of the most frequent items in the network that are not ranked as the most frequent in the distributional analysis. These items are marked as frequent. In addition, we identify the items that are most central in the network and also frequent, and mark these as especially frequent. We then compare the distribution of exceptional, frequent, and especially frequent items in the network with the distribution of items in the same categories based on their occurrence in a manually annotated reference corpus. The comparison shows that the distribution of items in the network is consistent with the manually annotated reference corpus in terms of both the number of items in each category and their relative frequency. There are, however, two notable differences. First, the network has many more especially frequent items than the reference corpus. Second, the network has many fewer frequent items than the reference corpus. We discuss possible reasons for these differences and conclude that they are most likely due to the particular properties of the network. Our results therefore provide evidence that network statistics can be used to investigate structural criteria in syntax.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Araucaria Project. The Distance to the Local Group Galaxy WLM from\n  Cepheid Variables discovered in a Wide-Field Imaging Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2075, "human_text": "  We have conducted an extensive wide-field imaging survey for Cepheid variables in the Local Group irregular galaxy WLM. From data obtained on 101 nights, we have discovered 60 Cepheids which include 14 of the 15 Cepheid variables previously detected by Sandage and Carlson. Down to a period of 3 days, our Cepheid survey in WLM should be practically complete. Importantly, we have found for the first time a long-period Cepheid (P=54.2 days) in this galaxy, alleviating the puzzle that WLM with its many blue, massive stars does not contain Cepheids with periods longer than about 10 days. Our data define tight period-luminosity relations in V, I and the reddening-free Wesenheit magnitude ${\\rm W}_{\\rm I}$ which are all extremely well fit by the corresponding slopes of the LMC Cepheid PL relation, suggesting no change of the PL relation slope down to a Cepheid metal abundance of about -1.0 dex, in agreement with other recent studies. We derive a true distance modulus to WLM of 25.144 $\\pm$0.03 (r) $\\pm$0.07 (s) mag from our data, in good agreement with the earlier 24.92 $\\pm$ 0.21 mag determination of Lee, Freedman and Madore (1993a) from Cepheid variables. The quoted value of the systematic uncertainty does not include the contribution from the LMC distance which we have assumed to be 18.50 mag, as in the previous papers in our project. ", "machine_text": "  We present the Araucaria Project, a wide-field imaging survey for Cepheid variables in galaxies within 100 Mpc, with the aim of measuring the distance to the Local Group galaxy WLM. We describe the survey methodology, the data processing pipeline, and the results from the analysis of the first year of data, comprising 2, Edelmann, M. E. et al. 2018, ApJ, 853, 34, 10.3838/ apj.2017.85S1. The survey covers an area of 3.4 steradians with 3, 70-arcmin diameter fields, selected to be free of dust and highly extinction, and to contain a high-redshift galaxy cluster in the background for purposes of distance calibration. The cluster is a member of the Great Attractor, at a distance of 200 Mpc, providing a highly reliable indicator of the distance to our galaxy. The cluster is also well-studied, providing an anchor for the distance measurement. The galaxies in the survey are extracted from the SDSS DR7, and the Cepheid variables are identified with the TYC catalogue. We find three candidate Cepheid variables in the first year of data. We discuss the quality of the candidates, and show that one of them is a known variable, and that the other two are likely to be variables, but that further observations are required to confirm this. We also show that there are a number of known variables in the survey area that were not extracted from SDSS DR7, providing a useful archive of variables for future studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dark Matter in Gauge Mediation from Emergent Supersymmetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2258, "human_text": "  We investigated the viability of neutralino dark matter in the gauge mediation from emergent supersymmetry proposal. In this proposal, supersymmetry is broken at Planck scale and consequently, the gravitino is superheavy and completely decouples from the low energy theory. Squarks and sleptons obtain their soft masses dominantly through gauge mediation with other mechanisms highly suppressed. The lightest supersymmetric partner, in contrast to traditional gauge mediation, is a neutralino which is also a dark matter candidate. By explicit calculation of the low energy spectra, the parameter space was constrained using the WMAP observed relic density of dark matter, LEP2 Higgs mass bounds, collider bounds on supersymmetric partners and exotic B-meson decays. We found that the model has intriguing hybrid features such as a nearly gauge-mediated spectrum (the exception being the superheavy gravitino) but with a dominant mSUGRA-like bino-stau coannihilation channel and at large $\\tan \\beta$, A-resonance-like annihilation. ", "machine_text": " We propose a new mechanism for the generation of dark matter in gauge mediation theories, based on the emergent breaking of supersymmetry in the presence of non-Abelian symmetries. We show that the resulting dark matter candidates can have a wide range of masses, from being extremely light to being heavier than the standard model particles. We discuss the experimental signatures of our mechanism and find that they are different for different masses. Our main results are summarized as follows. (i) We show that for dark matter particles to be extremely light, the non-Abelian symmetries in the theory must be very close to the weak scale, and the resulting theory is not very attractive from the practical point of view. (ii) We show that for dark matter particles to be heavy, the non-Abelian symmetries must be very large, and we discuss a simple model in which this is the case. (iii) We show that there is a special intermediate mass range, for which the non-Abelian symmetries are not too small and not too large, and in which the theory is particularly well- behaved and attractive.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Culminating paths. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0694, "human_text": "  Let a and b be two positive integers. A culminating path is a path of Z^2 that starts from (0,0), consists of steps (1,a) and (1,-b), stays above the x-axis and ends at the highest ordinate it ever reaches. These paths were first encountered in bioinformatics, in the analysis of similarity search algorithms. They are also related to certain models of Lorentzian gravity in theoretical physics. We first show that the language on a two letter alphabet that naturally encodes culminating paths is not context-free. Then, we focus on the enumeration of culminating paths. A step by step approach, combined with the kernel method, provides a closed form expression for the generating fucntion of culminating paths ending at a (generic) height k. In the case a=b, we derive from this expression the asymptotic behaviour of the number of culminating paths of length n. When a>b, we obtain the asymptotic behaviour by a simpler argument. When a<b, we only determine the exponential growth of the number of culminating paths. Finally, we study the uniform random generation of culminating paths via various methods. The rejection approach, coupled with a symmetry argument, gives an algorithm that is linear when a>= b, with no precomputation stage nor non-linear storage required. The choice of the best algorithm is not as clear when a<b. An elementary recursive approach yields a linear algorithm after a precomputation stage involving O(n^3) arithmetic operations, but we also present some alternatives that may be more efficient in practise. ", "machine_text": "  Culminating paths  We present a new approach to the problem of computing the shortest paths between two points on a grid, which is motivated by the need to solve this problem for large graphs on large grids. We show that if the underlying graph is a tree, then one can preprocess the graph in order to find a vector of shortest path lengths between every pair of points. This vector is indexed by the two points, and is of size n\u00d7n, where n is the number of points on the grid. Given two points p and q, one can then find the shortest path between p and q by simply taking the minimum over i and j of the elements of the vector. For more general graphs, the preprocessing step is more involved, but it is still possible to compute a vector of shortest path lengths in this way. We show that this algorithm is much more efficient than the naive algorithm of computing the shortest path for every pair of points.  Our work differs from previous work on this problem in several ways. First, we give a more general algorithm that is applicable to a wider class of inputs. In particular, our algorithm is guaranteed to work on graphs that are not tree-like. Also, previous work on this problem was restricted to square grids, while our algorithm is applicable to general rectilinear grids. Finally, our algorithm has a much better worst-case running time. In particular, we show that if the underlying graph is a tree, then our algorithm runs in O(n2log n) time, where n is the number of points on the grid. For more general graphs, the running time is still polynomial in n.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modules over operads and functors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.309, "human_text": "  In the theory of operads we consider functors of generalized symmetric powers defined by sums of coinvariant modules under actions of symmetric groups. One observes classically that the construction of symmetric functors provides an isomorphism from the category of symmetric modules to a subcategory of the category of functors on the base category. The purpose of this book is to obtain a similar relationship for functors on a category of algebras over an operad.   We observe that right modules over operads, symmetric modules equipped with a right operad action, give rise to functors on categories of algebras and we prove that this construction yields an embedding of categories. Then we check that right modules over operads form a model category. In addition we prove that weak-equivalences of right modules correspond to pointwise weak-equivalences at the functor level. As a conclusion, we obtain that right modules over operads supply good models for the homotopy of associated functors on algebras over operads. ", "machine_text": " We study modules over operads and functors. We show that modules over operads are ubiquitous in algebra, geometry, and representation theory, and we explain how they arise in many different situations. We give a criterion for when two modules over operads are isomorphic, and we use this criterion to give a complete description of the category of modules over the operad of symmetric bisets. We show that this category is isomorphic to the category of modules over the full subcategory of the category of sets that consists of those sets that have a symmetric difference. We show that this category of modules is monadic over the category of sets. We then turn to the study of functors. We give a general criterion for when a functor F between two categories of modules is a tensor functor, and we use this criterion to give a complete description of the category of functors from the category of modules over the operad of symmetric bisets to the category of modules over the operad of sets. We show that this category of functors is isomorphic to the category of functors from the category of modules over the full subcategory of the category of sets that consists of those sets that have a symmetric difference. We show that this category of functors is monadic over the category of modules over the operad of sets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolutionary dynamics of the most populated genotype on rugged fitness\n  landscapes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0406, "human_text": "  We consider an asexual population evolving on rugged fitness landscapes which are defined on the multi-dimensional genotypic space and have many local optima. We track the most populated genotype as it changes when the population jumps from a fitness peak to a better one during the process of adaptation. This is done using the dynamics of the shell model which is a simplified version of the quasispecies model for infinite populations and standard Wright-Fisher dynamics for large finite populations. We show that the population fraction of a genotype obtained within the quasispecies model and the shell model match for fit genotypes and at short times, but the dynamics of the two models are identical for questions related to the most populated genotype. We calculate exactly several properties of the jumps in infinite populations some of which were obtained numerically in previous works. We also present our preliminary simulation results for finite populations. In particular, we measure the jump distribution in time and find that it decays as $t^{-2}$ as in the quasispecies problem. ", "machine_text": "  We investigated the dynamics of gene frequencies on rugged fitness landscapes using an evolutionary model with explicit representation of phenotypic fitness. We considered the evolution of selfish genotypes, that is, genotypes that have no effect on the fitness of other genotypes. Our results show that rugged fitness landscapes can be stable against invasion of selfish genotypes if the degree of ruggedness is not too large. We found that the invasibility of a population is determined by the relative distribution of fitnesses of the individuals within the population. The higher the relative fitness of the individuals in the population, the easier it is for the population to resist invasion of a selfish genotype. We also found that the population can invade the population of a selfish genotype if the distribution of the fitnesses of the individuals in the population is peaked on the fitness landscape. The probability of this invasion event increases with the sharpness of the peak and the number of individuals in the population. Our results suggest that the invasibility of a population to invasion by a selfish genotype depends only on the global structure of the fitness landscape and not on the particular genotypes that occupy the landscape.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: How a \"Hit\" is Born: The Emergence of Popularity from the Dynamics of\n  Collective Choice. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2955, "human_text": "  In recent times there has been a surge of interest in seeking out patterns in the aggregate behavior of socio-economic systems. One such domain is the emergence of statistical regularities in the evolution of collective choice from individual behavior. This is manifested in the sudden emergence of popularity or \"success\" of certain ideas or products, compared to their numerous, often very similar, competitors. In this paper, we present an empirical study of a wide range of popularity distributions, spanning from scientific paper citations to movie gross income. Our results show that in the majority of cases, the distribution follows a log-normal form, suggesting that multiplicative stochastic processes are the basis for emergence of popular entities. This suggests the existence of some general principles of complex organization leading to the emergence of popularity. We discuss the theoretical principles needed to explain this socio-economic phenomenon, and present a model for collective behavior that exhibits bimodality, which has been observed in certain empirical popularity distributions. ", "machine_text": "  How a \"Hit\" is Born: The Emergence of Popularity from the Dynamics of Collective Choice  We study the emergence of popularity in a cultural market where consumers choose from a large number of items. We develop a model in which items are selected from a slate of options that is too large to allow for an efficient choice process. We find that the dynamics of choice have a crucial impact on the emergence of popularity. In particular, we show that the frequency with which an item is chosen can be sharply increased by creating an item that is chosen in between two other items that are already popular. To explore the mechanism behind this effect we introduce the concept of \"Russian Doll Learning,\" which captures the idea that consumers learn about the popularity of an item based on their own preferences as well as the preferences of other consumers. We show that Russian Doll Learning can dramatically increase the chances for an item to become popular, and that the effect is particularly strong when the number of items is large. Our findings help to explain why some items become extremely popular even though they do not possess any unique features that would make them stand out from other items.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A ferrofluid based neural network: design of an analogue associative\n  memory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3402, "human_text": "  We analyse an associative memory based on a ferrofluid, consisting of a system of magnetic nano-particles suspended in a carrier fluid of variable viscosity subject to patterns of magnetic fields from an array of input and output magnetic pads. The association relies on forming patterns in the ferrofluid during a trainingdphase, in which the magnetic dipoles are free to move and rotate to minimize the total energy of the system. Once equilibrated in energy for a given input-output magnetic field pattern-pair the particles are fully or partially immobilized by cooling the carrier liquid. Thus produced particle distributions control the memory states, which are read out magnetically using spin-valve sensors incorporated in the output pads. The actual memory consists of spin distributions that is dynamic in nature, realized only in response to the input patterns that the system has been trained for. Two training algorithms for storing multiple patterns are investigated. Using Monte Carlo simulations of the physical system we demonstrate that the device is capable of storing and recalling two sets of images, each with an accuracy approaching 100%. ", "machine_text": " We present a novel ferrofluid based neural network for the design of an analogue associative memory. The motivation for this work is the need for a low-cost, fast, and portable artificial neural network that can be used in non-electrical and remote areas. The key idea is the use of a ferrofluid, which is a stable suspension of magnetic nanoparticles in a liquid, as the artificial synapse. We show that the magnetic properties of the ferrofluid can be used to change the synaptic strength, which is the basis for learning and memory. The methodology is based on the use of a permanent magnet to apply a magnetic field to the ferrofluid and change its properties. The results obtained show that the ferrofluid based neural network is capable of learning and remembering input patterns. The problem this work attempts to solve is the need for a low-cost and portable artificial neural network. The practical application of this work is the potential use of a ferrofluid based neural network as an analogue associative memory. The theoretical application of this work is the further understanding of the potential use of magnetic materials in artificial neural networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation of Single Reed Instruments Oscillations Based on Modal\n  Decomposition of Bore and Reed Dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2803, "human_text": "  This paper investigates the sound production in a system made of a bore coupled with a reed valve. Extending previous work (Debut, 2004), the input impedance of the bore is projected on the modes of the air column. The acoustic pressure is therefore calculated as the sum of modal components. The airr&#114;&#64258;ow blown into the bore is modulated by reed motion, assuming the reed to be a single degree of freedom oscillator. Calculation of self-sustained oscillations controlled by time-varying mouth pressure and player's embouchure parameter is performed using ODE solvers. Results emphasize the par ticipation of the whole set of components in the mode locking process. Another impor tant feature is the mutual inn&#110;&#64258;uence of reed and bore resonance during growing blowing pressure transients, oscillation threshold being altered by the reed natural frequency and the reed damping. Steady-state oscillations are also investigated and compared with results given by harmonic balance method and by digital sound synthesis. ", "machine_text": "  We present a method for simulation of single reed instrument oscillations based on the modal decomposition of bore and reed dynamics. The governing equations for the dynamic behavior of a single reed instrument are formulated in the basis of the thin-shell theory and the method of stationary stress. The problem is then solved by the FEM method. The Modal Decomposition (MD) technique is applied to reduce the computation efforts. In the MD method the instrument is considered as a linear system with multiple degrees of freedom (DOF). Each DOF has a proper dynamic model. The technique of theNormal Mode Analysis is used to identify the dynamic model of each DOF. The identified dynamic models are then assembled to obtain the total model of the instrument. The proposed method is applied to simulate the dynamic behavior of a single reed instrument. The results are compared with the available experimental data. The obtained good agreement between the simulation results and the experiment proves the effectiveness of the proposed method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complexity Considerations, cSAT Lower Bound. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0514, "human_text": "  This article discusses completeness of Boolean Algebra as First Order Theory in Goedel's meaning. If Theory is complete then any possible transformation is equivalent to some transformation using axioms, predicates etc. defined for this theory. If formula is to be proved (or disproved) then it has to be reduced to axioms. If every transformation is deducible then also optimal transformation is deducible. If every transformation is exponential then optimal one is too, what allows to define lower bound for discussed problem to be exponential (outside P). Then we show algorithm for NDTM solving the same problem in O(n^c) (so problem is in NP), what proves that P \\neq NP.   Article proves also that result of relativisation of P=NP question and oracle shown by Baker-Gill-Solovay distinguish between deterministic and non-deterministic calculation models. If there exists oracle A for which P^A=NP^A then A consists of infinite number of algorithms, DTMs, axioms and predicates, or like NDTM infinite number of simultaneous states. ", "machine_text": "  Considerations of complexity are common in computer science. We present a complexity consideration which has not been well studied: the worst-case running time of a randomized algorithm which is guaranteed to output the correct answer with a probability of 2-1 is at most a constant factor larger than the worst-case running time of the same algorithm without the guarantee. This answers a question oficzkowski andzlatar in the negative: it is not sufficient for an $\\mathcal{O}(\\log n)$ algorithm to output the correct answer with probability 2-1 in order to achieve an $\\mathcal{O}(n)$ worst-case running time. We show that the probability of the output of a randomized algorithm achieving any given confidence level is closely related to the worst-case running time of the same algorithm. We show that the class of problems which can be solved in worst-case $\\mathcal{O}(n)$ time by a randomized algorithm which outputs the correct answer with probability 2-1 is the same as the class of problems which can be solved in worst-case $\\mathcal{O}(n)$ time by a deterministic algorithm. We show how to use the study of randomized algorithms which output the correct answer with high probability to obtain new lower bounds for the complexity of several important problems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Systematic Scan for 7-colourings of the Grid. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1625, "human_text": "  We study the mixing time of a systematic scan Markov chain for sampling from the uniform distribution on proper 7-colourings of a finite rectangular sub-grid of the infinite square lattice, the grid. A systematic scan Markov chain cycles through finite-size subsets of vertices in a deterministic order and updates the colours assigned to the vertices of each subset. The systematic scan Markov chain that we present cycles through subsets consisting of 2x2 sub-grids and updates the colours assigned to the vertices using a procedure known as heat-bath. We give a computer-assisted proof that this systematic scan Markov chain mixes in O(log n) scans, where n is the size of the rectangular sub-grid. We make use of a heuristic to compute required couplings of colourings of 2x2 sub-grids. This is the first time the mixing time of a systematic scan Markov chain on the grid has been shown to mix for less than 8 colours. We also give partial results that underline the challenges of proving rapid mixing of a systematic scan Markov chain for sampling 6-colourings of the grid by considering 2x3 and 3x3 sub-grids. ", "machine_text": "  We systematically search for 7-colourings of the grid in which no two adjacent squares have the same colour. We show that every such 7-colouring can be obtained from a 3-colouring of the grid by adding two rows and two columns, each of which has all seven colours. We show further that the number of such 7-colourings is equal to the number of ways to 3-colour the grid such that no two adjacent squares have the same colour and no two rows or columns have the same colour. Thus, the number of 7-colourings of the grid is at most 7!2^3. We show that this number is at most 7!2^3 by exhibiting a 7-colouring of the grid with this property and by proving that no 7-colouring of the grid with this property can have a repeated colour. We also show that there are at most 5!2^3 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour. Thus, the number of 7-colourings of the grid is at least 2(5!2^3) greater than the number of 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour. We also show that the number of 7-colourings of the grid is at most 2(5!2^3) less than the number of 3-colourings of the grid with the property that no two adjacent squares have the same colour and no two rows or columns have the same colour.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Using Images to create a Hierarchical Grid Spatial Index. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0204, "human_text": "  This paper presents a hybrid approach to spatial indexing of two dimensional data. It sheds new light on the age old problem by thinking of the traditional algorithms as working with images. Inspiration is drawn from an analogous situation that is found in machine and human vision. Image processing techniques are used to assist in the spatial indexing of the data. A fixed grid approach is used and bins with too many records are sub-divided hierarchically. Search queries are pre-computed for bins that do not contain any data records. This has the effect of dividing the search space up into non rectangular regions which are based on the spatial properties of the data. The bucketing quad tree can be considered as an image with a resolution of two by two for each layer. The results show that this method performs better than the quad tree if there are more divisions per layer. This confirms our suspicions that the algorithm works better if it gets to look at the data with higher resolution images. An elegant class structure is developed where the implementation of concrete spatial indexes for a particular data type merely relies on rendering the data onto an image. ", "machine_text": "  We present a new image representation, which we call a hierarchical grid spatial index, that is designed to improve the efficiency of evaluating queries that require aggregation of image pixels within a specified rectangle. To generate this representation, we first divide each image into a number of tiles. We then identify the edges of these tiles and the boundaries between foreground and background regions. Based on this information, we compute a hierarchical clustering of the tiles to obtain a compact representation of the images. To evaluate a query, we traverse this hierarchy from the root node to the leaf nodes that intersect the query rectangle. We aggregate the pixel values at each level by summing the values in the child nodes. Finally, we return the result to the user. We show that this new representation is particularly useful for evaluating spatial queries that require the aggregation of image pixels within a rectangle. We present experimental results that demonstrate the efficiency of our representation compared to the naive approach of evaluating such queries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unicast and Multicast Qos Routing with Soft Constraint Logic Programming. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1783, "human_text": "  We present a formal model to represent and solve the unicast/multicast routing problem in networks with Quality of Service (QoS) requirements. To attain this, first we translate the network adapting it to a weighted graph (unicast) or and-or graph (multicast), where the weight on a connector corresponds to the multidimensional cost of sending a packet on the related network link: each component of the weights vector represents a different QoS metric value (e.g. bandwidth, cost, delay, packet loss). The second step consists in writing this graph as a program in Soft Constraint Logic Programming (SCLP): the engine of this framework is then able to find the best paths/trees by optimizing their costs and solving the constraints imposed on them (e.g. delay < 40msec), thus finding a solution to QoS routing problems. Moreover, c-semiring structures are a convenient tool to model QoS metrics. At last, we provide an implementation of the framework over scale-free networks and we suggest how the performance can be improved. ", "machine_text": "  We propose a framework for joint unicast and multicast QoS routing using soft constraint logic programming. Our framework is based on a generic mechanism that can handle both unicast and multicast routing with the same formalism. In this framework, a router is abstracted as a label-switching device that receives packets with labeled edges and outputs packets with labeled edges. The input and output labeled edges are related by a set of edge-rewrite rules. A rule specifies the conditions for matching an input edge and the resulting output edge. Our framework handles both quality-driven routing and hop-by-hop routing. In quality-driven routing, the rules are selected to achieve a given QoS requirement, while in hop-by-hop routing, the rules are selected to minimize the number of hops or to achieve some other optimization criteria. We present an implementation of our framework using the DISTO principle, which combines decision-theoretic and heuristic methods to obtain near-optimal solutions to resource-constrained problems. The implementation is evaluated using simulation, and the results are compared with those of other protocols.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The building up of the disk galaxy M33 and the evolution of the\n  metallicity gradient. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3187, "human_text": "  The evolution of radial gradients of metallicity in disk galaxies and its relation with the disk formation are not well understood. Theoretical models of galactic chemical evolution make contrasting predictions about the time evolution of metallicity gradients. To test chemical evolution models and trace the star formation and accretion history of low luminosity disk galaxies we focus on the Local Group galaxy M33. We analyze O/H and S/H abundances in planetary nebulae, H{\\sc ii} regions, and young stars, together with known [Fe/H] abundances in the old stellar population of M33. With a theoretical model, we follow the time evolution of gas (diffuse and condensed in clouds), stars, and chemical abundances in the disk of M33, assuming that the galaxy is accreting gas from an external reservoir. Our model is able to reproduce the available observational constraints on the distribution of gas and stars in M33 and to predict the time evolution of several chemical abundances. In particular, we find that a model characterized by a continuous infall of gas on the disk, at a rate of $\\dot M_{\\rm inf}\\approx 1$ $M_\\odot$ yr$^{-1}$, almost constant with time, can also account for the relatively high rate of star formation and for the shallow chemical gradients. Supported by a large sample of high resolution observations for this nearby galaxy, we conclude that the metallicity in the disk of M33 has increased with time at all radii, with a continuous flattening of the gradient over the last $\\sim 8$ Gyr. ", "machine_text": "  We present a cosmological hydrodynamical model for the formation of the disk galaxy M33, based on the assumption that the accretion of baryonic matter and the metal content are coupled in the process of galaxy evolution. We find that a strong metallicity gradient is naturally built up during the evolution of the disk, with the metal abundance in the core increasing by a factor of about three from the birth to the present time. This is consistent with the observed metallicity distribution in M33, provided that the stars in the core were formed early in the history of the galaxy, while those in the outer parts were formed later. We also show that the large-scale distribution of the molecular hydrogen in M33 is due to a strong evolution of the chemical composition, in particular to the removal of the gas in the core. We discuss the relevance of our results for the understanding of chemical evolution in disk galaxies, and in particular for the controversy about the nature of the molecular hydrogen in M33.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Neutral Networks of Sequence to Shape Maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.076, "human_text": "  In this paper we present a novel framework for sequence to shape maps. These combinatorial maps realize exponentially many shapes, and have preimages which contain extended connected subgraphs of diameter n (neutral networks). We prove that all basic properties of RNA folding maps also hold for combinatorial maps. Our construction is as follows: suppose we are given a graph $H$ over the $\\{1 >...,n\\}$ and an alphabet of nucleotides together with a symmetric relation $\\mathcal{R}$, implied by base pairing rules. Then the shape of a sequence of length n is the maximal H subgraph in which all pairs of nucleotides incident to H-edges satisfy $\\mathcal{R}$. Our main result is to prove the existence of at least $\\sqrt{2}^{n-1}$ shapes with extended neutral networks, i.e. shapes that have a preimage with diameter $n$ and a connected component of size at least $(\\frac{1+\\sqrt{5}}{2})^n+(\\frac{1-\\sqrt{5}}{2})^n$. Furthermore, we show that there exists a certain subset of shapes which carries a natural graph structure. In this graph any two shapes are connected by a path of shapes with respective neutral networks of distance one. We finally discuss our results and provide a comparison with RNA folding maps. ", "machine_text": "  Motivation: While the extraction of shape features from point clouds is well-developed, it is still an open problem to robustly and efficiently extract higher-level properties, such as genus or dimensions, from large point clouds of different shapes. In this work, we focus on the extraction of sequence to shape maps from large point clouds.   Key ideas and methodology: We propose a simple yet effective algorithm to extract sequence to shape maps from large point clouds. Our method takes advantage of the point cloud's local structure and the hierarchical octree to obtain a low-dimensional representation of the input point cloud. In our method, the shape features are extracted from this low-dimensional representation instead of the original point cloud. Since the low-dimensional representation has a much lower dimensionality than the original point cloud, the shape features can be efficiently extracted in our method. Our method has two main steps. In the first step, we construct a hierarchical octree from the input point cloud. In the second step, we extract the shape features from the leaf nodes of the hierarchical octree. The shape features extracted by our method can be used to represent the input point cloud.   Results: We evaluated our method on two benchmark point clouds. Our method achieved state-of-the-art performance in both tests.   Problem work attempts to solve: Our work attempts to solve the problem of extracting sequence to shape maps from large point clouds. Our method is able to robustly and efficiently extract the shape features from large point clouds.   Practical or theoretical applications: The extracted shape features can be used to represent the input point cloud. Our method can be used to extract shape features from large point clouds in practical applications such as object recognition and segmentation. The extracted shape features can also be used in theoretical applications such as shape classification.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fluidization of a vertically oscillated shallow granular layer. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3852, "human_text": "  Molecular dynamics simulations are used to study fluidization of a vertically vibrated, three-dimensional shallow granular layer. As the container acceleration is increased above g, the granular temperature and root mean square particle displacement increase, gradually fluidizing the layer. For nearly elastic particles, or low shaking frequencies, or small layer depths, the end of the fluidization process is marked by an abrupt increase in the granular temperature and rms particle displacement. The layer is then fully fluidized since macroscopic, fluid-like phenomena such as convection rolls and surface waves are observed. Increasing the total dissipation (by either decreasing the restitution coefficient or increasing the total number of particles) decreases the increase in granular temperature and rms particle displacement at fluidization, and shifts the increase to higher accelerations. Increasing the frequency also decreases the magnitude of the jump, and shifts the change to lower accelerations. ", "machine_text": " We study the influence of a rigidly-held plane on the dynamics of a shallow granular layer resting on a rigid foundation. The system is excited vertically and the corresponding wave equation is solved analytically. We find a strong difference between the situations where the plane is located at the top or bottom of the layer. In the former case, the system is in a state of quasi-equilibrium, with the acceleration of the granular material being proportional to the vertical displacement given by the wave equation. This is similar to the case of a vertically-oscillated rigid plane on a liquid, where the notion of criticality has been developed. By contrast, when the plane is located at the bottom of the layer, the system is in a state of complete chaos, with the acceleration of the granular material being proportional to the square of the vertical displacement given by the wave equation. Our results suggest that the state of criticality may be achieved by a continuous adjustment of the height of the plane within the granular layer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Almost the supersymmetric Standard Model from intersecting D6-branes on\n  the Z_6' orientifold. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0646, "human_text": "  Intersecting stacks of supersymmetric fractional branes on the Z_6' orientifold may be used to construct the supersymmetric Standard Model. If a,b are the stacks that generate the SU(3)_{colour} and SU(2)_L gauge particles, then, in order to obtain {\\em just} the chiral spectrum of the (supersymmetric) Standard Model (with non-zero Yukawa couplings to the Higgs mutiplets), it is necessary that the number of intersections a \\cap b of the stacks a and b, and the number of intersections a \\cap b' of a with the orientifold image b' of b satisfy (a \\cap b,a \\cap b')=(2,1) or (1,2). It is also necessary that there is no matter in symmetric representations of the gauge group, and not too much matter in antisymmetric representations, on either stack. Fractional branes having all of these properties may be constructed on the Z_6' orientifold. We construct a (four-stack) model with two further stacks, each with just a single brane, which has precisely the matter spectrum of the supersymmetric Standard Model, including a single pair of Higgs doublets. However, the gauge group is SU(3)_{\\rm colour} x SU(2)_L x U(1)_Y x U(1)_H. Only the Higgs doublets are charged with respect to U(1)_H. ", "machine_text": " We show that there exists a non-trivial class of intersecting D6-branes on the Z_6' orientifold that is almost the supersymmetric Standard Model. The motivation for this work is the following observation: In the minimal supersymmetric extension of the Standard Model, the three generations of fermions are related by the non-trivial braid group symmetry. We can view this as the result of a particular choice of branes in a\ufffd-theory. We show that a choice of D6-branes on the Z_6' orientifold results in a class of models with the same fermionic structure as the minimal supersymmetric extension of the Standard Model. The key idea is to use the (non-existing) theory of D6-branes on Z_6' as a starting point, and show that the choice of D6-branes corresponding to the Standard Model must intersect in a certain way. The methodology is to work with the induced representations on the space of harmonic functions on the sphere, and show that the restriction to the plane gives rise to the Standard Model. We show that such a choice of branes exists by describing the constraints it must satisfy, and then showing that these constraints can be satisfied by a class of non-trivial choices of branes. We also show that this class of models has a natural extension to the full supersymmetric Standard Model by including the three generations of neutrinos. We also discuss the possibility of further extending this class of models to incorporate higher generations of fermions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing String Theory with CMB. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0647, "human_text": "  Future detection/non-detection of tensor modes from inflation in CMB observations presents a unique way to test certain features of string theory. Current limit on the ratio of tensor to scalar perturbations, r=T/S, is r < 0.3, future detection may take place for r > 10^{-2}-10^{-3}. At present all known string theory inflation models predict tensor modes well below the level of detection. Therefore a possible experimental discovery of tensor modes may present a challenge to string cosmology.   The strongest bound on r in string inflation follows from the observation that in most of the models based on the KKLT construction, the value of the Hubble constant H during inflation must be smaller than the gravitino mass. For the gravitino mass in the usual range, m_{3/2} < O(1) TeV, this leads to an extremely strong bound r < 10^{-24}. A discovery of tensor perturbations with r > 10^{-3} would imply that the gravitinos in this class of models are superheavy, m_{3/2} > 10^{13} GeV. This would have important implications for particle phenomenology based on string theory. ", "machine_text": " We have tested string theory by analyzing the cosmic microwave background (CMB) radiation. Our analysis is based on the precise measurements of the CMB anisotropy made by the COBE/FIRAS instrument. We show that the COBE/FIRAS data can be explained by a simple model in which the fluctuations in the CMB are caused by a random scalar field with a large range. This is strong evidence that string theory is a good description of the early universe.  We have also tested string theory by analyzing the CMB using the theory of entanglement. We show that the entanglement between the CMB and a detector can be used to test string theory. The entanglement is largest when the detector is in a state that is correlated with the CMB. This is strong evidence that string theory is a good description of the early universe.  We have also tested string theory by analyzing the CMB using the theory of information. We show that the information content of the CMB can be used to test string theory. The information content is largest when the CMB is in a state that is correlated with the detector. This is strong evidence that string theory is a good description of the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Classification of Finite Dimensional Complex Filiform Leibniz\n  Algebras (Part 2). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3885, "human_text": "  The paper is devoted to classification problem of finite dimensional complex none Lie filiform Leibniz algebras. Actually, the observations show there are two resources to get classification of filiform Leibniz algebras. The first of them is naturally graded none Lie filiform Leibniz algebras and the another one is naturally graded filiform Lie algebras. Using the first resource we get two disjoint classes of filiform Leibniz algebras. The present paper deals with the second of the above two classes, the first class has been considered in our previous paper. The algebraic classification here means to specify the representatives of the orbits, whereas the geometric classification is the problem of finding generic structural constants in the sense of algebraic geometry. Our main effort in this paper is the algebraic classification. We suggest here an algebraic method based on invariants. Utilizing this method for any given low dimensional case all filiform Leibniz algebras can be classified. Moreover, the results can be used for geometric classification of orbits of such algebras. ", "machine_text": "  We continue the study of filiform algebras which we initiated in our previous paper. We classify finite-dimensional complex filiform Leibniz algebras in a way which generalizes the usual classification of finite-dimensional simple Lie algebras. We show that any finite-dimensional complex filiform Leibniz algebra is isomorphic to a subalgebra of a certain standard algebra, and that this standard algebra has a special class of subalgebras which includes all the simple filiform Leibniz algebras. We then give a description of this special class of subalgebras in terms of a maximal parabolic subalgebra and a minimal injective subalgebra. The importance of this work is that it gives a geometric description of the simple filiform Leibniz algebras in terms of parabolic and injective subalgebras. As an application, we show that any finite-dimensional complex filiform Sprague-Grundy algebra is isomorphic to a subalgebra of a certain standard algebra, and that this standard algebra has a special class of subalgebras which includes all the simple filiform Sprague-Grundy algebras. As a by-product, we give a description of the simple filiform Sprague-Grundy algebras in terms of a maximal parabolic subalgebra and a minimal injective subalgebra.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detection of GRB 060927 at z = 5.47: Implications for the Use of\n  Gamma-Ray Bursts as Probes of the End of the Dark Ages. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1257, "human_text": "  We report on follow-up observations of the GRB 060927 using the ROTSE-IIIa telescope and a suite of larger aperture ground-based telescopes. An optical afterglow was detected 20 s after the burst, the earliest rest-frame detection of optical emission from any GRB. Spectroscopy performed with the VLT about 13 hours after the trigger shows a continuum break at lambda ~ 8070 A produced by neutral hydrogen absorption at z~5.6. We also detect an absorption line at 8158 A which we interpret as SiII at z=5.467. Hence, GRB 060927 is the second most distant GRB with a spectroscopically measured redshift. The shape of the red wing of the spectral break can be fitted by a damped Lyalpha profile with a column density with log(N_HI/cm^-2) ~ 22.5. We discuss the implications of this work for the use of GRBs as probes of the end of the dark ages and draw three main conclusions: i) GRB afterglows originating from z>6 should be relatively easy to detect from the ground, but rapid NIR monitoring is necessary to ensure that they are found; ii) The presence of large HI column densities in some GRBs host galaxies at z>5 makes the use of GRBs to probe the reionization epoch via spectroscopy of the red damping wing challenging; iii) GRBs appear crucial to locate typical star-forming galaxies at z>5 and therefore the type of galaxies responsible for the reionization of the universe. ", "machine_text": "  We report the detection of the short-duration gamma-ray burst (GRB) 060927 at z = 5.47, the most distant burst recorded so far. The burst has a fluence of about 2.6 k_W m^-2, and an isotropic-radiation peak energy of about 1.6 k_T, with a redshift-corrected isotropic-radiation energy of about 4.5 k_T. The burst occurs at a glancing angle of about 45 degrees with respect to the line of sight, and the intrinsic energy distribution is well described by a power law with a photon index of about 1.3. The burst is accompanied by a weak optical afterglow, which is detected by the WFC3/UVIS instrument on board the Hubble Space Telescope (HST) with a depth of about 19 mag, and by the ground-based optical telescopes, with an observed magnitude of about 16 mag. The HST observations are used to determine the burst's position to be about 3 arcmin south-west of the Hubble Deep Field (HDF) source DR2227, in the direction of the Subaru Deep Field (SDF). The location is consistent with the burst occurring in a star-forming region, as dust and gas clouds are visible in the HST images. We find that the burst properties are consistent with those expected from a short-duration burst, and that the burst energy is small compared to known bursts at low redshift. We discuss the use of GRBs as probes of the end of the Dark Ages, and find that bursts with an isotropic-radiation energy of at least 2 k_T would be needed to be detected at redshift 5 and beyond, assuming a line-of-sight coverage of 10 percent.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nurturing Breakthroughs: Lessons from Complexity Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1839, "human_text": "  A general theory of innovation and progress in human society is outlined, based on the combat between two opposite forces (conservatism/inertia and speculative herding \"bubble\" behavior). We contend that human affairs are characterized by ubiquitous ``bubbles'', which involve huge risks which would not otherwise be taken using standard cost/benefit analysis. Bubbles result from self-reinforcing positive feedbacks. This leads to explore uncharted territories and niches whose rare successes lead to extraordinary discoveries and provide the base for the observed accelerating development of technology and of the economy. But the returns are very heterogeneous, very risky and may not occur. In other words, bubbles, which are characteristic definitions of human activity, allow huge risks to get huge returns over large scales. We outline some underlying mathematical structure and a few results involving positive feedbacks, emergence, heavy-tailed power laws, outliers/kings/black swans, the problem of predictability and the illusion of control, as well as some policy implications. ", "machine_text": "  We propose that the complexity of the innovation process has important implications for how breakthrough results are achieved. Our research to date indicates that the relationship between the degree of complexity of the innovation process and the characteristics of breakthrough results is nonlinear. We find that as the complexity of the process increases, the number of breakthrough results decreases, but the impact of the results increases significantly. We also find that the rate of introduction of breakthrough results has an inverse relationship with the degree of process complexity, with the rate of introduction of breakthrough results increasing as the complexity of the process decreases. Our work has important implications for the management of innovation and the design of innovation processes.  Our research to date has focused on two broad areas: the study of complexity and the study of innovation. In the first area, we have been developing a theory of complexity and testing it against empirical data. Our work has shown that complexity is a key driver of breakthrough results. We have also been studying the relationship between complexity and the characteristics of breakthrough results. Our work has shown that as the complexity of the process increases, the number of breakthrough results decreases, but the impact of the results increases significantly. In the second area, we have been studying the innovation process and the factors that affect the introduction of breakthrough results. Our work has shown that the rate of introduction of breakthrough results has an inverse relationship with the degree of process complexity, with the rate of introduction of breakthrough results increasing as the complexity of the process decreases.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The metallicity gradient of M 33: chemical abundances of HII regions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3116, "human_text": "  We present spectroscopic observations of a sample of 72 emission-line objects, including mainly HII regions, in the spiral galaxy M 33. Spectra were obtained with the multi-object, wide field spectrograph AF2/WYFFOS at the 4.2m WHT telescope. Line intensities, extinction, and electron density were determined for the whole sample of objects. The aim of the present work was to derive chemical and physical parameters of a set of HII regions, and from them the metallicity gradient. Electron temperatures and chemical abundances were derived for the 14 HII regions where both [OII] and [OIII] emission line fluxes were measured, including the electron temperature sensitive emission line [OIII] 436.3 nm and in a few cases [NII] 575.5 nm. The ionization correction factor (ICF) method was used to derive the total chemical abundances. The presence of abundance gradients was inferred from the radial behaviour of several emission-line ratios, and accurately measured from chemical abundances directly derived in 14 HII regions. The oxygen abundances of our HII regions, located in the radial region from ~2 to ~7.2 kpc, gave an oxygen gradient -0.054+/-0.011 dex/kpc The overall oxygen gradient for M 33 obtained using ours and previous oxygen determinations in a large number of HII regions with direct electron temperature determination as well as abundance in young stars presented a two slope shape: -0.19 dex/kpc for the central regions (R<3kpc), and -0.038dex/kpc for the outer regions (R>=3kpc). ", "machine_text": "  We present a study of the chemical abundances of HII regions in M 33. Our sample consists of HII regions with metallicities that have been determined by a variety of independent methods. We find a good agreement between the metallicities obtained from an analysis of the observed line profiles and those obtained from an analysis of the colors of the HII regions. We find that the metallicities increase towards the outer regions of M 33, in agreement with theoretical predictions of a cosmological chemical evolution model. The increase of the metallicity with radius is well described by a power law of index 1.9 \u00b1 0.1. We also present a comparison between the chemical abundances of HII regions in M 33 and in the Milky Way. In particular, we show that the metallicity of the HII regions in M 33 is, on average, higher than that of the Milky Way, but there is no significant difference in the proportion of elements heavier than iron. We discuss our results in the framework of chemical evolution models, and in particular of the massive-chain-processing model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-sided optimal bounds for Green function of half-spaces for\n  relativistic $\\alpha$-stable process. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1175, "human_text": "  The purpose of this paper is to find optimal estimates for the Green function of a half-space of {\\it the relativistic $\\alpha$-stable process} with parameter $m$ on $\\Rd$ space. This process has an infinitesimal generator of the form $mI-(m^{2/\\alpha}I-\\Delta)^{\\alpha/2},$ where $0<\\alpha<2$, $m>0$, and reduces to the isotropic $\\alpha$-stable process for $m=0$. Its potential theory for open bounded sets has been well developed throughout the recent years however almost nothing was known about the behaviour of the process on unbounded sets. The present paper is intended to fill this gap and we provide two-sided sharp estimates for the Green function for a half-space. As a byproduct we obtain some improvements of the estimates known for bounded sets specially for balls. The advantage of these estimates is a clarification of the relationship between the diameter of the ball and the parameter $m$ of the process.   The main result states that the Green function is comparable with the Green function for the Brownian motion if the points are away from the boundary of a half-space and their distance is greater than one. On the other hand for the remaining points the Green function is somehow related the Green function for the isotropic $\\alpha$-stable process. For example, for $d\\ge3$, it is comparable with the Green function for the isotropic $\\alpha$-stable process, provided that the points are close enough. ", "machine_text": " We establish two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes. Our approach is based on the rigorous analysis of the asymptotic behavior of the solution as the core of the singularity is approached. The rigorous proof of the bounds established in this work is based on a combination of theinside-out algorithm and the lower bound of the Cauchy integral formula. The main motivation for this research is to investigate the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The key idea is to use the rigorous analysis of the singular behavior of the Green function of half-spaces as the core of the singularity is approached. The main methodology is based on the use of the inside-out algorithm combined with the lower bound of the Cauchy integral formula. The results obtained in this work are two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes. The problem this work attempts to solve is to investigate the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The practical application of this work is to develop a rigorous theory for the singular behavior of the Green function of half-spaces for relativistic $\\alpha$-stable processes. The theoretical application of this work is to establish two-sided optimal bounds for the Green function of half-spaces for relativistic $\\alpha$-stable processes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale\n  bar funnelling gas into the nuclear region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3662, "human_text": "  This work is part of the NUGA survey of CO emission in nearby active galaxies. We present observations of NGC4569, a member of the Virgo Cluster. We analyse the molecular gas distribution and kinematics in the central region and we investigate a possible link to the strong starburst present at the nucleus. 70% of the 1.1x10^9 Msolar of molecular gas detected in the inner 20\" is found to be concentrated within the inner 800 pc and is distributed along the large scale stellar bar seen in near-infrared observations. A hole in the CO distribution coincides with the nucleus where most of the Halpha emission and blue light are emitted. The kinematics are modelled in three different ways, ranging from the purely geometrical to the most physical. This approach allows us to constrain progressively the physical properties of the galaxy and eventually to emerge with a reasonable fit to an analytical model of orbits in a barred potential. Fitting an axisymmetric model shows that the non-circular motions must be comparable in amplitude to the circular motions (120 km/s). Fitting a model based on elliptical orbits allows us to identify with confidence the single inner Lindblad resonance (ILR) of the large scale bar. Finally, a model based on analytical solutions for the gas particle orbits in a weakly barred potential constrained by the ILR radius reproduces the observations well. The mass inflow rate is then estimated and discussed based on the best fit model solution. The gravitational torques implied by this model are able to efficiently funnel the gas inside the ILR down to 300 pc, although another mechanism must take over to fuel the nuclear starburst inside 100 pc. ", "machine_text": "  Molecular gas in NUclei of GAlaxies (NUGA) VII. NGC4569, a large scale bar funnelling gas into the nuclear region  We present observations of molecular gas in the nuclear region of NGC4569, a barred spiral galaxy in which a large-scale bar is responsible for funneling gas into the nuclear region, in a fashion similar to that observed in NGC1365. We have imaged with milliarcsecond resolution, by means of Very Long Baseline Interferometry, the distribution of CO, COJ=1-0, and HCN in the nuclear region of NGC4569. We find that the molecular gas is distributed in a bar-like structure, with the bar being oriented at an angle of 30 deg with respect to the optical bar. The bar is covered by a layer of HCN J=1-0, with a peak abundance of log(OCN/H2) = 1.05 +0.06/-0.05. The distribution of molecular gas in the nuclear region is quite different in the two galaxies, reflecting the different processes taking place in the two galaxies. In particular, while the molecular gas in NGC1365 is distributed in a relatively smooth and roundly shaped structure, in NGC4569 the gas is distributed in a rather irregular fashion, with a large number of dense knots along the bar, and a tail of gas streaming out along the minor axis of the bar. We discuss the origin of these different distributions, in the framework of the \"bar-driven\" and \"dating\" scenarios for the evolution of molecular gas in galactic nuclei. We find that the models in their current form cannot produce molecular gas distributions as observed in both galaxies, in particular the distribution of HCN J=1-0 in NGC4569. We discuss the problems of the models, and suggest that the observed distributions of HCN J=1-0 in NGC4569 and in NGC1365 may be the result of different physical processes, taking place at different galactic scales.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HST/FGS Parallaxes of AM CVn Stars and Astrophysical Consequences. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3855, "human_text": "  We present absolute parallaxes and relative proper motions for five AM CVn stars, which we obtained using the Fine Guidance Sensors on board the Hubble Space Telescope. Our parallax measurements translate into distances d(AM CVn)=606+135-93 pc, d(HP Lib)=197+14-12 pc, d(CR Boo)=337+44-35 pc, d(V803 Cen)=347+32-27 pc, and d(GP Com)=75+2-2 pc. From these distances we estimate the space density of AM CVn stars and suggest that previous estimates have been too high by about an order of magnitude. We also infer the mass accretion rates which allows us to constrain the masses of the donor stars, and we show that relatively massive, semi-degenerate donor stars are favored in all systems except GP Com. Finally, we give updated estimates for their gravitational-wave signals, relevant for future space missions such as the proposed Laser Interferometer Space Antenna (LISA), based on their distances and the inferred masses of the binary components. We show that all systems but GP Com are excellent candidates for detection with LISA. ", "machine_text": "  We present new high-precision parallax measurements for 18 stars of the AM CVn type, obtained with the Hubble Space Telescope (HST) and the Fine Guidance Sensor (FGS). These data are combined with previous HST/FGS parallax measurements for 19 other AM CVn stars, resulting in a total of 37 stars with measured parallaxes. We show that the true AM CVn binary Galactic field is much larger than previously thought on the basis of optical observations, and it extends to at least 8 kpc away from the Sun. The new data also suggest that the masses of the AM CVn stars are distributed between 2.5 and 3.5 M\u2299, with a peak at 3.1 M\u2299, in good agreement with the results of the analysis of the optically-selected sample. Finally, we show that the observed distribution of the orbital periods of the AM CVn stars is consistent with the hypothesis that the evolution of these stars is governed by the stripping of their initial hydrogen envelopes, a process that naturally leads to a distribution of orbital periods centered on the synodic period.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electrical transport and optical studies of ferromagnetic Cobalt doped\n  ZnO nanoparticles exhibiting a metal-insulator transition. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1593, "human_text": "  The observed correlation of oxygen vacancies and room temperature ferromagnetic ordering in Co doped ZnO1-o nanoparticles reported earlier (Naeem et al Nanotechnology 17, 2675-2680) has been further explored by transport and optical measurements. In these particles room temperature ferromagnetic ordering had been observed to occur only after annealing in forming gas. In the current work the optical properties have been studied by diffuse reflection spectroscopy in the UV-Vis region and the band gap of the Co doped compositions has been found to decrease with Co addition. Reflections minima are observed at the energies characteristic of Co+2 d-d (tethrahedral symmetry) crystal field transitions, further establishing the presence of Co in substitutional sites. Electrical transport measurements on palletized samples of the nanoparticles show that the effect of a forming gas is to strongly decrease the resistivity with increasing Co concentration. For the air annealed and non-ferromagnetic samples the variation in the resistivity as a function of Co content are opposite to those observed in the particles prepared in forming gas. The ferromagnetic samples exhibit an apparent change from insulator to metal with increasing temperatures for T>380K and this change becomes more pronounced with increasing Co content. The magnetic and resistive behaviors are correlated by considering the model by Calderon et al [M. J. Calderon and S. D. Sarma, Annals of Physics 2007 (Accepted doi: 10.1016/j.aop.2007.01.010] where the ferromagnetism changes from being mediated by polarons in the low temperature insulating region to being mediated by the carriers released from the weakly bound states in the higher temperature metallic region. ", "machine_text": "  We have synthesized ferromagnetic Co doped ZnO nanoparticles of different Co concentration by using sol-gel method and studied their structural, electrical, and optical properties. The synthesized particles were found to have spherical shape with the size of 100-300 nm as confirmed by transmission electron microscopy. The structural study revealed that the particles are single crystalline and the Co atoms are randomly distributed throughout the particles. The magnetic properties of the particles were studied by using a vibrating sample magnetometer and the particles were found to be ferromagnetic below the critical concentration of Co atoms and superparamagnetic above the critical concentration. The particles exhibited a transition from metallic behavior to insulating behavior as the Co concentration was increased. The electrical transport studies showed that the resistivity of the particles increases as the Co concentration was increased and a steep increase in resistivity was observed at the critical concentration. The particles exhibited a thermally activated behavior for the electrical transport below the critical concentration and a behavior close to the Mott variable range hopping below the critical concentration. The optical studies revealed that the particles exhibited a strong absorption peak below the critical concentration and a weak absorption peak above the critical concentration. The results showed that the electrical and optical properties of the particles are sensitive to the concentration of Co atoms and can be used to detect the presence of a magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: BVRI Surface Photometry of Isolated Spiral Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2041, "human_text": "  A release of multicolor broad band (BVRI) photometry for a subsample of 44 isolated spirals drawn from the Catalogue of Isolated Galaxies (CIG) is presented. Total magnitudes and colors at various circular apertures, as well as some global structural/morphological parameters are estimated. Morphology is reevaluated through optical and sharp/filtered R band images, (B-I) color index maps, and archive near-IR JHK images from the Two-Micron Survey. The CAS structural parameters (Concentration, Asymmetry, and Clumpiness) were calculated from the images in each one of the bands. The fraction of galaxies with well identified optical/near-IR bars (SB) is 63%, while a 17% more shows evidence of weak or suspected bars (SAB). The sample average value of the maximum bar ellipticity is 0.4. Half of the galaxies in the sample shows rings. We identify two candidates for isolated galaxies with disturbed morphology. The structural CAS parameters change with the observed band, and the tendencies they follow with the morphological type and global color are more evident in the redder bands. In any band, the major difference between our isolated spirals and a sample of interacting spirals is revealed in the A-S plane. A deep and uniformly observed sample of isolated galaxies is intended for various purposes including (i) comparative studies of environmental effects, (ii) confronting model predictions of galaxy evolution and (iii) evaluating the change of galaxy properties with redshift. ", "machine_text": "  We present surface photometry of 49 isolated spiral galaxies in the optical bands B, V, R, and I obtained with the Subaru Telescope. The sample galaxies were chosen from the 2 Micron All Sky Survey (2MASS) based on their optical counterparts having an axisymmetric (centered) surface brightness profile. We find that the surface brightness profiles of these galaxies are well described by a single power law in the radial direction. We derive the power law index and find that it is independent of the total optical galaxy luminosity and radius. This implies that the surface brightness profiles of isolated spiral galaxies are not a simple function of the scale of the galaxy. The photometry also shows that the surface brightness profile is not axisymmetric for a significant region of the outer disk, a signature of the influence of the presence of the spiral arms. We derive a parameter, , that measures the radial variation of the surface brightness and show that it is correlated with the total optical galaxy luminosity, radius, and the surface brightness at the center. The correlation with the surface brightness at the center implies that the inner 10% of the galaxy is not a simple power law and may contain multiple components including a central point source. The correlation with radius and total luminosity implies that the outer 80% of the galaxy is also not a simple power law. We conclude that the surface brightness profile of isolated spiral galaxies is not described by a single power law over the whole galaxy, but instead is made up of multiple components. The presence of these components has important implications for the evolution of these galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galactic Wind Signatures around High Redshift Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0652, "human_text": "  We carry out cosmological chemodynamical simulations with different strengths of supernova (SN) feedback and study how galactic winds from star-forming galaxies affect the features of hydrogen (HI) and metal (CIV and OVI) absorption systems in the intergalactic medium at high redshift. We find that the outflows tend to escape to low density regions, and hardly affect the dense filaments visible in HI absorption. As a result, the strength of HI absorption near galaxies is not reduced by galactic winds, but even slightly increases. We also find that a lack of HI absorption for lines of sight (LOS) close to galaxies, as found by Adelberger et al., can be created by hot gas around the galaxies induced by accretion shock heating. In contrast to HI, metal absorption systems are sensitive to the presence of winds. The models without feedback can produce the strong CIV and OVI absorption lines in LOS within 50 kpc from galaxies, while strong SN feedback is capable of creating strong CIV and OVI lines out to about twice that distance. We also analyze the mean transmissivity of HI, CIV, and OVI within 1 h$^{-1}$ Mpc from star-forming galaxies. The probability distribution of the transmissivity of HI is independent of the strength of SN feedback, but strong feedback produces LOS with lower transmissivity of metal lines. Additionally, strong feedback can produce strong OVI lines even in cases where HI absorption is weak. We conclude that OVI is probably the best tracer for galactic winds at high redshift. ", "machine_text": "  We present an analysis of the stellar content of galaxies in the high redshift Universe, based on a sample of galaxies selected from the Ultra Deep Survey. We find that the stellar populations of galaxies in the redshift range z < 1 have typical metallicities [Fe/H] > +0.5, whereas galaxies at higher redshift (z >> 1) have metallicities that are a factor of ~2 lower. This difference is interpreted as the effect of a 'galactic wind' that has been removing metals from galaxies in the high redshift Universe. We derive an empirical relation between the stellar metallicity and the galaxies' stellar mass, which we use to infer the metallicities of galaxies at very high redshift (z >> 5), where no useful photometric metallicities can be obtained. We find that these galaxies also show the tell-tale sign of a strong metal-poor population, suggesting that galaxies in the early Universe were much more efficient at removing metals than galaxies in the local Universe. We discuss the implications of our findings for the theory of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gauge symmetry in Kitaev-type spin models and index theorems on odd\n  manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3829, "human_text": "  We construct an exactly soluble spin-$\\frac{1}2$ model on a honeycomb lattice, which is a generalization of Kitaev model. The topological phases of the system are analyzed by study of the ground state sector of this model, the vortex-free states. Basically, there are two phases, A phase and B phase. The behaviors of both A and B phases may be studied by mapping the ground state sector into a general p-wave paired states of spinless fermions with tunable pairing parameters on a square lattice. In this p-wave paired state theory, the A phase is shown to be the strong paired phase, an insulating phase. The B phase may be either gapped or gapless determined by the generalized inversion symmetry is broken or not. The gapped B is the weak pairing phase described by either the Moore-Read Pfaffian state of the spinless fermions or anti-Pfaffian state of holes depending on the sign of the next nearest neighbor hopping amplitude. A phase transition between Pfaffian and anti-Pfaffian states are found in the gapped B phase. Furthermore, we show that there is a hidden SU(2) gauge symmetry in our model. In the gapped B phase, the ground state has a non-trivial topological number, the spectral first Chern number or the chiral central charge, which reflects the chiral anomaly of the edge state. We proved that the topological number is identified to the reduced eta-invariant and this anomaly may be cancelled by a bulk Wess-Zumino term of SO(3) group through an index theorem in 2+1 dimensions. ", "machine_text": "  We study the relation between gauge symmetry and the structure of odd manifolds in the context of Kitaev-type spin models. We show that the common belief that the symmetry of such models is tightly related to the existence of a symmetry group acting on the spins of the model is not correct. We show that the underlying group of the gauge symmetry of a model can be an infinite analog of the symmetry group of the spins, in the sense that it acts on the sets of spins by taking the ordinary symmetric group SO(n) to the symmetric group SO(n+1). We show further that this result does not imply the existence of an action of the underlying group on the spins. As an application, we give a description of the set of index theorems on odd manifolds in terms of the properties of the discriminant of a trilinear form on the constituent vector space of a representation. We show that this description provides a natural way of classifying the index theorems on odd manifolds according to the symmetry of the underlying group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unravelling the morphologies of Luminous Compact Galaxies using the\n  HST/ACS GOODS survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2177, "human_text": "  (Abridged) Luminous Compact Galaxies (LCGs) (M_B < -20, R_{1/2} < 4.5kpc and EW_{0}(OII) >15\\AA) constitute one of the most rapidly evolving galaxy populations over the last ~8 Gyr history of the universe. Due to their inherently compact sizes, any detailed quantitative analysis of their morphologies has proved to be difficult in the past. In this work we use the high angular resolution imaging data, from the HST/ACS GOODS survey, to study the quantitative morphology of a complete sample of LCGs in the redshift range 0.5 < z < 1.2. We have derived structural parameters for a representative sample of 39 LCGs selected from the GOODS-S field, using full 2-dimensional surface brightness profile fitting of the galaxy images in each of the four filters available. B-z color maps are used as an aid in the morphological classification. We then use the rest frame B band bulge flux fraction (B/T) to determine the morphological class of the galaxies. Mergers were essentially identified visually by the presence of multiple maxima of comparable intensity in the rest frame B band images, aided by the color maps to distinguish them from HII regions. We derive the following morphological mix for our sample of intermediate redshift LCGs: Mergers: ~36%, Disk dominated: ~22%, S0: ~20%, Early types: ~7%, Irr/tadpole: ~15%. We establish that our sample LCGs are intermediate mass objects with a median stellar mass of Log(M/M_{\\odot})=10.32. We also derive dust enshrouded SFR values ranging from a few to ~65 $M_{\\odot}$/year using Spitzer 24$\\mu m$ data. We estimate a factor ~11 fall in the comoving number density of blue LCGs from redshifts 0.5 < z < 1.2 to the current epoch. We finally discuss the evolutionary scenario of these LCGs which might give us some clues regarding their descendants in the local universe. ", "machine_text": "  Unravelling the morphologies of Luminous Compact Galaxies using the HST/ACS GOODS survey  We present a statistical analysis of the morphologies and photometric properties of a sample of 25 Luminous Compact Galaxies (LCGs) selected from the HST/ACS GOODS survey. We use the+/ - aperture photometry and the two-band colour information from the survey to determine the photometric parameters of our sample, and to probe the nature of the observed morphologies. We find that the LCGs in our sample are log(M/Mpc2) 10.5 +/- 1.4, which is consistent with the notion that LCGs are the most compact galactic objects in the Universe. We show that a simple model in which the observed photometric properties are related to the underlying stellar mass, via a power-law scale length, can quantitatively reproduce the observed morphology distribution, without the need to invoke specific physical mechanisms such as the bars and slingshot from the centre. We also show that the observed distribution of colour excesses can be reproduced by a simple model in which the colour excess is related to the local surface or volume density, and is not related to the overall shape of the galaxy. We discuss our results in the context of the current theory of LCG formation, and identify the regions of agreement and disagreement between the predictions of theory and the results of our analysis.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Augmented Sparse Reconstruction of Protein Signaling Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3989, "human_text": "  The problem of reconstructing and identifying intracellular protein signaling and biochemical networks is of critical importance in biology today. We sought to develop a mathematical approach to this problem using, as a test case, one of the most well-studied and clinically important signaling networks in biology today, the epidermal growth factor receptor (EGFR) driven signaling cascade. More specifically, we suggest a method, augmented sparse reconstruction, for the identification of links among nodes of ordinary differential equation (ODE) networks from a small set of trajectories with different initial conditions. Our method builds a system of representation by using a collection of integrals of all given trajectories and by attenuating block of terms in the representation itself. The system of representation is then augmented with random vectors, and minimization of the 1-norm is used to find sparse representations for the dynamical interactions of each node. Augmentation by random vectors is crucial, since sparsity alone is not able to handle the large error-in-variables in the representation. Augmented sparse reconstruction allows to consider potentially very large spaces of models and it is able to detect with high accuracy the few relevant links among nodes, even when moderate noise is added to the measured trajectories. After showing the performance of our method on a model of the EGFR protein network, we sketch briefly the potential future therapeutic applications of this approach. ", "machine_text": "  We present a new algorithm for sparse reconstruction of continuous-time dynamic models from DNA microarray time-series data. We assume that the underlying dynamical system is described by a set of ordinary differential equations and that the microarray data is obtained by sampling the system at finite and uniform time intervals. The proposed method is based on the Augmented Lagrangian method for sparse optimization. The new algorithm is tested on a number of synthetic examples and the results are compared to those obtained by the original Lagrangian method as well as to those obtained by the widely used Partial Least Squares (PLS) method. We also apply the new algorithm to the analysis of real microarray data sets, obtained from a publicly available resource. In all cases, the proposed method gives comparable or better results than the original Lagrangian method and the PLS method, in terms of both the quality of the reconstructed system and the statistical significance of the parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spherically symmetric problem on the brane and galactic rotation curves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0649, "human_text": "  We investigate the braneworld model with induced gravity to clarify the role of the cross-over length scale \\ell in the possible explanation of the dark-matter phenomenon in astrophysics and in cosmology. Observations of the 21 cm line from neutral hydrogen clouds in spiral galaxies reveal that the rotational velocities remain nearly constant at a value v_c ~ 10^{-3}--10^{-4} in the units of the speed of light in the region of the galactic halo. Using the smallness of v_c, we develop a perturbative scheme for reconstructing the metric in a galactic halo. In the leading order of expansion in v_c, at the distances r \\gtrsim v_c \\ell, our result reproduces that obtained in the Randall-Sundrum braneworld model. This inequality is satisfied in a real spiral galaxy such as our Milky Way for distances r ~ 3 kpc, at which the rotational velocity curve becomes flat, v_c ~ 7 \\times 10^{-4}, if \\ell \\lesssim 2 Mpc. The gravitational situation in this case can be approximately described by the Einstein equations with the so-called Weyl fluid playing the role of dark matter. In the region near the gravitating body, we derive a closed system of equations for static spherically symmetric situation under the approximation of zero anisotropic stress of the Weyl fluid. We find the Schwarzschild metric to be an approximate vacuum solution of these equations at distances r \\lesssim (r_g \\ell^2)^{1/3}. The value \\ell \\lesssim 2 Mpc complies well with the solar-system tests. At the same time, in cosmology, a low-density braneworld with \\ell of this order of magnitude can mimic the expansion properties of the high-density LCDM (lambda + cold dark matter) universe at late times. Combined observations of galactic rotation curves and gravitational lensing can possibly discriminate between the higher-dimensional effects and dark matter. ", "machine_text": " We consider a spherically symmetric problem on the brane and galactic rotation curves. The motivation for the research is to investigate the mechanism of the formation of the galactic rotation curves. The key ideas and methodology are to consider a spherically symmetric potential field $V(r)$, and the induced metric $g(r)$ is obtained by the metric theorem. The spherically symmetric solution with a potential $V(r)$ is obtained by the separation of variables. The galactic rotation curve is the solution of the Poisson equation with a piecewise constant right-hand side, which is the restriction of the solution to the galactic plane. The result obtained is that the galactic rotation curve is the solution of the Poisson equation with a piecewise constant right-hand side, which is the restriction of the solution to the galactic plane. The problem the work attempts to solve is that the mechanism of the formation of the galactic rotation curves is investigated. The work also attempts to show that the potential field $V(r)$ can be obtained by the integration of the divergence of the matter density $\\rho(r)$ in the galactic plane. Any practical or theoretical applications from your findings or implications for future research should be described. The work is applied to the galactic rotation curves and the result obtained is consistent with the observation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Redesigning Computer-based Learning Environments: Evaluation as\n  Communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1127, "human_text": "  In the field of evaluation research, computer scientists live constantly upon dilemmas and conflicting theories. As evaluation is differently perceived and modeled among educational areas, it is not difficult to become trapped in dilemmas, which reflects an epistemological weakness. Additionally, designing and developing a computer-based learning scenario is not an easy task. Advancing further, with end-users probing the system in realistic settings, is even harder. Computer science research in evaluation faces an immense challenge, having to cope with contributions from several conflicting and controversial research fields. We believe that deep changes must be made in our field if we are to advance beyond the CBT (computer-based training) learning model and to build an adequate epistemology for this challenge. The first task is to relocate our field by building upon recent results from philosophy, psychology, social sciences, and engineering. In this article we locate evaluation in respect to communication studies. Evaluation presupposes a definition of goals to be reached, and we suggest that it is, by many means, a silent communication between teacher and student, peers, and institutional entities. If we accept that evaluation can be viewed as set of invisible rules known by nobody, but somehow understood by everybody, we should add anthropological inquiries to our research toolkit. The paper is organized around some elements of the social communication and how they convey new insights to evaluation research for computer and related scientists. We found some technical limitations and offer discussions on how we relate to technology at same time we establish expectancies and perceive others work. ", "machine_text": "  Redesigning Computer-based Learning Environments: Evaluation as Communication The increasing use of computer technology in schools has led to the development of a variety of computer-based learning environments. In spite of the potential of these new environments to support learning, their current use does not always result in effective learning. This is due in part to the fact that the development of these environments has not been based on sound educational principles. In addition, the fact that these environments are new and often quite complex means that teachers often do not have the necessary skills and knowledge to use them effectively. In this article, we discuss the results of a research project in which we redesigned a computer-based learning environment, with the aim of making it more effective for learning. The key idea behind the redesign was that the environment should be based on sound educational principles and that it should be evaluated in terms of how well it supported learning. We discuss the results of our evaluation, which showed that the redesigned environment was more effective for learning than the original environment. We also discuss the implications of our results for the design and evaluation of computer-based learning environments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Wavelet transforms in a critical interface model for Barkhausen noise. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1574, "human_text": "  We discuss the application of wavelet transforms to a critical interface model, which is known to provide a good description of Barkhausen noise in soft ferromagnets. The two-dimensional version of the model (one-dimensional interface) is considered, mainly in the adiabatic limit of very slow driving. On length scales shorter than a crossover length (which grows with the strength of surface tension), the effective interface roughness exponent $\\zeta$ is $\\simeq 1.20$, close to the expected value for the universality class of the quenched Edwards-Wilkinson model. We find that the waiting times between avalanches are fully uncorrelated, as the wavelet transform of their autocorrelations scales as white noise. Similarly, detrended size-size correlations give a white-noise wavelet transform. Consideration of finite driving rates, still deep within the intermittent regime, shows the wavelet transform of correlations scaling as $1/f^{1.5}$ for intermediate frequencies. This behavior is ascribed to intra-avalanche correlations. ", "machine_text": "  Wavelet Transforms in a Critical Interface Model for Barkhausen Noise  We investigate the problem of statistical learning of a boundary between two different physical systems, where the observed data is generated by the critical coupling of the systems. Such problems arise, for example, in phase transitions between different statistical mechanics systems, in systems biology, or in the case of threshold-like phenomena in engineering. We consider a model problem in which the observations are samples from a random walk on a lattice, with a randomly chosen step size, and where the transition to a different random walk with a different step size occurs at a threshold value of the step size. The unknown threshold value is estimated from the data by using a wavelet transform. We show that both the empirical distribution of the wavelet coefficients and the minimum cross-validation error of the estimated threshold follow a heavy-tailed distribution, and we provide a rigorous theoretical explanation for this fact. We also show that the learned boundary can be used to generate new, synthetic data with a desired statistical properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer Mid-Infrared Spectroscopy of Infrared Luminous Galaxies at z~2\n  II: Diagnostics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1765, "human_text": "  We present mid-IR spectral decomposition of a sample of 48 Spitzer-selected ULIRGs spanning z~1-3 and likely L_IR~10^12-10^13Lsun. Our study aims at quantifying the star-formation and AGN processes in these sources which recent results suggest have evolved strongly between the observed epoch and today. To do this, we study the mid-IR contribution of PAH emission, continuum, and extinction. About 3/4 of our sample are continuum- (i.e. AGN) dominated sources, but ~60% of these show PAH emission, suggesting the presence of star-formation activity. These sources have redder mid-IR colors than typical optically-selected quasars. About 25% of our sample have strong PAH emission, but none are likely to be pure starbursts as reflected in their relatively high 5um hot dust continua. However, their steep 30um-to-14um slopes suggest that star-formation might dominate the total infrared luminosity. Six of our z~2 sources have EW6.2>~0.3um and L_14um>~10^12Lsun (implying L_IR>~10^13Lsun). At these luminosities, such high EW6.2 ULIRGs do not exist in the local Universe. We find a median optical depth at 9.7um of <tau_9.7>=1.4. This is consistent with local IRAS-selected ULIRGs, but differs from early results on SCUBA-selected z~2 ULIRGs. Similar to local ULIRGs about 25% of our sample show extreme obscuration (tau_9.7>~3) suggesting buried nuclei. In general, we find that our sources are similar to local ULIRGs, but are an order of magnitude more luminous. It is not clear whether our z~2 ULIRGs are simply scaled-up versions of local ULIRGs, or subject to fundamentally different physical processes. ", "machine_text": "  We present a diagnostic study of a sample of infrared luminous galaxies (ILGs) selected from the Spitzer Survey of Stellar Structure in Galaxies at z~2, using the Spitzer Mid-Infrared Spectrograph (SMIRS) to measure the gas mass and the stellar mass. We find that the gas mass of these ILGs is, on average, only 1.4 times the stellar mass, and that the distribution of gas masses is well described by a power law with a linear regression fit of the form log(gas mass/stellar mass) = 1.29 + 0.52(stellar mass)^{-0.37}, where the stellar mass is expressed in units of $10^{10} \\ M_{\\odot}$. This is consistent with a simple model in which the gas mass is a constant fraction (1.4) of the stellar mass, regardless of the galaxy's absolute magnitude, density, or star formation rate (SFR). The model also predicts that the minimum gas mass is equal to the stellar mass, and that the gas mass increases superlinearly with the stellar mass. We discuss the implications of our results for models of galaxy formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SubmilliJansky Transients in Archival Radio Observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3158, "human_text": "  [ABRIDGED] We report the results of a 944-epoch survey for transient sources with archival data from the Very Large Array spanning 22 years with a typical epoch separation of 7 days. Observations were obtained at 5 or 8.4 GHz for a single field of view with a full-width at half-maximum of 8.6' and 5.1', respectively, and achieved a typical point-source detection threshold at the beam center of ~300 microJy per epoch. Ten transient sources were detected with a significance threshold such that only one false positive would be expected. Of these transients, eight were detected in only a single epoch. Two transients were too faint to be detected in individual epochs but were detected in two-month averages. None of the ten transients was detected in longer-term averages or associated with persistent emission in the deep image produced from the combination of all epochs. The cumulative rate for the short timescale radio transients above 370 microJy at 5 and 8.4 GHz is 0.07 < R < 40 deg^-2 yr^-1, where the uncertainty is due to the unknown duration of the transients, 20 min < t_char < 7 days. A two-epoch survey for transients will detect 1.5 +/- 0.4 transient per square degrees above a flux density of 370 microJy. Two transients are associated with galaxies at z=0.040 and z=0.249. These may be similar to the peculiar Type Ib/c radio supernova SN 1998bw associated with GRB 980428. Six transients have no counterparts in the optical or infrared (R=27, Ks=18). The hosts and progenitors of these transients are unknown. ", "machine_text": "  We present a method to search archival radio observations for transients with sensitivity below one Jansky. We show that archival Very Long Baseline Interferometry (VLBI) observations can be searched with a sensitivity of  \u223c 1 \u03bcJansky with a signal-to-noise ratio of  \u223c 5, without any special processing. We present a catalog of 13 new transient sources found in archival VLBI observations, including three sources with fluxes above 10 \u03bcJansky. These transients are correlated with previously known transient sources in the Galactic plane, supporting the hypothesis that the transient population is tightly coupled to the Galactic magnetic field. We find that the observed transient distribution has a power law dependence on Galactic longitude  \u223c -0.35, which is consistent with a simple model in which the transient distribution is controlled by the local magnetic field configuration. Our results imply that the population of transient sources in the Galactic plane is several orders of magnitude larger than previously thought on the basis of optical observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Clustering Coefficients of Protein-Protein Interaction Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3748, "human_text": "  The properties of certain networks are determined by hidden variables that are not explicitly measured. The conditional probability (propagator) that a vertex with a given value of the hidden variable is connected to k of other vertices determines all measurable properties. We study hidden variable models and find an averaging approximation that enables us to obtain a general analytical result for the propagator. Analytic results showing the validity of the approximation are obtained. We apply hidden variable models to protein-protein interaction networks (PINs) in which the hidden variable is the association free-energy, determined by distributions that depend on biochemistry and evolution. We compute degree distributions as well as clustering coefficients of several PINs of different species; good agreement with measured data is obtained. For the human interactome two different parameter sets give the same degree distributions, but the computed clustering coefficients differ by a factor of about two. This shows that degree distributions are not sufficient to determine the properties of PINs. ", "machine_text": " We introduce and study a new index, the clustering coefficient of a graph, which measures the density of triangles in the graph. We show that this index is a robust measure of the clustering of the graph, in the sense that it is insensitive to the details of the graph, provided that it is large enough. We apply this new index to protein-protein interaction networks, and show that it can be used to detect communities and to evaluate the significance of an observed community structure. We find that the clustering coefficients of real protein-protein interaction networks are significantly higher than random graphs with the same degree distribution, and we show this by using both a random graph generator and by generating all possible graphs with a given degree distribution. We show that this result is consistent with a model in which the proteins in a network tend to form communities of size three. We also find that the size of the largest community is a good measure of the complexity of the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Gemini Deep Planet Survey -- GDPS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.429, "human_text": "  We present the results of the Gemini Deep Planet Survey, a near-infrared adaptive optics search for giant planets and brown dwarfs around nearby young stars. The observations were obtained with the Altair adaptive optics system at the Gemini North telescope and angular differential imaging was used to suppress the speckle noise of the central star. Detection limits for the 85 stars observed are presented, along with a list of all faint point sources detected around them. Typically, the observations are sensitive to angular separations beyond 0.5\" with 5-sigma contrast sensitivities in magnitude difference at 1.6 micron of 9.5 at 0.5\", 12.9 at 1\", 15.0 at 2\", and 16.5 at 5\". For the typical target of the survey, a 100 Myr old K0 star located 22 pc from the Sun, the observations are sensitive enough to detect planets more massive than 2 Mjup with a projected separation in the range 40-200 AU. Second epoch observations of 48 stars with candidates (out of 54) have confirmed that all candidates are unrelated background stars. A detailed statistical analysis of the survey results, yielding upper limits on the fractions of stars with giant planet or low mass brown dwarf companions, is presented. Assuming a planet mass distribution dN/dm m^{-1.2} and a semi-major axis distribution dN/da a^{-1}, the 95% credible upper limits on the fraction of stars with at least one planet of mass 0.5-13 Mjup are 0.28 for the range 10-25 AU, 0.13 for 25-50 AU, and 0.093 for 50-250 AU. The 95% credible interval for the fraction of stars with at least one brown dwarf companion having a semi-major axis in the range 25-250 AU is 0.019 (-0.015/+0.083), irrespective of any assumption on the mass and semi-major axis distributions. The stars HD 14802, HD 166181, and HD 213845 have been resolved into binaries for the first time. ", "machine_text": "  The Gemini Deep Planet Survey -- GDPS  The Gemini Deep Planet Survey (GDPS) is an optical/NIR imaging survey of the solar system's giant planets and their satellites, and the small bodies in the Kuiper Belt, using the international Gemini Observatory. The primary goal of the survey is to study the atmosphere of Jupiter and the structure and evolution of its ring and satellite system, in order to improve our understanding of the planet's history and fate. We will also study the structure and evolution of the satelliets of Saturn, Uranus, and Neptune, as well as the Kuiper Belt.  We have completed our survey of the giant planets and their satellites, and are now conducting a dedicated survey of the Kuiper Belt. The giant planet survey has resulted in the discovery of many new satellites, and a reclassification of the rings of Saturn and Uranus. The Kuiper Belt survey has resulted in the discovery of many new objects, and a better understanding of the belt's population.  The GDPS is a joint project of the Gemini Observatory, the California Institute of Technology, and the University of Hawaii. The survey is being conducted with the international Gemini Observatory, using the twin 8-m telescopes on Hawaii and Chile, and the infrared imaging capabilities of the W.M. Keck Observatory, also on Hawaii.  We have produced a number of scientific results. Here we present some of the key results from the survey.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetorotational Collapse of Population III Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1945, "human_text": "  We perform a series of two-dimensional magnetorotational core-collapse simulations of Pop III stars. Changing the initial distributions of rotation and magnetic fields prior to collapse in a parametric manner, we compute 19 models. By so doing, we systematically investigate how rotation and magnetic fields affect the collapse dynamics and explore how the properties of the black-hole formations and neutrino emissions could be affected. As for the microphysics, we employ a realistic equation of state and approximate the neutrino transfer by a multiflavour leakage scheme. With these computations, we find that the jet-like explosions are obtained by the magnetodriven shock waves if the initial magnetic field is as large as $10^{12}$ G. We point out that the black-hole masses at the formation decrease with the initial field strength, on the other hand, increase with the initial rotation rates. As for the neutrino properties, we point out that the degree of the differential rotation plays an important role to determine which species of the neutrino luminosity is more dominant than the others. Furthermore, we find that the stronger magnetic fields make the peak neutrino luminosities smaller, because the magnetic pressure acts to halt the collapse in the central regions, leading to the suppression of the releasable gravitational binding energies. ", "machine_text": " We propose that massive Population III stars with weak magnetic fields can form through the magnetorotational collapse of a rotating cloud. We show that such a collapse can occur provided that the magnetic field is sufficiently diluted, the angular momentum is high enough, and the resistivity is low. The simplest case we consider is a uniform magnetic field along the rotation axis. In this case, the instability is triggered when the ratio of the resistivity to the angular momentum per unit mass, \u03c1/L\u22c5kg\u20131, decreases below a critical value of \u03c1/L\u22c5kg\u20131\u22483.3\u00d71020\u03a9m. We show that this condition can be satisfied if the magnetic field is sufficiently weak (B\u22725G) and the angular momentum is high (L\u2273107kg\u22c5m2), as can be the case in a collapsing rotating cloud. The critical resistivity for the instability to be triggered increases with the magnetic field and reaches \u03c1\u22485\u00d71020\u03a9m when B\u22485G. We also consider the more general case of a radially varying magnetic field, which is likely to be present in a collapsing cloud that formed through the accretion of rotating magnetized infalling material. We show that for a collapsing cloud to be stable against the magnetorotational instability, the radial profile of the resistivity has to satisfy \u03c1\u22655\u00d71020\u03a9m, with \u03c1 being the resistivity at the cloud's inner radius. We discuss the effect of the ionization fraction on the critical resistivity and find that a cloud can be stable against the magnetorotational instability even if the ionization fraction \u0393 is relatively high, provided that \u03c1\u2265\u0393\u22c5\u03c10, where \u03c10 is the resistivity of an uncharged gas and \u0393\u22c5\u03c10\u22481020\u03a9m. We also derive a simple expression for the evolution of the frequency \u03c9 of the observed gravitational waves during the magnetorotational collapse of a massive Population III star and find that \u03c9 can be as low as \u03c9\u22481 Hz.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Complexity of Model Checking Higher-Order Fixpoint Logic. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3931, "human_text": "  Higher-Order Fixpoint Logic (HFL) is a hybrid of the simply typed \\lambda-calculus and the modal \\lambda-calculus. This makes it a highly expressive temporal logic that is capable of expressing various interesting correctness properties of programs that are not expressible in the modal \\lambda-calculus.   This paper provides complexity results for its model checking problem. In particular we consider those fragments of HFL built by using only types of bounded order k and arity m. We establish k-fold exponential time completeness for model checking each such fragment. For the upper bound we use fixpoint elimination to obtain reachability games that are singly-exponential in the size of the formula and k-fold exponential in the size of the underlying transition system. These games can be solved in deterministic linear time. As a simple consequence, we obtain an exponential time upper bound on the expression complexity of each such fragment.   The lower bound is established by a reduction from the word problem for alternating (k-1)-fold exponential space bounded Turing Machines. Since there are fixed machines of that type whose word problems are already hard with respect to k-fold exponential time, we obtain, as a corollary, k-fold exponential time completeness for the data complexity of our fragments of HFL, provided m exceeds 3. This also yields a hierarchy result in expressive power. ", "machine_text": "  We introduce a technique for combining two fundamental concepts of formal system theory, namely (termination) proof checking and ( Fixpoint ) model checking. The motivation for this work is the fact that termination can be viewed as an automatically generated ( recursive ) bisimulation class, and the question arises whether the technique of model checking can be used to automatically check the termination of a system. Our main result is that this is not possible in general, but that it is possible to construct a class of logic programs for which termination can be checked efficiently by model checking. We show how this result can be used to extract a class of logic programs for which the question of whether a program has an infinite execution can be answered by model checking. We also consider a more general setting, in which the class of systems for which model checking can answer the question of termination is significantly enlarged. In this setting, we show how to reduce the problem of termination to a problem of model checking.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Signatures of SUSY Dark Matter at the LHC and in the Spectra of Cosmic\n  Rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3943, "human_text": "  This thesis discusses the search for supersymmetry at the future Large Hadron Collider (LHC) and the ongoing construction of one of the four large LHC experiments, the Compact Muon Solenoid (CMS), and focuses on the detection of signals from the annihilation of supersymmetric dark matter in the spectra of cosmic rays.   Measurements of cosmic ray antiparticles, such as positrons, can impose strong constraints on the nature of new physics beyond the Standard Model. However, cosmic ray positron measurements are experimentally very challenging due to the vast proton background. A novel approach of positron identification with the space-borne AMS-01 experiment, namely through the detection of bremsstrahlung conversion in a silicon microstrip detector, is introduced. Bremsstrahlung from protons is suppressed by a factor of more than 3*10^6 with respect to positrons. The results of the positron measurement show that the bremsstrahlung approach extends the sensitivity range of AMS-01 to positron momenta up to 50 GeV/c, which is far beyond the original scope of the experiment. At momenta above 8 GeV/c there is indication for a positron overabundance with respect to model predictions for purely secondary positron production. Therefore, the AMS-01 data lend further weight to the hints of a positron overabundance seen in the data from earlier experiments.   The positron fraction measurements from the most recent experiments are combined with the results of this analysis, giving the most precise positron fraction data yet available. ", "machine_text": "  We propose signatures of weakly-interacting massive particles (WIMPs) of supersymmetric (SUSY) dark matter (DM) in the data from large-scale experiments at the LHC and in the spectra of cosmic rays (CRs). For the LHC experiments, we show that the semi-leptonic and radiative signals of WIMPs in the hadron final states are within the reach of the LHC, and we discuss the prospects of the LHC in searching for the SUSY WIMPs in the multi-tonne and TeV mass ranges. We also show that the expected rate of WIMP-nucleon collisions is large enough to produce the chorus of low-energy neutrinos observed by the IceCube experiment, provided that the WIMP mass is no heavier than a few TeV. As for the CRs, we show that the spectral distribution of CRs is consistent with the picture that the supergravity (SG) scale is close to the CR energy scale, provided that the mass of the lightest SUSY particle (LSP) is not heavier than a few TeV. We also show that the pattern of the primary and secondary CRs is consistent with the picture that the world-line of the CRs is affected by a small-scale (60-120GeV) Brantian symmetry, provided that the LSP mass is not heavier than a few TeV. Our results suggest that a lightweight SUSY scenario is preferred over a heavy SUSY scenario for the DM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Universality of the REM for dynamics of mean-field spin glasses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2135, "human_text": "  We consider a version of a Glauber dynamics for a p-spin Sherrington--Kirkpatrick model of a spin glass that can be seen as a time change of simple random walk on the N-dimensional hypercube. We show that, for any p>2 and any inverse temperature \\beta>0, there exist constants g>0, such that for all exponential time scales, $\\exp(\\gamma N)$, with $\\gamma< g$, the properly rescaled clock process (time-change process), converges to an \\alpha-stable subordinator where \\alpha=\\gamma/\\beta^2<1. Moreover, the dynamics exhibits aging at these time scales with time-time correlation function converging to the arcsine law of this \\alpha-stable subordinator. In other words, up to rescaling, on these time scales (that are shorter than the equilibration time of the system), the dynamics of p-spin models ages in the same way as the REM, and by extension Bouchaud's REM-like trap model, confirming the latter as a universal aging mechanism for a wide range of systems. The SK model (the case p=2) seems to belong to a different universality class. ", "machine_text": "  We consider a family of generalized spin glasses with long-range interactions and study the Universality of the REM (Response to External Fields) for their dynamics. We show that, for glasses whose symmetry is not too badly broken by the external fields, the dynamics is described by a set of master equations which are symmetric under the action of the internal symmetry group of the glass. This symmetry is not an exact one however, and is modified by a certain form of theuidyl representation. Our results are consistent with a large number of exactly solvable models which can be thought of as \"derived\" from the master equations by a process of \" froze-in\" symmetry breaking. In a second part we consider the case of glasses whose symmetry is badly broken by the external fields. We show that the corresponding dynamics is given by a set of differential equations which are symmetric under the action of the internal symmetry group. This symmetry is not an exact one however, and is modified by a certain form of theuidyl representation. Our results are consistent with a large number of exactly solvable models which can be thought of as \"derived\" from the differential equations by a process of \" froze-in\" symmetry breaking.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: XMM-Newton observations of the first unidentified TeV gamma-ray source\n  TeV J2032+4130. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0009, "human_text": "  (abridged) The first unidentified very high energy gamma ray source (TeV J2032+4130) in the Cygnus region has been the subject of intensive search for a counterpart source at other wavelengths. A deep ($\\approx 50$ ksec) exposure of TeV J2032+4130 with \\textit{XMM-Newton} has been obtained. The contribution of point sources to the observed X-ray emission from TeV J2032+4130 is subtracted from the data. The point-source subtracted X-ray data are analyzed using blank sky exposures and regions adjacent to the position of TeV J2032+4130 in the field of view covered by the XMM-Newton telescopes to search for diffuse X-ray emission. An extended X-ray emission region with a full width half maximum (FWHM) size of $\\approx 12$ arc min is found. The centroid of the emission is co-located with the position of TeV J2032+4130.The energy spectrum of the emission coinciding with the position and extension of TeV J2032+4130 can be modeled by a power-law model with a photon index $\\Gamma=1.5\\pm0.2_\\mathrm{stat}\\pm0.3_\\mathrm{sys}$ and an energy flux integrated between 2 and 10 keV of $f_{2-10 \\mathrm{keV}} \\approx 7\\cdot 10^{-13}$ ergs/(cm$^2$ s) which is lower than the very high energy gamma-ray flux observed from TeV J2032+4130. We conclude that the faint extended X-ray emission discovered in this observation is the X-ray counterpart of TeV J2032+4130. Formally, it can not be excluded that the extended emission is due to an unrelated population of faint, hot ($k_BT\\approx 10$ keV) unresolved point-sources which by chance coincides with the position and extension of TeV J2032+4130. We discuss our findings in the frame of both hadronic and leptonic gamma-ray production scenarios. ", "machine_text": " We present XMM-Newton observations of the first unidentified TeV gamma-ray source, TeV J2032+4130. We find that the X-ray and gamma-ray emission is due to a single entity. The X-ray spectrum is described by a power law with a photon index of 1.9 and a temperature of 3 kT. The intensity is modulated with a source count rate of $6 \\times 10^{-4}$ s$^{-1}$ and a morphology consistent with a single source. The Compton-thinning ratio is 1.5, indicating that the bulk of the gamma-ray emission is likely to be due to thermal Compton-scattering of the X-ray radiation. A 1-10 keV peak luminosity of $3 \\times 10^{36}$ erg s$^{-1}$ and a duty cycle of $25 \\%$ suggest a highly variable and transient source. The observed properties of the source are consistent with a single Wolf-Rayet star with a strong magnetic field and a non-spherically symmetric distribution of matter. We discuss the properties of the source in the context of known Wolf-Rayet stars and the phenomena that may produce the observed X-ray and gamma-ray emission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lifetime Improvement of Wireless Sensor Networks by Collaborative\n  Beamforming and Cooperative Transmission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3396, "human_text": "  Extending network lifetime of battery-operated devices is a key design issue that allows uninterrupted information exchange among distributive nodes in wireless sensor networks. Collaborative beamforming (CB) and cooperative transmission (CT) have recently emerged as new communication techniques that enable and leverage effective resource sharing among collaborative/cooperative nodes. In this paper, we seek to maximize the lifetime of sensor networks by using the new idea that closely located nodes can use CB/CT to reduce the load or even avoid packet forwarding requests to nodes that have critical battery life. First, we study the effectiveness of CB/CT to improve the signal strength at a faraway destination using energy in nearby nodes. Then, a 2D disk case is analyzed to assess the resulting performance improvement. For general networks, if information-generation rates are fixed, the new routing problem is formulated as a linear programming problem; otherwise, the cost for routing is dynamically adjusted according to the amount of energy remaining and the effectiveness of CB/CT. From the analysis and simulation results, it is seen that the proposed schemes can improve the lifetime by about 90% in the 2D disk network and by about 10% in the general networks, compared to existing schemes. ", "machine_text": "   Lifetime Improvement of Wireless Sensor Networks by Collaborative Beamforming and Cooperative Transmission. Wireless sensor networks have many applications in monitoring, tracking and controlling the systems in various fields. In this paper, we study the lifetime of wireless sensor networks (WSNs) using collaborative beamforming and cooperative transmission techniques. We consider the energy efficiency as a performance metric to improve the lifetime of WSNs. The conventional multi-hop WSNs suffer from the overhearing problem, which causes the energy consumption to increase rapidly. To address this problem, we propose a novel collaborative beamforming scheme that enables the nodes to overhear the least possible number of transmissions. We then further improve the lifetime of the network by allowing the nodes to use the multi-hop cooperative transmission technique. We analyze the proposed schemes via simulation and show that the collaborative beamforming and cooperative transmission techniques can significantly improve the lifetime of WSNs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolutionary Neural Gas (ENG): A Model of Self Organizing Network from\n  Input Categorization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0598, "human_text": "  Despite their claimed biological plausibility, most self organizing networks have strict topological constraints and consequently they cannot take into account a wide range of external stimuli. Furthermore their evolution is conditioned by deterministic laws which often are not correlated with the structural parameters and the global status of the network, as it should happen in a real biological system. In nature the environmental inputs are noise affected and fuzzy. Which thing sets the problem to investigate the possibility of emergent behaviour in a not strictly constrained net and subjected to different inputs. It is here presented a new model of Evolutionary Neural Gas (ENG) with any topological constraints, trained by probabilistic laws depending on the local distortion errors and the network dimension. The network is considered as a population of nodes that coexist in an ecosystem sharing local and global resources. Those particular features allow the network to quickly adapt to the environment, according to its dimensions. The ENG model analysis shows that the net evolves as a scale-free graph, and justifies in a deeply physical sense- the term gas here used. ", "machine_text": "  Evolutionary Neural Gas (ENG): A Model of Self Organizing Network from Input Categorization.  We present a new model of a self organizing network which is capable of learning an optimal categorization of its inputs. The proposed model, called Evolutionary Neural Gas (ENG), is an extension of the original Neural Gas model, which is capable of learning a general, continuously adjusted structure of clusters. The ENG model is based on the recently proposed Evolutionary Artificial Neural Networks (EANN), which are a generalization of multilayer feedforward ANNs to evolutionary systems. In the ENG, the structure of the network is not predefined but is formed during the learning process. The learning algorithm is based on the survival of the fittest principle, where the structures of the networks are evolved to perform the optimal categorization of the input data. We tested the ENG model on several benchmark datasets, including the standard Iris and Wine Quality datasets. The results show the superiority of the ENG model in the task of input categorization, in comparison to the original Neural Gas model and several other competitive models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: QCD Approach to B->D \\pi Decays and CP Violation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1575, "human_text": "  The branching ratios and CP violations of the $B\\to D\\pi$ decays, including both the color-allowed and the color-suppressed modes, are investigated in detail within QCD framework by considering all diagrams which lead to three effective currents of two quarks. An intrinsic mass scale as a dynamical gluon mass is introduced to treat the infrared divergence caused by the soft collinear approximation in the endpoint regions, and the Cutkosky rule is adopted to deal with a physical-region singularity of the on mass-shell quark propagators. When the dynamical gluon mass $\\mu_g$ is regarded as a universal scale, it is extracted to be around $\\mu_g = 440$ MeV from one of the well-measured $B\\to D\\pi$ decay modes. The resulting predictions for all branching ratios are in agreement with the current experimental measurements. As these decays have no penguin contributions, there are no direct $CP$ asymmetries. Due to interference between the Cabibbo-suppressed and the Cabibbo-favored amplitudes, mixing-induced CP violations are predicted in the $B\\to D^{\\pm}\\pi^{\\mp}$ decays to be consistent with the experimental data at 1-$\\sigma$ level. More precise measurements will be helpful to extract weak angle $2\\beta+\\gamma$. ", "machine_text": " We present a QCD approach to B->D \\pi decays and CP violation. We find that the standard unitary theory is able to account for the data in a satisfactory way, after a suitable choice of the parameters. The approach is based on the use of the so-called \" idiot \" fermions, which represent the lightest quark and antiquark pairs. The idiot fermions are assumed to be almost massless and to have a small effective lifetime. Therefore they can only be involved in the decays of heavy quarks. The dynamics of the idiot fermions is described by a master equation, which includes the production and the decay of the idiot fermions as well as their possible interactions with other quarks and antiquarks. We show that the introduction of the idiot fermions allows to understand the experimental data on B->D \\pi and B->D \\pi \\ell^+ \\ell^- decays, in particular the excess of D \\pi \\ell^+ \\ell^- and B\\overline{B} pairs over the Standard Model expectations, without the need of introducing new quark or antiquark states, as it is usually done in the context of the Unitary Theory. In addition, we analyze the role of CP violation in B->D \\pi and B->D \\pi \\ell^+ \\ell^- decays. We show that the standard unitary theory is able to account for the observed CP violation in these decays, if the violating couplings are small and have a suitable form.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Adaptive Strategy for the Classification of G-Protein Coupled\n  Receptors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3453, "human_text": "  One of the major problems in computational biology is the inability of existing classification models to incorporate expanding and new domain knowledge. This problem of static classification models is addressed in this paper by the introduction of incremental learning for problems in bioinformatics. Many machine learning tools have been applied to this problem using static machine learning structures such as neural networks or support vector machines that are unable to accommodate new information into their existing models. We utilize the fuzzy ARTMAP as an alternate machine learning system that has the ability of incrementally learning new data as it becomes available. The fuzzy ARTMAP is found to be comparable to many of the widespread machine learning systems. The use of an evolutionary strategy in the selection and combination of individual classifiers into an ensemble system, coupled with the incremental learning ability of the fuzzy ARTMAP is proven to be suitable as a pattern classifier. The algorithm presented is tested using data from the G-Coupled Protein Receptors Database and shows good accuracy of 83%. The system presented is also generally applicable, and can be used in problems in genomics and proteomics. ", "machine_text": " The classification of G-protein coupled receptors (GPCRs) has been largely based on the homology of their amino acid sequences. Because of the sequential and evolutionary nature of amino acid changes, however, differences in the amino acid sequences of GPCRs may not always reflect functional or pharmacological differences. We have recently proposed a method for the classification of GPCRs based on their conformational features, which we refer to as the 'Conformation Space Method'. In this paper, we show that this method is not only 'robust' in that it classifies GPCRs that have already been functionally characterized, but that it can also be used to identify novel classes of GPCRs based on their conformation space properties. We demonstrate this by identifying and characterizing a new class of GPCRs ( referred to as the 'Family C' GPCRs) whose members have characteristic three-dimensional features that are not apparent from their primary amino acid sequence. These 'Family C' GPCRs include the SREB (endothelial differentiation, retraction and migration) receptors, which we show to be receptors for the Scarletasterol family of lysophospholipids. We also show that the FES (Fibroblast Endothelial sf-1) receptors, which include the endothelin A, B and C receptors, and the CENP (centromere-binding protein) receptors, which include the Reelin receptor, both contain the characteristic 'Family C' conformation space signature. The 'Family C' GPCRs are a new class of GPCRs whose three-dimensional structures combine features of both Class A (the secretin-like receptors) and Class B (the glutamate receptors). We show that the 'Family C' GPCRs are evolutionarily related to the CCK/gastrin-like receptors, which are the founding members of Class A, and that they constitute a new subfamily within the Class A GPCRs. Our results also suggest that the 'Family C' GPCRs may have evolved from a common ancestor with the Class B GPCRs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Sedentary Survey of Extreme High Energy Peaked BL Lacs III. Results\n  from Optical Spectroscopy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1729, "human_text": "  The multi-frequency Sedentary Survey is a flux limited, statistically well-defined sample of highly X-ray dominated BL Lacertae objects (HBLs) which includes 150 sources. In this paper, the third of the series, we report the results of a dedicated optical spectroscopy campaign that, together with results from other independent optical follow up programs, led to the spectroscopic identification of all sources in the sample. We carried out a systematic spectroscopic campaign for the observation of all unidentified objects of the sample using the ESO 3.6m, the KPNO 4m, and the TNG optical telescopes. We present new identifications and optical spectra for 76 sources, 50 of which are new BL Lac objects, 18 are sources previously referred as BL Lacs but for which no redshift information was available, and 8 are broad emission lines AGNs. We find that the multi-frequency selection technique used to build the survey is highly efficient (about 90%) in selecting BL Lacs objects. We present positional and spectroscopic information for all confirmed BL Lac objects. Our data allowed us to determined 36 redshifts out of the 50 new BL Lacs and 5 new redshifts for the previously known objects. The redshift distribution of the complete sample is presented and compared with that of other BL Lacs samples. For 26 sources without recognizable absorption features, we calculated lower limits to the redshift using a method based on simulated optical spectra with different ratios between jet and galaxy emission. For a subsample of 38 object with high-quality spectra, we find a correlation between the optical spectral slope, the 1.4 GHz radio luminosity, and the Ca H&K break value, indicating that for powerful/beamed sources the optical light is dominated by the non-thermal emission from the jet. ", "machine_text": " We present the results of a unique optical spectroscopy survey of a well-studied sample of 42 extremely high energy (EHE) peaked BL Lacertae objects. Our sample consists of sources with extremely high optical variability, a large number of which have known X-ray binaries. We have obtained spectroscopy, with a resolution of $\\sim 1\\%$, of these sources in three different bands ($\\sim 4300$, $\\sim 5500$, and $\\sim 6300$ nm) with the aim of investigating the nature of the absorbing material in these sources, and the distribution of the absorbing material in the inner accretion disk. We find that in the cases where the absorbing material has a well-defined edge, a 1-dimensional (1D) model can well describe the data, thus allowing us to derive the optical depth of the absorbing material. In all cases the optical depth of the absorbing material is $\\sim 2-3$. We find that in the majority of our objects the absorbing material is located in a relatively narrow layer, at a few gravitational radii from the central engine. In one case, however, we find that the absorbing material is much more extended, and a 2-dimensional (2D) model is needed to describe the data. Our results are consistent with a model where the absorbing material is the result of a wind-driven accretion flow, and indicate that the inner accretion disk is only slightly truncated by the presence of the absorbing material. We discuss our results in the framework of a simple model, which allows us to explain the main features of our data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical BVI Imaging and HI Synthesis Observations of the Dwarf Irregular\n  Galaxy ESO 364-G 029. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.305, "human_text": "  As part of an effort to enlarge the number of well-studied Magellanic-type galaxies, we obtained broadband optical imaging and neutral hydrogen radio synthesis observations of the dwarf irregular galaxy ESO 364-G 029. The optical morphology characteristically shows a bar-like main body with a one-sided spiral arm, an approximately exponential light distribution, and offset photometric and kinematic centers. The HI distribution is mildly asymmetric and, although slightly offset from the photometric center, roughly follows the optical brightness distribution, extending to over 1.2 Holmberg radii (where mu_B = 26.5 mag/arcsec^2). In particular, the highest HI column densities closely follow the bar, one-arm spiral, and a third optical extension. The rotation is solid-body in the inner parts but flattens outside of the optical extent. The total HI flux F_HI = 23.1 pm 1.2 Jy km/s, yielding a total HI mass M_HI= (6.4 pm 1.7) x 10^8 Msun (for a distance D = 10.8 pm 1.4 Mpc) and a total HI mass-to-blue-luminosity ratio M_HI/L_B = (0.96 pm 0.14) Msun / Lsun,B (distance independent). The HI data suggest a very complex small-scale HI structure, with evidence of large shells and/or holes, but deeper observations are required for a detailed study. Follow-up observations are also desirable for a proper comparison with the Large Magellanic Cloud, where despite an optical morphology very similar to ESO 364-G 029 the HI bears little resemblance to the optical. ", "machine_text": " We present optical BVI imaging and HI synthesis observations of the dwarf irregular galaxy ESO 364-G 029, which reveal a nearly face-on barred system with a well-defined bar and a half-symmetrically placed inner ring structure. We discuss the nature of the bar and ring and their possible interactions. The bar is the dominant feature in the stellar distribution and is responsible for the streaky HI distribution. The observed bar structure is consistent with a Keplerian profile, with a characteristic radius of 5.6 kpc and a mass of 4.4 kpc gas mass. The bar has a high surface brightness, and is therefore likely to be optically thick. We estimate the bar to be more than one thousand million years old. The observed bar is longer than the half-light radius, indicating that it is still accreting gas. The gas in the bar is slightly metal-poor compared to the gas in the outer parts of the disk, a signature of a successive accretion history. We show that the bar is responsible for the excess gas in the center of the galaxy. We estimate the current accretion rate to be at least 10^( \u2212 3). The gas in the ring is metal-poor compared to the gas in the bar, suggesting that the ring is an older feature. The mean metallicity of the gas in the bar is 12 +log(O/H) = 7.06, while the gas in the ring has a metallicity of 12 +log(O/H) = 6.55. We discuss several possible formation scenarios for the bar and ring, and conclude that the bar has been formed by a violent interaction between the disk and a gas cloud. The ring may be a fossil feature, or it could have been formed by the interaction of the bar with a second gas cloud. The large vertical scale of the ring (6 kpc) indicates that the dynamics in the center of the galaxy is not two-body dominated, but rather has a more complicated three-body problem. We discuss this in the context of recent results for disk galaxy dynamics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The subpulse modulation properties of pulsars at 92 cm and the frequency\n  dependence of subpulse modulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3572, "human_text": "  A large sample of pulsars has been observed to study their subpulse modulation at an observing wavelength (when achievable) of both 21 and 92 cm using the Westerbork Synthesis Radio Telescope. In this paper we present the 92-cm data and a comparison is made with the already published 21-cm results. We analysed 191 pulsars at 92 cm using fluctuation spectra. The sample of pulsars is as unbiased as possible towards any particular pulsar characteristics. For 15 pulsars drifting subpulses are discovered for the first time and 26 of the new drifters found in the 21-cm data are confirmed. We discovered nulling for 8 sources and 8 pulsars are found to intermittently emit single pulses that have pulse energies similar to giant pulses. It is estimated that at least half of the total population of pulsars have drifting subpulses when observations with a high enough signal-to-noise ratio would be available. It could well be that the drifting subpulse mechanism is an intrinsic property of the emission mechanism itself, although for some pulsars it is difficult or impossible to detect. Drifting subpulses are in general found at both frequencies, although the chance of detecting drifting subpulses is possibly slightly higher at 92 cm. It appears that the youngest pulsars have the most disordered subpulses and the subpulses become more and more organized into drifting subpulses as the pulsar ages. The correlations with the modulation indices are argued to be consistent with the picture in which the radio emission can be divided in a drifting subpulse signal plus a quasi-steady signal which becomes, on average, stronger at high observing frequencies. The measured values of P3 at the two frequencies are highly correlated, but there is no evidence for a correlation with other pulsar parameters. ", "machine_text": "  We present new observations of the subpulse modulation properties of pulsars at 92 cm and the frequency dependence of subpulse modulation. We use the fast Fourier transform technique to extract the modulation spectrum from the pulse profiles of 13 pulsars observed at a frequency of 92 cm. The observed modulation is decomposed into amplitude and phase modulation, and the resulting power spectra are compared to the power spectra expected for a range of model modulation depths. The best fit to the data is obtained with a model in which the modulation depth is constant and equal to 0.12. This result is consistent with previous observations at 350 MHz and demonstrates that pulsars can support a large amount of modulation at radio frequencies. We also present observations of the frequency dependence of subpulse modulation. These observations show that the modulation depth is proportional to the frequency. This result is consistent with the theory of frequency-dependent modulation and indicates that the electrical activity in the accretion disk is independent of the orbital period of the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Origin of which-way information and generalization of the Born rule. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2877, "human_text": "  The possibility to recover the which-way information, for example in the two slit experiment, is based on a natural but implicit assumption about the position of a particle {\\it before} a position measurement is performed on it. This assumption cannot be deduced from the standard postulates of quantum mechanics. In the present paper this assumption is made explicit and formally postulated as a new rule, the {\\it quantum typicality rule}. This rule correlates the positions of the particles at two different times, thus defining their trajectories. Unexpectedly, this rule is also equivalent to the Born rule with regard to the explanation of the results of statistical experiments. For this reason it can be considered a generalization of the Born rule. The existence of the quantum typicality rule strongly suggests the possibility of a new trajectory-based formulation of quantum mechanics. According to this new formulation, a closed quantum system is represented as a {\\it quantum process}, which corresponds to a canonical stochastic process in which the probability measure is replaced by the wave function and the usual frequentist interpretation of probability is replaced by the quantum typicality rule. ", "machine_text": " We propose a new theory of the origin of conscious perception of oriented information, such as knowing \"which way is up.\" We show that such perception is not derived from the statistically optimal computation of orientation selectivity in downstream neurons, as has been widely assumed. Rather, it arises from an explicit, symmetric dependence on the neural response tobidirectional stimulation in the feedforward pathway. This makes conscious perception of orientation highly resilient to fluctuations in the statistics of the input, and endows it with a high degree of generalization ability. We further show that such a symmetric dependence on bidirectional stimulation cannot be captured by asymmetrically tuned neurons, and can only be accounted for by neurons with symmetric responses to bilateral stimulation, or by a combination of symmetric and asymmetric responses in a specific manner. We analyze a number of candidate neural mechanisms that may give rise to such symmetric responses, and propose a particular mechanism which is consistent with a large body of experimental evidence. We show that this mechanism is capable of producing orientation perception that is resilient to input noise and has a high degree of generalization ability, in a manner consistent with the Born rule. We propose that this mechanism plays a role in a number of perceptual tasks that require conscious detection of oriented information, including orientation discrimination, and explain why orientation perception is generally so resilient to input noise and has such a high degree of generalization ability.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Timing and Lensing of the Colliding Bullet Clusters: barely enough time\n  and gravity to accelerate the bullet. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0094, "human_text": "  We present semi-analytical constraint on the amount of dark matter in the merging bullet galaxy cluster using the classical Local Group timing arguments. We consider particle orbits in potential models which fit the lensing data. {\\it Marginally consistent} CDM models in Newtonian gravity are found with a total mass M_{CDM} = 1 x 10^{15}Msun of Cold DM: the bullet subhalo can move with V_{DM}=3000km/s, and the \"bullet\" X-ray gas can move with V_{gas}=4200km/s. These are nearly the {\\it maximum speeds} that are accelerable by the gravity of two truncated CDM halos in a Hubble time even without the ram pressure. Consistency breaks down if one adopts higher end of the error bars for the bullet gas speed (5000-5400km/s), and the bullet gas would not be bound by the sub-cluster halo for the Hubble time. Models with V_{DM}~ 4500km/s ~ V_{gas} would invoke unrealistic large amount M_{CDM}=7x 10^{15}Msun of CDM for a cluster containing only ~ 10^{14}Msun of gas. Our results are generalisable beyond General Relativity, e.g., a speed of $4500\\kms$ is easily obtained in the relativistic MONDian lensing model of Angus et al. (2007). However, MONDian model with little hot dark matter $M_{HDM} \\le 0.6\\times 10^{15}\\msun$ and CDM model with a small halo mass $\\le 1\\times 10^{15}\\msun$ are barely consistent with lensing and velocity data. ", "machine_text": " We present an analysis of the dynamics of the accretion disc around the black hole in the LMXB source 1E0658-56. We find that the disc is likely to have been formed by the accretion of the hydrogen gas from a large rotating infalling object, such as a giant planet, that strayed too close to the black hole. The dynamics of the system is consistent with a gravitational slingshot of the bullet cluster, only barely enough time and gravity to accelerate the bullet. The Event Horizon Telescope (EHT) observations of the black hole in 1E0658-56, in combination with the 2015 theory by1966(); 1997(); 2002() that the largest objects in galactic nuclei are the remnants of giant planets that formed around the early galactic nuclei and were later ripped off by the central black holes, suggest that the process of planet formation in the galactic nuclei is a violent one. We propose that the accretion discs around black holes in galactic nuclei are formed by the same process as the discs around young stars, by the accretion of gas from the infalling object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Antiproliferative MCR peptides block physical interaction of insulin\n  with retinoblastoma protein (RB) in human lung cancer cells. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1991, "human_text": "  Fifteen years ago, a structural analysis of the hormone insulin and the retinoblastoma tumor suppressor protein (RB) revealed that they may physically interact with one another. Subsequently, an RB peptide corresponding to the proposed RB binding site for insulin was found to recognize full-length insulin in vitro. As part of efforts aimed at developing this RB peptide into an anti-cancer drug, this molecule was chemically coupled to a cellular internalization signal and termed \"MCR peptide\". Meanwhile, several such MCR peptide variants have been demonstrated to restrain the proliferation of different human cancer cells in vitro and in vivo. Moreover, one of the MCR peptides coined MCR-10 was shown to be capable of interfering with the complex formation between insulin and RB in HepG2 human hepatoma cells, as monitored by immunofluorescence. This latter result indicating an in vivo association between insulin and RB was confirmed by a follow-up study combining the methods of co-immunoprecipitation and immunoblotting. Here, we provide evidence for the existence of the insulin-RB complex in A549 human non-small cell lung cancer cells. Specifically, we demonstrate this heterodimer by means of a magnetic beads-based immunoprecipitation approach and equally show that this dimer can be disrupted by MCR-4 or MCR-10 each of which is known to possess antiproliferative properties, yet to a much lesser extent by a control peptide. Thus, this investigation has yielded another important proof for the occurrence of the insulin-RB dimer and, furthermore, its validity as a target for antineoplastic MCR peptides. ", "machine_text": " Motivation: The retinoblastoma (RB) protein is a tumor suppressor that plays a central role in cell cycle regulation and in the etiology of several cancers, including lung cancer, where it is frequently lost by RB mutation or by epigenetic inactivation. In our previous work, we showed that a small synthetic peptide corresponding to the C-terminal part of RB (MCR) has antiproliferative and proapoptotic effects in several cancer cells, including lung cancer cells, and that these effects are mediated by inhibition of the physical interaction of MCR with the protein insulin-like growth factor 1 receptor (IR). Key ideas and methodology: In the present work, we sought to determine the structural basis for the interaction of MCR with IR and to study the effects of this interaction on cell cycle regulation. We have shown that MCR and IR form a complex in vitro, and that this complex is able to activate the cell cycle inhibitor p21. We have also shown that MCR peptides are able to block the interaction of IR with RB in vivo and to inhibit cell cycle progression in lung cancer cells. Results obtained: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced. Problem work attempts to solve: The aim of our work was to study the structural basis for the interaction of MCR with IR and to study the effects of this interaction on cell cycle regulation. Any practical or theoretical applications from your findings or implications for future research: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced.  Implications for future research: Our results suggest that the MCR-IR interaction may be a potential therapeutic target in lung cancer and other cancers where RB is mutated or silenced.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galaxy evolution in the infra-red: comparison of a hierarchical galaxy\n  formation model with SPITZER data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1562, "human_text": "  We present predictions for the evolution of the galaxy luminosity function, number counts and redshift distributions in the IR based on the Lambda-CDM cosmological model. We use the combined GALFORM semi-analytical galaxy formation model and GRASIL spectrophotometric code to compute galaxy SEDs including the reprocessing of radiation by dust. The model, which is the same as that in Baugh et al (2005), assumes two different IMFs: a normal solar neighbourhood IMF for quiescent star formation in disks, and a very top-heavy IMF in starbursts triggered by galaxy mergers. We have shown previously that the top-heavy IMF seems to be necessary to explain the number counts of faint sub-mm galaxies. We compare the model with observational data from the SPITZER Space Telescope, with the model parameters fixed at values chosen before SPITZER data became available. We find that the model matches the observed evolution in the IR remarkably well over the whole range of wavelengths probed by SPITZER. In particular, the SPITZER data show that there is strong evolution in the mid-IR galaxy luminosity function over the redshift range z ~ 0-2, and this is reproduced by our model without requiring any adjustment of parameters. On the other hand, a model with a normal IMF in starbursts predicts far too little evolution in the mid-IR luminosity function, and is therefore excluded. ", "machine_text": "  We present a comparison of the evolution of galaxies in a hierarchical galaxy formation model with the observed distribution of galaxies in the infra-red, as obtained from the SPITZER Deep Extragalactic Survey. We show that the model can reproduce the main properties of the SPITZER infra-red galaxy distribution, in terms of the number density of galaxies, their sizes, and their distribution in space and in time. We find that the main difference between the model and the observations is that the model predicts more galaxies at large redshifts and fewer at small redshifts than are observed. We discuss possible physical reasons for this difference, and we show that relaxing the assumption of perfect galaxy formation in the model can produce a distribution of galaxies more in agreement with observations. Our results suggest that the distribution of galaxies in the SPITZER infra-red survey is consistent with a simple hierarchical galaxy formation model, with some possible additional physical mechanisms such as the inefficient conversion of gas into galaxies, the feedback from massive galaxies, and the presence of large-scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What is the order of 2D polymer escape transition?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1857, "human_text": "  An end-grafted flexible polymer chain in 3d space between two pistons undergoes an abrupt transition from a confined coil to a flower-like conformation when the number of monomers in the chain, N, reaches a critical value. In 2d geometry, excluded volume interactions between monomers of a chain confined inside a strip of finite length 2L transform the coil conformation into a linear string of blobs. However, the blob picture raises questions on the nature of this escape transition. To check the theoretical predictions based on the blob picture we study 2d single polymer chains with excluded volume interactions and with one end grafted in the middle of a strip of length   2L and width H by simulating self-avoiding walks on a square lattice with the pruned-enriched-Rosenbluth method (PERM). We estimate the free energy, the end-to-end distance, the number of imprisoned monomers, the order parameter, and its distribution. It is shown that in the thermodynamic limit of large N and L but finite L/N, there is a small but finite jump in several average characteristics, including the order parameter. We also present a theoretical description based on the Landau free energy approach, which is in good agreement with the simulation results. Both simulation results and the analytical theory indicate that the 2d escape transition is a weak first-order phase transition. ", "machine_text": " We study the order of the two-dimensional (2D) polymer escape transition as a function of the system size and the solvent quality using Monte Carlo simulations. We find a strong dependence of the transition order on the system size and the solvent quality. In particular, we observe a critical system size for the transition, above which the order is absolutely first order, and below which the order is second order. We also find a strong dependence of the order on the solvent quality, where the order is generally first order in a good solvent and second order in a bad solvent. In addition, we study the polymer conformation and the statistical properties of the system as a function of the transition order. We find that the polymers adopt a more compact conformation and the system becomes more ordered in a first-order transition, while the polymers adopt a more extended conformation and the system becomes less ordered in a second-order transition. Our results suggest that the 2D polymer escape transition is generally first order, but can be second order in a small system or in a bad solvent.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: MiniBooNE Results and Neutrino Schemes with 2 sterile Neutrinos:\n  Possible Mass Orderings and Observables related to Neutrino Masses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1462, "human_text": "  The MiniBooNE and LSND experiments are compatible with each other when two sterile neutrinos are added to the three active ones. In this case there are eight possible mass orderings. In two of them both sterile neutrinos are heavier than the three active ones. In the next two scenarios both sterile neutrinos are lighter than the three active ones. The remaining four scenarios have one sterile neutrino heavier and another lighter than the three active ones. We analyze all scenarios with respect to their predictions for mass-related observables. These are the sum of neutrino masses as constrained by cosmological observations, the kinematic mass parameter as measurable in the KATRIN experiment, and the effective mass governing neutrinoless double beta decay. It is investigated how these non-oscillation probes can distinguish between the eight scenarios. Six of the eight possible mass orderings predict positive signals in the KATRIN and future neutrinoless double beta decay experiments. We also remark on scenarios with three sterile neutrinos. In addition we make some comments on the possibility of using decays of high energy astrophysical neutrinos to discriminate between the mass orderings in presence of two sterile neutrinos. ", "machine_text": " We present results of a detailed study of the allowed mass orderings of a simple two-neutrino scenario, the so-called \"lightest- sterile-neutrino- is-a- Dirac-neutrino\" model. We consider all physically allowed mass orderings and use the so-called \" Designer Neutrino\" scheme to extract the required mass matrix elements from the conditions of the standard model. In this way we can derive the masses of the three neutrinos in terms of the fundamental Standard Model parameters and the neutrino masses can be related to the masses of the other elementary particles. In the mass matrix we find the small element (with a value of about 0.07 eV) representing the Dirac neutrino mass. We find that the mass of the lightest sterile neutrino is a multiple of the Dirac neutrino mass, with the value depending on the details of the mixing and the mass ordering. The Dirac neutrino and the sterile neutrinos can be assigned masses within the framework of the standard model without the need to introduce new parameters. We discuss the implications of this scenario for neutrino mass detection and for the question of the mass ordering.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the generalization of the Costas property in the continuum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1379, "human_text": "  We extend the definition of the Costas property to functions in the continuum, namely on intervals of the reals or the rationals, and argue that such functions can be used in the same applications as discrete Costas arrays. We construct Costas bijections in the real continuum within the class of piecewise continuously differentiable functions, but our attempts to construct a fractal-like Costas bijection there are successful only under slight but necessary deviations from the usual arithmetic laws. Furthermore, we are able, contingent on the validity of Artin's conjecture, to set up a limiting process according to which sequences of Welch Costas arrays converge to smooth Costas bijections over the reals. The situation over the rationals is different: there, we propose an algorithm of great generality and flexibility for the construction of a Costas fractal bijection. Its success, though, relies heavily on the enumerability of the rationals, and therefore it cannot be generalized over the reals in an obvious way. ", "machine_text": " We show that a certain generalization of the Costas property holds in the continuum. Let $\\mathfrak{g}$ be a semisimple Lie group with a Levi decomposition $\\mathfrak{g}=\\mathfrak{r}^\\mathfrak{t}\\mathfrak{u}$, where $\\mathfrak{r}$ and $\\mathfrak{t}$ are certain connected and simply connected subspaces of $\\mathfrak{g}$ and $\\mathfrak{u}$ is the real vector space of all upper triangular matrices. Let $\\mathfrak{h}$ be a Cartan subspace of $\\mathfrak{g}$ and $\\mathfrak{f}=\\mathfrak{g}_\\mathfrak{h}^\\mathfrak{h}$ be the adjoint representation of $\\mathfrak{g}$. Let $\\mathfrak{c}$ be a semisimple subspace of $\\mathfrak{f}$. We show that, if $\\pi_\\mathfrak{g}: \\mathfrak{g} \\to \\mathfrak{c}$ is the irreducible representation of $\\mathfrak{g}$ in $\\mathfrak{c}$, then there exists a non-trivial character $\\chi_\\mathfrak{g}:\\mathfrak{g}$ such that $\\chi_\\mathfrak{g}\\pi_\\mathfrak{g}=\\epsilon_\\mathfrak{g}$, where $\\epsilon_\\mathfrak{g}$ is the character of $\\mathfrak{c}$. As an application, we give a description of the root system of $\\mathfrak{g}$ in terms of the structure of $\\mathfrak{c}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray Timing of PSR J1852+0040 in Kesteven 79: Evidence of Neutron Stars\n  Weakly Magnetized at Birth. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0978, "human_text": "  The 105-ms X-ray pulsar J1852+0040 is the central compact object (CCO) in SNR Kes 79. We report a sensitive upper limit on its radio flux density of 12 uJy at 2 GHz using the NRAO GBT. Timing using XMM and Chandra over a 2.4 yr span reveals no significant change in its spin period. The 2 sigma upper limit on the period derivative leads, in the dipole spin-down formalism, to an energy loss rate E-dot < 7e33 ergs/s, surface magnetic field strength B_p < 1.5e11 G, and characteristic age tau_c = P/2P-dot > 8 Myr. This tau_c exceeds the age of the SNR by 3 orders of magnitude, implying that the pulsar was born spinning at its current period. However, the X-ray luminosity of PSR J1852+0040, L(bol) ~ 3e33(d/7.1 kpc)^2 ergs/s is a large fraction of E-dot, which challenges the rotation-powered assumption. Instead, its high blackbody temperature, 0.46+/-0.04 keV, small blackbody radius ~ 0.8 km, and large pulsed fraction, ~ 80%, may be evidence of accretion onto a polar cap, possibly from a fallback disk made of supernova debris. If B_p < 1e10 G, an accretion disk can penetrate the light cylinder and interact with the magnetosphere while resulting torques on the neutron star remain within the observed limits. A weak B-field is also inferred in another CCO, the 424-ms pulsar 1E 1207.4-5209, from its steady spin and soft X-ray absorption lines. We propose this origin of radio-quiet CCOs: the B-field, derived from a turbulent dynamo, is weaker if the NS is formed spinning slowly, which enables it to accrete SN debris. Accretion excludes neutron stars born with both B_p < 1e11 G and P > 0.1 s from radio pulsar surveys, where B_p < 1e11 G is not encountered except among very old (tau_c > 40 Myr) or recycled pulsars. Finally, such a CCO, if born in SN 1987A, could explain the non-detection of a pulsar there. ", "machine_text": " We present observations of the low-mass X-ray binary PSR J1852+0040 in the Galactic globular cluster Kesteven 79. The system consists of a magnetized, weakly- magnetized-at-birth neutron star with a relatively long spin-down lifetime, accreting from a Donor, and an accretion disc around the Donor. We observed the system in quiescence, and found that the accretion disc is not actively accreting, and that the system is in a relatively long spin-down epoch. Our observations are consistent with the disc being in a quiescent state, possibly due to a relatively high mass-transfer rate during accretion, compared to the accretion rate during the short spin-up epochs. We conclude that a large fraction of low-mass X-ray binaries in globular clusters are in this type of quiescent state, and that this could provide a natural explanation for the lack of in-between states (accreting but with a low accretion rate) observed in low-mass X-ray binaries in our Galaxy. We find that the accretion disc in PSR J1852+0040 is geometrically thin, with a thickness of $\\sim 10$ times the accretion disc radius, and with a mass distribution that is consistent with a uniform density disc. We discuss the implications of this for the stability of the disc, and find that it is consistent with a relatively long spin-down lifetime of the system. We find that the observed spin-down rate is consistent with the system having been weakly magnetized at birth, and having experienced relatively large torque from accretion in the past. We discuss the implications of this for the low-mass X-ray binary initial mass function, and for the accretion history of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Detailed Study of Gas and Star Formation in a Highly Magnified Lyman\n  Break Galaxy at z=3.07. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1721, "human_text": "  We report the detection of CO(3-2) emission from a bright, gravitationally lensed Lyman Break Galaxy, LBGJ213512.73-010143 (the 'Cosmic Eye'), at z=3.07 using the Plateau de Bure Interferometer. This is only the second detection of molecular gas emission from an LBG and yields an intrinsic molecular gas mass of (2.4+/-0.4)x10^9 Mo. The lens reconstruction of the UV morphology of the LBG indicates that it comprises two components separated by ~2 kpc. The CO emission is unresolved, and appears to be centered on the intrinsically fainter (and also less highly magnified) of the two UV components. The width of the CO line indicates a dynamical mass of (8+/-2)x10^9csc(i)^2 Mo within the central 2 kpc. Employing mid-infrared observations from Spitzer we derive a stellar mass of ~(6+/-2)x10^9 Mo and a star-formation rate of ~60 Mo/yr, indicating that the molecular gas will be consumed in ~40 Myr. The gas fractions, star-formation efficiencies and line widths suggests that LBGJ213512 is a high-redshift, gas-rich analog of a local luminous infrared galaxy. This galaxy has a similar gas-to-dynamical mass fraction as observed in the submillimeter-selected population, although the gas surface density and star-formation efficiency is a factor of 3x less, suggesting less vigorous activity. We discuss the uncertainties in our conclusions arising from adopting a CO-to-H2 conversion factor appropriate for either the Milky Way or local luminous infrared galaxies. These observations demonstrate that current facilities, when aided by fortuitous gravitational magnification, can study 'ordinary' galaxies at high-redshift and so act as pathfinders for ALMA. ", "machine_text": "  We present a detailed study of a highly magnified Lyman break galaxy (LBM) at z=3.07 in order to investigate the role of the molecular line in galaxy formation and evolution. We find that the far ultraviolet (FUV) and near-infrared (NIR) photometry, combined with the dust emission, are able to constrain the relative gas and star formation rates (GIFs) in these galaxies. We find that LBMs at high magnifications are more likely to be gas-rich and have higher GIFs than LBMs at low magnifications. This is consistent with the hypothesis that LBMs at high magnifications are more evolved galaxies that have formed stars more efficiently. We show that the relative strength of the molecular line compared to the dust and FUV/NIR continuum is correlated with the evolution of the galaxy, with more evolved galaxies having lower relative molecular line strengths. We also present an analysis of the morphologies of LBMs in order to further probe the evolution of these galaxies. We find that LBMs at high magnifications are more likely to have complex morphologies, while LBMs at low magnifications are more likely to have simple morphologies. This is consistent with the hypothesis that LBMs at high magnifications are more evolved galaxies that have formed stars and are undergoing further mergers and interactions, producing more complex and irregular morphologies. Our results suggest that the molecular line can be used as a tracer of galaxy evolution and star formation in LBMs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Room temperature spin polarized magnetic semiconductor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2993, "human_text": "  Alternating layers of granular Iron (Fe) and Titanium dioxide (TiO$_{2-\\delta}$) were deposited on (100) Lanthanum aluminate (LaAlO$_3$) substrates in low oxygen chamber pressure using a controlled pulsed laser ablation deposition technique. The total thickness of the film was about 200 nm. The films show ferromagnetic behavior for temperatures ranging from 4 to $400 ^oK$. The layered film structure was characterized as p-type magnetic semiconductor at $300 ^oK$ with a carrier density of the order of $10^{20} /cm^3$. The undoped pure TiO$_{2-\\delta}$ film was characterized as an n-type magnetic semiconductor. The hole carriers were excited at the interface between the granular Fe and TiO$_{2-\\delta}$ layers similar to holes excited in the metal/n-type semiconductor interface commonly observed in Metal-Oxide-Semiconductor (MOS) devices. The holes at the interface were polarized in an applied magnetic field raising the possibility that these granular MOS structures can be utilized for practical spintronic device applications. ", "machine_text": " We have investigated the spin-dependent transport in a ferromagnetic (FM) semiconductor (Bi0.5Fe0.5)0.9Te0.1) with a room temperature (RT) spin-orbital-liquid (SOL) order, in an effort to understand the mechanism of the spin-mediated transport in such materials, and to explore its potential for spintronic applications. We have found that the spin-diffusion length (L) in this material is much shorter than the previously reported L values in non-magnetic semiconductors, which is consistent with the notion that the spin-mediated transport in magnetic semiconductors is inherently different from the ordinary charge-mediated transport. We have also found that the room temperature L value in this material is large enough (6.5 \u03bcm) to be potentially useful for spintronic applications. We have further found that the low temperature (T< 100 K) behavior of the spin-induced magnetoresistance (MR) is consistent with the standard Boltzmann transport model, but the RT behavior of the MR is different from the behavior predicted by this model. We have explained this discrepancy by a model in which the RT MR is dominated by the re-population of the mobile carriers at the Fermi level after their spin-dependent diffusion. We have also found that the MR is sensitive to an external magnetic field even in the absence of any spin-polarization of the injected carriers, which is consistent with the notion that the MR in magnetic semiconductors is due to the spin-dependent scattering of the carriers by the internal spin-ordsal moment, and is therefore different from the MR in magnetic metals, in which the MR is due to the spin-dependent scattering of the spin-polarized carriers by the internal spin-orbit moment. Finally, we have found that the temperature dependence of the MR in this material is consistent with the model in which the RT MR is dominated by the re-population of the mobile carriers at the Fermi level after their spin-dependent diffusion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kinematic Evolution of Strong MgII Absorbers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0515, "human_text": "  We consider the evolution of strong (W_r(2796) > 0.3A) MgII absorbers, most of which are closely related to luminous galaxies. Using 20 high resolution quasar spectra from the VLT/UVES public archive, we examine 33 strong MgII absorbers in the redshift range 0.3 < z < 2.5. We compare and supplement this sample with 23 strong MgII absorbers at 0.4 < z < 1.4 observed previously with HIRES/Keck. We find that neither equivalent width nor kinematic spread (the optical depth weighted second moment of velocity) of MgII2796 evolve. However, the kinematic spread is sensitive to the highest velocity component, and therefore not as sensitive to additional weak components at intermediate velocities relative to the profile center. The fraction of absorbing pixels within the full velocity range of the system does show a trend of decreasing with decreasing redshift. Most high redshift systems (14/20) exhibit absorption over the entire system velocity range, which differs from the result for low redshift systems (18/36) at the 95% level. This leads to a smaller number of separate subsystems for high redshift systems because weak absorping components tend to connect the stronger regions of absorption. We hypothesize that low redshift MgII profiles are more likely to represent well formed galaxies, many of which have kinematics consistent with a disk/halo structure. High redshift MgII profiles are more likely to show evidence of complex protogalactic structures, with multiple accretion or outflow events. Although these results are derived from measurements of gas kinematics, they are consistent with hierarchical galaxy formation evidenced by deep galaxy surveys. ", "machine_text": "  We present a study of the kinematic structure of strong MgII absorbers in the solar photosphere. We use a combination of photospheric magnetic field measurements and spectroscopy of a small-area weakly-magnetized region in the photosphere to show that the kinematic structure of strong MgII absorbers is due to the superposition of three different populations of photospheric granules: (i) fast-moving granules at high latitudes, (ii) slow-moving granules at low latitudes, and (iii) a population of granules with intermediate speeds at all latitudes. We find that each of these three populations has a different velocity structure function (VSF), with the fast-moving granules having a VSF that is characterized by a cut-off at low frequencies and a slow-moving population that has a flat VSF. We show that these two populations can be fit well by power law distributions with different exponents. In contrast, the intermediate-speed population has a VSF that is well described by a single power law with a frequency-independent exponent. We argue that the observed VSFs are consistent with the different populations of granules being subject to different magnetic field strengths, with the fast-moving granules at high latitudes being subject to stronger magnetic fields and the slow-moving granules at low latitudes being subject to weaker magnetic fields. We show that the VSF for the intermediate-speed population can be fit well by a power law with an exponent of \u22121.7, suggesting that this population is subject to intermediate magnetic field strengths. We discuss various physical mechanisms that could give rise to these different populations of granules and find that the most promising mechanism is that the different populations correspond to different temperature structures, with the fast-moving granules at high latitudes being the coolest and the slow-moving granules at low latitudes being the warmest.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The generator coordinate method in time-dependent density-functional\n  theory: memory made simple. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2855, "human_text": "  The generator coordinate (GC) method is a variational approach to the quantum many-body problem in which interacting many-body wave functions are constructed as superpositions of (generally nonorthogonal) eigenstates of auxiliary Hamiltonians containing a deformation parameter. This paper presents a time-dependent extension of the GC method as a new approach to improve existing approximations of the exchange-correlation (XC) potential in time-dependent density-functional theory (TDDFT). The time-dependent GC method is shown to be a conceptually and computationally simple tool to build memory effects into any existing adiabatic XC potential. As an illustration, the method is applied to driven parametric oscillations of two interacting electrons in a harmonic potential (Hooke's atom). It is demonstrated that a proper choice of time-dependent generator coordinates in conjunction with the adiabatic local-density approximation reproduces the exact linear and nonlinear two-electron dynamics quite accurately, including features associated with double excitations that cannot be captured by TDDFT in the adiabatic approximation. ", "machine_text": " The generator coordinate method in time-dependent density-functional theory: memory made simple  We present a simple method to evaluate the exact eigenvalues and eigenvectors of the spatial Laplace operator in a time-dependent density-functional theory (TDDFT) calculation. The method, which we dub the generator coordinate method, is based on a formal similarity transformation of the time-dependent Kohn-Rostoker Green function (TDKGF) which yields a matrix representation of the Laplace operator in the basis of the coherent states of the TDKGF. The use of the generator coordinate method allows one to solve the eigenvalue and eigenvector problems in TDDFT calculations exactly, without the need for the introduction of any additional memory variables. We show that the method can be applied to both time-independent and time-dependent systems, and we present a thorough analysis of its application to a class of time-dependent systems for which the solution of the eigenvalue and eigenvector problems is particularly difficult.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Inhomogeneities in the Universe and the Fitting Problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1029, "human_text": "  Observational cosmology provides us with a large number of high precision data which are used to derive models trying to reproduce ``on the mean'' our observable patch of the Universe. Most of these attempts are achieved in the framework of a Friedmann-Lema\\^itre cosmology where large scale homogeneity is assumed. However, we know, from the observation of structures at increasing scales, that these models are only approximations of a smoothed or averaged inhomogeneous underlying patern. Anyhow, when modelling the Universe, the usual method is to use continuous functions representing the kinematical scalars of the velocity field, implicitly assuming that they represent volume averages of the corresponding fine-scale inhomogeneous quantities, then put them into the Einstein equations which are solved to give the model and its dependance upon a number of parameters arbitrarily defined. In General Relativity, such a method is very much involved since the equations which determine the metric tensor and the quantities calculated from it are highly nonlinear. The question raised by the method consisting of determining the parameters of an a priori assumed FLRW model from observational data is the ``fitting problem'' brought to general attention by Ellis and Stoeger in the 80's. This problem has recently experienced a reniewed attention due to the amount of available data and the increase of the minimum scale at which homogeneity can be assumed. We propose a discussion of this issue in the light of the latest developments of observational and theoretical cosmology. ", "machine_text": " We present an analysis of the impact of inhomogeneities in the Universe on the fitting problem. We show that the probability distribution of the measurements can be non-Gaussian even if the true distribution is Gaussian, provided that the measurements are sufficiently inhomogeneously spaced in space. We analyze this effect for different choices of the probability distribution of the noise, and show that in the case of a uniform noise distribution the effect is most severe, leading to a significant degradation of the statistical significance. On the other hand, if the noise distribution is peaked on small scales, the impact of the inhomogeneities is negligible. We analyze the optimal distribution of the measurements for a given noise distribution, and show that for a Gaussian noise distribution the optimal distribution is a highly non-uniform one, while for a Laplace noise distribution the optimal distribution is very uniform. We finally propose a simple method to reduce the impact of the inhomogeneities, which consists in performing a spatial binning of the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Thurston norm via Normal Surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0673, "human_text": "  Given a triangulation of a closed, oriented, irreducible, atoroidal 3-manifold every oriented, incompressible surface may be isotoped into normal position relative to the triangulation. Such a normal oriented surface is then encoded by non-negative integer weights, 14 for each 3-simplex, that describe how many copies of each oriented normal disc type there are. The Euler characteristic and homology class are both linear functions of the weights. There is a convex polytope in the space of weights, defined by linear equations given by the combinatorics of the triangulation, whose image under the homology map is the unit ball, B, of the Thurston norm.   Applications of this approach include (1) an algorithm to compute B and hence the Thurston norm of any homology class, (2) an explicit exponential bound on the number of vertices of B in terms of the number of simplices in the triangulation, (3) an algorithm to determine the fibred faces of B and hence an algorithm to decide whether a 3-manifold fibres over the circle. ", "machine_text": "  We introduce a family of norms on the space of continuous paths on a simple algebraic variety that generalizes both the Lebesgue and Thurston norms. We show that these norms are equivalent to asking that a function be the restriction to a normal surface of a certain function on the Variety. As an application, we give an example of a function that is continuous on a non- normalize algebraic surface but is not the restriction of a continuous function on the variety.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetic structure of Sm2IrIn8. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.148, "human_text": "  The magnetic structure of the intermetallic antiferromagnet Sm2IrIn8 was determined using x-ray resonant magnetic scattering (XRMS). Below TN = 14.2, Sm2IrIn8 has a commensurate antiferromagnetic structure with a propagation vector (1/2,0,0). The Sm magnetic moments lie in the ab plane and are rotated roughly 18 degrees away from the a axis. The magnetic structure of this compound was obtained by measuring the strong dipolar resonant peak whose enhancement was of over two orders of magnitude at the L2 edge. At the L3 edge both quadrupolar and dipolar features were observed in the energy line shape. The magnetic structure and properties of Sm2IrIn8 are found to be consistent with the general trend already seen for the Nd-, Tb- and the Ce-based compounds from the RmMnIn3m+2n family (R = rare earth; M=Rh or Ir, m = 1, 2; n = 0, 1), where the crystalline electrical field (CEF) effects determine the direction of magnetic moments and the TN evolution in the series. The measured Neel temperature for Sm2IrIn8 is slightly suppressed when compared to the TN of the parent cubic compound SmIn3. ", "machine_text": "  The magnetic structure of the rare-earth intermetallic compound Sm2IrIn8 was investigated by means of magnetic susceptibility, magnetometry, and neutron diffraction measurements. We found a long-range magnetic order with a = 8.45 \u00c5 and c = 5.71 \u00c5, which is consistent with the observed magnetic correlations in the ordered phase. To reveal the detailed magnetic structure, we performed a three-dimensional (3D) magnetic vector analysis. The analysis showed a 3D network of magnetic vectors, which were found to originate from a 2D network of magnetic clusters in the basal plane. The magnetic clusters are composed of a few magnetic ions, which are evenly distributed in the cluster. The intercluster magnetic vectors form a 3D network and link the clusters to each other. The long-range magnetic order is related to the antiferromagnetic correlations between the clusters. The 3D magnetic vector analysis also revealed the presence of a non-zero spin-orbit interaction (SOI) along the c axis, which is related to the Dzyaloshinksy-Moriya interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flavour-Dependent Type II Leptogenesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1591, "human_text": "  We reanalyse leptogenesis via the out-of-equilibrium decay of the lightest right-handed neutrino in type II seesaw scenarios, taking into account flavour-dependent effects. In the type II seesaw mechanism, in addition to the type I seesaw contribution, an additional direct mass term for the light neutrinos is present. We consider type II seesaw scenarios where this additional contribution arises from the vacuum expectation value of a Higgs triplet, and furthermore an effective model-independent approach. We investigate bounds on the flavour-specific decay asymmetries, on the mass of the lightest right-handed neutrino and on the reheat temperature of the early universe, and compare them to the corresponding bounds in the type I seesaw framework. We show that while flavour-dependent thermal type II leptogenesis becomes more efficient for larger mass scale of the light neutrinos, and the bounds become relaxed, the type I seesaw scenario for leptogenesis becomes more constrained. We also argue that in general, flavour-dependent effects cannot be ignored when dealing with leptogenesis in type II seesaw models. ", "machine_text": " Flavour-Dependent Type II Leptogenesis  We study the flavour-dependent formation of heavy nuclei far from stability, so-called type II leptogenesis, in the framework of the interacting- pebble bed model. We find that the favourable branching ratio of the ${}^{10}$ ${}^{56}$ ${}^{90}$ ${}^{144}$ channels is small and decreases with increasing mass number. In contrast, the ${}^{56}$ ${}^{90}$ ${}^{144}$ ${}^{198}$ ${}^{252}$ channels have a strongly flavour-dependent branching ratio and the ${}^{90}$ ${}^{144}$ ${}^{198}$ ${}^{252}$ channels even have a branching ratio that increases with the mass number. We show that this striking difference is due to the strong $(n-1)$- and $(n-2)$-level interactions in the ${}^{56}$ and ${}^{90}$ nuclei that strongly suppress the formation of the ${}^{10}$ and ${}^{144}$ nuclei and to the large $(n-1)$- and $(n-2)$-level interactions in the ${}^{144}$ and ${}^{198}$ nuclei that strongly enhance the formation of the ${}^{56}$ and ${}^{90}$ nuclei. We also discuss the ${}^{10}$ ${}^{90}$ ${}^{198}$ ${}^{252}$ channels and find that their branching ratios are small and increase with the mass number.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective inverse spectral problem for rational Lax matrices and\n  applications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.012, "human_text": "  We reconstruct a rational Lax matrix of size R+1 from its spectral curve (the desingularization of the characteristic polynomial) and some additional data. Using a twisted Cauchy--like kernel (a bi-differential of bi-weight (1-nu,nu)) we provide a residue-formula for the entries of the Lax matrix in terms of bases of dual differentials of weights nu and 1-nu respectively. All objects are described in the most explicit terms using Theta functions. Via a sequence of ``elementary twists'', we construct sequences of Lax matrices sharing the same spectral curve and polar structure and related by conjugations by rational matrices. Particular choices of elementary twists lead to construction of sequences of Lax matrices related to finite--band recurrence relations (i.e. difference operators) sharing the same shape. Recurrences of this kind are satisfied by several types of orthogonal and biorthogonal polynomials. The relevance of formulae obtained to the study of the large degree asymptotics for these polynomials is indicated. ", "machine_text": "  We consider effective inverse spectral problems for rational Lax matrices. Such problems were introduced by Donath and Falkirk to study the structure of the solution space of certain partial differential equations. We show that the effective inverse spectral problem is very sensitive to the particular boundary conditions imposed on the rational Lax matrix. In particular, we show that the effective inverse spectral problem is ill-posed for general rational Lax matrices, but is well-posed for certain classes of rational Lax matrices, such as the Somepin- scraps or the voter- scraps. We also show that the effective inverse spectral problem for a rational Lax matrix is equivalent to the solution of a certain Fredholm integral equation of the first kind. We apply our results to prove that certain classes of rational Lax matrices have an effective inverse which is bounded in a neighborhood of the identity matrix. As an application, we give an example of a linear partial differential equation which has a solution space with a \"Friends of infinity\" structure, in the sense of L\u00e4mmer WITHrss and Wirsing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Comparison between Anomalous 6-cm H$_2$CO Absorption and CO(1-0)\n  Emission in the L1204/S140. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0272, "human_text": "  We report observations of the dust cloud L1204 with the Onsala 25-m telescope in the 6 cm (1$_{11}-1_{10}$) transition of \\htco. The observed region includes the   S140 H${\\alpha}$ arc. This spectral line is seen here in absorption against the cosmic microwave background, indicating the presence of widespread warm molecular gas at intermediate densities. Overall, the distributions of H$_2$CO and CO (taken from the literature) are fairly similar, though significant differences exist at small scales. Most notably, while the CO peak is nearly coincident with the S140 H${\\alpha}$ arc, the maximum H$_2$CO absorption is clearly separated from it by a full 10$'$ beam ($\\sim$ 3 pc). We argue that these differences result from differing abundances and excitation requirements. The CO(1-0) line is more optically thick and more biased towards warm gas than the H$_2$CO 6 cm line. On the other hand, formaldehyde is more easily photodissociated and is, therefore, a poorer tracer of the molecular gas located immediately behind Photon Dominated Regions. ", "machine_text": " We present an analysis of the 6-cm H$_{2}$CO absorption and CO(1-0) emission in the L1204/S140 region. The main aim of our work is to investigate the possible connection between these two molecular lines. We find that the H$_{2}$CO absorption features are, in fact, due to the photodissociation of CO by the incident far-UV radiation and subsequent recombination with H$_{2}$. We show that this process produces an additional population of CO(1-0) excited state, which is not present in the case of CO photodissociation by IR radiation. The most likely sink for the excited state CO(1-0) is its collision with H$_{2}$ or another CO molecule, resulting in the deexcitation and the CO(1-0) ground state population. We discuss the possibility of using the CO(1-0)-to-CO(0-0) transition as a diagnostic tool for detecting shocked H$_{2}$. Our results are consistent with the earlier suggestion that the far-UV-induced 6-cm H$_{2}$CO absorption may be used for detecting shocked H$_{2}$. We propose that the strength of this absorption may be used as a measure of the degree of H$_{2}$ shocked state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Searching for Gravitational Radiation from Binary Black Hole MACHOs in\n  the Galactic Halo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1514, "human_text": "  The Laser Interferometer Gravitational Wave Observatory (LIGO) is one of a new generation of detectors of gravitational radiation. The existence of gravitational radiation was first predicted by Einstein in 1916, however gravitational waves have not yet been directly observed. One source of gravitation radiation is binary inspiral. Two compact bodies orbiting each other, such as a pair of black holes, lose energy to gravitational radiation. As the system loses energy the bodies spiral towards each other. This causes their orbital speed and the amount of gravitational radiation to increase, producing a characteristic ``chirp'' waveform in the LIGO sensitive band. In this thesis, matched filtering of LIGO science data is used to search for low mass binary systems in the halo of dark matter surrounding the Milky Way. Observations of gravitational microlensing events of stars in the Large Magellanic Cloud suggest that some fraction of the dark matter in the halo may be in the form of Massive Astrophysical Compact Halo Objects (MACHOs). It has been proposed that low mass black holes formed in the early universe may be a component of the MACHO population; some fraction of these black hole MACHOs will be in binary systems and detectable by LIGO. The inspiral from a MACHO binary composed of two 0.5 solar mass black holes enters the LIGO sensitive band around 40 Hz. The chirp signal increases in amplitude and frequency, sweeping through the sensitive band to 4400 Hz in 140 seconds. By using evidence from microlensing events and theoretical predictions of the population an upper limit is placed on the rate of black hole MACHO inspirals in the galactic halo. ", "machine_text": "  We present non-detections of gravitational radiation (GR) from three binary black hole (BBH) MACHOs in the Galactic halo, as searched for by the LIGO and Virgo detectors, during the ongoing Advanced LIGO Observing run (O4). We consider the prospects for detecting low-mass X-ray binaries (LMXBs) containing black holes in the future, in the context of a growing population of detections of electromagnetic counterparts to LMXBs in the Galactic halo. We discuss how non-detections of GR from known LMXBs containing black holes can constrain the likelihood of detecting new LMXBs in the Galactic halo via the gravitational lensing effect, and the implications of our non-detections for models of accretion onto black holes in LMXBs. We also consider prospects for detecting a gravitating object in the Galactic halo that is not known to be a LMXB, on the basis of its weakly non-linear gravitational signature, and discuss what such a detection would imply about the nature of the halo. We conclude that a large-scale survey of the Galactic halo for weakly non-linear gravitational signatures is an interesting and important direction for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gauge-Higgs Unification and Radiative Electroweak Symmetry Breaking in\n  Warped Extra Dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1281, "human_text": "  We compute the Coleman Weinberg effective potential for the Higgs field in RS Gauge-Higgs unification scenarios based on a bulk SO(5) x U(1)_X gauge symmetry, with gauge and fermion fields propagating in the bulk and a custodial symmetry protecting the generation of large corrections to the T parameter and the coupling of the Z to the bottom quark. We demonstrate that electroweak symmetry breaking may be realized, with proper generation of the top and bottom quark masses for the same region of bulk mass parameters that lead to good agreement with precision electroweak data in the presence of a light Higgs. We compute the Higgs mass and demonstrate that for the range of parameters for which the Higgs boson has Standard Model-like properties, the Higgs mass is naturally in a range that varies between values close to the LEP experimental limit and about 160 GeV. This mass range may be probed at the Tevatron and at the LHC. We analyze the KK spectrum and briefly discuss the phenomenology of the light resonances arising in our model. ", "machine_text": "  We propose a mechanism for radiative electroweak symmetry breaking in warped extra dimensions. The physical picture is that theHiggs sector couples to a U(1) gauge group that is itself warped in the extra dimensions. This produces a non-trivial Higgs potential with two distinct mass scales for the Higgs boson, one near the TeV scale and the other near the electroweak scale. The mass term for the Higgs boson is given by a non-trivial curve in the warped extra dimensions. We show that for a large class of warped extra dimension models, the mass term for the Higgs boson is always quadratic, and so the potential is aMexican hat potential. We consider the consequences of this model for the Higgs sector, and show that in certain cases the low-scale Higgs boson can be very light, and the high-scale Higgs boson can be very heavy. We show that this model can naturally explain the \"miracle\" that the Higgs boson is so light. We also show that in this model, the Higgs boson can have a Standard Model (SM) Yukawa coupling, and so the Higgs sector can be related to the SM Yukawa coupling in the same way that the SM Higgs sector is related to the Yukawa coupling in the warped extra dimensions. This has the potential to provide a unified framework for understanding both the Higgs sector and the Yukawa coupling in the warpped extra dimensions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Post-Newtonian gravitational radiation and equations of motion via\n  direct integration of the relaxed Einstein equations. V. Evidence for the\n  strong equivalence principle to second post-Newtonian order. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2243, "human_text": "  Using post-Newtonian equations of motion for fluid bodies valid to the second post-Newtonian order, we derive the equations of motion for binary systems with finite-sized, non-spinning but arbitrarily shaped bodies. In particular we study the contributions of the internal structure of the bodies (such as self-gravity) that would diverge if the size of the bodies were to shrink to zero. Using a set of virial relations accurate to the first post-Newtonian order that reflect the stationarity of each body, and redefining the masses to include 1PN and 2PN self-gravity terms, we demonstrate the complete cancellation of a class of potentially divergent, structure-dependent terms that scale as s^{-1} and s^{-5/2}, where s is the characteristic size of the bodies. This is further evidence of the Strong Equivalence Principle, and supports the use of post-Newtonian approximations to derive equations of motion for strong-field bodies such as neutron stars and black holes. This extends earlier work done by Kopeikin. ", "machine_text": " We continue our study of the equations of motion in post-Newtonian theory, obtained via direct integration of the relaxed Einstein equations. In this article, we consider the particular case of a weakly asymmetric double-pulse test configuration, which allows us to test the strong equivalence principle (SEP) to second post-Newtonian order (PN2). In our previous work, which considered a symmetric double-pulse test configuration, we found that thePN2 equations of motion exhibited a form of constraint relaxation, in which the structure of the constraint surface was different in the two post-Newtonian frames moving at different speeds. This finding was inconsistent with the strong equivalence principle, and we were able to show that this inconsistency could be resolved by introducing a small non-singular structure on the constraint surface. In this article, we consider the particular case of a weakly asymmetric double-pulse test configuration, which allows us to test the strong equivalence principle to second post-Newtonian order (PN2). In our previous work, which considered a symmetric double-pulse test configuration, we found that thePN2 equations of motion exhibited a form of constraint relaxation, in which the structure of the constraint surface was different in the two post-Newtonian frames moving at different speeds. This finding was inconsistent with the strong equivalence principle, and we were able to show that this inconsistency could be resolved by introducing a small non-singular structure on the constraint surface.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: One- and two-component bottle-brush polymers: simulations compared to\n  theoretical predictions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1124, "human_text": "  Scaling predictions and results from self-consistent field calculations for bottle-brush polymers with a rigid backbone and flexible side chains under good solvent conditions are summarized and their validity and applicability is assessed by a comparison with Monte Carlo simulations of a simple lattice model. It is shown that under typical conditions, as they are also present in experiments, only a rather weak stretching of the side chains is realized, and then the scaling predictions based on the extension of the Daoud-Cotton blob picture are not applicable.   Also two-component bottle brush polymers are considered, where two types (A,B) of side chains are grafted, assuming that monomers of different kind repel each other. In this case, variable solvent quality is allowed for, such that for poor solvent conditions rather dense cylinder-like structures result. Theories predict ``Janus Cylinder''-type phase separation along the backbone in this case. The Monte Carlo simulations, using the pruned-enriched Rosenbluth method (PERM) then are restricted to rather short side chain length. Nevertheless, evidence is obtained that the phase separation between an A-rich part of the cylindrical molecule and a B-rich part can only occur locally. The correlation length of this microphase separation can be controlled by the solvent quality. This lack of a phase transition is interpreted by an analogy with models for ferromagnets in one space dimension. ", "machine_text": " We present a theoretical study of the structure and properties of one- and two-component bottle-brush polymers in good solvent, in the limit of large brush height and small number density of macromolecules. The key ideas and methodology are: (i) the description of the polymers' structure by the mean-field theory in the basis of the nearest-neighbor approach, (ii) the assumption that the polymer conformers are tightly packed and fully overlapping, (iii) the calculation of the spatial and orientational correlations, and (iv) the use of the conformational space generated by these correlations for the construction of the configurational trees and the computation of the statistical properties. We compare our theoretical predictions with the results of computer simulations of two recently proposed algorithms for the simulation of bottle-brush polymers in good solvent, which are based on the representation of the brush by a two-level hierarchical tree and on the assumption that the solvent molecules are much more numerous than the polymer molecules. In particular, we show that both algorithms give good predictions of the radial distribution function, if the brush height is large enough, independently of the number density of macromolecules. We also show that the prediction of the configurational tree obtained by the two-component algorithm is in a very good agreement with our theory, if the number density of the polymer is not too large. We discuss the limitations of the simulation algorithms in the description of the bottle-brush structure in the limit of large number density of macromolecules and small brush height.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Discovery of two candidate pulsar wind nebulae in very-high-energy gamma\n  rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1605, "human_text": "  We present the discovery of two very-high-energy gamma-ray sources in an ongoing systematic search for emission above 100 GeV from pulsar wind nebulae in survey data from the H.E.S.S. telescope array. Imaging Atmospheric Cherenkov Telescopes are ideal tools for searching for extended emission from pulsar wind nebulae in the very-high-energy regime. H.E.S.S., with its large field of view of 5 degrees and high sensitivity, gives new prospects for the search for these objects. An ongoing systematic search for very-high-energy emission from energetic pulsars over the region of the Galactic plane between -60 degrees < l < 30 degrees, -2 degrees < b < 2 degrees is performed. For the resulting candidates, the standard H.E.S.S. analysis was applied and a search for multi-wavelength counterparts was performed. We present the discovery of two new candidate gamma-ray pulsar wind nebulae, HESS J1718-385 and HESS J1809-193. H.E.S.S. has proven to be a suitable instrument for pulsar wind nebula searches. ", "machine_text": "  We present the discovery of two candidate pulsar wind nebulae (PWNe) in very-high-energy gamma rays (VHEs). The first, identified in archival data from the MAGIC telescope, is associated with the young radio pulsar B1257+12. This is the first definitive detection of a PWN in VHEs, and the first identification of a PWN in any wavelength band based on a firm association with a single pulsar. The second is a likely PWN detected in archival data from the IceCube neutrino telescope, associated with the young radio pulsar B1510+57. This is the first candidate PWN detected in VHEs based on a firm association with a single pulsar. We find that the VHEs from these sources have a power law spectra with a cut-off energy around 100 GeV, and are accompanied by a significant excess of multi-TeV VHEs from the direction of the pulsars. These properties are consistent with a shock-ignition of VHE emission in a PWN, possibly in combination with inverse-Compton scattering of relativistic electrons in the magnetosphere of the pulsars. Our results suggest that a significant fraction of pulsars are likely to host a PWN, and that these objects may be able to explain the origin of the multi-TeV VHEs detected by previous experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-dimensional Ising model with competing interactions and its\n  application to clusters and arrays of $\\pi$-rings and adiabatic quantum\n  computing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1643, "human_text": "  We study planar clusters consisting of loops including a Josephson $\\pi$-junction ($\\pi$-rings). Each $\\pi$-ring carries a persistent current and behaves as a classical orbital moment. The type of particular state associated with the orientation of orbital moments at the cluster depends on the interaction between these orbital moments and can be easily controlled, i.e. by a bias current or by other means. We show that these systems can be described by the two-dimensional Ising model with competing nearest-neighbor and diagonal interactions and investigate the phase diagram of this model. The characteristic features of the model are analyzed based on the exact solutions for small clusters such as a 5-site square plaquette as well as on a mean-field type approach for the infinite square lattice of Ising spins. The results are compared with spin patterns obtained by Monte Carlo simulations for the 100 $\\times$ 100 square lattice and with experiment. We show that the $\\pi$-ring clusters may be used as a new type of superconducting memory elements. The obtained results may be verified in experiments and are applicable to adiabatic quantum computing where the states are switched adiabatically with the slow change of coupling constants. ", "machine_text": " We consider a two-dimensional Ising model with competing interactions and its application to clusters and arrays of $\\pi$-rings and adiabatic quantum computing. The Ising model is used to study the influence of various competing interactions on the structure of the ground state and the low-lying excitations. The $\\pi$-rings are used to realize the Ising model in a particular type of cluster and to study its low-lying excitations. We show that the ground state of the cluster Ising model is degenerate and has long-range order. The low-lying excitations of the cluster Ising model are found to be associated with the static subcluster structures. We also study the Ising model on the array of $\\pi$-rings. The ground state of the array Ising model is found to be a superposition of several simple states, and its low-lying excitations are found to be associated with the static array structures. Finally, we discuss the possibility of using the Ising model with competing interactions as a quantum bit for adiabatic quantum computation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information, information processing and gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1154, "human_text": "  I discuss fundamental limits placed on information and information processing by gravity. Such limits arise because both information and its processing require energy, while gravitational collapse (formation of a horizon or black hole) restricts the amount of energy allowed in a finite region. Specifically, I use a criterion for gravitational collapse called the hoop conjecture. Once the hoop conjecture is assumed a number of results can be obtained directly: the existence of a fundamental uncertainty in spatial distance of order the Planck length, bounds on information (entropy) in a finite region, and a bound on the rate of information processing in a finite region. In the final section I discuss some cosmological issues related to the total amount of information in the universe, and note that almost all detailed aspects of the late universe are determined by the randomness of quantum outcomes. This paper is based on a talk presented at a 2007 Bellairs Research Institute (McGill University) workshop on black holes and quantum information. ", "machine_text": " We show that information processing is necessary to explain the behavior of systems with many degrees of freedom in fields such as physics, chemistry, and biology. We find that information processing is always related to the concept of complexity. We define the concept of Complexity as the Information Capacity of a system to process information. We show that the dynamics of systems with many degrees of freedom can be described as a process of increasing complexity. We show that this process of increasing complexity is related to the process of gravitational attraction between bodies. We find that the process of increasing complexity is related to the process of increasing the capacity to process information. We show that the behavior of systems with many degrees of freedom can be explained by the dynamics of information processing. We show that this dynamics of information processing can be described by the concept of complexity. We find that complexity is always related to the Information Capacity of a system to process information.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kinematics and Dynamics of the Globular Clusters and the Planetary\n  Nebulae of NGC 5128. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1189, "human_text": "  A new kinematic and dynamic study of the halo of the giant elliptical galaxy, NGC 5128, is presented. From a spectroscopically confirmed sample of 340 globular clusters and 780 planetary nebulae, the rotation amplitude, rotation axis, velocity dispersion, and the total dynamical mass are determined for the halo of NGC 5128. The globular cluster kinematics were searched for both radial dependence and metallicity dependence by subdividing the globular cluster sample into 158 metal-rich ([Fe/H] > -1.0) and 178 metal-poor ([Fe/H] < -1.0) globular clusters. Our results show the kinematics of the metal-rich and metal-poor subpopulations are quite similar. The kinematics are compared to the planetary nebula population where differences are apparent in the outer regions of the halo. The total mass of NGC 5128 is found using the Tracer Mass estimator (Evans et al. 2003), to determine the mass supported by internal random motions, and the spherical component of the Jeans equation to determine the mass supported by rotation. We find a total mass of (1.0+/-0.2) x 10^(12) Msun from the planetary nebulae data out to a projected radius of 90 kpc and (1.3+/-0.5) x 10^(12) Msun from the globular clusters out to a projected radius of 50 kpc. Lastly, we present a new and homogeneous catalog of known globular clusters in NGC 5128. This catalog combines all previous definitive cluster identifications from radial velocity studies and HST imaging studies, as well as 80 new globular clusters from a study of M.A. Beasley et al. (2007, in preparation). ", "machine_text": "  The kinematics and dynamics of the globular clusters and the planetary nebulae of NGC 5128  We present a kinematic and dynamic study of the globular clusters and the planetary nebulae of the face-on barred spiral galaxy NGC 5128. The stellar populations of the globular clusters have been derived using high-resolution spectroscopy obtained with the DEIMOS multi-object spectrograph on Keck Observatory. We have measured the orbital speeds of the globular clusters and found that they follow two different radial distributions. The inner clusters have average speeds of 75 km/s and range from 52 to 86 km/s. The outer clusters have average speeds of 55 km/s and range from 44 to 69 km/s. The difference in the speeds of the two populations is statistically significant (p < 0.001, Student's t-test) and implies that the two populations are not genetically related. We have also measured the orbital speeds of the planetary nebulae and found that they are higher than the globular clusters, ranging from 85 to 99 km/s. The average orbital speed of the planetary nebulae is 87 km/s. We conclude that the globular clusters and the planetary nebulae of NGC 5128 have dynamical origins different from each other. The globular clusters were probably born in the same manner as those in the Milky Way, while the planetary nebulae were probably born by the gravitational interactions of the globular clusters with the bar.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stellar Evolution in NGC 6791: Mass Loss on the Red Giant Branch and the\n  Formation of Low Mass White Dwarfs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0977, "human_text": "  We present the first detailed study of the properties (temperatures, gravities, and masses) of the NGC 6791 white dwarf population. This unique stellar system is both one of the oldest (8 Gyr) and most metal-rich ([Fe/H] ~ 0.4) open clusters in our Galaxy, and has a color-magnitude diagram (CMD) that exhibits both a red giant clump and a much hotter extreme horizontal branch. Fitting the Balmer lines of the white dwarfs in the cluster, using Keck/LRIS spectra, suggests that most of these stars are undermassive, <M> = 0.43 +/- 0.06 Msun, and therefore could not have formed from canonical stellar evolution involving the helium flash at the tip of the red giant branch. We show that at least 40% of NGC 6791's evolved stars must have lost enough mass on the red giant branch to avoid the flash, and therefore did not convert helium into carbon-oxygen in their core. Such increased mass loss in the evolution of the progenitors of these stars is consistent with the presence of the extreme horizontal branch in the CMD. This unique stellar evolutionary channel also naturally explains the recent finding of a very young age (2.4 Gyr) for NGC 6791 from white dwarf cooling theory; helium core white dwarfs in this cluster will cool ~3 times slower than carbon-oxygen core stars and therefore the corrected white dwarf cooling age is in fact ~7 Gyr, consistent with the well measured main-sequence turnoff age. These results provide direct empirical evidence that mass loss is much more efficient in high metallicity environments and therefore may be critical in interpreting the ultraviolet upturn in elliptical galaxies. ", "machine_text": "  We present photometric and spectroscopic observations of the red giant branch (RGB) in the globular cluster NGC 6791. The photometry comprises a series of periodograms of over 5500 stars in the cluster, obtained with the Transiting Exoplanet Survey Satellite. The spectroscopic observations were made with the Multi-Object Spectrograph for Infra-Red Astronomy on the Very Large Telescope, and include high-resolution spectroscopy of about 70 of the cluster's red giants, as well as more than 1000 lower resolution spectra of field stars. We determine the evolutionary status of the cluster's red giants by fitting theoretical isochrones to the observed photometry. We find that a significant fraction (43%) of the red giants in the cluster are below the expected mass for the RGB, consistent with the hypothesis that a large number of low-mass stars suffer significant mass loss on the RGB. We show that the current mean metallicity of the RGB is [Fe/H] \u2248 +0.3 dex, consistent with the cluster having formed in a medium- metallicity environment, and having lost a significant fraction of its initial metal content. We discuss the evolution of the cluster and find that the current RGB is very well described by the simple King-oshima model, with an age of 12 Gyr, a star formation rate of 0.45 R\u2299 yr-1, and a mass loss rate of 1.1 R\u2299 yr-1. We find that the cluster has a significant population of low-mass white dwarfs, with a current mass of about 8.5 R\u2299. We show that this population is comprised of stars with initial masses in the range 1.5\u20132.5 M\u2299, that have lost a significant fraction of their mass on the RGB, and that have therefore cooled and contracted to become low-mass white dwarfs. We conclude that significant mass loss on the RGB is a common feature of globular clusters, and that it can have a major impact on the evolution of the cluster, affecting both the structure of the red giant branch and the properties of the low-mass white dwarf population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On Predicting the Solar Cycle using Mean-Field Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2345, "human_text": "  We discuss the difficulties of predicting the solar cycle using mean-field models. Here we argue that these difficulties arise owing to the significant modulation of the solar activity cycle, and that this modulation arises owing to either stochastic or deterministic processes. We analyse the implications for predictability in both of these situations by considering two separate solar dynamo models. The first model represents a stochastically-perturbed flux transport dynamo. Here even very weak stochastic perturbations can give rise to significant modulation in the activity cycle. This modulation leads to a loss of predictability. In the second model, we neglect stochastic effects and assume that generation of magnetic field in the Sun can be described by a fully deterministic nonlinear mean-field model -- this is a best case scenario for prediction. We designate the output from this deterministic model (with parameters chosen to produce chaotically modulated cycles) as a target timeseries that subsequent deterministic mean-field models are required to predict. Long-term prediction is impossible even if a model that is correct in all details is utilised in the prediction. Furthermore, we show that even short-term prediction is impossible if there is a small discrepancy in the input parameters from the fiducial model. This is the case even if the predicting model has been tuned to reproduce the output of previous cycles. Given the inherent uncertainties in determining the transport coefficients and nonlinear responses for mean-field models, we argue that this makes predicting the solar cycle using the output from such models impossible. ", "machine_text": " We develop a simple mean-field model for the solar cycle that is based on the hypothesis that the solar magnetic field is influenced by a combination of a secular trend and a series of periodically oscillating terms. We show that the model is able to reproduce the main features of the solar cycle, including the occurrence of sunspots, their latitudes, and the length of the cycle. We use a Monte Carlo technique to investigate the sensitivity of the model to the choice of the model parameters and to the input series of periodically oscillating terms. We show that the model can be used to predict the future development of the solar cycle. In particular, we find that the model is able to predict the occurrence of a solar maximum several years in advance with a probability higher than 0.5. The prediction is based on the knowledge of the current level of solar activity and on the previous evolution of the cycle. We discuss the relevance of our findings for understanding the underlying physical processes that give rise to the solar cycle.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hidden Symmetry of the CKM and Neutrino Mapping Matrices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4156, "human_text": "  We propose that the smallness of the light quark masses is related to the smallness of the T violation in hadronic weak interactions. Accordingly, for each of the two quark sectors (\"upper\" and \"lower\") we construct a 3\\times 3 mass matrix in a bases of unobserved quark states, such that the \"upper\"and \"lower\" basis states correspond exactly via the $W^\\pm$ transitions in the weak interaction. In the zeroth approximation of our formulation, we assume T conservation by making all matrix elements real. In addition, we impose a \"hidden symmetry\" (invariance under simultaneous translations of all three basis quark states in each sector), which ensures a zero mass eigenstate in each sector.   Next, we simultaneously break the hidden symmetry and T invariance by introducing a phase factor e^{i\\chi} in the interaction for each sector. The Jarlskog invariant J_{CKM}, as well as the light quark masses are evaluated in terms of the parameters of the model. We find a simple relation with J_{CKM}=(m_dm_s/m_b^2)^{1/2}A\\lambda^3\\cos(\\chi/2), with A and \\lambda the Wolfenstein parameters. Setting J_{CKM}=3.08 \\times 10^{-5}, m_b=4.7GeV, m_s=95MeV, A=0.818 and \\lambda=0.227, we find m_d\\cos^2(\\chi/2) \\simeq 2.4MeV, consistent with the accepted value m_d=3-7MeV.   We make a parallel proposal for the lepton sectors. With the hidden symmetry and in the approximation of T invariance, both the masses of e and \\nu_1 are zero. The neutrino mapping matrix V_\\nu is shown to be of the same Harrison-Scott form which is in agreement with experiments. We also examine the correction due to T violation, and evaluate the corresponding Jarlskog invariant {\\cal J}_\\nu. ", "machine_text": "  Hidden Symmetry of the CKM and Neutrino Mapping Matrices We show that the quark mixing matrix and the neutrino mapping matrix share a common, hidden symmetry which is related to the flavor-changing symmetries of the weak interaction. We consider the simplest case of a narrow quark-flavor distribution with three quark generations and a small number N of active neutrino flavors. The N\u00d7N neutrino mapping matrix is related to the 3\u00d73 quark mixing matrix in a way which allows to deduce the hidden symmetry of the neutrino matrix from the quark mixing matrix. We show that this symmetry is related to the flavor-changing symmetries of the weak interaction. We finally consider a more general case with a wider quark-flavor distribution and a large number N of neutrinos, and we discuss the case of an infinite number N of neutrinos. In all cases we show that the hidden symmetry of the neutrino matrix is related to the quark mixing matrix through a combination of the flavor-changing symmetries of the weak interaction and the general concept of the conservation of quadratic forms.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Top production at the Tevatron/LHC and nonstandard, strongly interacting\n  spin one particles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1499, "human_text": "  In this note, we consider possible constraints from $t \\bar t$ production on the gauge bosons of theories with an extended strong interaction sector such as axigluons or flavour universal colorons. Such constraints are found to be competitive with those obtained from the dijet data. The current $t \\bar t$ data from the Tevatron rule out axigluon masses ($m_A$) up to 900 GeV and 850 GeV at 2 $\\sigma$ and 4 $\\sigma$ levels respectively. For the case of flavour universal colorons the data rule out a mass ($m_C$) below 800 GeV (780 GeV) at the $2 (4) \\sigma $ level and also the mass range between 900 GeV to 2.1 TeV at 2 $\\sigma$ level, for $\\cot \\xi = 1$, where $\\xi$ is the mixing angle. For $\\cot \\xi =2$ on the other hand, the excluded range is $m_C \\lsim 950 (920)$ GeV and $m_C \\gsim 1.02 (1.15 \\lsim m_C \\lsim 1.8)$ TeV at $2 \\sigma$ ($4 \\sigma $) level. We point out that for higher axigluon/coloron masses, even for the dijet channel, the limits on the coloron mass, for $\\cot \\xi = 1$, may be different than those for the axigluon. We also compute the expected forward-backward asymmetry for the case of the axigluons which would allow it to be discriminated against the SM as also the colorons. We further find that at the LHC, the signal should be visible in the $t \\bar t$ invariant mass spectrum for a wide range of axigluon and coloron masses that are still allowed. We point out how top polarisation may be used to further discriminate the axigluon and coloron case from the SM as well as from each other. ", "machine_text": " We motivate our research by noting that the top quark is unique among quarks in that it can be produced in hadron collisions with a large rate, and thus offers the possibility of studying quarkonia in a new, strongly interacting regime. We briefly review the status of the Tevatron and LHC top quark searches, and outline the conditions that would have to be met in order for the top quark to be produced in large numbers at hadron colliders. We then propose a mechanism for the production of multiple top quarks in hadron collisions, and show that this mechanism is able to produce a significant number of top quarks at the Tevatron, and would be even more efficient at the LHC. We also propose a mechanism for the production of a new type of quarkonia, which we call nonstandard, strongly interacting spin one particles (NSSIPs). We show that NSSIPs can be produced at the Tevatron and LHC, and that they can be distinguished from Standard Model (SM) quarkonia. We finally discuss the experimental signatures of NSSIPs, and outline a search strategy for them at the LHC.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Anomalies and de Sitter radiation from the generic black holes in de\n  Sitter spaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3871, "human_text": "  Robinson-Wilczek's recent work shows that, the energy momentum tensor flux required to cancel gravitational anomaly at the event horizon of a Schwarzschild-type black hole has an equivalent form to that of a (1+1)-dimensional blackbody radiation at the Hawking temperature. Motivated by their work, Hawking radiation from the cosmological horizons of the general Schwarzschild-de Sitter and Kerr-de Sitter black holes, has been studied by the method of anomaly cancellation. The result shows that the absorbing gauge current and energy momentum tensor fluxes required to cancel gauge and gravitational anomalies at the cosmological horizon are precisely equal to those of Hawking radiation from it. It should be emphasized that the effective field theory for generic black holes in de Sitter spaces should be formulated within the region between the event horizon (EH) and the cosmological horizon (CH), to integrate out the classically irrelevant ingoing modes at the EH and the classically irrelevant outgoing modes at the CH, respectively. ", "machine_text": "  We study generic black holes in de Sitter spaces. We find two different classes of anomalies. One of them is a result of a local coordinate singularity, and the other is due to the dynamical Casimir effect. The first class of anomalies is eliminated by a change of the coordinate system, while the second one is only partially eliminated and results in a finite thermal mass flux for the black hole. We show that this non-zero mass flux is a result of a special form of the black hole horizon, which is different from the standard round horizon but still allows the black hole to be stable against any perturbations. The physical origin of this special form of the horizon is a strong gravitational interaction between the black hole and the space-time. We show that this interaction is a result of the de Sitter space-time being curved. We call this type of a black hole a de Sitter black hole. It has a finite temperature and a non-zero mass flux. We discuss a physical origin of the de Sitter black hole and show that it is a result of a particular form of the Einstein equations in the de Sitter space-time.  We also discuss a possibility of a detection of the de Sitter radiation from the de Sitter black hole and show that it is different from the Hawking radiation. The de Sitter radiation is a result of a periodic transient in the dipole moment of the black hole, which is caused by the periodically changing structure of the space-time. We show that this transient is related to a modulation of the Einstein equations and can be induced by a change in the radius of the de Sitter space-time. We calculate the energy flux of the de Sitter radiation and show that it is a very small fraction of the Hawking radiation for any reasonable choice of the de Sitter space-time. We also discuss a possibility of an experimental detection of the de Sitter radiation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information-Based Asset Pricing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1976, "human_text": "  A new framework for asset price dynamics is introduced in which the concept of noisy information about future cash flows is used to derive the price processes. In this framework an asset is defined by its cash-flow structure. Each cash flow is modelled by a random variable that can be expressed as a function of a collection of independent random variables called market factors. With each such \"X-factor\" we associate a market information process, the values of which are accessible to market agents. Each information process is a sum of two terms; one contains true information about the value of the market factor; the other represents \"noise\". The noise term is modelled by an independent Brownian bridge. The market filtration is assumed to be that generated by the aggregate of the independent information processes. The price of an asset is given by the expectation of the discounted cash flows in the risk-neutral measure, conditional on the information provided by the market filtration. When the cash flows are the dividend payments associated with equities, an explicit model is obtained for the share-price, and the prices of options on dividend-paying assets are derived. Remarkably, the resulting formula for the price of a European call option is of the Black-Scholes-Merton type. The information-based framework also generates a natural explanation for the origin of stochastic volatility. ", "machine_text": "  We show that information-based asset pricing models can be derived from a general principle of combining risk and Knightian uncertainty in a sophisticated way. Our approach is based on a strict synthesis of the traditional capital asset pricing model and the probabilistic methodology of Von Mises. In particular, we demonstrate that a general risk-based asset pricing model can be obtained by combining the moments of the distribution of future cash flows in a particular way, and that such a model can be arbitrage-free only if the distribution of future cash flows is completely specified. In this case, we show that the resulting model can be used to price any kind of asset, including stocks, bonds, options, futures, etc. We also show that the same principle can be used to derive an information-based asset pricing model from the moment structure of the distribution of future cash flows, and that the resulting model can be arbitrage-free only if the distribution of future cash flows is not completely specified. In this case, the model can be used to price assets which are managed in a particular way, and may lead to the pricing of assets that have no future cash flows (such as currencies or commodities).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-equilibrium coherence dynamics in one-dimensional Bose gases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2259, "human_text": "  Low-dimensional systems are beautiful examples of many-body quantum physics. For one-dimensional systems the Luttinger liquid approach provides insight into universal properties. Much is known of the equilibrium state, both in the weakly and strongly interacting regime. However, it remains a challenge to probe the dynamics by which this equilibrium state is reached. Here we present a direct experimental study of the coherence dynamics in both isolated and coupled degenerate 1d Bose gases. Dynamic splitting is used to create two 1d systems in a phase coherent state. The time evolution of the coherence is revealed in local phase shifts of the subsequently observed interference patterns. Completely isolated 1d Bose gases are observed to exhibit a universal sub-exponential coherence decay in excellent agreement with recent predictions by Burkov et al. [Phys. Rev. Lett. 98, 200404 (2007)]. For two coupled 1d Bose gases the coherence factor is observed to approach a non-zero equilibrium value as predicted by a Bogoliubov approach. This coupled-system decay to finite coherence is the matter wave equivalent of phase locking two lasers by injection. The non-equilibrium dynamics of superfluids plays an important role in a wide range of physical systems, such as superconductors, quantum-Hall systems, superfluid Helium, and spin systems. Our experiments studying coherence dynamics show that 1d Bose gases are ideally suited for investigating this class of phenomena. ", "machine_text": " We investigate the dynamics of a Bose-Einstein condensate (BEC) in a one-dimensional optical lattice, which is first prepared in a thermal equilibrium state and then rapidly displaced out of equilibrium by a short laser pulse. We find that the dynamics of the BEC during the evolution towards the new equilibrium state can be described by a general theoretical formalism based on the concept of non-equilibrium coherence. Our theory provides a good description of the experimentally observed dynamics in a recent experiment by Lucas et al., in which a one-dimensional BEC in a shallow optical lattice was driven out of equilibrium by a laser pulse. We also make predictions for the dynamics of a BEC in a deep optical lattice, which has not been investigated experimentally so far. Our results are relevant for a better understanding of the dynamics of quasiparticles in non-equilibrium states and for the development of practical schemes for the realization of matter-wave solitons in optical lattices.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gamma-ray probe of cosmic-ray pressure in galaxy clusters and\n  cosmological implications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2588, "human_text": "  Cosmic rays produced in cluster accretion and merger shocks provide pressure to the intracluster medium (ICM) and affect the mass estimates of galaxy clusters. Although direct evidence for cosmic-ray ions in the ICM is still lacking, they produce gamma-ray emission through the decay of neutral pions produced in their collisions with ICM nucleons. We investigate the capability of the Gamma-ray Large Area Space Telescope (GLAST) and imaging atmospheric Cerenkov telescopes (IACTs) for constraining the cosmic-ray pressure contribution to the ICM. We show that GLAST can be used to place stringent upper limits, a few per cent for individual nearby rich clusters, on the ratio of pressures of the cosmic rays and thermal gas. We further show that it is possible to place tight (<~10%) constraints for distant (z <~ 0.25) clusters in the case of hard spectrum, by stacking signals from samples of known clusters. The GLAST limits could be made more precise with the constraint on the cosmic-ray spectrum potentially provided by IACTs. Future gamma-ray observations of clusters can constrain the evolution of cosmic-ray energy density, which would have important implications for cosmological tests with upcoming X-ray and Sunyaev-Zel'dovich effect cluster surveys. ", "machine_text": "  We present a measurement of the cosmic-ray (CR) pressure in a large volume of the local galaxy cluster Fornax, obtained with the Gamma-Ray unlucky imaging telescope (GRIT). The measurement uses the stacking of ~50,000 CR-excess images obtained with a fish-eye lens, to obtain a map of the CR pressure integrated over the cluster. We find a pressure of $6 \\times 10^{-6}$ cm-5, which is consistent with the pressure measured by the Fermi satellite in the Galactic disk, and with other cluster measurements. We show that this pressure is in agreement with the pressure expected from a simple model in which the CRs are relativistic, and the cluster acts as a perfect drag-free Yorker bottle. In this model, the pressure is given by the relativistic energy loss of the CRs, and depends only on the CR bulk velocity and the cluster radius. We show that this model predicts a pressure of $4-6 \\times 10^{-6}$ cm-5, in good agreement with our measurement, and with other cluster measurements. We discuss the implications of our measurement for CR propagation in clusters, and for the CR source. We find that the pressure is consistent with a simple model in which the CRs are produced by a large number of weakly-ionized sources, with a uniform ionization spectrum, and with a bulk velocity that varies smoothly with the cluster radius.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Recent progresses in the simulation of small-scale magnetic fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1848, "human_text": "  New high-resolution observations reveal that small-scale magnetic flux concentrations have a delicate substructure on a spatial scale of 0.1''. Its basic structure can be interpreted in terms of a magnetic flux sheet or tube that vertically extends through the ambient weak-field or field-free atmosphere with which it is in mechanical equilibrium. A more refined interpretation comes from new three-dimensional magnetohydrodynamic simulations that are capable of reproducing the corrugated shape of magnetic flux concentrations and their signature in the visible continuum. Furthermore it is shown that the characteristic asymmetric shape of the contrast profile of facular granules is an effect of radiative transfer across the rarefied atmosphere of the magnetic flux concentration. I also discuss three-dimensional radiation magnetohydrodynamic simulations of the integral layers from the top of the convection zone to the mid-chromosphere. They show a highly dynamic chromospheric magnetic field, marked by rapidly moving filaments of stronger than average magnetic field that form in the compression zone downstream and along propagating shock fronts. The simulations confirm the picture of flux concentrations that strongly expand through the photosphere into a more homogeneous, space filling chromospheric field. Future directions in the simulation of small-scale magnetic fields are indicated by a few examples of very recent work. ", "machine_text": "  We review the state-of-the-art in the simulation of small-scale magnetic fields, including both computational techniques and recent progress in the theory of magnetic nanostructures. We discuss a range of computational methods that have been developed to simulate small-scale magnetic fields, including both empirical approaches and methods that are based on the fundamental laws of physics. We also review recent progress in the theory of magnetic nanostructures, including the development of effective theories for describing the behavior of small magnetic particles and the application of these theories to the design of new magnetic nanostructures.  The study of small-scale magnetic fields is of interest both for its own sake and for the insight it can provide into the behavior of magnetic materials at the nanoscale. Small-scale magnetic fields can be used to control the behavior of magnetic nanostructures, and they can also be used to sense and manipulate nanoscale magnetic phenomena. In this review, we discuss recent progress in the simulation of small-scale magnetic fields, including both computational techniques and recent progress in the theory of magnetic nanostructures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evaporation of buffer gas-thermalized anions out of a multipole rf ion\n  trap. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0224, "human_text": "  We identify plain evaporation of ions as the fundamental loss mechanism out of a multipole ion trap. Using thermalized negative Cl- ions we find that the evaporative loss rate is proportional to a Boltzmann factor. This thermodynamic description sheds new light on the dynamics of particles in time-varying confining potentials. It specifically allows us to extract the effective depth of the ion trap as the activation energy for evaporation. As a function of the rf amplitude we find two distinct regimes related to the stability of motion of the trapped ions. For low amplitudes the entire trap allows for stable motion and the trap depth increases with the rf field. For larger rf amplitudes, however, rapid energy transfer from the field to the ion motion can occur at large trap radii, which leads to a reduction of the effective trapping volume. In this regime the trap depth decreases again with increasing rf amplitude. We give an analytical parameterization of the trap depth for various multipole traps that allows predictions of the most favorable trapping conditions. ", "machine_text": "  We investigate the evaporation of buffer gas-thermalized anions out of a multipole rf ion trap. The problem of anion loss from a quadrupole ion trap is studied via a Monte Carlo algorithm which describes the collisions between anions and the buffer gas. The dependence of the anion loss rate on the buffer gas pressure, trap voltage and frequency as well as on the thermal velocity of the anions is investigated. We find that anion loss is mostly due to a finite number of large amplitude vibrations which are excited by the buffer gas collisions. Our results are in good agreement with an analytical theory, which is based on the assumption of a large number of thermalized anions. The agreement of the two approaches provides a good test of the respective theories. We also found that anion loss is significantly higher for anions with a large charge to mass ratio than for anions with a small charge to mass ratio. This is explained by a Boltzmann distribution of the thermalized anions in the trap. Finally we found that anion loss is much more efficient if the anions are resonantly excited by an rf field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: GRB blastwaves through wind-shaped circumburst media. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2461, "human_text": "  Context:A significant fraction of progenitors for long gamma-ray bursts (GRBs) are believed to be massive stars. The investigation of long GRBs therefore requires modeling the propagation of ultra-relativistic blastwaves through the circumburst medium surrounding massive stars. We simulate the expansion of an isotropic, adiabatic relativistic fireball into the wind-shaped medium around a massive GRB progenitor. The circumburst medium is composed of a realistically stratified stellar wind zone up to its termination shock, followed by a region of shocked wind characterized by a constant density. Aims: We followed the evolution of the blastwave through all its stages, including the extremely rapid acceleration up to a Lorentz factor 75 flow, its deceleration by interaction with stellar wind, its passage of the wind termination shock, until its propagation through shocked wind. Methods: We used the adaptive mesh refinement versatile advection code to follow the evolution of the fireball. Results: We show that the acceleration from purely thermal to ultra-relativistic kinetic regimes is abrupt and produces an internally structured blastwave. We resolved the structure of this ultra-relativistic shell in all stages, thanks to the adaptive mesh. We comment on the dynamical roles played by forward and reverse shock pairs in the phase of interaction with the free stellar wind and clearly identify the complex shock-dominated structure created when the shell crosses the terminal shock. Conclusion: We show that in our model where the terminal shock is taken relatively close to the massive star, the phase of self-similar deceleration of Blandford-McKee type can only be produced in the constant density, shocked wind zone. ", "machine_text": " We present a detailed study of the interaction of a GRB with a generic circumburst medium, focusing on the case of wind-driven formations. We find that in all cases the energy injection by the GRB is negligible compared to the energy already contained in the medium. This is confirmed by detailed dynamic calculations for simple ( iso-density ) and more realistic ( varying density ) wind-driven flows. We discuss in detail the various physical mechanisms that can give rise to a range of phenomena that have been observed, and we conclude that in most cases a simple ballistic description is sufficient to explain the observations. We do, however, point out a range of phenomena that require a more detailed description, and which therefore may be signatures of an interesting physics that is specific to these media. We also point out that although the energy injection by the GRB is not large, this may not be true for small perturbations on large length scales, and we discuss a range of phenomena that may be due to this sensitivity. We also point out that the interaction of a powerful GRB with a weakly ionized medium may have interesting effects, and we discuss a range of phenomena that may arise in such a case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Virtual photons in imaginary time: Computing exact Casimir forces via\n  standard numerical-electromagnetism techniques. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3661, "human_text": "  We describe a numerical method to compute Casimir forces in arbitrary geometries, for arbitrary dielectric and metallic materials, with arbitrary accuracy (given sufficient computational resources). Our approach, based on well-established integration of the mean stress tensor evaluated via the fluctuation-dissipation theorem, is designed to directly exploit fast methods developed for classical computational electromagnetism, since it only involves repeated evaluation of the Green's function for imaginary frequencies (equivalently, real frequencies in imaginary time). We develop the approach by systematically examining various formulations of Casimir forces from the previous decades and evaluating them according to their suitability for numerical computation. We illustrate our approach with a simple finite-difference frequency-domain implementation, test it for known geometries such as a cylinder and a plate, and apply it to new geometries. In particular, we show that a piston-like geometry of two squares sliding between metal walls, in both two and three dimensions with both perfect and realistic metallic materials, exhibits a surprising non-monotonic ``lateral'' force from the walls. ", "machine_text": "  We present a method, based on standard numerical-electromagnetism techniques, for computing the exact Casimir force between a perfect-conducting parallel-plate capacitor and a dielectric sphere in the presence of a homogeneous, isotropic, and static magnetic field. This method is exact, numerically stable, and does not require the introduction of any auxiliary fields. The computation of the Casimir force between the plates and the dielectric sphere is performed in imaginary time. The only input quantities that are computed in real time are the standard Greens functions for the electromagnetic fields in the spatial domain. The fact that the computation is performed in imaginary time does not mean that it is an approximate computation. Rather, it means that it is a exact computation that is obtained by integrating the relevant Green's functions in imaginary time. We show that the imaginary-time Greens functions for the electric and magnetic fields can be expressed in terms of the standard Greens functions for the fields in the spatial domain. This expression enables us to use standard numerical-electromagnetism techniques to compute the imaginary-time Greens functions. It also allows us to visualize the electromagnetic fields in the spatial domain and in imaginary time. We present a numerical example that illustrates our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A model for the Globular Cluster extreme anomalies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3401, "human_text": "  In spite of the efforts made in the latest years, still there is no comprehensive explanation for the chemical anomalies of globular cluster stars. Among these, the most striking is oxygen depletion, which reaches values down to [O/Fe]~-0.4 in most clusters, but in M13 it goes down to less than [O/Fe]~ - 1. In this work we suggest that the anomalies are due to the super position of two different events: 1) PRIMORDIAL SELF-ENRICHMENT: this is asked to explain the oxygen depletion down to a minimum value [O/Fe]~ -0.4; 2) EXTRA MIXING IN A FRACTION OF THE STARS ALREADY BORN WITH ANOMALOUS COMPOSITION: these objects, starting with already low [O/Fe], will reduce the oxygen abundance down to the most extreme values. Contrary to other models that invoke extra mixing to explain the chemical anomalies, we suggest that it is active only if there is a fraction of the stars in which the primordial composition is not only oxygen depleted, but also extremely helium rich (Y~ 0.4), as found in a few GCs from their main sequence multiplicity. We propose that the rotational evolution (and an associated extra mixing) of extremely helium rich stars may be affected by the fact that they develop a very small or non existent molecular weight barrier during the evolution. We show that extra mixing in these stars, having initial chemistry that has already been CNO processed, affects mainly the oxygen abundance, and to a much smaller extent if affects the sodium abundance. The model also predicts a large fluorine depletion concomitant with the oxygen depletion, and a further enhancement of the surface helium abundance, which reaches values close to Y=0.5 in the computed models. We stress that, in this tentative explanation, those stars that are primordially O--depleted, but ARE NOT extremely helium rich do not suffer deep extra mixing. ", "machine_text": "  We have developed a model that can explain the extreme anomalies observed in Globular Cluster (GC) systems. Our model consists of two components: a correlation matrix element and a non-correlation matrix element. The correlation matrix element represents the correlation between a GC and its companion stars, and can be used to derive the systemic radial velocity. The non-correlation matrix element represents the non-correlated motion of the GC and can be used to derive the peculiar velocity. We show that the peculiar velocity has a lower limit of  \u223c3 km s \u2212 1 for oldGCs and a upper limit of  \u223c120 km s \u2212 1 for youngGCs. We also show that the ratio of the peculiar velocity to the systemic velocity has a uniform lower limit of  \u223c1.5 and a uniform upper limit of  \u223c5 for all GCs. Our model provides a physical explanation for the so-called extreme anomalies and predicts a universal behaviour for all GCs. We have verified our model by applying it to the analysis of the radial velocity data obtained for the globular cluster 47 Tuc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: TrES-3: A Nearby, Massive, Transiting Hot Jupiter in a 31-Hour Orbit. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2004, "human_text": "  We describe the discovery of a massive transiting hot Jupiter with a very short orbital period (1.30619 d), which we name TrES-3. From spectroscopy of the host star GSC 03089-00929, we measure T_eff = 5720 +- 150 K, logg=4.6 +- 0.3, and vsini < 2 km/s, and derive a stellar mass of 0.90 +- 0.15 M_sun. We estimate a planetary mass of 1.92 +- 0.23 M_Jup, based on the sinusoidal variation of our high-precision radial velocity measurements. This variation has a period and phase consistent with our transit photometry. Our spectra show no evidence of line bisector variations that would indicate a blended eclipsing binary star. From detailed modeling of our B and z photometry of the 2.5%-deep transits, we determine a stellar radius 0.802 +- 0.046 R_sun and a planetary radius 1.295 +- 0.081 R_Jup. TrES-3 has one of the shortest orbital periods of the known transiting exoplanets, facilitating studies of orbital decay and mass loss due to evaporation, and making it an excellent target for future studies of infrared emission and reflected starlight. ", "machine_text": "  We present photometric and spectroscopic observations of the massive transiting exoplanet TrES-3 b, the outermost of the two giant planets in the tight, retrograde-orbit system TrES-3. We found that the planet's inner dayside is significantly hotter than its outer nightside, indicating that the dayside is irradiated by four point sources in addition to the central star. These sources are the three inner giant planets and the Sun, all of which are more or less edge-on to the orbit of TrES-3 b. We estimate that the planet's dayside temperature is Te \u2243 890 K, while the nightside temperature is Tn \u2243 710 K. We explain this temperature difference by heat transport via thermal radiation and spillover of the dayside atmosphere into the nightside hemisphere. We show that this mechanism can also explain the temperature difference observed for the giant planet Neptune. We discuss the implication of these results for the fate of hydrogen-rich planets such as TrES-3 b as they migrate to smaller orbits.   The giant planet TrES-3 b was discovered in 2007. It has since been determined to be in a retrograde orbit, making it the only giant planet known to have both a retrograde orbit and a tight orbit around its star. The properties of this planet have been extensively studied, but its orbital evolution is not yet understood. We have measured the dayside and nightside temperatures of this planet using photometry and spectroscopy, and found that the dayside temperature is 890 K, while the nightside temperature is only 710 K. We can explain this temperature difference using a model in which the dayside is irradiated by four point sources: the central star, the Sun, and the inner giant planets. We show that this model can also explain the temperature difference observed for the giant planet Neptune. We discuss the implications of our results for the fate of hydrogen-rich planets such as TrES-3 b as they migrate to smaller orbits.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The influence of AGN nuclear parameters on the FRI/FRII dichotomy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1891, "human_text": "  We have investigated the influence of nuclear parameters such as black hole (BH) mass and photoionizing luminosity on the FRI/FRII transition in a sample of nearby (z<0.2) 3CR radio galaxies. The sample was observed with medium-resolution, optical spectroscopy and contains some galaxies with unpublished velocity dispersion measurements and emission-line fluxes. Measured velocity dispersions are 130-340 km/s with a mean of 216 km/s. Converting to BH mass, we find that the BH mass distribution is identical for FRIs and FRIIs, with a mean of approximately 2.5x10^8 Msun. We convert [OII] and [OIII] emission-line luminosities to photoionizing luminosity under the assumption that the gas is ionized by the nuclear UV continuum. Most of the galaxies with FRI morphology and/or low-excitation emission-line spectra have progressively lower BH masses at lower photoionizing (and jet) luminosities. This agrees with the Ledlow-Owen relation which states that the radio luminosity at the FRI/FRII transition depends on the optical luminosity of the host, L_radio ~ L_optical^1.8, because both L_radio and L_optical relate to AGN nuclear parameters. When recasting the Ledlow-Owen relation into BH mass versus photoionizing and jet luminosity, we find that the recasted relation describes the sample quite well. The FRI/FRII transition occurs at approximately an order of magnitude lower luminosity relative to the Eddington luminosity than the soft-to-hard transition in X-ray binaries. This difference is consistent with the Ledlow-Owen relation, which predicts a weak BH mass dependence in the transition luminosity. We conclude that the FRI/FRII dichotomy is caused by a combination of external and nuclear factors, with the latter dominating. ", "machine_text": " We present a study of the influence of nuclear parameters of active galactic nuclei (AGN) on the FRI/FRII dichotomy. We consider a large sample of active galaxies with well-studied central engines, for which we have reliable redshift information and high-quality ultraviolet (UV) data from the GALAXY 2000 survey. We find that the relative contribution of the nuclear emission to the total UV emission of the galaxy, as traced by the ratio of the nuclear to the integrated UV luminosity, is a powerful diagnostic of the FRI/FRII dichotomy. We find that the probability of a galaxy being FRI is inversely proportional to this nuclear luminosity ratio. This is consistent with the idea that an AGN with a lower nuclear luminosity is less capable of powering the luminosity of its surrounding IGM, and hence is less likely to be a member of an FRI system. We also find that the accretion rate, as traced by the ratio of the nuclear to the total (nuclear plus IGM) luminosity, is a powerful diagnostic of the friend or foe dichotomy. A higher accretion rate is significantly more likely to be associated with a foe galaxy. We discuss these results in the context of the accretion history of an AGN and the feedback from the central engine to the surrounding IGM.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New possible properties of atomic nuclei investigated by non linear\n  methods: Fractal and recurrence quantification analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0903, "human_text": "  For the first time we apply the methodologies of nonlinear analysis to investigate atomic matter. We use these methods in the analysis of Atomic Weights and of Mass Number of atomic nuclei. Using the AutoCorrelation Function and Mutual Information we establish the presence of nonlinear effects in the mechanism of increasing mass of atomic nuclei considered as a function of the atomic number. We find that increasing mass is divergent, possibly chaotic. We also investigate the possible existence of a Power Law for atomic nuclei and, using also the technique of the variogram, we conclude that a fractal regime could superintend to the mechanism of increasing mass for nuclei. Finally, using the Hurst exponent, evidence is obtained that the mechanism of increasing mass in atomic nuclei is in the fractional Brownian regime. The most interesting results are obtained by using Recurrence Quantification Analysis (RQA). New recurrences, psudoperiodicities, self-resemblance and class of self-similarities are identified with values of determinism showing oscillating values indicating the presence of more or less stability during the process of increasing mass of atomic nuclei. In brief, new regimes of regularities are identified for atomic nuclei that deserve to be studied by future researches. In particular an accurate analysis of binding energy values by nonlinear methods is further required. ", "machine_text": " We have developed a new method for investigating the properties of atomic nuclei, based on the analysis of the distribution of statistical Shannon entropies associated with the emission of radiation by nuclear excited states. We show that, in addition to the well-known properties related to the standard model of atomic nuclei, our method reveals new properties, which are related to the concepts of fractal and recurrence, that we have introduced in this field for the first time. We find that the entropies distribution has a fractal structure, and that this fractal structure is related to the occurrence of recurrent patterns in the distribution of the amplitudes of the emitted radiation. Our method is based on the use of non-linear measures of statistical entropies, such as the difference between the entropies associated with the emission of radiation and the entropies associated with the excitation of the corresponding quantum states. Our results show that the new properties found are related to the violation of the commutativity and the associativity of the operations of multiplication and addition, in the set of the quantum numbers which describe the atomic nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A modified cable formalism for modeling neuronal membranes at high\n  frequencies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3759, "human_text": "  Intracellular recordings of cortical neurons in vivo display intense subthreshold membrane potential (Vm) activity. The power spectral density (PSD) of the Vm displays a power-law structure at high frequencies (>50 Hz) with a slope of about -2.5. This type of frequency scaling cannot be accounted for by traditional models, as either single-compartment models or models based on reconstructed cell morphologies display a frequency scaling with a slope close to -4. This slope is due to the fact that the membrane resistance is \"short-circuited\" by the capacitance for high frequencies, a situation which may not be realistic. Here, we integrate non-ideal capacitors in cable equations to reflect the fact that the capacitance cannot be charged instantaneously. We show that the resulting \"non-ideal\" cable model can be solved analytically using Fourier transforms. Numerical simulations using a ball-and-stick model yield membrane potential activity with similar frequency scaling as in the experiments. We also discuss the consequences of using non-ideal capacitors on other cellular properties such as the transmission of high frequencies, which is boosted in non-ideal cables, or voltage attenuation in dendrites. These results suggest that cable equations based on non-ideal capacitors should be used to capture the behavior of neuronal membranes at high frequencies. ", "machine_text": "  A modified cable formalism for modeling neuronal membranes at high frequencies  We have developed a modified cable formalism that enables us to analyze the propagation of extracellularly applied electric fields in cables of arbitrary geometry, including cables that are terminated in neuronal membranes. Our formalism is based on a finite-element model of the cable and includes a dynamic model of the transmembrane potential in the neuronal membranes. We show that this formalism can be used to analyze the effects of geometry and spatial distributions of conductivities in cables on the extracellular signatures of neuronal membranes. In particular, we show that the cables can be treated as if all of their conducting elements were lumped together into a single element, as long as the frequency of the applied field is sufficiently high. We apply our formalism to study the extracellular signatures of cables that are terminated in neuronal membranes and that have complex geometries, and we show that these signatures can be obtained from the solution to a set of simple ordinary differential equations. We also show that our formalism can be used to investigate the effects of cable geometries on the transmission of extracellularly applied signals to the interiors of neuronal membranes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-adiabatic transport in a quantum dot turnstile. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0968, "human_text": "  We present a theoretical study of the electronic transport through a many-level quantum dot driven by time-dependent signals applied at the contacts to the leads. If the barriers oscillate out of phase the system operates like a turnstile pump under a finite constant bias, as observed in the experiments of Kouwenhoven {\\it et al.} [Phys. Rev. Lett. {\\bf 67}, 1626 (1991)]. The time-dependent currents and their averages over succesive pumping periods are computed from the Keldysh formalism for tight-binding models. The calculation considers a sudden application of the pumping potentials at $t=0$ which leads to transient features of the time-dependent and averaged currents during the first pumping cycles which turn out to be important in the high-frequency regime. We show that in the transient regime the efficiency of the system as a pump is rather poor because it mainly absorbs charge from both leads in order to fill the levels located below the bias window. Under a finite bias and a low-frequency pumping signal the charge transferred across the system depends on the number of levels located within the bias window. The internal charge dynamics and the role of energy sidebands are investigated. The so called satellite peaks of the averaged current are observed also in the transient regime. ", "machine_text": " We investigate non-adiabatic transport in a quantum dot turnstile. We consider a broad range of initial conditions and find that the transport is universal, in the sense that the total transport can be predicted from the initial condition most distant from the turnstile. The transport is due to a combination of quantum tunnelling and thermal diffusion, the latter being particularly important for the initial transport away from the turnstile. The transport is found to be ballistic for a range of initial conditions, and the ballisticity is shown to be related to the interatomic distance in the quantum dot. Our results are consistent with the transport being due to a non-adiabatic flip of the electron between two atomic orbits in the quantum dot, resulting in a discrete energy spectrum with a gap between the two orbitals. We also found a good agreement between our results and those obtained by numerical solutions of the time-dependent Schr\u00f6dinger equation for a broad range of initial conditions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Holography in Three-dimensional Kerr-de Sitter Space with a\n  Gravitational Chern-Simons Term. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4381, "human_text": "  The holographic description of the three-dimensional Kerr-de Sitter space with a gravitational Chern-Simons term is studied, in the context of dS/CFT correspondence. The space has only one (cosmological) event horizon and its mass and angular momentum are identified from the holographic energy-momentum tensor at the asymptotic infinity. The thermodynamic entropy of the cosmological horizon is computed directly from the first law of thermodynamics, with the usual Hawking temperature, and it is found that the usual Gibbons-Hawking entropy is modified. It is remarked that, due to the gravitational Chern-Simons term, (a) the results go beyond analytic continuation from AdS, (b) the maximum-mass/N-bound conjecture may be violated, and (c) the three-dimensional cosmology is chiral. A statistical mechanical computation of the entropy, from a Cardy-like formula for a dual CFT at the asymptotic boundary, is discussed. Some technical difference in the Chern-Simons energy-momentum tensor, from literatures is remarked also. ", "machine_text": "  We consider a semiclassical formulation of three-dimensional holography in the presence of a gravitational Chern-Simons term. We show that a general bulk gravity theory with a Chern-Simons term can be holographically described by a Chern-Weil ( Lagrangian) formulation in the original bulk theory. The main step is to show that the Chern-Simons term in the bulk theory can be identified with a Chern-Weil structure in the bulk theory. As an application, we show that the three-dimensional Einstein-Chern-Simons theory can be holographically described by a Chern-Weil formulation in the three-dimensional Kerr-de Sitter bulk space. We also comment on the difference between our holographic description and the previously known two-dimensional version.  We consider the semiclassical formulation of three-dimensional holography in the presence of a gravitational Chern-Simons term. We show that a general bulk gravity theory with a Chern-Simons term can be holographically described by a Chern-Weil ( Lagrangian) formulation in the original bulk theory. The main step is to show that the Chern-Simons term in the bulk theory can be identified with a Chern-Weil structure in the bulk theory. As an application, we show that the three-dimensional Einstein-Chern-Simons theory can be holographically described by a Chern-Weil formulation in the three-dimensional Kerr-de Sitter bulk space. We also comment on the difference between our holographic description and the previously known two-dimensional version.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The nature of a broad line radio galaxy: Simultaneous RXTE and Chandra\n  HETG observations of 3C 382. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2756, "human_text": "  We present the results from simultaneous chandra and rxte observations of the X-ray bright Broad-Line Radio Galaxy (BLRG) 3C 382. The long (120 ks) exposure with chandra HETG allows a detailed study of the soft X-ray continuum and of the narrow component of the Fe Kalpha line. The rxte PCA data are used to put an upper limit on the broad line component and constrain the hard X-ray continuum. A strong soft excess below 1 keV is observed in the time-averaged HETG spectrum, which can be parameterized with a steep power law or a thermal model. The flux variability at low energies indicates that the origin of the soft excess cannot be entirely ascribed to the circumnuclear diffuse emission, detected by chandra on scales of 20-30 arcsec (22-33 kpc). A narrow (sigma<90 eV) Fe Kalpha line (with EW< 100 eV) is observed by the chandra HEG. Similar values for the line parameters are measured by the rxte PCA, suggesting that the contribution from a broad line component is negligible. The fact that the exposure is split into two observations taken three days apart allows us to investigate the spectral and temporal evolution of the source on different timescales. Significant flux variability associated with spectral changes is observed on timescales of hours and days. The spectral variability is similar to that observed in radio-quiet AGN ruling out a jet-dominated origin of the X-rays. ", "machine_text": "  We present simultaneous observations of the broad line radio galaxy 3C 382 with the Chandra X-ray Observatory and the Rossi X-ray Timing Explorer. We find that the accretion phase of the blazar is much longer than previously estimated on the basis of optical observations, lasting at least 2.2 kyr. The observed phenomenology is consistent with a smoothly increasing flux triggered at random intervals with a distribution of phases in the binary system. We estimate the accretion rate to be  \u223c 10^( \u2212 2) M_(\u2299) yr^( \u2212 1) and the mass of the black hole to be  \u223c 6.6 kM_(\u2299). We conclude that the accretion phase of blazars is not constant, but rather it is modulated, possibly by the orbital period. We discuss several possibilities for the observed phenomenology, including a model in which the accretion rate is regulated by the orbital period, with many short orbital periods, but accretion episodes of constant duration. The accretion phase may thus be understood as a superposition of many shorter periods, with each period being individually stable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Exact half-BPS Type IIB interface solutions I: Local solution and\n  supersymmetric Janus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0022, "human_text": "  The complete Type IIB supergravity solutions with 16 supersymmetries are obtained on the manifold $AdS_4 \\times S^2 \\times S^2 \\times \\Sigma$ with $SO(2,3) \\times SO(3) \\times SO(3)$ symmetry in terms of two holomorphic functions on a Riemann surface $\\Sigma$, which generally has a boundary. This is achieved by reducing the BPS equations using the above symmetry requirements, proving that all solutions of the BPS equations solve the full Type IIB supergravity field equations, mapping the BPS equations onto a new integrable system akin to the Liouville and Sine-Gordon theories, and mapping this integrable system to a linear equation which can be solved exactly. Amongst the infinite class of solutions, a non-singular Janus solution is identified which provides the AdS/CFT dual of the maximally supersymmetric Yang-Mills interface theory discovered recently. The construction of general classes of globally non-singular solutions, including fully back-reacted $AdS_5 \\times S^5$ and supersymmetric Janus doped with D5 and/or NS5 branes, is deferred to a companion paper. ", "machine_text": "  We construct a family of BPS type IIB interfaces that generalize the construction of junction conditions at BPS type IIA interfaces. These are local solutions of the BPS type IIB equation of motion that are in general exactly half-BPS, and thus may be regarded as Janus solutions in the sense of Bergh and STagg. The construction is motivated by the desire to have a simple model of a BPS interface that is always half-BPS, even when the total BPS charge is odd. This is in contrast to the standard BPS type IIA junction conditions, which are not half-BPS when the total BPS charge is odd. The family of BPS type IIB interfaces we construct has as its limiting case the BPS type IIA junction conditions, and in particular is related to the construction of junction conditions via BPS type IIA pity LPs. We consider the simplest case of a family of BPS type IIB interfaces that is symmetric under the exchange of the ghost and anti-ghost variables. This is the case in which the BPS type IIB interfaces have the structure of BPS type IIA interfaces with an extra term that is the square of the ghost field. We show that such BPS type IIB interfaces can be obtained as the limit of a family of supersymmetric Janus solutions of the BPS type IIB equation of motion, and compute their singularities. We show that the singularities have the structure of anti-self-duality. We then consider a generalization of our construction to the case in which the BPS type IIB interfaces are not symmetric under the exchange of the ghost and anti-ghost variables.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Homogenized spectral problems for exactly solvable operators:\n  asymptotics of polynomial eigenfunctions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2822, "human_text": "  Consider a homogenized spectral pencil of exactly solvable linear differential operators $T_{\\la}=\\sum_{i=0}^k Q_{i}(z)\\la^{k-i}\\frac {d^i}{dz^i}$, where each $Q_{i}(z)$ is a polynomial of degree at most $i$ and $\\la$ is the spectral parameter. We show that under mild nondegeneracy assumptions for all sufficiently large positive integers $n$ there exist exactly $k$ distinct values $\\la_{n,j}$, $1\\le j\\le k$, of the spectral parameter $\\la$ such that the operator $T_{\\la}$ has a polynomial eigenfunction $p_{n,j}(z)$ of degree $n$. These eigenfunctions split into $k$ different families according to the asymptotic behavior of their eigenvalues. We conjecture and prove sequential versions of three fundamental properties: the limits $\\Psi_{j}(z)=\\lim_{n\\to\\infty} \\frac{p_{n,j}'(z)}{\\la_{n,j}p_{n,j}(z)}$ exist, are analytic and satisfy the algebraic equation $\\sum_{i=0}^k Q_{i}(z) \\Psi_{j}^i(z)=0$ almost everywhere in $\\bCP$. As a consequence we obtain a class of algebraic functions possessing a branch near $\\infty\\in \\bCP$ which is representable as the Cauchy transform of a compactly supported probability measure. ", "machine_text": " We consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.  We consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.  We consider the problem of finding a basis of polynomial eigenvectors for a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space. We show that if the eigenvalue is an eigenvalue of a symmetric Toeplitz operator on a Hilbert space.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dirichlet sigma models and mean curvature flow. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3985, "human_text": "  The mean curvature flow describes the parabolic deformation of embedded branes in Riemannian geometry driven by their extrinsic mean curvature vector, which is typically associated to surface tension forces. It is the gradient flow of the area functional, and, as such, it is naturally identified with the boundary renormalization group equation of Dirichlet sigma models away from conformality, to lowest order in perturbation theory. D-branes appear as fixed points of this flow having conformally invariant boundary conditions. Simple running solutions include the paper-clip and the hair-pin (or grim-reaper) models on the plane, as well as scaling solutions associated to rational (p, q) closed curves and the decay of two intersecting lines. Stability analysis is performed in several cases while searching for transitions among different brane configurations. The combination of Ricci with the mean curvature flow is examined in detail together with several explicit examples of deforming curves on curved backgrounds. Some general aspects of the mean curvature flow in higher dimensional ambient spaces are also discussed and obtain consistent truncations to lower dimensional systems. Selected physical applications are mentioned in the text, including tachyon condensation in open string theory and the resistive diffusion of force-free fields in magneto-hydrodynamics. ", "machine_text": "  We consider the asymptotic behavior of solutions to the heat equation with a nonlinear boundary condition, as the initial data tends to a Dirichlet boundary condition. We show that, in a natural class of examples, the solutions tend to a solution of the Dirichlet sigma model with a nonlinear boundary condition. The main tool is the version of theNash-Moser theorem for a Dirichlet boundary condition. The analysis also provides a motivation for the study of a class of partial differential equations which includes the heat equation with a nonlinear boundary condition, the Navier-Stokes equation with a nonlinear boundary condition and the Euler equations with a transversally varying boundary condition. It also suggests an approach to the study of the limiting behavior of solutions to these equations as the initial data tends to a Dirichlet boundary condition.  The results in this paper are based on the work of the author and M. Zalaudek. The authors would like to thank M. Zalaudek for many useful discussions and for suggesting this problem. The author would also like to thank the Austrian Science Fund (FWF) for financial support under the project P18007.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The KATRIN sensitivity to the neutrino mass and to right-handed currents\n  in beta decay. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.393, "human_text": "  The aim of the KArlsruhe TRItium Neutrino experiment KATRIN is the determination of the absolute neutrino mass scale down to 0.2 eV, with essentially smaller model dependence than from cosmology and neutrinoless double beta decay. For this purpose, the integral electron energy spectrum is measured close to the endpoint of molecular tritium beta decay. The endpoint, together with the neutrino mass, should be fitted from the KATRIN data as a free parameter. The right-handed couplings change the electron energy spectrum close to the endpoint, therefore they have some effect also to the precise neutrino mass determination. The statistical calculations show that, using the endpoint as a free parameter, the unaccounted right-handed couplings constrained by many beta decay experiments can change the fitted neutrino mass value, relative to the true neutrino mass, by not larger than about 5-10 %. Using, incorrectly, the endpoint as a fixed input parameter, the above change of the neutrino mass can be much larger, order of 100 %, and for some cases it can happen that for large true neutrino mass value the fitted neutrino mass squared is negative. Publications using fixed endpoint and presenting large right-handed coupling effects to the neutrino mass determination are not relevant for the KATRIN experiment. ", "machine_text": " The KATRIN sensitivity to the neutrino mass and to right-handed currents in beta decay   The neutrino mass is a violation of the Standard Model (SM) and can be probed by the measure-ment of the ratio \ue0c1Meb/\ue0c1Meu, where e and u are the SM generations of elementary fermions. The smallest such ratio is expected to be found in beta decays with a very light neutrino mass and a heavy partner (e.g. a charged lepton). The current best prediction for the neutrino mass is \ue0c1Mnu \u223c 1 eV. A large excess of events in the final state with two energetic electrons in the KATRIN experiment would unambiguously indicate the presence of a non-SM neutrino mass \ue0c1Mnu > 1 eV.   A non-SM right-handed neutrino current in the beta decay could be searched for by looking for a significant excess of events with a final state containing two electrons and two jets, where the two electrons are produced from the decay of a charged lepton. The search strategy is to use the fact that the flavor changing processes are strictly forbidden in the SM, therefore any significant departure from the SM expectation would be a clear sign of new physics.   We show that the proposed KATRIN experiment is sensitive to a right-handed neutrino current in the beta decay, if the neutrino mass is \ue0c1Mnu > 10 GeV. A small excess of events with two electrons and two jets would already be an indication of a non-SM neutrino mass \ue0c1Mnu > 10 GeV.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Role of the rho meson in the description of pion electroproduction\n  experiments at JLab. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1844, "human_text": "  We study the p(e,e' pi+)n reaction in the framework of an effective Lagrangian approach including nucleon, pi and rho meson degrees of freedom and show the importance of the rho-meson t-pole contribution to sigmaT, the transverse part of cross section. We test two different field representations of the rho meson, vector and tensor, and find that the tensor representation of the rho meson is more reliable in the description of the existing data. In particular, we show that the rho-meson t-pole contribution, including the interference with an effective non-local contact term, sufficiently improves the description of the recent JLab data at invariant mass W less 2.2 GeV and Q2 less 2.5 GeV2/c2. A ``soft'' variant of the strong piNN and rhoNN form factors is also found to be compatible with these data. On the basis of the successful description of both the sigmaL and sigmaT parts of the cross section we discuss the importance of taking into account the sigmaT data when extracting the charge pion form factor Fpi from sigmaL. ", "machine_text": " We present a brief summary of our work on the role of the rho meson in the description of pion electroproduction experiments at JLab. We discuss the motivation for our research, the key ideas and methodology used, the results obtained, the problem our work attempts to solve, and any practical or theoretical applications of our findings or implications for future research.   Our work aims to better understand the role of the rho meson in the description of pion electroproduction experiments at JLab. We use a formalism that includes the rho meson and the pion in the final state. We fit the data to the theory in a systematic way, and we obtain a good description of the data, which allows us to extract the physical parameters that are needed to understand the pion electroproduction process.   Our work makes use of the fact that the rho meson is an unstable particle that can decay to a variety of final states. We use a formalism that includes the rho meson and the pion in the final state. We fit the data to the theory in a systematic way, and we obtain a good description of the data, which allows us to extract the physical parameters that are needed to understand the pion electroproduction process.   We have been able to extract the physical parameters that are needed to understand the pion electroproduction process. Our results are in good agreement with the predictions of the Standard Model, and we have been able to constrain some of the theoretical parameters. We have also been able to make predictions for future experiments.   Our work has implications for the future of pion electroproduction experiments. We have been able to make predictions for future experiments, and we have also been able to constrain some of the theoretical parameters. Our work is important for the understanding of the pion electroproduction process, and it has practical applications for the design of future experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining the Geometry of the Neutron Star RX J1856.5-3754. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4543, "human_text": "  RX J1856.5-3754 is one of the brightest, nearby isolated neutron stars, and considerable observational resources have been devoted to its study. In previous work, we found that our latest models of a magnetic, hydrogen atmosphere matches well the entire spectrum, from X-rays to optical (with best-fitting neutron star radius R=14 km, gravitational redshift z_g~0.2, and magnetic field B~4x10^12 G). A remaining puzzle is the non-detection of rotational modulation of the X-ray emission, despite extensive searches. The situation changed recently with XMM-Newton observations that uncovered 7 s pulsations at the 1% level. By comparing the predictions of our model (which includes simple dipolar-like surface distributions of magnetic field and temperature) with the observed brightness variations, we are able to constrain the geometry of RX J1856.5-3754, with one angle < 6 deg and the other angle = 20-45 deg, though the solutions are not definitive given the observational and model uncertainties. These angles indicate a close alignment between the rotation and magnetic axes or between the rotation axis and the observer. We discuss our results in the context of RX J1856.5-3754 being a normal radio pulsar and a candidate for observation by future X-ray polarization missions such as Constellation-X or XEUS. ", "machine_text": " We present new radio timing observations of the isolated neutron star RX J1856.5-3754. We find that the system is best described by a Lorentzian orbit with a 6.6 day period, in disagreement with previous suggestions of a longer period. This 6.6 day period is nearly identical to that of the well-studied low-mass X-ray binary 4U0142-69, for which we present a detailed comparison. We find no evidence of any long-term timing variations, but we do observe a secular trend in the data which may be due to small-scale timing variations on timescales of years. We present a formalism which can be used to extract the contribution of such variations to the measured time derivative of the orbital elements. Our best-fit model requires that the accretion disc be eccentric, which is inconsistent with the assumption of a circular orbit, and we discuss possible geometries which could give rise to this. We also present observations of the X-ray and radio brightnesses as a function of orbital phase, which together with the timing observations, constrain the geometry of the accretion disc. We conclude that the disc is unlikely to be in a bipolar geometry, and we discuss the implications of this for the stability of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A discrete computer network model with expanding dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0855, "human_text": "  Complex networks with expanding dimensions are studied, where the networks may be directed and weighted, and network nodes are varying in discrete time in the sense that some new nodes may be added and some old nodes may be removed from time to time. A model of such networks in computer data transmission is discussed. Each node on the network has fixed dimensionality, while the dimension of the whole network is defined by the total number of nodes. Based on the spectacular properties of data transmission on computer networks, some new concepts of stable and unstable networks differing from the classical Lyapunov stability are defined. In particular, a special unstable network model, called devil network, is introduced and discussed. It is further found that a variety of structures and connection weights affects the network stability substantially. Several criteria on stability, instability, and devil network are established for a rather general class of networks, where some conditions are actually necessary and sufficient. Mathematically, this paper makes a first attempt to rigorously formulate a fundamental issue of modeling discrete linear time-varying systems with expanding dimensions and study their basic stability property. ", "machine_text": "  We consider a simple model of a discrete computer network in which the underlying graph changes with time, as nodes are added to and deleted from the network. We suppose that the addition and deletion of nodes are independent events, and that the underlying graph is a random graph which is generated according to a given probability distribution. Our main results relate the degree distribution of the network at time t to the degree distribution of the network at time t+1. In particular, we show that if the underlying graph is a random graph which is generated according to a given probability distribution, then the degree distribution at time t+1 is approximately multinomial, with parameters which are related to the degree distribution at time t and the probability distribution which is used to generate the underlying graph. As a by-product of our main results, we show that if the underlying graph is a random graph which is generated according to a given probability distribution, then the expected number of links per node is independent of the number of nodes in the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamic response of Ag monolayers adsorbed on Au(100) upon an\n  oscillatory variation of the chemical potential: A Monte Carlo simulation\n  study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.447, "human_text": "  Based on the fact that the underpotential electrochemical deposition of Ag atoms on the $Au(100)$ surface exhibits sharp first-order phase transitions at well-defined values of the (coexistence) chemical potential ($\\mu_{coex}$), we performed extensive simulations aimed at investigating the hysteretic dynamic behavior of the system close to coexistence upon the application of a periodic signal of the form $\\mu(t) = \\mu_{coex} + \\mu_{o}sin(2\\Pi t/\\tau) $, where $\\mu_{o}$ and $\\tau$ are the amplitude and the period of the sweep, respectively. For relatively short periods and small enough amplitudes the system becomes trapped either at low or high Ag coverage states, as evidenced by recording hysteresis loops. This scenario is identified as dynamically ordered states (DOS), such that the relaxation time $(\\tau_{relax})$ of the corresponding metastable state obeys $\\tau_{relax} > \\tau $. On the other hand, by properly increasing $\\mu_{o}$ or/and $\\tau$, one finds that the $Ag$ coverage gently follows the external drive (here $\\tau_{relax} < \\tau $) and the system is said to enter into dynamically disordered states (DDS), where hysteresis loops show almost symmetric limiting cycles. This symmetry breaking between limiting cycles driven by an external signal is discussed in terms of the concept of (out-of-equilibrium) Dynamic Phase Transitions between DOS and DDS, similar to those encountered when a magnetic system is placed in the presence of a variable external magnetic field. However, a careful finite-size scaling study reveals that, at least at $T = 300K$, the $Ag/Au(100)$ system does not exhibit true second-order phase transitions but rather a crossover behavior between states. A diagram showing the location of the ordered and disordered states in the $\\mu$ versus $\\tau$ plane is obtained and discussed. ", "machine_text": " We present a Monte Carlo simulation study of the dynamic response of Ag adsorbates on Au(100) to an oscillatory variation of the chemical potential. We find that the distribution of the adsorbates is affected in a manner that depends on the magnitude of the amplitude of the chemical potential variation as well as on the frequency with which it is varied. Our results show that the distribution of the adsorbates becomes more uniform as the amplitude is increased, but that the standard deviation of the distribution increases as the frequency is increased. We also find that the dynamic response is affected by the history of the variation of the chemical potential, with the distribution of the adsorbates becoming more uniform if the variation is started from a state in which the adsorbates are highly ordered, and becoming more disordered if the variation is started from a state in which the adsorbates are highly disordered. We discuss our results in the framework of a simple model in which the adsorbates are treated as hard disks that can rotate in response to an external torque.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High-energy threshold reaction rates on 0.8 GeV proton-irradiated thick\n  Pb-target. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1024, "human_text": "  This works presents results of activation-aided determination of threshold reaction rates in 92 209Bi, natPb, 197Au, 181Ta, 169Tm, natIn, 93Nb, 64Zn, 65Cu, 63Cu, 59Co, 19F, and 12C samples and in 121 27Al samples. All the samples were aligned with the proton beam axis inside and outside the demountable 92-cm thick Pb target of 15-cm diameter assembled of 23 4-cm thick discs. The samples were placed on 12 target disks to reproduce the long axis distribution of protons and neutrons. In June 2006, the target was exposed for 18 hours to a 800-MeV proton beam extracted from the ITEP U-10 accelerator. The proton fluence and the proton beam shape were determined using the 27Al(p,x)7Be monitor reaction. The reaction rates were determined by the direct gamma-spectrometry techniques. In total, 1196 gamma-spectra have been measured, and about 1500 reaction rates determined. The measured reaction rates were simulated by the MCNPX code using the following databases: ENDF/B6 for neutrons below 20 MeV, MENDL2 for 20-100 MeV neutrons, and MENDL2P for proton cross sections up to 200 MeV. An acceptable agreement of simulations with experimental data has been found. ", "machine_text": " We present here the results of a comprehensive study of the high-energy threshold reaction rates on a 0.8 GeV proton-irradiated thick Pb target. The main goal of the work is to establish the viability of using such an irradiated target as a source of high-energy X-rays in an X-ray generator. The study consists of measurements of the X-ray yield as a function of the accelerating voltage in an X-ray tube using such a target and of the resulting high-energy threshold reaction rates. We observe a clear and strong peak in the X-ray yield at an accelerating voltage of 60 kV. The corresponding threshold reaction rate is 1.5 \u00b7 10-6 cm2s-1. We also find that the threshold reaction rate increases rapidly with the accelerating voltage, in spite of the fact that the nuclear reactions that are responsible for the X-ray emission become less and less efficient as the proton energy increases. This is explained by the fact that at high accelerating voltages the tube geometry becomes more and more favourable for the emission of high-energy X-rays. We discuss our results in the framework of a simple theoretical model, according to which the X-ray yield is related to the nuclear track density in the target. We estimate the track density in our target and find that it is in reasonable agreement with our model predictions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information diffusion epidemics in social networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0641, "human_text": "  The dynamics of information dissemination in social networks is of paramount importance in processes such as rumors or fads propagation, spread of product innovations or \"word-of-mouth\" communications. Due to the difficulty in tracking a specific information when it is transmitted by people, most understanding of information spreading in social networks comes from models or indirect measurements. Here we present an integrated experimental and theoretical framework to understand and quantitatively predict how and when information spreads over social networks. Using data collected in Viral Marketing campaigns that reached over 31,000 individuals in eleven European markets, we show the large degree of variability of the participants' actions, despite them being confronted with the common task of receiving and forwarding the same piece of information. This have a profound effect on information diffusion: Firstly, most of the transmission takes place due to super-spreading events which would be considered extraordinary in population-average models. Secondly, due to the different way individuals schedule information transmission we observe a slowing down of the spreading of information in social networks that happens in logarithmic time. Quantitative description of the experiments is possible through an stochastic branching process which corroborates the importance of heterogeneity. Since high variability of both the intensity and frequency of human responses are found in many other activities, our findings are pertinent to many other human driven diffusion processes like rumors, fads, innovations or news which has important consequences for organizations management, communications, marketing or electronic social communities. ", "machine_text": " We study the problem of information diffusion in social networks. We define an information diffusion epidemic as a rapid and extensive propagation of information in a social network. We identify three basic mechanisms for the diffusion of information: local updating, global updating, and error propagation. We study the effect of these mechanisms on the speed of information diffusion and on the spatial and temporal patterns of diffusion. In particular, we show that the speed of information diffusion increases with the density of the social network, but it decreases with the degree of the social network. We find that the local updating mechanism is the most important one in small social networks, while the global updating mechanism is the most important one in large social networks. We also study the spatial and temporal patterns of information diffusion, and we find that they can be explained by a simple model based on the Hopfield model. Finally, we present a simple model of information diffusion that is consistent with the main results of our study.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near- and Far-Infrared Counterparts of Millimeter Dust Cores in the Vela\n  Molecular Ridge Cloud D. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1228, "human_text": "  The aim of this paper is to identify the young protostellar counterparts associated to dust millimeter cores of the Vela Molecular Ridge Cloud D through new IR observations (H_2 narrow-band at 2.12 micron and N broad band at 10.4 micron) along with an investigation performed on the existing IR catalogues. The association of mm continuum emission with infrared sources from catalogues (IRAS, MSX, 2MASS), JHK data from the literature and new observations, has been established according to spatial coincidence, infrared colours and spectral energy distributions. Only 7 out of 29 resolved mm cores (and 16 out of the 26 unresolved ones) do not exhibit signposts of star formation activity. The other ones are clearly associated with: far-IR sources, H_2 jets or near-IR objects showing a high intrinsic colour excess. The distribution of the spectral indices pertaining to the associated sources is peaked at values typical of Class I objects, while three objects are signalled as candidates Class 0 sources. We remark the high detection rate (30%) of H_2 jets driven by sources located inside the mm-cores. They appear not driven by the most luminous objects in the field, but rather by less luminous objects in young clusters, testifying the co-existence of both low- and intermediate-mass star formation. The presented results reliably describe the young population of VMR-D. However, the statistical evaluation of activity vs inactivity of the investigated cores, even in good agreement with results found for other star forming regions, seems to reflect the limiting sensitivity of the available facilities rather than any property intrinsic to the mm-condensations. ", "machine_text": "  We present a search for optically thick dust cores in the Vela Molecular Ridge Cloud D by combining near-infrared and far-infrared images obtained with the Hubble Space Telescope. We find seven core candidates, four of which are associated with the oxygen rich shocked molecular hydrogen sources in the region. One of these cores, in the source VMR D1, contains an optically thick core with a mass of about 15 M . The core is nearly axisymmetric and has a well-defined boundary. It is embedded in a much larger and more extended core of optically thin gas. We discuss this core in the context of models for the formation of massive cores and the termination of star formation in molecular clouds.  We present a new method for finding optically thick dust cores in molecular clouds. We search for the counterparts of the dust cores in the near-infrared and far-infrared. We find that the far-infrared images are best suited for this purpose because they are insensitive to small temperature variations in the gas. In the Vela Molecular Ridge Cloud D we find a strong correlation between the location of the shocked molecular hydrogen sources and the position of the optically thick cores. We present a model in which the massive cores are formed through the accretion of small cores along the streamline of the supersonic turbulence. The model predicts that massive cores will be found in association with the sources, as we observe in VMR D1. We discuss the implication of this model for the termination of star formation in molecular clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Separability Criterion for multipartite quantum states based on the\n  Bloch representation of density matrices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3942, "human_text": "  We give a new separability criterion, a necessary condition for separability of $N$-partite quantum states. The criterion is based on the Bloch representation of a $N$-partite quantum state and makes use of multilinear algebra, in particular, the matrization of tensors. Our criterion applies to {\\it arbitrary} $N$-partite quantum states in $\\mathcal{H}=\\mathcal{H}^{d_1}\\otimes \\mathcal{H}^{d_2} \\otimes ... \\otimes \\mathcal{H}^{d_N}.$ The criterion can test whether a $N$-partite state is entangled and can be applied to different partitions of the $N$-partite system. We provide examples that show the ability of this criterion to detect entanglement. We show that this criterion can detect bound entangled states. We prove a sufficiency condition for separability of a 3-partite state, straightforwardly generalizable to the case $N > 3,$ under certain condition. We also give a necessary and sufficient condition for separability of a class of $N$-qubit states which includes $N$-qubit PPT states. ", "machine_text": "  We introduce a separability criterion for multipartite quantum states based on the Bloch representation of density matrices. The motivation for this work is the fact that, while the separability criterion for bipartite quantum states is well-known and widely used, a similar criterion for multipartite states is not available, despite the fact that such states occur naturally in many physical systems. The key idea is to use the Bloch representation to decompose a density matrix into a direct sum of simpler density matrices, each of which is either completely separable or at most a singlet state. The methodology is to use the Jordan decomposition to reduce the density matrix to a matrix with only diagonal blocks, which can then be further reduced to a direct sum of blocks that are either completely separable or at most a singlet state. The results obtained are that the proposed criterion is satisfied by any multipartite state that is either completely separable or at most a singlet state. The problem the work attempts to solve is to provide a separability criterion for multipartite quantum states that is as simple and straightforward as the criterion for bipartite states. The practical application of the work is that it provides a way to test whether a given multipartite state is separable or not, which could be useful in the study of multipartite quantum systems. The theoretical application of the work is that it provides a way to classify multipartite quantum states according to their level of separability, which could be useful in the study of the properties of quantum systems with more than two participants.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Imaging the Cosmic Matter Distribution using Gravitational Lensing of\n  Pregalactic HI. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0849, "human_text": "  21-cm emission from neutral hydrogen during and before the epoch of cosmic reionisation is gravitationally lensed by material at all lower redshifts. Low-frequency radio observations of this emission can be used to reconstruct the projected mass distribution of foreground material, both light and dark. We compare the potential imaging capabilities of such 21-cm lensing with those of future galaxy lensing surveys. We use the Millennium Simulation to simulate large-area maps of the lensing convergence with the noise, resolution and redshift-weighting achievable with a variety of idealised observation programmes. We find that the signal-to-noise of 21-cm lens maps can far exceed that of any map made using galaxy lensing. If the irreducible noise limit can be reached with a sufficiently large radio telescope, the projected convergence map provides a high-fidelity image of the true matter distribution, allowing the dark matter halos of individual galaxies to be viewed directly, and giving a wealth of statistical and morphological information about the relative distributions of mass and light. For instrumental designs like that planned for the Square Kilometer Array (SKA), high-fidelity mass imaging may be possible near the resolution limit of the core array of the telescope. ", "machine_text": "  We present a new method for constructing a three-dimensional map of the distribution of matter in the Universe, based on the gravitational lensing of the hydrogen (HI) radio galaxies. The method is independent of the galaxies' redshifts, but requires a redshift-dependent calibration of the lensing effect. We have constructed a catalog of 30,000 galaxies in a redshift range of 1 - 2, and use this catalog to calibrate the lensing effect. We show that the method is able to detect the matter distribution in a range of scales from clusters to super clusters, provided that the clusters are located in front of the galaxies. We demonstrate that the method is sensitive to the matter distribution in a range of concentrations from 10 - 10^2 cm^-3. We show that the clusters detected by our method are consistent with the clusters found by the current cluster detection methods. We estimate the statistical significance of our detection, and compare it to the current cluster detection methods. We also discuss the systematic errors in our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Comment on the statistical analysis in \"A new experimental limit for the\n  stability of the electron\" by H.V. Klapdor-Kleingrothaus, I.V. Krivosheina\n  and I.V. Titkova. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2047, "human_text": "  We point out the evident errors in statistical analysis of the data, performed by Klapdor-Kleingrothaus et al in recently published paper to establish a limit on the stability of electron with respect to the decay into $\\nu+\\gamma$. We performed the reestimation of the sensitivity of the experimental setups to the 256 keV gamma emitted in the hypothetical electron decay, and show that in [1] the limits on the electron stability and charge nonconservation parameter $\\epsilon_{e\\nu\\gamma}^{2}$ are overestimated by at least a factor of 5. We have revealed evident errors in the statistical analysis, performed by Klapdor-Kleingrothaus et al in a recently published paper [1] to establish a limit on the stability of electron with respect to the decay into $\\nu+\\gamma$. The performed reestimation of the sensitivity of the experimental setups to the 256 keV gamma emitted in the hypothetical electron decay, has shown that the limits on the electron stability and charge nonconservation parameter $\\epsilon_{e\\nu\\gamma}^{2}$ presented in [1], have been overestimated by at least a factor of 5. ", "machine_text": " We comment on the statistical analysis in \"A new experimental limit for the stability of the electron\" by H.V. Klapdor-Kleingrothaus, I.V. Krivosheina and I.V. Titkova. We point out that the criterion of the stability of the electron proposed in this work is not equivalent to the usual definition of the electron stability. The authors introduce the additional condition that the energy of the electron should be minimal not only with respect to the entire potential energy surface, but also with respect to the space of the functions which are regular in the regions of the atomic nuclei and the electrons. As a result the usual definition of the electron stability is not satisfied and the obtained limit for the stability of the electron is larger than the corresponding limit obtained by using the usual definition. The work of the authors is an example of the application of the false logic in the statistical analysis. The obtained limit for the stability of the electron does not correspond to the physically possible values of the electron stability and has no physical meaning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Massive gravity and structure formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1301, "human_text": "  We study the growth of cosmological perturbations in the model of Lorentz-violating massive gravity. The Friedman equation in this model acquires an unconventional term due to the Lorentz-breaking condensates which has the equation of state w = -1 / (3 gamma) with gamma being a free parameter taking values outside of the range [0,1/3]. Apart from the standard contributions, the perturbations above the Friedmann background contain an extra piece which is proportional to an arbitrary function theta(x) of the space coordinates. This function appears as an integration constant and corresponds to a non-propagating scalar mode which may, however, become dynamical with the account of the higher-derivative corrections. For -1 < gamma < 0 and gamma = 1 the ``anomalous'' perturbations grow slower than the standard ones and thus the model is compatible with observations. Whether the model is experimentally acceptable at other values of \\gamma depends on the value of the function theta(x) at the beginning of the radiation-dominated epoch. ", "machine_text": " We consider massive gravity in the regime where the asymptotic speed of propagation of gravity waves is less than the speed of light. Such a regime can be found by using an auxiliary field theory in which the massive gravity is described by a gauge theory with a non-minimally coupled vector field. In this formalism the massively gravity is effectively described by a pure gravity theory with a structure constant which takes a negative value and with a non-vanishing cosmological constant. This description has a clear physical interpretation: massive gravity is described by an effective four-dimensional theory which contains a two-dimensional gravity theory with a structure constant taking a negative value and with a non-vanishing cosmological constant, coupled to a two-dimensional Yang-Mills theory with a non-minimally coupled vector field. We show that this effective theory describes the same physical system as the massive gravity in the regime where the asymptotic speed of propagation of gravity waves is less than the speed of light. We then use this effective theory to study the early structure formation in the universe. We find that the massive gravity structure formation is different from the pure gravity structure formation, and the massive gravity structure formation is described by a simpler model in which the evolution is determined by the two-dimensional gravity theory with a structure constant taking a negative value and with a non-vanishing cosmological constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cosmic Code Comparison Project. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.127, "human_text": "  Current and upcoming cosmological observations allow us to probe structures on smaller and smaller scales, entering highly nonlinear regimes. In order to obtain theoretical predictions in these regimes, large cosmological simulations have to be carried out. The promised high accuracy from observations make the simulation task very demanding: the simulations have to be at least as accurate as the observations. This requirement can only be fulfilled by carrying out an extensive code validation program. The first step of such a program is the comparison of different cosmology codes including gravitation interactions only. In this paper we extend a recently carried out code comparison project to include five more simulation codes. We restrict our analysis to a small cosmological volume which allows us to investigate properties of halos. For the matter power spectrum and the mass function, the previous results hold, with the codes agreeing at the 10% level over wide dynamic ranges. We extend our analysis to the comparison of halo profiles and investigate the halo count as a function of local density. We introduce and discuss ParaView as a flexible analysis tool for cosmological simulations, the use of which immensely simplifies the code comparison task. ", "machine_text": " The Cosmic Code Comparison Project is a collaboration between the Department of Energy's Lawrence Berkeley National Laboratory and the Institute for Code comparison in Cosmology and Astrophysics at the University of Chicago. The goal of this project is to compare the cosmic microwave background radiation data from the WMAP and Planck satellite missions in order to constrain the exact scaling of the amplitude of the first peak in the power spectrum. The project is motivated by the fact that the first peak in the power spectrum is thought to be a key indicator of the level of non-Gaussianity in the early universe, and so precise measurements of this peak are important for understanding the nature of the primordial fluctuations. The comparison of the two data sets will provide a precise measurement of the first peak in the power spectrum, and will also provide a rigorous test of the current models for the power spectrum. The project is expected to provide important constraints on the nature of the primordial fluctuations, and will also provide a rigorous test of the current models for the power spectrum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Characterization of Instrumental Phase Stability. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.216, "human_text": "  Atmospheric water vapor causes significant undesired phase fluctuations for the Submillimeter Array (SMA) interferometer, particularly in its highest frequency observing band of 690 GHz. One proposed solution to this atmospheric effect is to observe simultaneously at two separate frequency bands of 230 and 690 GHz. Although the phase fluctuations have a smaller magnitude at the lower frequency, they can be measured more accurately and on shorter timescales due to the greater sensitivity of the array to celestial point source calibrators at this frequency. In theory, we can measure the atmospheric phase fluctuations in the 230 GHz band, scale them appropriately with frequency, and apply them to the data in 690 band during the post-observation calibration process. The ultimate limit to this atmospheric phase calibration scheme will be set by the instrumental phase stability of the IF and LO systems. We describe the methodology and initial results of the phase stability characterization of the IF and LO systems. ", "machine_text": "  Characterization of Instrumental Phase Stability The motivation for this work is the need for high-throughput techniques for measuring the instrumental phase stability of fiber-based components. The goal is to develop an approach that does not require the use of a reference during the measurement. The proposed approach combines the advantages of two different techniques: the transmission-based technique of dual-wave mixing and the reflection-based technique of spectral interferometry. The key idea is to use the spectral interferometry technique to measure the phase contribution of a single-mode fiber and the dual-wave mixing technique to simultaneously measure the phase contribution of a multi-mode fiber. The combination of these two measurements allows us to isolate the instrumental phase contribution. The proposed approach was tested on a simple fiber-based Mach-Zehnder interferometer. The results obtained show that the instrumental phase stability can be characterized with a high degree of confidence using only the proposed approach, without the need for a reference.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of the top-quark mass using missing $E_T$+jets events with\n  secondary vertex $b$-tagging at CDF II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1594, "human_text": "  We present a measurement of the top-quark mass in $p\\bar p$ collisions at \\hbox{$\\sqrt{s}=1.96$} TeV which uses events with an inclusive signature of missing transverse energy and jets. % The event selection is sensitive to $t\\bar t\\to W^+bW^-\\bar b\\to l\\nu b q q^\\prime \\bar b$ independent of the lepton flavor, and results in a large acceptance for $W\\to\\tau\\nu$ decays. % All-hadronic $t\\bar t$ decays and events with identified electrons or muons are vetoed to provide a statistically independent sample with respect to all previous measurements. % The top-quark mass is inferred from the distribution of the scalar sum of all jet transverse energies and the missing transverse energy. Using 311 pb$^{-1}$ of integrated luminosity recorded by the Collider Detector at Fermilab, we measure a top-quark mass $m_t = 172.3 ^{+10.8}_{-9.6}$(stat.)$\\pm 10.8$(syst.) GeV/$c^2$. While the uncertainty on $m_t$ is larger than that of other measurements, the result is statistically uncorrelated with those of other methods, and thus can help to reduce the overall $m_t$ uncertainty when combined with other existing measurements. ", "machine_text": " We present a measurement of the top-quark mass using missing $E_T$+jets events with secondary vertex $b$-tagging at CDF II. The analysis uses events with at most one jet and one $b$-tag, where the $b$-tag is required to be within a cone around the missing $E_T$ vertex, and the jet is required to be within a cone around the $b$-tag. The $b$-tagging requirement significantly reduces the rate of spurious $b$-tags due to strong background. The mass is measured in the final state with one jet and one $b$-tag, using the resolved $S$-wave-function method. The $b$-tag is assumed to be a top-quark in the final state, and the top-quark mass is determined from the measured $S$-wave function. The analysis uses events in the $\\rm{tt}$-channel with the cdftophat variable set to $\\rm{tt}$ and the vis-ex variable set to $\\rm{tt}$, $\\rm{bb}$, or $\\rm{b}$ and where the number of jets is set to one. The missing $E_T$ is estimated from the $E_T$-jet separation in the event with the largest $E_T$. We observe 3.42+0.47$\\,$sigma $\\rm{top}$ events in the $\\rm{tt}$-channel, and measure the top-quark mass to be $\\rm{mt}$ = $68.06\\,$GeV/c^2 + $1.16\\,$sigma, where $\\rm{mt}$ is the mean and $\\sigma$ is the rms uncertainty.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Compton Scattering of Fe K alpha Lines in Magnetic Cataclysmic Variables. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1516, "human_text": "  Compton scattering of X-rays in the bulk flow of the accretion column in magnetic cataclysmic variables (mCVs) can significantly shift photon energies. We present Monte Carlo simulations based on a nonlinear algorithm demonstrating the effects of Compton scattering on the H-like, He-like and neutral Fe K alpha lines produced in the post-shock region of the accretion column. The peak line emissivities of the photons in the post-shock flow are taken into consideration and frequency shifts due to Doppler effects are also included. We find that line profiles are most distorted by Compton scattering effects in strongly magnetized mCVs with a low white dwarf mass and high mass accretion rate and which are viewed at an oblique angle with respect to the accretion column. The resulting line profiles are most sensitive to the inclination angle. We have also explored the effects of modifying the accretion column width and using a realistic emissivity profile. We find that these do not have a significant overall effect on the resulting line profiles. A comparison of our simulated line spectra with high resolution Chandra/HETGS observations of the mCV GK Per indicates that a wing feature redward of the 6.4 keV line may result from Compton recoil near the base of the accretion column. ", "machine_text": "  We present observations of Fe K alpha lines in a sample of 22 magnetic cataclysmic variables (MCVs) observed with the optical/NIR telescope TANTAN. We use the magnetic field strength and orientation, and the temperature and density structure in the donor and accretor, to construct a model of the magnetic field configuration in the inner few donor stellar radii. We find that a model in which the magnetic field is aligned with the orbital angular momentum but with a large amplitude, i.e. a Larmor precession model, consistently describes the observations. We show that this model predicts a blue wing in the scattered Fe K alpha lines, which is in agreement with observations in a few cases. In addition, the model predicts that the strength of the blue wing depends on the viewing angle, which is in agreement with the observations. We discuss several methods to estimate the strength of the magnetic field from the observations of scattered Fe K alpha lines. We show that the precession model predicts a dependence of the strength of the magnetic field on the viewing angle which is in good agreement with the observations. We also present a model in which the magnetic field is aligned with the viewing angle, but with a large amplitude. This model predicts a red wing in the scattered Fe K alpha lines and we show that this model is in agreement with observations in a few cases. We discuss the physical origin of the different features in the scattered Fe K alpha lines and we compare our predictions with observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Suzaku Observation of the Nucleus of the Radio-Loud Active Galaxy\n  Centaurus A: Constraints on Abundances of the Accreting Material. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3743, "human_text": "  A Suzaku observation of the nucleus of the radio-loud AGN Centaurus A in 2005 has yielded a broadband spectrum spanning 0.3 to 250 keV. The net exposure times after screening were: 70 ks per X-ray Imaging Spectrometer (XIS) camera, 60.8 ks for the Hard X-ray Detector (HXD) PIN, and 17.1 ks for the HXD-GSO. The hard X-rays are fit by two power-laws of the same slope, absorbed by columns of 1.5 and 7 * 10^{23} cm^{-2} respectively. The spectrum is consistent with previous suggestions that the power-law components are X-ray emission from the sub-pc VLBI jet and from Bondi accretion at the core, but it is also consistent with a partial covering interpretation. The soft band is dominated by thermal emission from the diffuse plasma and is fit well by a two-temperature VAPEC model, plus a third power-law component to account for scattered nuclear emission, jet emission, and emission from X-ray Binaries and other point sources. Narrow fluorescent emission lines from Fe, Si, S, Ar, Ca and Ni are detected. The Fe K alpha line width yields a 200 light-day lower limit on the distance from the black hole to the line-emitting gas. Fe, Ca, and S K-shell absorption edges are detected. Elemental abundances are constrained via absorption edge depths and strengths of the fluorescent and diffuse plasma emission lines. The high metallicity ([Fe/H]=+0.1) of the circumnuclear material suggests that it could not have originated in the relatively metal-poor outer halo unless enrichment by local star formation has occurred. Relative abundances are consistent with enrichment from Type II and Ia supernovae. ", "machine_text": "  We present results of a Suzaku hard X-ray observation of the nuclear region of the radio-loud active galaxy Centaurus A. The aim of the observation was to test the hypothesis that the accretion disk of the supermassive black hole, which is responsible for the nuclear emission, iswarmer than the gas in the surrounding bulge. We find that the accretion disk, if it exists, must be at least 4 kK cooler than the gas in the bulge. We also find that the gas in the bulge is at most 6 kK cooler than the gas in the disk. This result rules out the possibility that the gas in the bulge is heated by accretion, and therefore that the bulge is the accretion disk seen at a very large radius. We discuss this result in the framework of simple models of the nuclear region. In addition, we derive constraints on the abundances of the accreiting material, assuming that the gas in the disk is a combination of gas in the bulge and a flow derived from the intergalactic medium. We find that the accretion gas is most probably close to solar in composition, regardless of the origin of the gas in the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Curvature Inspired Cosmological Scenario. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.041, "human_text": "  Using modified gravity with non-linear terms of curvature, $R^2$ and $R^{(r +2)}$ (with $r$ being the positive real number and $R$ being the scalar curvature), cosmological scenario,beginning at the Planck scale, is obtained. Here, a unified picture of cosmology is obtained from $f(R)-$ gravity. In this scenario, universe begins with power-law inflation, followed by deceleration and acceleration in the late universe as well as possible collapse of the universe in future. It is different from $f(R)-$ dark energy models with non-linear curvature terms assumed as dark energy. Here, dark energy terms are induced by linear as well as non-linear terms of curvature in Friedmann equation being derived from modified gravity.It is also interesting to see that, in this model, dark radiation and dark matter terms emerge spontaneously from the gravitational sector. It is found that dark energy, obtained here, behaves as quintessence in the early universe and phantom in the late universe. Moreover, analogous to brane-tension in brane-gravity inspired Friedmann equation, a tension term $\\lambda$ arises here being called as cosmic tension. It is found that, in the late universe, Friedmann equation (obtained here) contains a term $- \\rho^2/2\\lambda$ ($\\rho$ being the phantom energy density) analogous to a similar term in Friedmann equation with loop quantum effects, if $\\lambda > 0$ and brane-gravity correction when $\\lambda < 0.$ ", "machine_text": "  Motivation The motivation for this work is to develop a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far. The key idea is to use the concept of curvature to inspire a new cosmological scenario that can explain the origin of the matter in the Universe. The methodology used in this work is to first develop a simple model that can explain the origin of the matter in the Universe, and then to use this model to inspire a new cosmological scenario. The results obtained from this work are a new cosmological scenario that can explain the origin of the matter in the Universe. The problem that this work attempts to solve is the origin of the matter in the Universe. The practical application of this work is to provide a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far. The theoretical application of this work is to provide a new cosmological scenario that can explain the origin of the matter in the Universe in a way that is consistent with the principles of physics and the observations that we have made so far.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo\n  Codes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0361, "human_text": "  It has been observed that particular rate-1/2 partially systematic parallel concatenated convolutional codes (PCCCs) can achieve a lower error floor than that of their rate-1/3 parent codes. Nevertheless, good puncturing patterns can only be identified by means of an exhaustive search, whilst convergence towards low bit error probabilities can be problematic when the systematic output of a rate-1/2 partially systematic PCCC is heavily punctured. In this paper, we present and study a family of rate-1/2 partially systematic PCCCs, which we call pseudo-randomly punctured codes. We evaluate their bit error rate performance and we show that they always yield a lower error floor than that of their rate-1/3 parent codes. Furthermore, we compare analytic results to simulations and we demonstrate that their performance converges towards the error floor region, owning to the moderate puncturing of their systematic output. Consequently, we propose pseudo-random puncturing as a means of improving the bandwidth efficiency of a PCCC and simultaneously lowering its error floor. ", "machine_text": "  Pseudo-random Puncturing: A Technique to Lower the Error Floor of Turbo Codes  We introduce a new technique, called pseudo-random puncturing, to reduce the error floor of turbo codes. This technique has two key ingredients. The first is to use a carefully designed puncturing pattern to generate a high-rate code with a large minimum distance. The second is to use the turbo codes' feedback loop to remove the correlations that may remain in the high-rate code, and thus approach the channel capacity. We show that with a turbo code of rate R=1/2 and an interleaver length of 2^n, the new technique can lower the error floor to about (7/2 + O(1/n))-dB for a large n. For an interleaver length of 2^n, this means that the number of reliable bits per frame is about (7/2 + O(1/n)) times the number of bits that can be reliably transmitted over the channel by the turbo code without any puncturing. This improves on the original turbo code design by about 7 dB. We also show that for large n, the proposed technique converges quickly to its error floor. We implement the proposed technique using both the original turbo code and the recent low-dibit turbo code, and we show that the new technique achieves better performance with both codes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lorentzian and signature changing branes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.338, "human_text": "  General hypersurface layers are considered in order to describe brane-worlds and shell cosmologies. No restriction is placed on the causal character of the hypersurface which may thus have internal changes of signature. Strengthening the results in our previous letter [1], we confirm that a good, regular and consistent description of signature change is achieved in these brane/shells scenarios, while keeping the hypersurface and the bulk completely regular. Our formalism allows for a unified description of the traditional timelike branes/shells together with the signature-changing, or pure null, ones. This allows for a detailed comparison of the results in both situations. An application to the case of hypersurface layers in static bulks is presented, leading to the general Robertson-Walker geometry on the layer --with a possible signature change. Explicit examples on anti de Sitter bulks are then studied. The permitted behaviours in different settings ($Z_{2}$-mirror branes, asymmetric shells, signature-changing branes) are analysed in detail. We show in particular that (i) in asymmetric shells there is an upper bound for the energy density, and (ii) that the energy density within the brane vanishes when approaching a change of signature. The description of a signature change as a `singularity' seen from within the brane is considered. We also find new relations between the fundamental constants in the brane/shell, its tension, and the cosmological and gravitational constants of the bulk, independently of the existence or not of a change of signature. ", "machine_text": "  We consider the properties of Lorentzian and signature changing branes in a general framework of a 4-dimensional spacetime with a non-trivial metric and non-zero cosmological constant. We show that the simplest such a theory is given by the signature changing planes in a 4-dimensional Anti-de Sitter spacetime with a cosmological constant proportional to the volume density of the spacetime. The resulting signatures of the branes are (3+1)-dimensional, (2+2)-dimensional and (1+3)-dimensional. We show that all bulk vibrational states of such a brane must be (3+1)-dimensional. We show that in a generic theory with a non-trivial bulkmetric and non-zero cosmological constant the bulk vibrational states can be (2+2)-dimensional as well as (1+3)-dimensional. The relevant bulkmetric functions are related to the stress-energy tensor and the bulk Lorentzian condition is shown to be equivalent to the energy conditions in the bulk. We discuss the bulk dynamics in the presence of a cosmological constant and relate the resulting theory to the Einstein-Maxwell-Chern theory in a (3+1)-dimensional space-time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multicolor observations of the afterglow of the short/hard GRB 050724. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1273, "human_text": "  New information on short/hard gamma-ray bursts (GRBs) is being gathered thanks to the discovery of their optical and X-ray afterglows. However, some key aspects are still poorly understood, including the collimation level of the outflow, the duration of the central engine activity, and the properties of the progenitor systems. We want to constrain the physical properties of the short GRB 050724 and of its host galaxy, and make some inferences on the global short GRB population. We present optical observations of the afterglow of GRB 050724 and of its host galaxy, significantly expanding the existing dataset for this event. We compare our results with models, complementing them with available measurements from the literature. We study the afterglow light curve and spectrum including X-ray data. We also present observations of the host galaxy. The observed optical emission was likely related to the large flare observed in the X-ray light curve. The apparent steep decay was therefore not due to the jet effect. Available data are indeed consistent with low collimation, in turn implying a large energy release, comparable to that of long GRBs. The flare properties also constrain the internal shock mechanism, requiring a large Lorentz factor contrast between the colliding shells. This implies that the central engine was active at late times, rather than ejecting all shells simultaneously. The host galaxy has red colors and no ongoing star formation, consistent with previous findings on this GRB. However, it is not a pure elliptical, and has some faint spiral structure. GRB 050724 provides the most compelling case for association between a short burst and a galaxy with old stellar population. It thus plays a pivotal role in constraining progenitors models, which should allow for long delays between birth and explosion. ", "machine_text": " We present multicolor observations of the optical afterglow of the short/hard Gamma-Ray Burst (GRB) 050724, made with the Nordic Optical Telescope (NOT) at La Palma, Spain. The observations were triggered by the detection of the burst by the Gamma Ray Burst Monitor (GRBM) on board the INTEGRAL spacecraft. We find that the optical afterglow of GRB 050724 is characterized by a very red continuum, which is consistent with a host galaxy spectral type of M, and a mildly blueshifted ultra-weak NII morphology. The host galaxy has a radius of 1.3 kpc and is at a distance of 60 Mpc. The afterglow exhibits no significant brightenings, and is thus considered to be a steady afterglow. We determine the redshift of the burst to be z = 1.645, which makes this burst the nearest burst observed so far. We discuss the nature of the host galaxy and its possible relationship to the burst, and find that it has properties consistent with a disk galaxy. The burst occurred in a relatively inactive part of the galaxy, at a radius of 7 kpc from the galactic center. This burst is the closest burst to a disk galaxy observed so far, and it suggests that bursts can occur in galaxies which are not predominantly elliptical galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Depletion effects in smectic phases of hard rod--hard sphere mixtures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.114, "human_text": "  It is known that when hard spheres are added to a pure system of hard rods the stability of the smectic phase may be greatly enhanced, and that this effect can be rationalised in terms of depletion forces. In the present paper we first study the effect of orientational order on depletion forces in this particular binary system, comparing our results with those obtained adopting the usual approximation of considering the rods parallel and their orientations frozen. We consider mixtures with rods of different aspect ratios and spheres of different diameters, and we treat them within Onsager theory. Our results indicate that depletion effects, and consequently smectic stability, decrease significantly as a result of orientational disorder in the smectic phase when compared with corresponding data based on the frozen--orientation approximation. These results are discussed in terms of the $\\tau$ parameter, which has been proposed as a convenient measure of depletion strength. We present closed expressions for $\\tau$, and show that it is intimately connected with the depletion potential. We then analyse the effect of particle geometry by comparing results pertaining to systems of parallel rods of different shapes (spherocylinders, cylinders and parallelepipeds). We finally provide results based on the Zwanzig approximation of a Fundamental--Measure density--functional theory applied to mixtures of parallelepipeds and cubes of different sizes. In this case, we show that the $\\tau$ parameter exhibits a linear asymptotic behaviour in the limit of large values of the hard--rod aspect ratio, in conformity with Onsager theory, as well as in the limit of large values of the ratio of rod breadth to cube side length, $d$, in contrast to Onsager approximation, which predicts $\\tau\\sim d^3$. ", "machine_text": " We investigate depletion effects in smectic phases of hard rod--hard sphere mixtures. The hard rods are represented by theYouthful model with anisotropic hard spheres in a simple cubic arrangement and the smectic phase is obtained by the addition of a quenching agent that acts to form a soft layer between the hard rod layers. We use a single parameter to describe the smectic texture, namely, the ratio of the soft to hard material in the mixture. We find that the smectic texture is very sensitive to this single parameter and that the texture undergoes a continuous evolution as the quenching agent is increased. The texture evolution has several interesting features. For a particular range of quenching agent concentration, the smectic texture is very compact, with hard rod layers almost completely isolated from each other by the soft material. We find that such a compact texture is only possible if the soft material is significantly more effective at quenching the hard rods than the solvent. At high concentrations of quenching agent, the texture becomes extremely loose and approaches a  smectic  phase of pure solvent with hard rods randomly distributed throughout. We find that such a loose texture is only possible if the quenching agent is significantly less effective at quenching the hard rods than the solvent. In both the compact and loose textures, the hard rods form a quasi-regular arrangement, with the long axis of each hard rod nearly parallel to the smectic layers. In addition, we find that the hard rods form an unusual core--shell structure, with the hard cores completely surrounded by a soft shell. The structure is stable with respect to changes in the solvent content. We also investigate the temperature dependence of the hard rod orientation in the smectic phase.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Where post-Newtonian and numerical-relativity waveforms meet. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1305, "human_text": "  We analyze numerical-relativity (NR) waveforms that cover nine orbits (18 gravitational-wave cycles) before merger of an equal-mass system with low eccentricity, with numerical uncertainties of 0.25 radians in the phase and less than 2% in the amplitude; such accuracy allows a direct comparison with post-Newtonian (PN) waveforms. We focus on one of the PN approximants that has been proposed for use in gravitational-wave data analysis, the restricted 3.5PN ``TaylorT1'' waveforms, and compare these with a section of the numerical waveform from the second to the eighth orbit, which is about one and a half orbits before merger. This corresponds to a gravitational-wave frequency range of $M\\omega = 0.0455$ to 0.1. Depending on the method of matching PN and NR waveforms, the accumulated phase disagreement over this frequency range can be within numerical uncertainty. Similar results are found in comparisons with an alternative PN approximant, 3PN ``TaylorT3''. The amplitude disagreement, on the other hand, is around 6%, but roughly constant for all 13 cycles that are compared, suggesting that only 4.5 orbits need be simulated to match PN and NR waves with the same accuracy as is possible with nine orbits. If, however, we model the amplitude up to 2.5PN order, the amplitude disagreement is roughly within numerical uncertainty up to about 11 cycles before merger. ", "machine_text": " We discuss the problem of matching up the waveform generated by a full-scale post-Newtonian (PN) model of a binary black hole with that produced by the numerical-relativity (NR) solution of the same system. We show that this is a necessary step toward the construction of a hybrid model which combines the strong gravity and fast evolution of the NR solution with the weak-gravity and slow-evolution approximation of the PN model. We then derive a simple expression for the mismatch between the NR and PN waveform that is valid for an arbitrary NR solution and for an arbitrary PN model. In particular, this expression is shown to be valid both for the NR solutions obtained using the standard slice method as well as the NR solutions obtained using the streamline method. We use this expression to compute the mismatch for a standard NR solution for a non-rotating binary black hole system and for a number of different PN models, including the Churchill-Appleman-diniz, Teukolsky-Fetherolf-N incentini, and Herriott-Tanner models. We find that the discrepancies between the NR and PN waveforms increase approximately as the square of the PN mass parameter $m_{\\rm PN}$, and thus are much more severe for compact binaries than for wide binaries. We also show that for all of these PN models the mismatch between the NR and PN waveforms can be greatly reduced by a simple modification of the PN model which consists of making the radial displacement of the circles of constant latitude proportional to $m_{\\rm PN}^{-2}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Cornell Caltech Atacama Telescope. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3031, "human_text": "  Cornell University, the California Institute for Technology, and the Jet Propulsion Laboratory are jointly studying the construction of a 25 m diameter telescope for submillimeter astronomy on a high mountain in northern Chile. This Cornell Caltech Atacama Telescope (CCAT) will combine high sensitivity, a wide field of view, and a broad wavelength range to provide an unprecedented capability for deep, large area, multi-color submillimeter surveys to complement narrow field, high resolution studies with ALMA. CCAT observations will address fundamental themes in contemporary astronomy, notably the formation and evolution of galaxies, the nature of the dark matter and dark energy that comprise most of the content of the universe, the formation of stars and planets, the conditions in circumstellar disks, and the conditions during the early history of the Solar system. The candidate CCAT site, at 5600 m in northern Chile, enjoys superb observing conditions. To accommodate large format bolometer cameras, CCAT is designed with a 20 arcmin field of view. CCAT will incorporate closed loop active control of its segmented primary mirror to maintain a half wavefront error of 10 mum rms or less. Instrumentation under consideration includes both short (650 mum-200 mum) and long (2 mm-750 mum) wavelength bolometer cameras, direct detection spectrometers, and heterodyne receiver arrays. The University of Colorado, a Canadian university consortium, and the UK Astronomy Technology Centre on behalf of the UK community are pursuing participation in the CCAT consortium. When complete early in the next decade, CCAT will be the largest and most sensitive facility of its class as well as the highest altitude astronomical facility on Earth. ", "machine_text": "  We describe the Cornell Caltech Atacama Telescope (CCAT), a proposed 25m diameter telescope to be located at an altitude of 5,000m on the Atacama Plateau in Chile. The telescope will be a joint project of Cornell University and the California Institute of Technology, and will be constructed and operated by a newly formed non-profit organization, the CCAT Corporation. The mission of the telescope is twofold: to advance cosmic microwave background research and to provide a high-resolution, high-sensitivity telescope for astronomical and atmospheric studies. In this article we focus on the scientific capabilities of the telescope and the unique aspects of its design that enable these capabilities. We summarize the results of the Site Selection Study, including the analysis of the optical, thermal, and mechanical properties of the proposed site and the geotechnical analysis of the foundation design. We describe the fully integrated design of the telescope and the adaptive optics system, and the optimization of the design for operation in the Atacama environment. We conclude with a discussion of the scientific opportunities made possible by the combination of the unique telescope design and the excellent site, and the steps that are underway to secure the funding required to build and operate the telescope.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Growth mechanisms and structure of fullerene-like carbon-based thin\n  films: superelastic materials for tribological applications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2258, "human_text": "  In this chapter we review our findings on the bonding structure and growth mechanisms of carbon-based thin solid films with fullerene-like (FL) microstructure. The so-called FL arrangements arise from the curvature and cross-linking of basal planes in graphitic-like structures, partially resembling that of molecular fullerenes. This three-dimensional superstructure takes advantage of the strength of planar pi bonds in sp2 hybrids and confers the material interesting mechanical properties, such as high hardness, high elastic recovery, low-friction and wear-resistance. These properties can be tailored by controlling the curvature, size and connectivity of the FL arrangements, making these materials promising coatings for tribological applications. We have focused our interest mostly on carbon nitride (CNx) since nitrogen promotes the formation of FL arrangements at low substrate temperatures and they are emerging over pure carbon coatings in tribological applications such as protective overcoats in magnetic hard disks. We address structural issues such as origin of plane curvature, nature of the cross-linking sites and sp2 clustering, together with growth mechanisms based on the role of film-forming precursors, chemical re-sputtering or concurrent ion assistance during growth. ", "machine_text": " We report on the growth mechanisms and structure of fullerene-like carbon-based thin films: superelastic materials for tribological applications. The motivation for the research is the demand for novel materials with unique properties for tribological applications. The key ideas and methodology are the use of the detonation process as a method for the synthesis of fullerene-like carbons, and the implementation of in situ diagnostics by using a quartz microbalance that allows us to monitor the growth process. The results obtained are the description of the growth mechanisms and the determination of the structural and tribological properties of the films. The problem the work attempts to solve is to find a method for the synthesis of fullerene-like carbon films with tailored properties for tribological applications. Any practical or theoretical applications from the findings or implications for future research include the potential use of fullerene-like carbon films as novel materials with unique properties for tribological applications, and the potential use of the detonation process as a method for the synthesis of nanocarbon materials with tailored properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Interval Conjectures for level Hilbert functions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0806, "human_text": "  We conjecture that the set of all Hilbert functions of (artinian) level algebras enjoys a very natural form of regularity, which we call the {\\em Interval Conjecture} (IC): If, for some positive integer $\\alpha $, $(1,h_1,...,h_i,...,h_e)$ and $(1,h_1,...,h_i+\\alpha ,...,h_e)$ are both level $h$-vectors, then $(1,h_1,...,h_i+\\beta ,...,h_e)$ is also level for each integer $\\beta =0,1,..., \\alpha .$ In the Gorenstein case, i.e. when $h_e=1$, we also supply the {\\em Gorenstein Interval Conjecture} (GIC), which naturally generalizes the IC, and basically states that the same property simultaneously holds for any two symmetric entries, say $h_i$ and $h_{e-i}$, of a Gorenstein $h$-vector.   These conjectures are inspired by the research performed in this area over the last few years. A series of recent results seems to indicate that it will be nearly impossible to characterize explicitly the sets of all Gorenstein or of all level Hilbert functions. Therefore, our conjectures would at least provide the existence of a very strong - and natural - form of order in the structure of such important and complicated sets.   We are still far from proving the conjectures at this point. However, we will already solve a few interesting cases, especially when it comes to the IC, in this paper. Among them, that of Gorenstein $h$-vectors of socle degree 4, that of level $h$-vectors of socle degree 2, and that of non-unimodal level $h$-vectors of socle degree 3 and any given codimension. ", "machine_text": "  Interval Conjectures for Level Hilbert Functions  We consider the problem of characterizing the values of level Hilbert functions on certain sets related to the relative consensus zone of a finitely-restarted iteration process. We show that two such sets, which we call the strong interval and the weak interval, are characterized by certain forms of interval conjecture, in a way which generalizes the strong and weak restrictions of the Pisot and Rapoport conjectures for Pisot and Rapoport functions. In particular, we show that if the strong interval conjecture holds for a level Hilbert function, then this function takes its maximum value on the strong interval, and if the weak interval conjecture holds, then this function takes its minimum value on the weak interval. We show further that both the strong and weak interval conjectures are equivalent to certain forms of the strong and weak Restricted Conjectures for Pisot and Rapoport functions, and that both conjectures are also equivalent to a conjecture of Finger on interval functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Stokes phenomenon in the confluence of the hypergeometric equation\n  using Riccati equation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1773, "human_text": "  In this paper we study the confluence of two regular singular points of the hypergeometric equation into an irregular one. We study the consequence of the divergence of solutions at the irregular singular point for the unfolded system. Our study covers a full neighborhood of the origin in the confluence parameter space. In particular, we show how the divergence of solutions at the irregular singular point explains the presence of logarithmic terms in the solutions at a regular singular point of the unfolded system. For this study, we consider values of the confluence parameter taken in two sectors covering the complex plane. In each sector, we study the monodromy of a first integral of a Riccati system related to the hypergeometric equation. Then, on each sector, we include the presence of logarithmic terms into a continuous phenomenon and view a Stokes multiplier related to a 1-summable solution as the limit of an obstruction that prevents a pair of eigenvectors of the monodromy operators, one at each singular point, to coincide. ", "machine_text": " We consider the Stokes phenomenon in the confluence of the hypergeometric equation using the Riccati equation. We show that the limiting solution of the hypergeometric equation in the form of a generalized airy function can be obtained by using the limit relation between the Riccati and hypergeometric equations. The hypergeometric equation is a generalization of the exponential and logaritaic equations. The hypergeometric equation has many applications in diverse areas of mathematics, physics and engineering. We get the exponential and logaritaic equations as the special cases of the hypergeometric equation. The Stokes phenomenon is the effect of a moderate increase in the right hand side of a differential equation on the solution. The Stokes phenomenon has many applications in diverse areas of physics and engineering. We obtain the asymptotic form of the solution of the hypergeometric equation with a moderate increase in the right hand side. We obtain the special case of the exponential and logaritaic equations in the context of the Stokes phenomenon.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Valley Dependent Optoelectronics from Inversion Symmetry Breaking. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4683, "human_text": "  Inversion symmetry breaking allows contrasted circular dichroism in different k-space regions, which takes the extreme form of optical selection rules for interband transitions at high symmetry points. In materials where band-edges occur at noncentral valleys, this enables valley dependent interplay of electrons with light of different circular polarizations, in analogy to spin dependent optical activities in semiconductors. This discovery is in perfect harmony with the previous finding of valley contrasted Bloch band features of orbital magnetic moment and Berry curvatures from inversion symmetry breaking [Phys. Rev. Lett. 99, 236809 (2007)]. A universal connection is revealed between the k-resolved optical oscillator strength of interband transitions, the orbital magnetic moment and the Berry curvatures, which also provides a principle for optical measurement of orbital magnetization and intrinsic anomalous Hall conductivity in ferromagnetic systems. The general physics is demonstrated in graphene where inversion symmetry breaking leads to valley contrasted optical selection rule for interband transitions. We discuss graphene based valley optoelectronics applications where light polarization information can be interconverted with electronic information. ", "machine_text": "  We propose and demonstrate a novel approach to valley dependent optoelectronics based on symmetry breaking in a ferroelectric layer. We show that the broken symmetry can be used to generate a strong and fast optical response in an adjacent semiconductor layer, which can be used for various optoelectronic applications. Our approach is based on the realization that a symmetry breaking strain field in a ferroelectric layer can be efficiently and periodically mapped to a second material in a layered structure, in a similar way as the spontaneous polarization is mapped to the piezoelectric response in a ferroelectric-piezoelectric bilayer. We demonstrate a strong and fast photoresponse with a high on/off ratio in a photodetector configuration, as well as efficient and fast carrier injection in a light emitting device configuration, both in a nanostructured semiconductor material. Our results open up new avenues for designing nanostructured optoelectronic devices with a strong and fast response, which can be easily integrated with Si technology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of anomalous diffusive reaction rates on realistic self-affine\n  fractals. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2813, "human_text": "  In this letter, a theoretical method for the analysis of diffusive flux/current to limited scale self-affine random fractals is presented and compared with experimentally measured electrochemical current for such roughness. The theory explains the several experimental findings of the temporal scale invariance as well as deviation from this of current transients in terms of three dominant fractal parameters for the limited-length scales of roughness. This theoretical method is based on limited scale power-law characterization of the interfacial roughness spectrum and the solution of diffusion equation under the diffusion-limited boundary conditions on rough interfaces. More broadly, these calculations challenges the earlier belief that the anomalous behavior is solely dependent on fractal dimension of roughness and highlight the potential to apply this equation for the scale invariant roughness determination. Finally, the validity of theoretical result is tested with extensive experimental data. ", "machine_text": " We consider the problem of anomalous diffusive reaction rates on realistic self-affine fractals. We show that such reaction rates are related to the thermal conductivity of the fractal, and that this conductivity in turn is related to the volume conductivities of the positive and negative fractal components. These relationships provide a possible physical explanation for the large number of microscopic reaction channels that are typically associated with anomalous reaction rates on fractals. We analyze the simplest case of a self-affine fractal in one dimension, and evaluate the conductivity of a fractal as a function of its fractal dimension. We find that the conductivity tends to decrease rapidly with increasing fractal dimension, and we show that this decrease is related to the large number of necks or connectors between the positive and negative fractal components. In two and higher dimensions, we find that the conductivity of a fractal is proportional to the product of its volume conductivity and its fractal dimension. We show that this proportionality is consistent with the assumption that the conductivity is related to the average number of connectors per volume. We also derive a simple expression for the conductivity of a self-affine fractal as a function of its fractal dimension in any number of dimensions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is diversity good?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2466, "human_text": "  Prominent ethical and policy issues such as affirmative action and female enrollment in science and engineering revolve around the idea that diversity is good. However, even though diversity is an ambiguous concept, a precise definition is seldom provided. We show that diversity may be construed as a factual description, a craving for symmetry, an intrinsic good, an instrumental good, a symptom, or a side effect. These acceptions differ vastly in their nature and properties. The first one cannot lead to any action and the second one is mistaken. Diversity as intrinsic good is a mere opinion, which cannot be concretely applied; moreover, the most commonly invoked forms of diversity (sexual and racial) are not intrinsically good. On the other hand, diversity as instrumental good can be evaluated empirically and can give rise to policies, but these may be very weak. Finally, symptoms and side effects are not actually about diversity. We consider the example of female enrollment in science and engineering, interpreting the various arguments found in the literature in light of this polysemy.   Keywords: ethics, policy, higher education, female students, minority students, affirmative action ", "machine_text": " We are motivated by a desire to understand the effects of diversity on outcomes important to firms. Our interest is both theoretical and empirical. The theoretical motivation is based on the idea that diversity may affect firm performance through increasing the diversity of ideas exchanged in the firm. We expect this to be the case if the diversity is structured, or if it increases the variety of skills and knowledge in the firm. The empirical motivation is based on the observation that firms with higher degrees of diversity, especially racial and gender diversity, tend to have higher levels of performance. We review the theoretical and empirical literature to develop a model of the relationship between diversity, the flow of ideas within the firm, and performance. The model is tested using a sample of firms from the Fortune 500. We find that the model provides a good fit to the data, and that the model can explain the effect of diversity on performance. Our findings suggest that diversity is good for performance, but only if it is structured and leads to the exchange of diverse ideas.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Linkage between Accretion Disks and Blazars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2636, "human_text": "  The magnetic field in an accretion disk is estimated assuming that all of the angular momentum within prescribed accretion disk radii is removed by a jet. The magnetic field estimated at the base of the jet is extrapolated to the blazar emission region using a model for a relativistic axisymmetric jet combined with some simplifying assumptions based on the relativistic nature of the flow. The extrapolated magnetic field is compared with estimates based upon the synchrotron and inverse Compton emission from three blazars, MKN 501, MKN 421 and PKS 2155-304. The magnetic fields evaluated from pure synchrotron self- Compton models are inconsistent with the magnetic fields extrapolated in this way. However, in two cases inverse Compton models in which a substantial part of the soft photon field is generated locally agree well, mainly because these models imply magnetic field strengths which are closer to being consistent with Poynting flux dominated jets. This comparison is based on estimating the mass accretion rate from the jet energy flux. Further comparisons along these lines will be facilitated by independent estimates of the mass accretion rate in blazars and by more detailed models for jet propagation near the black hole. ", "machine_text": "  We present a linkage between accretion disks and blazars. We show that the accretion disks around supermassive black holes can heat the surrounding gas to a temperature capable of sustaining nuclear fusion, and thereby creating a blazar. We show that accretion disks around stellar-mass black holes can produce a jet, but not a blazar. We discuss a simple model in which a fraction of the matter in the accretion disk is heated to a temperature capable of sustaining nuclear fusion, and the rest is accreted onto the black hole. We show that in this model the accretion disk has a sharp inner boundary, and the gas pressure outside this boundary is very small. We show that in this model the accretion disk has a strong faraday Rmongodb, and can therefore be detected at radio wavelengths. We discuss a more elaborate model, in which the gas is heated by compression in the accretion disk, and by friction from the accretion disk. We show that in this model the accretion disk has a steep spectrum, and therefore produces a blazar. We show that in this model the accretion disk has a strong magnetosphere, and therefore can produce a relativistic wind. We discuss the motivation for this work, and we discuss the implications of this work for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cryptoplanet update. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.286, "human_text": "  We have had several talks recently reviewing 11 years of exoplanet discoveries through radial velocity variations, or from transits, or from microlensing. More than 200 exoplanets have been found, including some around pulsars that we do not discuss here.   My physical definition for a planet is a roughly spherical, self-gravitating body more massive than 10**26 g formed from the leftover material in a protostellar disk after the protostar forms. Radiation from the protostar pushes the inner wall of the disk outward. The material agglomerates and forms planets in radial sequence. The outer planets are formed slowly by classical dynamical mechanisms acting in the snow zone. Planets have dense cores because of agglomeration.   Not one of the exoplanets discovered thus far is a planet. They are cryptoplanets formed from matter ejected by protostars. When protostars have excessive infall at high latitudes, they partially balance angular momentum through outflow at the equator as they spin up. The ejected matter is trapped in the magnetic torus formed between the star and the disk, like a tokamak. The tokamak eventully reconnects and magnetic compression forms self-gravitating remnants trapped and compressed by a closed spherical magnetic field, spheromaks. Cooled spheromaks are cryptoplanets. They orbit near the star. They can merge with each other or fall into the star or be ejected. They can grow by accreting gas. They have a low density core and abundances characteristic of the protostar. Their masses, radii, densities, and orbits are random, and are inconsistent with the parameters for planets. They tend to have lower density than planets. ", "machine_text": "  Cryptoplanet update This work presents an update to our previous work on cryptoplanets. In this work, we present a detailed analysis of the astrometric data for the Kepler-107 system. We find that the system contains two planets, one with a mass close to that of the Earth. This is the second system found by the Kepler Mission that contains a rocky planet in the habitable zone. We also present a new method to constrain the thickness of the atmosphere of Kepler planets. The method is based on a combination of atmospheric modeling and an analysis of the diffraction patterns produced by the atmospheres of transiting planets. With this method we constrain the atmospheric thickness of the two large gas giants in the Kepler-107 system. We find that the atmosphere of the larger planet is optically thick, while the atmosphere of the smaller planet is likely to be thinner. We also present an update to our method to determine the true size of giant planets using a combination of photometric and spectroscopic observations. We apply this method to the gas giants in the Kepler-107 system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Outer jet X-ray and radio emission in R Aquarii: 1999.8 to 2004.0. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.257, "human_text": "  Chandra and VLA observations of the symbiotic star R Aqr in 2004 reveal significant changes over the three to four year interval between these observations and previous observations taken with the VLA in 1999 and with Chandra in 2000. This paper reports on the evolution of the outer thermal X-ray lobe-jets and radio jets. The emission from the outer X-ray lobe-jets lies farther away from the central binary than the outer radio jets, and comes from material interpreted as being shock heated to ~10^6 K, a likely result of collision between high speed material ejected from the central binary and regions of enhanced gas density. Between 2000 and 2004, the Northeast (NE) outer X-ray lobe-jet moved out away from the central binary, with an apparent projected motion of ~580 km s^-1. The Southwest (SW) outer X-ray lobe-jet almost disappeared between 2000 and 2004, presumably due to adiabatic expansion and cooling. The NE radio bright spot also moved away from the central binary between 2000 and 2004, but with a smaller apparent velocity than of the NE X-ray bright spot. The SW outer lobe-jet was not detected in the radio in either 1999 or 2004. The density and mass of the X-ray emitting material is estimated. Cooling times, shock speeds, pressure and confinement are discussed. ", "machine_text": "  We present new X-ray and radio observations of the accretion disc around R Aquarii. These data, obtained over the period 1999.8 to 2004.0, are the most complete monitoring of the X-ray and radio emission from this source to date, and they are the first such data to be acquired since the mid-1990s. We find that the X-ray and radio luminosities have increased by factors of 1.4 and 1.6 respectively since the last monitoring campaign. We show that the accretion disc is now radiating at the same X-ray and radio luminosity as it was in 1995, after a period of quiescence in which the luminosity had been reduced by factors of 3 and 5 respectively. The radial and vertical structures in the X-ray and radio emission are consistent with the disc being oriented close to face-on to us, as it was in 1995. We estimate that the inner disc has a temperature of about 0.75 keV, and that the outer disc has a temperature of about 1.25 keV. These temperatures are only slightly higher than in 1995. We discuss these results in the context of a simple model in which the accretion disc is fed by episodic accretion events.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-cooperative games for spreading code optimization, power control and\n  receiver design in wireless data networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0783, "human_text": "  This paper focuses on the issue of energy efficiency in wireless data networks through a game theoretic approach. The case considered is that in which each user is allowed to vary its transmit power, spreading code, and uplink receiver in order to maximize its own utility, which is here defined as the ratio of data throughput to transmit power. In particular, the case in which linear multiuser detectors are employed at the receiver is treated first, and, then, the more challenging case in which non-linear decision feedback multiuser receivers are adopted is addressed. It is shown that, for both receivers, the problem at hand of utility maximization can be regarded as a non-cooperative game, and it is proved that a unique Nash equilibrium point exists. Simulation results show that significant performance gains can be obtained through both non-linear processing and spreading code optimization; in particular, for systems with a number of users not larger than the processing gain, remarkable gains come from spreading code optimization, while, for overloaded systems, the largest gainscome from the use of non-linear processing. In every case, however, the non-cooperative games proposed here are shown to outperform competing alternatives. ", "machine_text": "  We consider the problem of jointly optimizing the codebooks at the transmitter and the receiver in a multiple access network while minimizing the overall power consumption. We show that this problem can be formulated and solved as a non-cooperative game, in which the players are the transmitters and the receiver. We consider two levels of cooperation among the transmitters: (i) when all the transmitters use the same codebook, and (ii) when the transmitters use different, but related codebooks. In both cases, we show that the game has a unique solution, which is efficiently solvable. We then extend the results to the problem of joint optimization of the codebooks at the transmitter and the receiver, as well as the power allocation, in a wireless data network. We show that this problem can be formulated and solved as a non-cooperative game, in which the players are the transmitters and the receiver. We consider two levels of cooperation among the transmitters: (i) when all the transmitters use the same codebook, and (ii) when the transmitters use different, but related codebooks. In both cases, we show that the game has a unique solution, which is efficiently solvable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complementarity in the Bohr-Einstein Photon Box. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2762, "human_text": "  The photon box thought experiment can be considered a forerunner of the EPR-experiment: by performing suitable measurements on the box it is possible to ``prepare'' the photon, long after it has escaped, in either of two complementary states. Consistency requires that the corresponding box measurements be complementary as well. At first sight it seems, however, that these measurements can be jointly performed with arbitrary precision: they pertain to different systems (the center of mass of the box and an internal clock, respectively). But this is deceptive. As we show by explicit calculation, although the relevant quantities are simultaneously measurable, they develop non-vanishing commutators when calculated back to the time of escape of the photon. This justifies Bohr's qualitative arguments in a precise way; and it illustrates how the details of the dynamics conspire to guarantee the requirements of complementarity. In addition, our calculations exhibit a ``fine structure'' in the distribution of the uncertainties over the complementary quantities: depending on \\textit{when} the box measurement is performed, the resulting quantum description of the photon differs. This brings us close to the argumentation of the later EPR thought experiment. ", "machine_text": " We consider a thought experiment based on the Bohr-Einstein photon box. The motivation for our work is to understand the complementarity inherent in the quantum theory of light. We show that if we try to prepare a pure state of a single-photon in a photon box, then we can only achieve this in a limited number of ways. The analysis of these possibilities shows that the complementarity principle is encoded in the dynamics of the photon box. In particular, we find a clear signature of the standard complementarity principle in the form of a distinction between a quantum-mechanical and a classical (winning- Ticket) approach to a quantum-optical game. We also show that if we try to prepare a mixed state of a single-photon in a photon box, then the dynamics of the photon box will always be such that the final state will be well described by a thermal mixture. Our analysis shows that this fact is encoded in the dynamics of the photon box, in the form of a distinction between a quantum-mechanical and a classical (winning-Ticket) approach to a quantum-optical game.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relaxation of a dewetting contact line Part 2: Experiments. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3583, "human_text": "  The dynamics of receding contact lines is investigated experimentally through controlled perturbations of a meniscus in a dip coating experiment. We first characterize stationary menisci and their breakdown at the coating transition. It is then shown that the dynamics of both liquid deposition and long-wavelength perturbations adiabatically follow these stationary states. This provides a first experimental access to the entire bifurcation diagram of dynamical wetting, confirming the hydrodynamic theory developed in Part 1. In contrast to quasi-static theories based on a dynamic contact angle, we demonstrate that the transition strongly depends on the large scale flow geometry. We then establish the dispersion relation for large wavenumbers, for which we find that sigma is linear in q. The speed dependence of sigma is well described by hydrodynamic theory, in particular the absence of diverging time-scales at the critical point. Finally, we highlight some open problems related to contact angle hysteresis that lead beyond the current description. ", "machine_text": " We continue our study of the relaxation of a dewetting contact line (Part 1: Theory) by analyzing the experimental results of our previous work. We first confirm the theoretical prediction that the contact area decreases in a manner that is consistent with the contact line moving in a series of small jerks. We then show that the experimental data are consistent with the assumption that the distribution of the interfacial tension over the contact area is independent of the contact area itself. This allows us to evaluate the impact of the relative spatial distribution of the interfacial tension over the contact area on the dynamics of the contact line. We find that the assumption of a constant distribution of interfacial tension over the contact area results in a good qualitative description of the data, but the quantitative description is somewhat inaccurate. We then consider a more general model in which the distribution of interfacial tension over the contact area is allowed to vary in a prescribed way. We find that this model is able to provide a good quantitative description of the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Possible X-ray diagnostic for jet/disk dominance in Type 1 AGN. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1587, "human_text": "  Using Rossi X-ray Timing Explorer Seyfert 1 and 1.2 data spanning 9 years, we study correlations between X-ray spectral features. The sample consists of 350 time-resolved spectra from 12 Seyfert 1 and 1.2 galaxies. Each spectrum is fitted to a model with an intrinsic powerlaw X-ray spectrum produced close to the central black hole that is reprocessed and absorbed by material around the black hole. To test the robustness of our results, we performed Monte Carlo simulations of the spectral sample. We find a complex relationship between the iron line equivalent width (EW) and the underlying power law index (Gamma). The data reveal a correlation between Gamma and EW which turns over at Gamma <~ 2, but finds a weak anti-correlation for steeper photon indices. We propose that this relationship is driven by dilution of a disk spectrum (which includes the narrow iron line) by a beamed jet component and, hence, could be used as a diagnostic of jet-dominance. In addition, our sample shows a strong correlation between the reflection fraction (R) and Gamma, but we find that it is likely the result of modeling degeneracies. We also see the X-ray Baldwin effect (an anti-correlation between the 2-10 keV X-ray luminosity and EW) for the sample as a whole, but not for the individual galaxies and galaxy types. ", "machine_text": "  We have carried out a statistical study of the X-ray emission in a sample of Type 1 active galactic nuclei (AGN) in which the accretion-disc luminosity has been estimated from optical and N-ray observations. We have used the mean X-ray count-rate as a function of the accretion-disc luminosity to infer the dominate power law behaviour of the X-ray emission. The inferred power law indices are found to be distributed in a wide range, and in addition, the shape of the X-ray count-rate - accretion-disc luminosity relation is very poorly described by a single power law. These results suggest that the power law index of the X-ray emission is not uniquely related to the accretion-disc luminosity, but rather, the relation is likely to be complex and dependent on the detailed structure of the accretion disc and the innermost region of the jet. We have found a significant correlation between the X-ray power law index and the accretion-disc structure as revealed by high-resolution imaging of the accretion disc. Our results suggest that the jet power law index is a useful diagnostic for the dominant contribution to the accretion-flow luminosity: either the disc or the jet.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonholonomic Ricci Flows: III. Curve Flows and Solitonic Hierarchies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2062, "human_text": "  The geometric constructions are elaborated on (semi) Riemannian manifolds and vector bundles provided with nonintegrable distributions defining nonlinear connection structures induced canonically by metric tensors. Such spaces are called nonholonomic manifolds and described by two equivalent linear connections also induced in unique forms by a metric tensor (the Levi Civita and the canonical distinguished connection, d-connection). The lifts of geometric objects on tangent bundles are performed for certain classes of d-connections and frame transforms when the Riemann tensor is parametrized by constant matrix coefficients. For such configurations, the flows of non-stretching curves and corresponding bi-Hamilton and solitonic hierarchies encode information about Ricci flow evolution, Einstein spaces and exact solutions in gravity and geometric mechanics. The applied methods were elaborated formally in Finsler geometry and allows us to develop the formalism for generalized Riemann-Finsler and Lagrange spaces. Nevertheless, all geometric constructions can be equivalently re-defined for the Levi Civita connections and holonomic frames on (semi) Riemannian manifolds. ", "machine_text": " We consider the nonholonomic Ricci flow on a symplectic manifold, namely the flow of the Ricci tensor that is generated by the standard Ricci flow and the additional flow of the tensor that is induced by the nonholonomic contribution to theChristoffel symbols. We show that this flow is a curve flow, that is, it is an infinitesimal generator of a deformation of curves in the symmetric andantisymmetric parts of the fiber of a vector field along the curve. The geometric properties of such a flow are similar to those of a Fano flow. In particular,  we show that a certain class of nonsymmetric Fano flows is equivalent to a class of nonholonomic Ricci flows on certain kinds of symplectic manifolds. We also discuss some geometric properties of the associated singularity. We show that the nonholonomic Ricci flow is a solitonic flow, that is, it has a constant speed in a certain class of symplectic manifolds. As an application, we show that the fiber of a generic curve flow is an isotropic submanifold of the symmetric and antisymmetric parts of the fiber of a vector field along the curve.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multidimensional fluid motions with planar waves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2311, "human_text": "  In the classical one-dimensional solution of fluid dynamics equations all unknown functions depend only on time t and Cartesian coordinate x. Although fluid spreads in all directions (velocity vector has three components) the whole picture of motion is relatively simple: trajectory of one fluid particle from plane x=const completely determines motion of the whole plane. Basing on the symmetry analysis of differential equations we propose generalization of this solution allowing movements in different directions of fluid particles belonging to plane x=const. At that, all functions but an angle determining the direction of particle's motion depend on t and x only, whereas the angle depends on all coordinates. In this solution the whole picture of motion superposes from identical trajectories placed under different angles in 3D space. Orientations of the trajectories are restricted by a finite relation possessing functional arbitrariness. The solution describes three-dimensional nonlinear processes and singularities in infinitely conducting plasma, gas or incompressible liquid. ", "machine_text": "  We consider the problem of describing fluid motions in a many-dimensional space. We restrict ourselves to the case of motions of ideal fluids, i.e., fluids with no internal viscosity and no bulk stress, in order to be able to describe the fluid motions by a small number of parameters. Our approach is based on the analysis of the Fourier spectrum of the velocity field. We show that a multidimensional fluid can be characterized by a few parameters in the same way as the one-dimensional case. In particular, we show that any smooth map from the set of spherical harmonics to the set of wave vectors in the space can be uniquely inverted. This provides a method for describing the structure of the velocity field. We also consider the problem of describing the shape of the velocity field in the space. We show that the velocity field of a multidimensional fluid has a simple structure if it is not changing too fast in a neighborhood of a point. In particular, we show that the shape of the velocity field is described by a few parameters in the same way as the one-dimensional case.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A theorem about relative entropy of quantum states with an application\n  to privacy in quantum communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2437, "human_text": "  We prove the following theorem about relative entropy of quantum states. \"Substate theorem: Let rho and sigma be quantum states in the same Hilbert space with relative entropy S(rho|sigma) = Tr rho (log rho - log sigma) = c. Then for all epsilon > 0, there is a state rho' such that the trace distance ||rho' - rho||_t = Tr sqrt{(rho' - rho)^2} <= epsilon, and rho'/2^{O(c/epsilon^2)} <= sigma.\"   It states that if the relative entropy of rho and sigma is small, then there is a state rho' close to rho, i.e. with small trace distance ||rho' - rho||_t, that when scaled down by a factor 2^{O(c)} `sits inside', or becomes a `substate' of, sigma. This result has several applications in quantum communication complexity and cryptography. Using the substate theorem, we derive a privacy trade-off for the set membership problem in the two-party quantum communication model. Here Alice is given a subset A of [n], Bob an input i in [n], and they need to determine if i in A.   \"Privacy trade-off for set membership: In any two-party quantum communication protocol for the set membership problem, if Bob reveals only k bits of information about his input, then Alice must reveal at least n/2^{O(k)} bits of information about her input.\"   We also discuss relationships between various information theoretic quantities that arise naturally in the context of the substate theorem. ", "machine_text": " We introduce a technique for characterizing entanglement which avoids the usual formalism of entanglement measures. We show that this technique can be used to prove a version of theHTML obtained by rearranging the mathematical symbols in the proof of theSets results characterizing entanglement. We show that this version of the inequality implies theSets results, and that the technique can be used to prove several otherresults in quantum information theory. We also show how our technique can be used to characterize the amount of information that can be extracted from a quantum state by partial measurements. Finally, we show that our technique can be used to prove a version of the much stronger Iguess that in any experiment one can think of, there is a measurement that can be performed such that the outcome of this measurement has a positive probability of being correct. Our technique provides a way of proving such an assurance for any measurement with a positive-semidefinite Fisher information. We also show that the technique can be used to prove a version of the that is independent of the particular measurement employed. We show that the proposed technique can be used to prove several otherresults in quantum information theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-Infrared Spectra of the Black Hole X-Ray Binary, A0620-00. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0267, "human_text": "  We present broadband NIR spectra of A0620-00 obtained with SpeX on the IRTF. The spectrum is characterized by a blue continuum on which are superimposed broad emission lines of HI and HeII and a host of narrower absorption lines of neutral metals and molecules. Spectral type standard star spectra scaled to the dereddened spectrum of A0620-00 in K exceed the A0620-00 spectrum in J and H for all stars of spectral type K7V or earlier, demonstrating that the donor star, unless later than K7V, cannot be the sole NIR flux source in A0620-00. In addition, the atomic absorption lines in the K3V spectrum are too weak with respect to those of A0620-00 even at 100% donor star contribution, restricting the spectral type of the donor star in A0620-00 to later than K3V. Comparison of the A0620-00 spectrum to scaled K star spectra indicates that the CO absorption features are significantly weaker in A0620-00 than in field dwarf stars. Fits of scaled model spectra of a Roche lobe-filling donor star to the spectrum of A0620-00 show that the best match to the CO absorption lines is obtained when the C abundance is reduced to [C/H] = -1.5. The donor star contribution in the H waveband is determined to be 82+-2%. Combined with previous published results from Froning & Robinson (2001) and Marsh et al. (1994), this gives a precise mass for the black hole in A0620-00 of M_BH = 9.7+-0.6 M_solar. ", "machine_text": "  We present near-infrared (NIR) spectroscopy and photometry of the black hole X-ray binary A0620-00. The motivation for our research is to better understand the accretion process in this object, which has been experiencing a large variability in its optical and NIR light during the last two years. We have performed a time series of NIR spectroscopy with the VISIR instrument at the Very Large Telescope Array, which allowed us to study the inner accretion flow in the broad-line region. We find that the accretion flow is variable on timescales of days, consistent with the observed variability in the optical and NIR light of the source. We find that the observed variability in the accretion flow is not correlated with the orbital period, but rather with the accretion phase. We find that the accretion flow is blueshifted during the early part of the accretion phase, consistent with an inward-directed accretion flow, while it is redshifted at later times, consistent with an outward-directed accretion flow. We find that the accretion flow is at its blueshifted peak when the accretion efficiency is highest, while it is at its redshifted minimum when the accretion efficiency is lowest. We also present NIR photometry of the source, which shows variability on timescales of days. We find that the variability in the photometry is not correlated with the orbital period, but rather with the accretion phase. We find that the brightness is highest when the accretion flow is blueshifted, while it is lowest when the accretion flow is redshifted. We discuss our results in the context of other black hole X-ray binaries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scaling Relations of Compressible MHD Turbulence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2464, "human_text": "  We study scaling relations of compressible strongly magnetized turbulence. We find a good correspondence of our results with the Fleck (1996) model of compressible hydrodynamic turbulence. In particular, we find that the density-weighted velocity, i.e. $u \\equiv \\rho^{1/3} v$, proposed in Kritsuk et al. (2007) obeys the Kolmogorov scaling, i.e. $E_{u}(k)\\sim k^{-5/3}$ for the high Mach number turbulence. Similarly, we find that the exponents of the third order structure functions for $u$ stay equal to unity for the all the Mach numbers studied. The scaling of higher order correlations obeys the She-Leveque (1994) scalings corresponding to the two-dimensional dissipative structures, and this result does not change with the Mach number either. In contrast to $v$ which exhibits different scaling parallel and perpendicular to the local magnetic field, the scaling of $u$ is similar in both directions. In addition, we find that the peaks of density create a hierarchy in which both physical and column densities decrease with the scale in accordance to the Fleck (1996) predictions. This hierarchy can be related ubiquitous small ionized and neutral structures (SINS) in the interstellar gas. We believe that studies of statistics of the column density peaks can provide both consistency check for the turbulence velocity studies and insight into supersonic turbulence, when the velocity information is not available. ", "machine_text": "  We study the statistical properties of the velocity field in compressible MHD turbulence. We show that, for a large class of numerical simulations, the velocity field is well described by a scaling relation that relates the mean velocity to the velocity fluctuations and the compression ratio. Within this class of simulations, the standard deviation of the velocity field scales as the square of the mean velocity. We show this result by fitting the empirical scaling relation to the data with an appropriate model. We also show that the model can be used to extract the local compression ratio in regions of the flow. We find that the local compression ratio is correlated with the local mean velocity, but that the correlation is very weak. We also show that the local compression ratio is uncorrelated with the local standard deviation of the velocity field. We discuss these results in the framework of the Gurruwiwi-Ohno model, and show that the Gurruwiwi-Ohno model can be used to quantitatively reproduce our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detection of Crab Giant Pulses Using the Mileura Widefield Array Low\n  Frequency Demonstrator Field Prototype System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0404, "human_text": "  We report on the detection of giant pulses from the Crab Nebula pulsar at a frequency of 200 MHz using the field deployment system designed for the Mileura Widefield Array's Low Frequency Demonstrator (MWA-LFD). Our observations are among the first high-quality detections at such low frequencies. The measured pulse shapes are deconvolved for interstellar pulse broadening, yielding a pulse-broadening time of 670$\\pm$100 $\\mu$s, and the implied strength of scattering (scattering measure) is the lowest that is estimated towards the Crab nebula from observations made so far. The sensitivity of the system is largely dictated by the sky background, and our simple equipment is capable of detecting pulses that are brighter than $\\sim$9 kJy in amplitude. The brightest giant pulse detected in our data has a peak amplitude of $\\sim$50 kJy, and the implied brightness temperature is $10^{31.6}$ K. We discuss the giant pulse detection prospects with the full MWA-LFD system. With a sensitivity over two orders of magnitude larger than the prototype equipment, the full system will be capable of detecting such bright giant pulses out to a wide range of Galactic distances; from $\\sim$8 to $\\sim$30 kpc depending on the frequency. The MWA-LFD will thus be a highly promising instrument for the studies of giant pulses and other fast radio transients at low frequencies. ", "machine_text": "  We report on a pilot study for the detection of crab giant pulses (GPs) using the Mileura Widefield Array (MWA) Low Frequency Demonstrator (LFD) Field Prototype system. The LFD is a precursor to the MWA LFD which will be a dedicated low frequency array for the investigation of a wide range of astrophysical phenomena in the frequency range of 20-200 Hz. The MWA LFD will be constructed and operated as a collaborative facility by the Australian National University (ANU) and CSIRO, with ANU responsible for the construction and operation of the LFD Field Prototype. We describe the LFD Field Prototype system and the motivation for the research, and report on the results of our pilot study for the detection of crab GPs. We describe the data processing pipeline and the criteria used to identify crab GPs, and present the frequency distribution of GP occurrence. We show that the LFD Field Prototype system has sufficient sensitivity to detect crab GPs, and discuss the prospects for using the LFD for further study of crab GP occurrence and its possible relation to other astrophysical phenomena.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The origin of the molecular emission around the southern hemisphere Re 4\n  IRS - HH 188 region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1427, "human_text": "  We present SEST observations of the molecular environment ahead of the southern Herbig-Haro object 188 (HH188), associated with the low-mass protostar Re4 IRS. We have also used the SuperCosmos Halpha survey to search for Halpha emission associated with the Re4 IRS - HH188 region. The aim of the present work is to study the properties of the molecular gas and to better characterize this southern star forming region. We mapped the HCO+ 3-2 and H13CO+ 1-0 emission around the YSO and took spectra of the CH3OH 2(0)-1(0)A+ and 2(-1)-1(-1)E and SO 6(5)-5(4) towards the central source. Column densities are derived and different scenarios are considered to explain the origin of the molecular emission. HCO+ arises from a relatively compact region around the YSO; however, its peak emission is displaced to the south following the outflow direction. Our chemical analysis indicates that a plausible scenario is that most of the emission arises from the cold, illuminated dense gas ahead of the HH188 object. We have also found that HH188, a high excitation object, seems to be part of a parsec scale and highly collimated HH system. Re4 IRS is probably a binary protostellar system, in the late Class 0 or Class I phase. One of the protostars, invisible in the near-IR, seems to power the HH188 system. ", "machine_text": " We present photometric detections of the CH and CN molecular lines in the source IRS - HH 188. The relative molecular luminosity of the source is  \u223c 10 38  W. We determine a radial molecular velocity of  \u223c 19  km s \u2212 1. This velocity is in good agreement with the measured proper motion of the ionised gas in the same source, thus confirming the hypothesis that the molecular gas and the ionised gas are the same physical entity. We have compared the observed distribution of the molecular gas with theoretical models. The best agreement is obtained with a model in which the molecular gas is distributed in a series of rings, with the molecular velocity at the centre being higher than the observed value. We discuss two possible mechanisms for producing this distribution, and conclude that the distribution has to be produced by a non-homogeneous process. We also discuss the distribution of the molecular gas in the region, and conclude that it is not possible to produce this distribution by a model in which the molecular gas is smoothly distributed with a constant velocity. We present a model in which the molecular gas is distributed in a series of expanding rings, with the number density of the rings declining exponentially with radius. We show that this model can produce the observed distribution of the molecular gas, with the number density being higher at the edge of the region than in its interior. We also discuss a model in which the molecular gas is distributed in a sphere, with the molecular velocity at the centre being higher than the observed value. We show that this model can also produce the observed distribution of the molecular gas, with the number density being higher at the edge of the region than in its interior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chandra Observations of Supernova 1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0209, "human_text": "  We have been monitoring Supernova (SN) 1987A with {\\it Chandra X-Ray Observatory} since 1999. We present a review of previous results from our {\\it Chandra} observations, and some preliminary results from new {\\it Chandra} data obtained in 2006 and 2007. High resolution imaging and spectroscopic studies of SN 1987A with {\\it Chandra} reveal that X-ray emission of SN 1987A originates from the hot gas heated by interaction of the blast wave with the ring-like dense circumstellar medium (CSM) that was produced by the massive progenitor's equatorial stellar winds before the SN explosion. The blast wave is now sweeping through dense CSM all around the inner ring, and thus SN 1987A is rapidly brightening in soft X-rays. At the age of 20 yr (as of 2007 January), X-ray luminosity of SN 1987A is $L_{\\rm X}$ $\\sim$ 2.4 $\\times$ 10$^{36}$ ergs s$^{-1}$ in the 0.5$-$10 keV band. X-ray emission is described by two-component plane shock model with electron temperatures of $kT$ $\\sim$ 0.3 and 2 keV. As the shock front interacts with dense CSM all around the inner ring, the X-ray remnant is now expanding at a much slower rate of $v$ $\\sim$ 1400 km s$^{-1}$ than it was until 2004 ($v$ $\\sim$ 6000 km s$^{-1}$). ", "machine_text": "  We present a detailed study of the supernova (SN) 1987A, based on observations with the Chandra X-ray Observatory. We find that the SN 1987A is still accreting matter, although at a rate that is most likely to be less than 1 M\u22c5 yr\u22121. We estimate the energy released in the first seven years of the supernova to be about 2.4 \u00d7 1051 erg, which corresponds to an excess energy with respect to the Chandrasekhar limit of about 3.4%. We find that the energy release rate has decreased significantly since the supernova burst, and is now only about 7% of the burst rate. We also find that the gas in the SN 1987A is still at high temperature, and that the temperature does not decrease as quickly as the accretion rate. This may be explained by the fact that the gas is not well mixed, and so the gas that is accreting has a higher temperature than the gas that has already been accreted. We discuss this in the framework of a simple model in which the accretion of gas is due to the infall of clumps of gas. The gas that has already been accreted is likely to have a temperature that is close to the Chandrasekhar limit, and so the overall temperature of the gas in the SN 1987A is likely to decrease slowly as the accretion continues.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Performance of the Charge Injection Capability of Suzaku XIS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1771, "human_text": "  A charge injection technique is applied to the X-ray CCD camera, XIS (X-ray Imaging Spectrometer) onboard Suzaku. The charge transfer inefficiency (CTI) in each CCD column (vertical transfer channel) is measured by the injection of charge packets into a transfer channel and subsequent readout. This paper reports the performances of the charge injection capability based on the ground experiments using a radiation damaged device, and in-orbit measurements of the XIS. The ground experiments show that charges are stably injected with the dispersion of 91eV in FWHM in a specific column for the charges equivalent to the X-ray energy of 5.1keV. This dispersion width is significantly smaller than that of the X-ray events of 113eV (FWHM) at approximately the same energy. The amount of charge loss during transfer in a specific column, which is measured with the charge injection capability, is consistent with that measured with the calibration source. These results indicate that the charge injection technique can accurately measure column-dependent charge losses rather than the calibration sources. The column-to-column CTI correction to the calibration source spectra significantly reduces the line widths compared to those with a column-averaged CTI correction (from 193eV to 173eV in FWHM on an average at the time of one year after the launch). In addition, this method significantly reduces the low energy tail in the line profile of the calibration source spectrum. ", "machine_text": "  We have investigated the charge injection capability of the X-ray imaging spectrometer (XIS) on board the Suzaku satellite, by utilizing the Hard X-ray transient hunter (HXT) instrument on board the Swift satellite. The charge injection is a major source of background in the energy-dispersive X-ray spectrometry (EDS) analysis of impulsive transient sources, and therefore has important implications for the study of such sources. We found that the charge injection effect produced by XIS is moderate and the injected charge is not depolarized immediately. The temporal behavior of the charge injection is consistent with a model in which the injected charge is distributed in a finite volume conductor, with a time constant longer than the duration of the transient event. We also found that the count rate in the energy range above 2 keV, where the XIS sensitivity is dominated by the charge injection, is depressed by a factor of  \u223c 4 immediately after the transient event. We discuss the implications of our results for the study of transient sources and the improvement of the data processing for the EDS analysis of transient events.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The time evolution of cosmological redshift as a test of dark energy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.235, "human_text": "  The variation of the expansion rate of the Universe with time produces an evolution in the cosmological redshift of distant sources (for example quasar Lyman-$\\alpha$ absorption lines), that might be directly observed by future ultra stable, high-resolution spectrographs (such as CODEX) coupled to extremely large telescopes (such as European Southern Observatory's Extremely Large Telescope, ELT). This would open a new window to explore the physical mechanism responsible for the current acceleration of the Universe. We investigate the evolution of cosmological redshift from a variety of dark energy models, and compare it with simulated data. We perform a Fisher matrix analysis and discuss the prospects for constraining the parameters of these models and for discriminating among competing candidates. We find that, because of parameter degeneracies, and of the inherent technical difficulties involved in this kind of observations, the uncertainties on parameter reconstruction can be rather large unless strong external priors are assumed. However, the method could be a valuable complementary cosmological tool, and give important insights on the dynamics of dark energy, not obtainable using other probes. ", "machine_text": " We have developed a new method to test the dark energy hypothesis by monitoring the evolution of cosmological redshift. Our method is independent of the choice of the distance metric and does not require a high confidence in the distance measurements. We show that our method is more sensitive to the evolution of the distance than the conventional method. This is because the conventional method uses the instantaneous distance measurements while our method uses the average distance measurements. Also our method is less vulnerable to systematics in the distance measurements. We show that our method can detect a slow-down of the evolution of the redshift at the 3sigma confidence level if the evolution of the distance is slowed down by a factor of  \u223c 2. We also show that our method can detect a fast-rise of the evolution of the redshift at the 3sigma confidence level if the evolution of the distance is accelerated by a factor of  \u223c 2. We estimate the systematic uncertainty in our method and show that our method is comparable to the conventional method in this respect. We also discuss the prospects of measuring the evolution of the redshift with the Next Generation Failure (ngc).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ly-alpha Emission-Line Galaxies at z = 3.1 in the Extended Chandra Deep\n  Field South. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3917, "human_text": "  We describe the results of an extremely deep, 0.28 deg^2 survey for z = 3.1 Ly-alpha emission-line galaxies in the Extended Chandra Deep Field South. By using a narrow-band 5000 Anstrom filter and complementary broadband photometry from the MUSYC survey, we identify a statistically complete sample of 162 galaxies with monochromatic fluxes brighter than 1.5 x 10^-17 ergs cm^-2 s^-1 and observers frame equivalent widths greater than 80 Angstroms. We show that the equivalent width distribution of these objects follows an exponential with a rest-frame scale length of w_0 = 76 +/- 10 Angstroms. In addition, we show that in the emission line, the luminosity function of Ly-alpha galaxies has a faint-end power-law slope of alpha = -1.49 +/- 0.4, a bright-end cutoff of log L^* = 42.64 +/- 0.2, and a space density above our detection thresholds of 1.46 +/- 0.12 x 10^-3 h70^3 galaxies Mpc^-3. Finally, by comparing the emission-line and continuum properties of the LAEs, we show that the star-formation rates derived from Ly-alpha are ~3 times lower than those inferred from the rest-frame UV continuum. We use this offset to deduce the existence of a small amount of internal extinction within the host galaxies. This extinction, coupled with the lack of extremely-high equivalent width emitters, argues that these galaxies are not primordial Pop III objects, though they are young and relatively chemically unevolved. ", "machine_text": "  We present the results of a narrow band imaging survey for Ly-alpha emission-line galaxies (ELGs) in the Extended Chandra Deep Field South (ECDF-S). The survey was conducted with Subaru/SuprimeCam at $z=3.1$, over an area of $2.37\\times 1.00$ degrees, and with $\\delta_{\\rm band}$ = $1.0$ arcmin. This is the first ELG survey conducted over an extragalactic sky field at intermediate redshift (z < 1), providing a unique view of the large-scale structure of the Universe at this epoch. We find 784 ELGs in our survey, with an estimated ELG number density of $2.5 \\times 10^{-2}$ deg$^{-1}$. The ELGs show a large degree of organisation, with a number of distinct groups and filaments, some of which extend several degrees. The properties of the ELGs (number density, sizes, and luminosities) are consistent with the large-scale distribution of galaxies in the Universe at z = 3.1, as traced by the survey galaxies in the optical and near-infrared, and by the distribution of intergalactic hydrogen at that epoch. The properties of the ELGs are inconsistent with the predictions of the currently popular theories of galaxy formation that assume a slow accretion history of galaxies in large scale structures, but are consistent with the predictions of theories that assume that galaxies in large-scale structure form through violent merging events. We show that the distribution of the ELGs is well described by a simple power law, with the probability of finding an ELG decreasing as the square of the distance from the nearest large scale structure. This provides strong evidence that large-scale structure forms through the aggregation of ELGs, rather than the accretion of galaxies in smooth accelerators. We discuss the implications of our results for theories of galaxy formation and large-scale structure formation, and for the nature of the intergalactic medium at z < 1.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Long Period, Massive Binaries HD 37366 and HD 54662: Potential\n  Targets for Long Baseline Optical Interferometry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3229, "human_text": "  We present the results from an optical spectroscopic analysis of the massive stars HD 37366 and HD 54662. We find that HD 37366 is a double-lined spectroscopic binary with a period of 31.8187 +/- 0.0004 days, and HD 54662 is also a double lined binary with a much longer period of 557.8 +/- 0.3 days. The primary of HD 37366 is classified as O9.5 V, and it contributes approximately two-thirds of the optical flux. The less luminous secondary is a broad-lined, early B-type main-sequence star. Tomographic reconstruction of the individual spectra of HD 37366 reveals absorption lines present in each component, enabling us to constrain the nature of the secondary and physical characteristics of both stars. Tomographic reconstruction was not possible for HD 54662; however, we do present mean spectra from our observations that show that the secondary component is approximately half as bright as the primary. The observed spectral energy distributions (SEDs) were fit with model SEDs and galactic reddening curves to determine the angular sizes of the stars. By assuming radii appropriate for their classifications, we determine distance ranges of 1.4 - 1.9 and 1.2 - 1.5 kpc for HD 37366 and HD 54662, respectively. ", "machine_text": "  The Long Period, Massive Binaries HD 37366 and HD 54662: Potential Targets for Long Baseline Optical Interferometry  We present high-resolution spectroscopy and photometry of the massive binary systems HD 37366 and HD 54662. We find that both systems are well-behaved and stable on time scales of at least several decades. The masses of the companions are 37M\u2299 and 34M\u2299 for HD 37366 and HD 54662, respectively. Both systems are sufficiently well-behaved that they may be useful targets for long baseline optical interferometry. We derive orbital elements for both systems, and find that the orbits are not perfectly periodic. We discuss the physical properties of the stars and their companions, and the evolution of the systems. We find that both systems are likely to have evolved from the main sequence in a Helium-rich envelope, and thus both are likely to be magnetically-quiet Helium-burning stars. We discuss the prospects for detection of sub-stellar companions using both interferometry and high-resolution spectroscopy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bounds on quark mass matrices elements due to measured properties of the\n  mixing matrix and present values of the quark masses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2851, "human_text": "  We obtain constraints on possible structures of mass matrices in the quark sector by using as experimental restrictions the determined values of the quark masses at the $M_Z$ energy scale, the magnitudes of the quark mixing matrix elements $V_{\\rm ud}$, $V_{\\rm us}$, $V_{\\rm cd}$, and $V_{\\rm cs}$, and the Jarlskog invariant $J(V)$. Different cases of specific mass matrices are examined in detail. The quality of the fits for the Fritzsch and Stech type mass matrices is about the same with $\\chi^2/{\\rm dof}=4.23/3=1.41$ and $\\chi^2/{\\rm dof}=9.10/4=2.28$, respectively. The fit for a simple generalization (one extra parameter) of the Fritzsch type matrices, in the physical basis, is much better with $\\chi^2/{\\rm dof}=1.89/4=0.47$. For comparison we also include the results using the quark masses at the 2 GeV energy scale. The fits obtained at this energy scale are similar to that at $M_Z$ energy scale, implying that our results are unaffected by the evolution of the quark masses from 2 to 91 GeV. ", "machine_text": "  We show that the elements of the quark mass matrices can be bounded from below by using the properties of the mixing matrix and the present values of the quark masses. The bounds obtained are sufficiently tight to rule out the possibility of a quark mass as small as the electron mass. The motivation for this work is to provide a simple argument that the quark mass matrices have positive definite elements, thus removing one possible technical problem in the formulation of the Einstein-Maxwell theory. The key idea is to use the fact that the non-singlet quark mixing matrix has real positive elements, whereas the singlet quark mixing matrix has elements which can be either positive or negative. The problem this work attempts to solve is to provide a simple and physically intuitive argument that the quark mass matrices have positive definite elements. The practical application of this work is that it removes one possible technical problem in the formulation of the Einstein-Maxwell theory. The theoretical application of this work is that it provides a simple argument that the quark mass matrices have positive definite elements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: \"Illusion of control\" in Minority and Parrondo Games. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.112, "human_text": "  Human beings like to believe they are in control of their destiny. This ubiquitous trait seems to increase motivation and persistence, and is probably evolutionarily adaptive. But how good really is our ability to control? How successful is our track record in these areas? There is little understanding of when and under what circumstances we may over-estimate or even lose our ability to control and optimize outcomes, especially when they are the result of aggregations of individual optimization processes. Here, we demonstrate analytically using the theory of Markov Chains and by numerical simulations in two classes of games, the Minority game and the Parrondo Games, that agents who optimize their strategy based on past information actually perform worse than non-optimizing agents. In other words, low-entropy (more informative) strategies under-perform high-entropy (or random) strategies. This provides a precise definition of the \"illusion of control\" in set-ups a priori defined to emphasize the importance of optimization. ", "machine_text": "  We study the illusion of control in minority and Parrondo games. We show that the illusion of control can be maintained in a minority game by means of a suitable randomization of the game's starting point. We also show that the illusion of control can be maintained in a Parrondo game if the randomization is performed on the moves rather than on the starting point. The main difference between the minority and Parrondo cases is that, while the minority game has a single Nash equilibria, the Parrondo game can have several, and the randomization must be designed in such a way that the illusion of control is maintained for all of them. We analyze the randomizations of the minority and Parrondo games by means of a suitable generalization of the concept of vertigo to random games, and we derive simple sufficient conditions for the randomization of the minority and Parrondo games that guarantee the maintenance of the illusion of control. We finally study the connection between the randomization of the minority and Parrondo games and the classical concepts ofrandomized retrospectively deterministic and stochastic games.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A CLT for Information-theoretic statistics of Gram random matrices with\n  a given variance profile. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0166, "human_text": "  Consider a $N\\times n$ random matrix $Y_n=(Y_{ij}^{n})$ where the entries are given by $$ Y_{ij}^{n}=\\frac{\\sigma_{ij}(n)}{\\sqrt{n}} X_{ij}^{n} $$ the $X_{ij}^{n}$ being centered, independent and identically distributed random variables with unit variance and $(\\sigma_{ij}(n); 1\\le i\\le N, 1\\le j\\le n)$ being an array of numbers we shall refer to as a variance profile. We study in this article the fluctuations of the random variable $$ \\log\\det(Y_n Y_n^* + \\rho I_N) $$ where $Y^*$ is the Hermitian adjoint of $Y$ and $\\rho > 0$ is an additional parameter. We prove that when centered and properly rescaled, this random variable satisfies a Central Limit Theorem (CLT) and has a Gaussian limit whose parameters are identified. A complete description of the scaling parameter is given; in particular it is shown that an additional term appears in this parameter in the case where the 4$^\\textrm{th}$ moment of the $X_{ij}$'s differs from the 4$^{\\textrm{th}}$ moment of a Gaussian random variable. Such a CLT is of interest in the field of wireless communications. ", "machine_text": " We consider a simple model of random matrices which is based on the independence of the entries of the matrix from each other and from the entries of the second row and second column. We show that such matrices have a specific distribution of the Mahalanobis metric and that this distribution depends only on the variance profile of the matrix, which is described by two parameters. This allows us to introduce a family of distributions of the Mahalanobis metric which is indexed by the variance profile. We show that this family has a limiting distribution which is an equivariant diffusion process. We obtain the distribution of the Trace of the matrix, which allows us to introduce a random symmetric positive definite matrix with a given variance profile. We show that this random matrix has a limiting distribution which is the normal random symmetric positive definite matrix. As an application, we show that the limiting distribution of the gradient of the mutual information is the Fr\u00e9chet random gradient.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Studies of Thermally Unstable Accretion Disks around Black Holes with\n  Adaptive Pseudo-Spectral Domain Decomposition Method I. Limit-Cycle Behavior\n  in the Case of Moderate Viscosity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2283, "human_text": "  We present a numerical method for spatially 1.5-dimensional and time-dependent studies of accretion disks around black holes, that is originated from a combination of the standard pseudo-spectral method and the adaptive domain decomposition method existing in the literature, but with a number of improvements in both the numerical and physical senses. In particular, we introduce a new treatment for the connection at the interfaces of decomposed subdomains, construct an adaptive function for the mapping between the Chebyshev-Gauss-Lobatto collocation points and the physical collocation points in each subdomain, and modify the over-simplified 1-dimensional basic equations of accretion flows to account for the effects of viscous stresses in both the azimuthal and radial directions. Our method is verified by reproducing the best results obtained previously by Szuszkiewicz & Miller on the limit-cycle behavior of thermally unstable accretion disks with moderate viscosity. A new finding is that, according to our computations, the Bernoulli function of the matter in such disks is always and everywhere negative, so that outflows are unlikely to originate from these disks. We are encouraged to study the more difficult case of thermally unstable accretion disks with strong viscosity, and wish to report our results in a subsequent paper. ", "machine_text": " We study limit-cycle behavior in the evolution of thermally unstable accretion disks around black holes with moderate viscosity. We employ the adaptive pseudo-spectral domain decomposition method, which is newly developed in this work, to accurately solve the viscousdisk equations with theopycnic-based boundary conditions on the inner and outer boundaries. We find that the disk eigenmodes are highly sensitive to the ratio of the viscous to thermal resistances, which may cause a significant decay in the amplitude of the fastest eigenmode even when the disk is slightly viscously stable. We also find that the disk becomes locally stable against small-scale perturbations in the inner region, which is consistent with the results of the linear stability analysis. The behavior of the local viscous coefficient, which is obtained from the solution of the disk equations, shows a strong correlation with the evolution of the disk structure in the inner region. Our results suggest that the local viscous coefficient may be a good indicator of the onset of the limit-cycle behavior in the inner region, even in the case of a thermally unstable disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rotation and activity of pre-main-sequence stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3266, "human_text": "  We present a study of rotation (vsini) and chromospheric activity (Halpha EW) based on an extensive set of high-resolution optical spectra obtained with MIKE on the 6.5m Magellan Clay telescope. Our targets are 74 F-M dwarfs in the young stellar associations Eta Cha, TW Hydrae, Beta Pic, and Tuc-Hor, spanning ages from 6 to 30 Myr. While the Halpha EW for most F and G stars are consistent with pure photospheric absorption, most K and M stars show chromospheric emission. By comparing Halpha EW in our sample to results in the literature, we see a clear evolutionary sequence: Chromospheric activity declines steadily from the T Tauri phase to the main sequence. Using activity as an age indicator, we find a plausible age range for the Tuc-Hor association of 10-40 Myr. Between 5 and 30 Myr, we do not see evidence for rotational braking in the total sample, thus angular momentum is conserved, in contrast to younger stars. This difference indicates a change in the rotational regulation at 5-10 Myr, possibly because disk braking cannot operate longer than typical disk lifetimes, allowing the objects to spin up. The rotation-activity relation is flat in our sample; in contrast to main-sequence stars, there is no linear correlation for slow rotators. We argue that this is because young stars generate their magnetic fields in a fundamentally different way from main-sequence stars, and not just the result of a saturated solar-type dynamo. By comparing our rotational velocities with published rotation periods for a subset of stars, we determine ages of 13 (7-20) Myr and 9 (7-17} Myr for the Eta Cha and TWA associations, respectively, consistent with previous estimates. Thus we conclude that stellar radii from evolutionary models by Baraffe et al. (1998) are in agreement with the observed radii within +-15%. (abridged) ", "machine_text": "  Pre-main-sequence stars are a class of stars that are in the process of evolving from a collapsed cloud of gas and dust to a stable source of light and heat. As these stars evolve, they undergo a period of rapid rotation and activity, during which they can display phenomena such as solar flares and coronal mass ejections. The activity of pre-main-sequence stars is driven by the strong magnetic fields that are generated as the stars collapse and heat up.  The rotation and activity of pre-main-sequence stars is an important topic of study, as it can provide insight into the processes that occur during the evolution of stars. In addition, pre-main-sequence stars can have a significant impact on the evolution of their solar systems, as they can affect the evolution of planets and other celestial objects.  In this work, we present a theoretical study of the rotation and activity of pre-main-sequence stars. We consider the effects of various physical processes, such as convection and turbulence, on the rotation and activity of these stars. We find that the rotation and activity of pre-main-sequence stars can be highly variable, depending on the physical processes that are occurring within the stars.  We also consider the impact of the rotation and activity of pre-main-sequence stars on the evolution of their solar systems. We find that the activity of these stars can have a significant impact on the evolution of planets and other celestial objects, and that the rotation of these stars can affect the stability of their solar systems.  Our results suggest that the rotation and activity of pre-main-sequence stars is an important topic of study, and that further research in this area can provide important insights into the evolution of stars and their solar systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Light curves and colours of the faint Uranian irregular satellites\n  Sycorax, Prospero, Stephano, Setebos and Trinculo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2187, "human_text": "  After the work of Gladman et al. (1998), it is now assessed that many irregular satellites are orbiting around Uranus. Despite many studies have been performed in past years, very few is know for the light-curves of these objects and inconsistencies are present between colours derived by different authors. This situation motivated our effort to improve both the knowledge of colours and light curves. We present and discuss time series observations of Sycorax, Prospero, Stephano, Setebos and Trinculo, five faint irregular satellites of Uranus, carried out at VLT, ESO Paranal (Chile) in the nights between 29 and 30 July, 2005 and 25 and 30 November, 2005. We derive light curves for Sycorax and Prospero and colours for all of these these bodies. For Sycorax we obtain colours B-V =0.839 +/- 0.014, V-R = 0.531 +/- 0.005 and a light curve which is suggestive of a periodical variation with period about 3.6 hours and amplitude about 0.067 +/- 0.004 mag. The periods and colours we derive for Sycorax are in agreement with our previous determination in 1999 using NTT. We derive also a light-curve for Prospero which suggests an amplitude of about 0.2 mag and a periodicity of about 4 hours. However, the sparseness of our data, prevents a more precise characterization of the light-curves, and we can not determine wether they are one-peaked or two-peaked. Hence, these periods and amplitudes have to be considered preliminary estimates. As for Setebos, Stephano and Trinculo the present data do not allow to derive any unambiguous periodicity, despite Setebos displays a significant variability with amplitude about as large as that of Prospero. Colours for Prospero, Setebos, Stephano and Trinculo are in marginal agreement with the literature. ", "machine_text": "  We present new visible and near-infrared photometry of the Uranian irregular satellites Sycorax, Prospero, Stephano, Setebos and Trinculo, obtained with the Hubble Space Telescope. We show that the satellites exhibit considerable colour diversity, particularly in the range 0.8\u20131.5 \u03bcm. Prospero and Stephano are relatively red, while Sycorax, Setebos and Trinculo are much bluer. The colours are stable with time, within the 1% level, except for Stephano, whose colour has changed by ~75% since 1999. We discuss the origin of the colour diversity in terms of different degrees of spacecraft contamination and photodegradation of the polymers and other materials composing the surfaces of the satellites. We estimate the size of the satellites by comparison with the radii of dust particles in the environment, and find that all of the irregulars are larger than 5 km in diameter, except for Setebos. We discuss the implications of our results for the evolution and origin of the irregular satellites, and the surface composition of the larger satellites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Self assembly of a model multicellular organism resembling the\n  Dictyostelium slime molds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0227, "human_text": "  The evolution of multicellular organisms from monocellular ancestors represents one of the greatest advances of the history of life. The assembly of such multicellular organisms requires signalling and response between cells: over millions of years these signalling processes have become extremely sophisticated and refined by evolution, such that study of modern organisms may not be able to shed much light on the original ancient processes . Here we are interested in determining how simple a signalling method can be, while still achieving self-assembly. In 2D a coupled cellular automaton/differential equation approach models organisms and chemotaxic chemicals, producing spiralling aggregation. In 3D Lennard-Jones-like particles are used to represent single cells, and their evolution in response to signalling is followed by molecular dynamics. It is found that if a single cell is able to emit a signal which induces others to move towards it, then a colony of single-cell organisms can assemble into shapes as complex as a tower, a ball atop a stalk, or a fast-moving slug. The similarity with the behaviour of modern Dictyostelium slime molds signalling with cyclic adenosine monophosphate (cAMP) is striking. ", "machine_text": "  We have developed a simple model multicellular organism that resembles the real multicellular organism Dictyostelium in several aspects. The model organism is composed of a large number of cells that can communicate with each other via gap junctions. Each cell is modeled as a set of compartments that represent the internal structures of the cell, such as the nucleus, the Golgi apparatus, the endoplasmic reticulum, etc. We used a modified version of the Kermit algorithm to obtain a color-based distinction between the different internal structures. This is achieved by analyzing the 3-dimensional structure of the cells, in particular, the topology of the transport network. The transport network is constructed from the 3-d pixel connectivity, using the information of the location of the internal structures. The communication via the gap junctions is reflected in a long-range synchronization of the internal structures. We show that this model can undergo a development similar to the one observed in the real Dictyostelium. In particular, we observe a transition from a disordered state, in which the cells are not synchronized, to a ordered state, in which the cells are synchronized. This transition is accompanied by a fast increase in the number of gap junctions. We discuss the mechanism of the development and the similarities and differences between the model and the real organism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer-IRAC GLIMPSE of high mass protostellar objects. I Infrared point\n  sources and nebulae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4399, "human_text": "  The GLIMPSE archive was used to obtain 3.6--8.0micron, point source photometry and images for 381 massive protostellar candidates lying in the Galactic mid-plane. The colours, magnitudes and spectral indicies of sources in each of the 381 target fields were analysed and compared with the predictions of 2D radiative transfer model simulations. Although no discernable embedded clusters were found in any targets, multiple sources or associations of redenned young stellar objects were found in many sources indicating multiplicity at birth. The spectral index ($\\alpha$) of these point sources in 3.6--8.0mum bands display large values of $\\alpha$=2--5. A color-magnitude analog plot was used to identify 79 infrared counterparts to the HMPOs. Compact nebulae are found in 75% of the detected sources with morphologies that can be well described by core-halo, cometary, shell-like and bipolar geometries similar to those observed in ultra-compact HII regions. The IRAC band SEDs of the IR counterparts of HMPOs are best described to represent YSOs with a mass range of 8--20\\msun in their Class I stages when compared with 2D radiative transfer models. They also suggest that the high $\\alpha$ values represent reprocessed star/star+disk emission that is arising in the dense envelopes. Thus we are witnessing the luminous envelopes around the protostars rather than their photospheres or disks. We argue that the compact infrared nebulae likely reflect the underlying physical structure of the dense cores and are found to imitate the morphologies of known UCHII regions. Our results favour models of continuuing accretion involving both molecular and ionised accretion components to build the most massive stars rather than purely molecular rapid accretion flows. ", "machine_text": "  We present Spitzer-IRAC GLIMPSE (Great Lyon's probe for the inner and mid-plane structure of protoplanetary objects) results for 42 high mass protostellar objects (HMPSOs), and find a strong correlation between the mid-IR and far-IR colors of the HMPSOs. The mid-IR colors show a well-defined difference between compact and extended sources. The compact HMPSOs are characterized by a blue color, while the extended sources are red. The difference in color is such that we can identify unambiguously the nature of the observed HMPSOs in the mid-IR, independently of the resolution. We conclude that the mid-IR color is a powerful tool to study the inner structure of the HMPSOs, and the far-IR a powerful tool to study the outer structure. The correlation between the mid-IR and far-IR colors can be explained by a simple model in which the compact HMPSOs are surrounded by a cold inner layer, and the extended sources are embedded in a hot outer layer. We show that the ratio of the far-IR to mid-IR colors is a strong indicator of the mass of the inner object. Our results suggest that the mass of the inner object is a key parameter in the formation and evolution of HMPSOs, with the mass distribution in the inner few AU possibly controlling the accretion process.  We present a model in which the non-LTE spectrum of a HMPSO is the sum of the spectra of the inner and outer objects, weighted by the distance $r$. Our model predicts a strong correlation between the mid-IR and far-IR colors of HMPSOs, which we observe in our data. The model can be used to infer the relative mass of the inner and outer objects, provided that the inner object is compact. We discuss several ways in which the compact inner object can form. We show that the observed correlation between the mid-IR and far-IR colors can be used to constrain the mass of the compact object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The anticenter old open cluster NGC 1883: radial velocity and\n  metallicity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.23, "human_text": "  Having already reported on the first photometric study of the intermediate-age open cluster NGC 1883 (Carraro et al. 2003), we present in this paper the first spectroscopic multi-epoch investigation of a sample of evolved stars in the same cluster. The aim is to derive the cluster membership, velocity and metallicity, and discuss recent claims in the literature (Tadross 2005) that NGC 1883 is as metal poor as globular clusters in the Halo. Besides, being one of the few outer Galactic disk intermediate-age open clusters known so far, it is an ideal target to improve our knowledge of the Galactic disk radial abundance gradient, that is a basic ingredient for any chemical evolution model of the Milky Way. The new data we obtained allow us to put NGC 1883's basic parameters more reliable. We find that the cluster has a mean metallicity of [Fe/H] = -0.20$\\pm$0.22, from which we infer an age (650$^{+70}_{-70}$ Myr) close to the Hyades one and a Galactocentric distance of 12.3$^{+0.4}_{-0.2}$ kpc. The metal abundance, kinematics, and position make NGC 1883 a genuine outer disk intermediate-age open cluster. We confirm that in the outer Galactic disk the abundance gradient is shallower than in the solar vicinity. ", "machine_text": "  The Anticenter Old Open Cluster NGC 1883: Radial Velocity and Metallicity  We present a study of the radial velocity and metallicity of 75 stars in the old open cluster NGC 1883. The sample consists of 31 giants and 44 turn-off stars selected from a catalog of over 200 cluster members observed with the Fabry-Perot telescope at La Silla. The radial velocities were measured with the MIKE-700 spectrometer attached to the MIKE-4 telescope at La Silla. The metallicities were obtained from high-resolution spectra taken with the FEROS spectrometer at the 2.2 m telescope at La Silla. The radial velocities show that the cluster is at an average velocity of 60 km s$^{-1}$ and has a systemic velocity of 65 km s$^{-1}$. The metallicities are in the range [Fe/H] = +0.08 to +0.35. These values are in good agreement with the metallicities of turn-off stars in the Pleiades and Hyades, and suggest that the cluster formed in a medium- metallicity gas cloud. The radial velocity distribution of the cluster members is well described by a Gaussian with a width of 8 km s$^{-1}$. The cluster has a tidal radius of 8.9 pc, a half-mass radius of 4.4 pc, and a mass of 2.2 x 10^4 M$_{\\odot}$. We have found no evidence for the presence of an old embedded cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal noise informatics: Totally secure communication via a wire;\n  Zero-power communication; and Thermal noise driven computing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0158, "human_text": "  Very recently, it has been shown that thermal noise and its artificial versions (Johnson-like noises) can be utilized as an information carrier with peculiar properties therefore it may be proper to call this topic Thermal Noise Informatics. Zero Power (Stealth) Communication, Thermal Noise Driven Computing, and Totally Secure Classical Communication are relevant examples. In this paper, while we will briefly describe the first and the second subjects, we shall focus on the third subject, the secure classical communication via wire. This way of secure telecommunication utilizes the properties of Johnson(-like) noise and those of a simple Kirchhoff's loop. The communicator is unconditionally secure at the conceptual (circuit theoretical) level and this property is (so far) unique in communication systems based on classical physics. The communicator is superior to quantum alternatives in all known aspects, except the need of using a wire. In the idealized system, the eavesdropper can extract zero bit of information without getting uncovered. The scheme is naturally protected against the man-in-the-middle attack. The communication can take place also via currently used power lines or phone (wire) lines and it is not only a point-to-point communication like quantum channels but network-ready. Tests have been carried out on a model-line with ranges beyond the ranges of any known direct quantum communication channel and they indicate unrivalled signal fidelity and security performance. This simple device has single-wire secure key generation/sharing rates of 0.1, 1, 10, and 100 bit/second for copper wires with diameters/ranges of 21 mm / 2000 km, 7 mm / 200 km, 2.3 mm / 20 km, and 0.7 mm / 2 km, respectively and it performs with 0.02% raw-bit error rate (99.98 % fidelity). ", "machine_text": "  Thermal noise informatics: Totally secure communication via a wire; Zero-power communication; and Thermal noise driven computing.  We present a new approach to information processing that uses thermal noise as the information carrier. We show that the shot noise current in a resistor can be used to transmit information, and that such a channel can be used to implement a one-way communication channel that is totally secure, and requires zero-power from the transmitter. We also show that thermal noise can be used as the information carrier in a two-way communication protocol, and that such a protocol can be used to implement a totally secure communication channel, again, requiring zero-power from the transmitter. We further show that thermal noise can be used as the basis for a computing architecture that is secure, and operates at zero-power. We show that a thermal noise source can be used to drive a watchdog circuit that operates at zero-power, and that such a watchdog circuit can be used to drive a computing element that operates at zero-power. We show that such a zero-power, thermal noise driven watchdog-computing element can be used to implement a totally secure computing architecture.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of Macroscopic Quantum Tunneling in High-T_c c-Axis Josephson\n  Junctions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1418, "human_text": "  We study macroscopic quantum tunneling (MQT) in c-axis twist Josephson junctions made of high-T_c superconductors in order to clarify the influence of the anisotropic order parameter symmetry (OPS) on MQT. The dependence of the MQT rate on the twist angle $\\gamma$ about the c-axis is calculated by using the functional integral and the bounce method. Due to the d-wave OPS, the $\\gamma$ dependence of standard deviation of the switching current distribution and the crossover temperature from thermal activation to MQT are found to be given by $\\cos2\\gamma$ and $\\sqrt{\\cos2\\gamma}$, respectively. We also show that a dissipative effect resulting from the nodal quasiparticle excitation on MQT is negligibly small, which is consistent with recent MQT experiments using Bi${}_2$Sr${}_2$CaCu${}_2$O${}_{8 + \\delta}$ intrinsic junctions. These results indicate that MQT in c-axis twist junctions becomes a useful experimental tool for testing the OPS of high-T_c materials at low temperature, and suggest high potential of such junctions for qubit applications. ", "machine_text": "  We have developed a theory of macroscopic quantum tunneling in high-T_c c-axis Josephson junctions, which we have tested against a variety of experiments. In a typical experiment, a superconducting tape is patterned into a long array of Josephson junctions, each of which is 0.5-1 micron in length and separated by an insulator. When the array is biased with a DC current, each junction is found to have a critical current density for supercurrent passage, I_c, which is several times greater than that expected from an ideal thermodynamic equilibrium condition, and a non-Equilibrium transport behavior, which we show to be in agreement with a model in which a macroscopic quantum tunneling process is invoked to describe the transport in these junctions. We analyze a series of experiments in which the role of the bias current, the thickness of the insulator, and the temperature is varied, in each case successfully explaining the results in terms of a theory of macroscopic quantum tunneling in which a massless exciton-like particle is coherently transported through the barrier between the superconducting electrodes. We also show that the theory predicts a non-monotonic behavior of I_c as a function of the thickness of the insulator, in qualitative agreement with a set of experiments in which the thickness of the insulator is varied over a wide range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evidence Of Dark Matter Annihilations In The WMAP Haze. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3655, "human_text": "  The WMAP experiment has revealed an excess of microwave emission from the region around the center of our Galaxy. It has been suggested that this signal, known as the ``WMAP Haze'', could be synchrotron emission from relativistic electrons and positrons generated in dark matter annihilations. In this letter, we revisit this possibility. We find that the angular distribution of the WMAP Haze matches the prediction for dark matter annihilations with a cusped density profile, $\\rho(r) \\propto r^{-1.2}$ in the inner kiloparsecs. Comparing the intensity in different WMAP frequency bands, we find that a wide range of possible WIMP annihilation modes are consistent with the spectrum of the haze for a WIMP with a mass in the 100 GeV to multi-TeV range. Most interestingly, we find that to generate the observed intensity of the haze, the dark matter annihilation cross section is required to be approximately equal to the value needed for a thermal relic, $\\sigma v \\sim 3 \\times 10^{-26}$ cm$^3$/s. No boost factors are required. If dark matter annihilations are in fact responsible for the WMAP Haze, and the slope of the halo profile continues into the inner Galaxy, GLAST is expected to detect gamma rays from the dark matter annihilations in the Galactic Center if the WIMP mass is less than several hundred GeV. ", "machine_text": "  We present evidence of dark matter annihilations in the WMAP Haze. The large scale structure in the matter power spectrum observed by WMAP is consistent with a Universe dominated by a Gaussian random field with a scale of approximately 250 hMpc. We show that this is consistent with the location of the peak of the matter power spectrum being a transition between a Gaussian random field and a pixelated one, in a manner analogous to the transition between a Poisson and a binomial distribution. This has the implication that the small scale structure in the matter power spectrum may be described by a pixelated distribution with a scale of order 1 hMpc, and may thus be due to the annihilation of dark matter. We present a simple model which quantitatively describes the small scale structure in the matter power spectrum observed by WMAP, and find that it is consistent with a transition between a Gaussian random field and a pixelated one, with the scale of the pixelation being proportional to the average number density of dark matter. We discuss the implications of this model for the nature of dark matter.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effective anisotropies and energy barriers of magnetic nanoparticles\n  with Neel surface anisotropy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1689, "human_text": "  Magnetic nanoparticles with Neel surface anisotropy, different internal structures, surface arrangements and elongation are modelled as many-spin systems. The results suggest that the energy of many-spin nanoparticles cut from cubic lattices can be represented by an effective one-spin potential containing uniaxial and cubic anisotropies. It is shown that the values and signs of the corresponding constants depend strongly on the particle's surface arrangement, internal structure and elongation. Particles cut from a simple cubic lattice have the opposite sign of the effective cubic term, as compared to particles cut from the face-centered cubic lattice. Furthermore, other remarkable phenomena are observed in nanoparticles with relatively strong surface effects: (i) In elongated particles surface effects can change the sign of the uniaxial anisotropy. (ii) In symmetric particles (spherical and truncated octahedral) with cubic core anisotropy surface effects can change its sign. We also show that the competition between the core and surface anisotropies leads to a new energy that contributes to both the 2nd- and 4th-order effective anisotropies. ", "machine_text": " Effective anisotropies and energy barriers of magnetic nanoparticles with Neel surface anisotropy.  We consider the effective anisotropy and the energy barrier of a ferromagnetic nanoparticle in a non-magnetic medium for a range of diameters and aspect ratios, in the limit of small magnetization, assuming the spherical nanoparticles to be fully magnetized and in the limit of large magnetization, assuming the magnetic dipole moment to be confined to the particle surface. The surface anisotropy constant depends on the ratio of the particle diameter to the exchange length. The anisotropy constant becomes positive for particles with diameters smaller than the exchange length and negative for particles with diameters much larger than the exchange length. We show that, for particles with diameters smaller than the exchange length, the energy barrier has a minimum with the direction of the easy axis of the surface anisotropy. In contrast, for particles with diameters much larger than the exchange length, the energy barrier has a maximum with the direction of the easy axis of the surface anisotropy. Our results can be used to optimize the magnetic response of nanoparticles with different diameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Note on the Inapproximability of Correlation Clustering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2092, "human_text": "  We consider inapproximability of the correlation clustering problem defined as follows: Given a graph $G = (V,E)$ where each edge is labeled either \"+\" (similar) or \"-\" (dissimilar), correlation clustering seeks to partition the vertices into clusters so that the number of pairs correctly (resp. incorrectly) classified with respect to the labels is maximized (resp. minimized). The two complementary problems are called MaxAgree and MinDisagree, respectively, and have been studied on complete graphs, where every edge is labeled, and general graphs, where some edge might not have been labeled. Natural edge-weighted versions of both problems have been studied as well. Let S-MaxAgree denote the weighted problem where all weights are taken from set S, we show that S-MaxAgree with weights bounded by $O(|V|^{1/2-\\delta})$ essentially belongs to the same hardness class in the following sense: if there is a polynomial time algorithm that approximates S-MaxAgree within a factor of $\\lambda = O(\\log{|V|})$ with high probability, then for any choice of S', S'-MaxAgree can be approximated in polynomial time within a factor of $(\\lambda + \\epsilon)$, where $\\epsilon > 0$ can be arbitrarily small, with high probability. A similar statement also holds for $S-MinDisagree. This result implies it is hard (assuming $NP \\neq RP$) to approximate unweighted MaxAgree within a factor of $80/79-\\epsilon$, improving upon a previous known factor of $116/115-\\epsilon$ by Charikar et. al. \\cite{Chari05}. ", "machine_text": "  We show that correlation clustering, a popular clustering algorithm that has been used to extract subtle structure in data, is NP-hard to approximate to within any constant factor. This answers a question oftradition, and suggests that approximation algorithms for this problem are unlikely to be found.  We show further that even if the problem is approximable, the approximation algorithm would have to be \" KT-cladistic\". This answers a question ofLgetInstance()ance, and suggests that such an algorithm would have little practical value.  We show finally that the problem is APX-hard to approximate, and hence unlikely to be approximable in practice.  These results apply to the problem of finding a minimum correlation among all partitions of the data. They also apply to the problem of finding a partition of minimum correlation among all possible partitions, provided that the number of clusters is fixed. They do not apply to the problem of finding a minimum correlation among all possible partitions, even if the number of clusters is fixed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Hopf Algebra Structure of the Character Rings of Classical Groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2029, "human_text": "  The character ring \\CGL of covariant irreducible tensor representations of the general linear group admits a Hopf algebra structure isomorphic to the Hopf algebra \\Sym$ of symmetric functions. Here we study the character rings \\CO and \\CSp of the orthogonal and symplectic subgroups of the general linear group within the same framework of symmetric functions. We show that \\CO and \\CSp also admit natural Hopf algebra structures that are isomorphic to that of \\CGL, and hence to \\Sym. The isomorphisms are determined explicitly, along with the specification of standard bases for \\CO and \\CSp analogous to those used for \\Sym. A major structural change arising from the adoption of these bases is the introduction of new orthogonal and symplectic Schur-Hall scalar products. Significantly, the adjoint with respect to multiplication no longer coincides, as it does in the \\CGL case, with a Foulkes derivative or skew operation. The adjoint and Foulkes derivative now require separate definitions, and their properties are explored here in the orthogonal and symplectic cases. Moreover, the Hopf algebras \\CO and \\CSp are not self-dual. The dual Hopf algebras \\CO^* and \\CSp^* are identified. Finally, the Hopf algebra of the universal rational character ring \\CGLrat of mixed irreducible tensor representations of the general linear group is introduced and its structure maps identified. ", "machine_text": "  We give a detailed account of the structure of the character rings of the classical groups over fields which are neither algebraic nor topological in origin. The approach is via the study of certain ( raided ) functors which form a two - level structure on the category of finite - dimensional representations of the classical groups. We show that the source and the target of these functors are the hopf algebras and that they are related by the well - known equivalence of categories between the representations of the classical groups and the self - adjoint representations of the symmetric groups. The main tool is the use of the celebrated representation - theoretic fact that the character ring of a representation of a finite group G is isomorphic to the quotient ring of the algebra of G - invariant linear forms on the algebra of all linear forms on the underlying vector space. We show that, in the presence of an algebra isomorphism between the character rings of two representations, the original representations can be recovered from the character rings up to equivalence. As an application, we give a description of the character ring of the regular representation of the symmetric group in terms of the Schur parameters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sparticle Spectra and LHC Signatures for Large Volume String\n  Compactifications. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3403, "human_text": "  We study the supersymmetric particle spectra and LHC collider observables for the large-volume string models with a fundamental scale of 10^{11} GeV that arise in moduli-fixed string compactifications with branes and fluxes. The presence of magnetic fluxes on the brane world volume, required for chirality, perturb the soft terms away from those previously computed in the dilute-flux limit. We use the difference in high-scale gauge couplings to estimate the magnitude of this perturbation and study the potential effects of the magnetic fluxes by generating many random spectra with the soft terms perturbed around the dilute flux limit. Even with a 40% variation in the high-scale soft terms the low-energy spectra take a clear and predictive form. The resulting spectra are broadly similar to those arising on the SPS1a slope, but more degenerate. In their minimal version the models predict the ratios of gaugino masses to be M_1 : M_2 : M_3=(1.5 - 2) : 2 : 6, different to both mSUGRA and mirage mediation. Among the scalars, the squarks tend to be lighter and the sleptons heavier than for comparable mSUGRA models. We generate 10 fb^{-1} of sample LHC data for the random spectra in order to study the range of collider phenomenology that can occur. We perform a detailed mass reconstruction on one example large-volume string model spectrum. 100 fb^{-1} of integrated luminosity is sufficient to discriminate the model from mSUGRA and aspects of the sparticle spectrum can be accurately reconstructed. ", "machine_text": " We consider the production of sparticles (i.e. lighter counterparts of the standard model quarks and charged leptons) in the framework of large volume string compactifications. In particular, we consider the sparticle spectra which can be generated by wrapping D-branes at different dimensions around a compactification of the large volume string. We find that a significant number of sparticles can be generated, and their masses can be as small as the tree level masses of the standard model quarks and charged leptons. In addition, we find that the produced sparticles can be grouped into several generations, and that the number of generations can be as large as three. We also discuss the production mechanism of the sparticles, and find that the large volume string has the potential to produce sparticles in a large mass range, and in large numbers. Furthermore, we discuss the LHC signatures for the large volume string compactifications, and find that the LHC can potentially see the signatures for a large volume string which is wrapped around a compactification of large radius.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological Constraints on f(R) Acceleration Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2399, "human_text": "  Models which accelerate the expansion of the universe through the addition of a function of the Ricci scalar f(R) leave a characteristic signature in the large-scale structure of the universe at the Compton wavelength scale of the extra scalar degree of freedom. We search for such a signature in current cosmological data sets: the WMAP cosmic microwave background (CMB) power spectrum, SNLS supernovae distance measures, the SDSS luminous red galaxy power spectrum, and galaxy-CMB angular correlations. Due to theoretical uncertainties in the nonlinear evolution of f(R) models, the galaxy power spectrum conservatively yields only weak constraints on the models despite the strong predicted signature in the linear matter power spectrum. Currently the tightest constraints involve the modification to the integrated Sachs-Wolfe effect from growth of gravitational potentials during the acceleration epoch. This effect is manifest for large Compton wavelengths in enhanced low multipole power in the CMB and anti-correlation between the CMB and tracers of the potential. They place a bound on the Compton wavelength of the field be less than of order the Hubble scale. ", "machine_text": " We consider the constraints that the latest cosmological observations place on f(R) models, which are scalar fields theories with a variable equation of state (f(R) = the function that relates the scalar field variable R to its potential). We show that a f(R) model with a variable equation of state can successfully describe the recent observations, provided that the variable equation of state is very close to a cosmological constant. We consider a possible physical explanation for this result, by analogy with the recently proposed \u2018hypertensor\u2019 model. We also point out that a variable equation of state with a small parameter that is not close to a cosmological constant can successfully describe the recent observations, provided that the parameter is dynamically controlled by the evolution of the Universe. This can be achieved by adding a variable cosmological constant to a model with a variable equation of state, so that the total equation of state is the sum of the two contributions, provided that the cosmological constant contribution is dynamically controlled by the evolution of the Universe. We show that a simple model in which the cosmological constant is related to the variable equation of state by a non-trivial power law can successfully describe the recent observations, provided that the power law parameter is dynamically controlled by the evolution of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: How to clean a dirty floor: Probabilistic potential theory and the\n  Dobrushin uniqueness theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3156, "human_text": "  Motivated by the Dobrushin uniqueness theorem in statistical mechanics, we consider the following situation: Let \\alpha be a nonnegative matrix over a finite or countably infinite index set X, and define the \"cleaning operators\" \\beta_h = I_{1-h} + I_h \\alpha for h: X \\to [0,1] (here I_f denotes the diagonal matrix with entries f). We ask: For which \"cleaning sequences\" h_1, h_2, ... do we have c \\beta_{h_1} ... \\beta_{h_n} \\to 0 for a suitable class of \"dirt vectors\" c? We show, under a modest condition on \\alpha, that this occurs whenever \\sum_i h_i = \\infty everywhere on X. More generally, we analyze the cleaning of subsets \\Lambda \\subseteq X and the final distribution of dirt on the complement of \\Lambda. We show that when supp(h_i) \\subseteq \\Lambda with \\sum_i h_i = \\infty everywhere on \\Lambda, the operators \\beta_{h_1} ... \\beta_{h_n} converge as n \\to \\infty to the \"balayage operator\" \\Pi_\\Lambda = \\sum_{k=0}^\\infty (I_\\Lambda \\alpha)^k I_{\\Lambda^c). These results are obtained in two ways: by a fairly simple matrix formalism, and by a more powerful tree formalism that corresponds to working with formal power series in which the matrix elements of \\alpha are treated as noncommuting indeterminates. ", "machine_text": "  We consider the problem of how to clean a dirty floor in a room with two entrances. We suppose that the dirt on the floor is distributed according to a given probability measure and that the cleaner has two strategies available: a standard strategy, which is a fixed procedure that always cleans the floor in the same way, and a random strategy, which chooses a random path over the floor and thus has the potential to be more efficient in principle. We investigate the behavior of the random strategy as the dirt on the floor becomes more concentrated, that is, as the potential function becomes more non-null. We show that the random strategy converges to the standard strategy as the potential function goes to infinity. This convergence is guaranteed by a uniqueness theorem due to Dobrushin. We derive an approximation theorem that relates the random strategy to a finite number of non-overlapping regions of the floor, and thus to the kind of random walk that is known as a random walk on a lattice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory for superconductivity in a magnetic field: A local approximation\n  approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2394, "human_text": "  We present a microscopic theory for superconductivity in a magnetic field based on a local approximation approach. We derive an expression for free energy density $F$ as a function of temperature $T$ and vector potential {\\bf a}, and two basic equations of the theory: the first is an implicit solution for energy gap parameter amplitude $|\\Delta_{\\bf k}|$ as a function of wave vector {\\bf k}, temperature $T$ and vector potential {\\bf a}; and the second is a London-like relation between electrical current density {\\bf j} and vector potential {\\bf a}, with an ``effective superconducting electron density'' $n_s$ that is both $T$- and {\\bf a}-dependent. The two equations allow determination of spatial variations of {\\bf a} and $|\\Delta_{\\bf k}|$ in a superconductor for given temperature $T$, applied magnetic field ${\\bf H}_a$ and sample geometry. The theory shows the existence of a ``partly-paired state,'' in which paired electrons (having $|\\Delta_{\\bf k}|>0$) and de-paired electrons (having $|\\Delta_{\\bf k}|=0$) co-exist. Such a ``partly-paired state'' exists even at T=0 when $H_a$ is above a threshold for a given sample, giving rise to a non-vanishing Knight shift at T=0 for $H_a$ above the threshold. We expect the theory to be valid for highly-local superconductors for all temperatures and magnetic fields below the superconducting transition. In the low-field limit, the theory reduces to the local-limit result of BCS. As examples, we apply the theory to the case of a semi-infinite superconductor in an applied magnetic field ${\\bf H}_a$ parallel to the surface of the superconductor and the case of an isolated vortex in an infinite superconductor, and determine, in each case, spatial variations of quantities such as {\\bf a} and $|\\Delta_{\\bf k}|$. We also calculate... ", "machine_text": " We propose a theory for superconductivity in a magnetic field based on a local approximation approach. Our theory accounts for the anisotropic nature of the superconducting order parameter, the fact that the superconductivity is strongly coupled to the magnetic field, and the energy scales of the problem. Within our framework, superconductivity in a magnetic field is regarded as a competition between anisotropic superconductivity and magnetic order. We determine the minimal anisotropic order parameter and the corresponding symmetry of the superconducting order parameter. Our theory predicts a transition temperature T_c^{*} below which the system is in the normal conducting state with a minimal superconducting order parameter of vanishing magnitude. We also derive a simplified model in which the anisotropic order parameter is replaced by a isotropic one. The predictions of this model are in good agreement with the experimental results for the system with the anisotropic order parameter in a strong magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new comprehensive set of elemental abundances in DLAs III. Star\n  formation histories. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.165, "human_text": "  We obtained comprehensive sets of elemental abundances for eleven damped Ly-alpha systems (DLAs) at z_DLA=1.7-2.5. In Paper I of this series, we showed for three DLA galaxies that we can derive their star formation histories and ages from a detailed comparison of their intrinsic abundance patterns with chemical evolution models. We determine in this paper the star formation properties of six additional DLA galaxies. The derived results confirm that no single star formation history explains the diverse sets of abundance patterns in DLAs. We demonstrate that the various star formation histories reproducing the DLA abundance patterns are typical of local irregular, dwarf starburst and quiescent spiral galaxies. Independent of the star formation history, the DLAs have a common characteristic of being weak star forming galaxies; models with high star formation efficiencies are ruled out. All the derived DLA star formation rates per unit area are moderate or low, with values between -3.2 < log SFR < -1.1 M_sol yr^{-1} kpc^{-2}. The DLA abundance patterns require a large spread in ages ranging from 20 Myr up to 3 Gyr. The oldest DLA in our sample is observed at z_DLA=1.864 with an age estimated to more than 3 Gyr; it nicely indicates that galaxies were already forming at z_f>10. But, most of the DLAs show ages much younger than that of the Universe at the epoch of observation. Young galaxies thus seem to populate the high redshift Universe at z>2, suggesting relatively low redshifts of formation (z~3) for most high-redshift galaxies. The DLA star formation properties are compared with those of other high-redshift galaxies identified in deep imaging surveys with the aim of obtaining a global picture of high-redshift objects. ", "machine_text": " We present a new comprehensive set of elemental abundances in dwarf late-type stars (DLAs) from high-resolution, high signal-to-noise ratio echelle spectroscopy of a carefully selected sample of 98 DLAs with solar metallicity. We have derived abundances for 31 chemical elements (Na, Mg, Al, Si, K, Ca, Sc, Ti, V, Cr, Mn, Fe, Co, Ni, Cu, Zn, Ga, In, Sn, Pb, Bi, Ce, La, Pr, Nd, Pm, Sm, Eu, Gd, Tb, Dy, Ho, Er, Tm, Yb, Lu) including the elements from hydrogen to nickel, which have not been reported in the literature for this kind of object. The internal consistency of the set of abundances is very good. We have used the new abundances to derive the star formation history (SFH) of the galactic disk. Our results are consistent with a single-zone model for the SFH with a constant star formation rate (SFR) of 2.5 \u00b1 0.2 M\u2299 yr-1. We have also derived a correlation between the space velocity and the metal content of the stars, which can be used to select stars with a large range of metallicities in order to study the variations of the SFH.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Communication Model for Adaptive Service Provisioning in Hybrid\n  Wireless Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.113, "human_text": "  Mobile entities with wireless links are able to form a mobile ad-hoc network. Such an infrastructureless network does not have to be administrated. However, self-organizing principles have to be applied to deal with upcoming problems, e.g. information dissemination. These kinds of problems are not easy to tackle, requiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks is arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could eliminate the need for any fixed infrastructure, has been damped. The goal is to overcome the limitations of pure ad-hoc networks by augmenting them with instant Internet access, e.g. via integration of UMTS respectively GSM links. However, this raises multiple questions at the technical as well as the organizational level. Motivated by characteristics of small-world networks that describe an efficient network even without central or organized design, this paper proposes to combine mobile ad-hoc networks and infrastructured networks to form hybrid wireless networks. One main objective is to investigate how this approach can reduce the costs of a permanent backbone link and providing in the same way the benefits of useful information from Internet connectivity or service providers. For the purpose of bridging between the different types of networks, an adequate middleware service is the focus of our investigation. This paper shows our first steps forward to this middleware by introducing the Injection Communication paradigm as principal concept. ", "machine_text": " We propose a communication model for adaptive service provisioning in hybrid wireless networks. Our model is motivated by the observation that, despite the significant advances in wireless communications, the provisioning of high-quality services over wireless networks remains a challenge. In particular, we focus on scenarios where a service provider has to offer services to users with heterogeneous wireless communication capabilities. Our model enables the service provider to efficiently allocate network resources among users with different capabilities, while maximizing the overall service quality perceived by all users. The model is based on a stochastic reward model, which takes into account the service quality perceived by each user and the wireless communication capabilities of each user. We show that the proposed model is equivalent to a stochastic game, where the service provider and the users are the players. We analyze the game and propose a solution, which results in a system of stochastic differential equations. We show that this system of equations has a unique solution, which corresponds to the optimal allocation of network resources among the users. Finally, we validate our results through simulations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Markovian entanglement dynamics of quantum continuous variable\n  systems in thermal environments. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0996, "human_text": "  We study two continuous variable systems (or two harmonic oscillators) and investigate their entanglement evolution under the influence of non-Markovian thermal environments. The continuous variable systems could be two modes of electromagnetic fields or two nanomechanical oscillators in the quantum domain. We use quantum open system method to derive the non-Markovian master equations of the reduced density matrix for two different but related models of the continuous variable systems. The two models both consist of two interacting harmonic oscillators. In model A, each of the two oscillators is coupled to its own independent thermal reservoir, while in model B the two oscillators are coupled to a common reservoir. To quantify the degrees of entanglement for the bipartite continuous variable systems in Gaussian states, logarithmic negativity is used. We find that the dynamics of the quantum entanglement is sensitive to the initial states, the oscillator-oscillator interaction, the oscillator-environment interaction and the coupling to a common bath or to different, independent baths. ", "machine_text": " We study non-Markovian entanglement dynamics of quantum continuous variable systems in thermal environments. We show that thermal noise can have a significant impact on the entanglement dynamics, in particular the entanglement per time evolution, in spite of the fact that it does not change the average entanglement. Our results indicate that a careful account of the non-Markovian dynamics is essential for a complete description of the effects of the environment on entanglement. We also analyze the time-evolution of the tomahawk state, a special state which is robust against thermal noise, and show that it does not evolve according to the usual Markovian dynamics. Finally, we show that the two-time-slot squeezed-statetomahawk-state transformation, recently proposed as a practical scheme for transforming a squeezed state into a tomahawk state, is in fact non-Markovian. Our results have important practical implications for the realization of quantum continuous variable systems in thermal environments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of the spin polarization of the magnetic semiconductor EuS\n  with zero-field and Zeeman-split Andreev reflection spectroscopy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1582, "human_text": "  We report measurements of the spin polarization (\\textbf{\\textit{P}}) of the concentrated magnetic semiconductor EuS using both zero-field and Zeeman-split Andreev reflection spectroscopy (ARS) with EuS/Al planar junctions. The zero-field ARS spectra are well described by the modified (spin-polarized) BTK model with expected superconducting energy gap and actual measurement temperature (no additional spectral broadening). The fittings consistently yield \\textbf{\\textit{P}} close to 80% regardless of the barrier strength. Moreover, we performed ARS in the presence of a Zeeman-splitting of the quasiparticle density of states in Al. To describe the Zeeman-split ARS spectra, we develop a theoretical model which incorporates the solution to the Maki-Fulde equations into the modified BTK analysis. The method enables the determination of the magnitude as well as the sign of \\textbf{\\textit{P}} with ARS, and the results are consistent with those from the zero-field ARS. The experiments extend the utility of field-split superconducting spectroscopy from tunnel junctions to Andreev junctions of arbitrary barrier strengths. ", "machine_text": " We present the results of a zero-field and Zeeman-split Andreev reflection spectroscopy study of the spin-dependent transport in single crystals of the magnetic semiconductor EuS. We show that the spin-dependent transport can be explained in terms of a simple model which comprises a non-hysteretic spin-dependent Mott variable range hopping and a uniform spin-dependent Anderson delocalization of the transport across the entire energy spectrum. We show that by using the technique of Andreev reflection spectroscopy we can access the spin-dependent transport in a clean way, without any contribution from the non-Mott variable range hopping. Our results show that the spin-dependent transport in EuS is sensitive to an external magnetic field in a way that is consistent with the predictions of the model. We also found a non-monotonic behavior of the spin-dependent conductivity as a function of the magnetic field, which we explain in terms of a competition between the variable range hopping and the delocalization. Our results are consistent with the idea that the variable range hopping is the relevant mechanism for the transport in the entire magnetic field range, except for the very small magnetic fields, where the Anderson delocalization plays a more important role.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Type D Einstein spacetimes in higher dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0435, "human_text": "  We show that all static spacetimes in higher dimensions are of Weyl types G, I_i, D or O. This applies also to stationary spacetimes if additional conditions are fulfilled, as for most known black hole/ring solutions. (The conclusions change when the Killing generator becomes null, such as at Killing horizons.) Next we demonstrate that the same Weyl types characterize warped product spacetimes with a one-dimensional Lorentzian (timelike) factor, whereas warped spacetimes with a two-dimensional Lorentzian factor are restricted to the types D or O. By exploring the Bianchi identities, we then analyze the simplest non-trivial case from the above classes - type D vacuum spacetimes, possibly with a cosmological constant, dropping, however, the assumptions that the spacetime is static, stationary or warped. It is shown that for ``generic'' type D vacuum spacetimes the corresponding principal null directions are geodetic in any dimension (this applies also to type II spacetimes). For n>=5, however, there may exist particular cases of type D spacetimes which admit non-geodetic multiple principal null directions and we present such examples in any n>=7. Further studies are restricted to five dimensions, where the type D Weyl tensor is described by a 3x3 matrix \\Phi_{ij}. In the case with ``twistfree'' (A_{ij}=0) principal null geodesics we show that in a ``generic'' case \\Phi_{ij} is symmetric and eigenvectors of \\Phi_{ij} coincide with those of the expansion matrix S_{ij}, providing us with three preferred spacelike directions of the spacetime. Similar results are also obtained when relaxing the twistfree condition and assuming instead that \\Phi_{ij} is symmetric. The n=5 Myers-Perry black hole and Kerr-NUT-AdS metrics in arbitrary dimension are briefly studied as specific examples of type D vacuum spacetime. ", "machine_text": "  We study type D Einstein spacetimes in higher dimensions. We show that such spacetimes can be fully described by a restricted set of solutions of the Einstein field equations which we call basic solutions. This description can be used to give a simple and elegant derivation and formulation of the type D Einstein spacetime in any dimension greater than two. We also show that, if the principal null directions are arranged in a certain way, the type D Einstein spacetime in higher dimensions can be made to have a simple structure in which the spacetime can be expressed as a special type of curved spacetime in a lower dimension. We show that this special structure is related to the principal null directions in a way which allows the type D Einstein spacetime to be understood as a special type of anti-de Sitter spacetime. We show that the de Sitter spacetime can be obtained as a special limiting case of this type D Einstein spacetime in higher dimensions. The results of this paper have been published in the companion paper 'Basic solutions for type D Einstein spacetimes in higher dimensions'.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: G-convergence and homogenization of viscoelastic flows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1088, "human_text": "  The paper is devoted to homogenization of two-phase incompressible viscoelastic flows with disordered microstructure. We study two cases. In the first case, both phases are modeled as Kelvin-Voight viscoelastic materials. In the second case, one phase is a Kelvin-Voight material, and the other is a viscous Newtonian fluid. The microscale system contains the conservation of mass and balance of momentum equations. The inertial terms in the momentum equation incorporate the actual interface advected by the flow. In the constitutive equations, a frozen interface is employed. The interface geometry is arbitrary: we do not assume periodicity, statistical homogeneity or scale separation. The problem is homogenized using G-convergence and oscillating test functions. Since the microscale system is not parabolic, previously known constructions of the test functions do not work here. The test functions developed in the paper are non-local in time and satisfy divergence-free constraint exactly. The latter feature enables us to avoid working with pressure directly. We show that the effective medium is a single phase viscoelastic material that is not necessarily of Kelvin-Voight type. The effective constitutive equation contains a long memory viscoelastic term, as well as instantaneous elastic and viscous terms. ", "machine_text": "  We study the large-scale behavior of viscoelastic flows in simple geometries. We show that a flow in a long cylindrical tube will display super-diffusive behavior, with a coefficient of diffusion that decreases with the reciprocal of the Deborah number. We show that this is due to the combined effects of shear and extension on the flow, and that the super-diffusive exponent depends on the physical properties of the fluid, in particular on the ratio of the shear and extension viscosity. In the limit of a large Deborah number, the flow develops a solid-like behavior, with a strain-rate dependent viscosity, and a dilatancy that depends on the sign of the shear modulus. The spatial structure of the flow is governed by the evolution of a Deborah number field, which is shown to be related to the large-scale structure of the flow through an extra stress-strain relation. In addition, the local structure of the flow is described by a decomposition in elementary volume elements, which evolve according to a local dynamics that depends on the Deborah number field. We also discuss the case of a viscoelastic flow in a planar geometry, for which we show that the large-scale structure is described by a vectorial diffusion equation, with a non-monotonic dependence of the diffusion coefficient on the Deborah number.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: La controverse de 1874 entre Camille Jordan et Leopold Kronecker. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2929, "human_text": "  During the whole of 1874, Camille Jordan and Leopold Kronecker quar- relled vigorously over the organisation of the theory of bilinear forms. That theory promised a \"general\" and \"homogeneous\" treatment of numerous questions arising in various 19th-century theoretical contexts, and it hinged on two theorems, stated independently by Jordan and Weierstrass, that would today be considered equivalent. It was, however, the perceived difference between those two theorems that sparked the 1874 controversy. Focusing on this quarrel allows us to explore the algebraic identity of the polynomial practices of the manipulations of forms in use before the advent of structural approaches to linear algebra. The latter approaches identified these practices with methods for the classification of similar matrices. We show that the prac- tices -- Jordan's canonical reduction and Kronecker's invariant computation -- reflect identities inseparable from the social context of the time. Moreover, these practices reveal not only tacit knowledge, local ways of thinking, but also -- in light of a long history tracing back to the work of Lagrange, Laplace, Cau- chy, and Hermite -- two internal philosophies regarding the significance of generality which are inseparable from two disciplinary ideals opposing algebra and arithmetic. By interrogating the cultural identities of such practices, this study aims at a deeper understanding of the history of linear algebra without focusing on issues related to the origins of theories or structures. ", "machine_text": "  The year is 1874. The place is the Office of the Director of the School of Mathematics in Paris. The controversial issue is the teaching of gymnastics. The two protagonists are Camille Jordan, the Director, and Leopold Kronecker, his deputy. The occasion is a memoir submitted by a former student of the School. The document is entitled \"Reflections on the Influence of Gymnastics on the Development of the Body and the Will.\" The student's name is \u00c9mile Cividale. The issue is the advisability of including in the School's curriculum a course in gymnastics.  Camille Jordan is the guardian of the tradition of the \"old school,\" which holds that mathematics is a \"matter of intelligence\" and that gymnastics is a \"matter of will.\" In a draft of a letter to Cividale, Jordan writes: \"I see in it [i.e., in gymnastics] a waste of time, and even a danger for the health of our students.\" His preferred course of action is to \"condemn the practice of gymnastics in our school.\"  In contrast, Leopold Kronecker is a strong advocate of gymnastics. In his eyes, it is essential to the well-being of the students. In a draft of a letter to Cividale, Kronecker writes: \"I support the initiative of those who wish to teach gymnastics to our students, and I will do all in my power to see that this initiative bears fruit.\"  The debate goes on for several weeks. The two mathematicians exchange a stream of letters, each one answering the other's arguments. Their personalities clash. The issue becomes one of who is to prevail, Jordan or Kronecker. The outcome is that Kronecker prevails. Mathematics is not to be separated from gymnastics. The teaching of gymnastics is to be given a place in the School's curriculum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Determination of the Far-Infrared Cosmic Background Using COBE/DIRBE and\n  WHAM Data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3966, "human_text": "  Determination of the cosmic infrared background (CIB) at far infrared wavelengths using COBE/DIRBE data is limited by the accuracy to which foreground interplanetary and Galactic dust emission can be modeled and subtracted. Previous determinations of the far infrared CIB (e.g., Hauser et al. 1998) were based on the detection of residual isotropic emission in skymaps from which the emission from interplanetary dust and the neutral interstellar medium were removed. In this paper we use the Wisconsin H-alpha Mapper (WHAM) Northern Sky Survey as a tracer of the ionized medium to examine the effect of this foreground component on determination of the CIB. We decompose the DIRBE far infrared data for five high Galactic latitude regions into H I and H-alpha correlated components and a residual component. We find the H-alpha correlated component to be consistent with zero for each region, and we find that addition of an H-alpha correlated component in modeling the foreground emission has negligible effect on derived CIB results. Our CIB detections and 2 sigma upper limits are essentially the same as those derived by Hauser et al. and are given by nu I_nu (nW m-2 sr-1) < 75, < 32, 25 +- 8, and 13 +- 3 at 60, 100, 140, and 240 microns, respectively. Our residuals have not been subjected to a detailed anisotropy test, so our CIB results do not supersede those of Hauser et al. We derive upper limits on the 100 micron emissivity of the ionized medium that are typically about 40% of the 100 micron emissivity of the neutral atomic medium. This low value may be caused in part by a lower dust-to-gas mass ratio in the ionized medium than in the neutral medium, and in part by a shortcoming of using H-alpha intensity as a tracer of far infrared emission. ", "machine_text": "  We present a far-infrared (IR) background spectrum of the cosmic background radiation (CBR) determined from the COBE/DIRBE data, and a corresponding set of far-IR spectral models. The data set used for the spectrum compilation consists of the latest COBE/DIRBE data, with a total integration time of 564.4 ks, and the WHAM data with an integration time of 105.4 ks. The high sensitivity of the COBE/DIRBE instrument allows us to measure the background in the far-IR region below 8 \u03bcm with a sensitivity of ~5 mK. The spectrum is featureless with a high level of homogeneity, and is in agreement with a blackbody spectrum with a temperature of 37 K. The fitting procedure used to derive the blackbody temperature from the spectrum is described. The main spectral model parameters are the dust temperature, the total optical depth, and the local excess optical depth. The best-fit model to the data has a dust temperature of 36.5 K, a total optical depth of 1.00, and a local excess optical depth of 0.09. We find that the far-IR CBR is well described by a blackbody spectrum.  The COBE/DIRBE far-infrared data set is available at: ftp://icola.harvard.edu/COBE/level5/DIRBE/Data_v5.html. The WHAM data set is available at: ftp://slac.stanford.edu/site/ Terrier/WHAM/", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical non-axisymmetric instabilities in rotating relativistic stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1826, "human_text": "  We present new results on dynamical instabilities in rapidly rotating neutron-stars. In particular, using numerical simulations in full General Relativity, we analyse the effects that the stellar compactness has on the threshold for the onset of the dynamical bar-mode instability, as well as on the appearance of other dynamical instabilities. By using an extrapolation technique developed and tested in our previous study [1], we explicitly determine the threshold for a wide range of compactnesses using four sequences of models of constant baryonic mass comprising a total of 59 stellar models. Our calculation of the threshold is in good agreement with the Newtonian prediction and improves the previous post-Newtonian estimates. In addition, we find that for stars with sufficiently large mass and compactness, the m=3 deformation is the fastest growing one. For all of the models considered, the non-axisymmetric instability is suppressed on a dynamical timescale with an m=1 deformation dominating the final stages of the instability. These results, together with those presented in [1], suggest that an m=1 deformation represents a general and late-time feature of non-axisymmetric dynamical instabilities both in full General Relativity and in Newtonian gravity. ", "machine_text": " We investigate dynamical non-axisymmetric instabilities in rotating relativistic stars. We show that the mirror symmetry of the equilibrium solution breaks down when the star is rotating fast enough, leading to the formation of a `twist'-related instability. This instability is associated with a pair of new vortices, which arise in the high-frequency limit of the solution. We show that this instability is always active when the angular velocity is larger than a certain threshold, which depends on the degree of anisotropy and the angular momentum per unit mass. We observe that the threshold is relatively low, so that this instability may be active in many real stars. We analyse the linear stability of this new instability, and show that it is stable against perturbations that are small in the angular-velocity space. Therefore, this new instability does not grow, but it may trigger other dynamical instabilities that are active in the slowly rotating regime. We find that this new instability is stable against a change in the degree of anisotropy, but it becomes unstable when the anisotropy is increased beyond a certain threshold. This implies that this instability may be active in many different systems, provided that the symmetry of the problem is broken in a relatively mild way. We also show that this instability is related to the previously discovered `utchin' instability, but the two instabilities are different in a number of ways. Our results imply that this new instability may be important in the dynamics of rotating relativistic stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sensitivity of solar off-limb line profiles to electron density\n  stratification and the velocity distribution anisotropy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1127, "human_text": "  The effect of the electron density stratification on the intensity profiles of the H I Ly-$\\alpha$ line and the O VI and Mg X doublets formed in solar coronal holes is investigated. We employ an analytical 2-D model of the large scale coronal magnetic field that provides a good representation of the corona at the minimum of solar activity. We use the mass-flux conservation equation to determine the outflow speed of the solar wind at any location in the solar corona and take into account the integration along the line of sight (LOS). The main assumption we make is that no anisotropy in the kinetic temperature of the coronal species is considered. We find that at distances greater than 1 Rsun from the solar surface the widths of the emitted lines of O VI and Mg X are sensitive to the details of the adopted electron density stratification. However, Ly-$\\alpha$, which is a pure radiative line, is hardly affected. The calculated total intensities of Ly-$\\alpha$ and the O VI doublet depend to a lesser degree on the density stratification and are comparable to the observed ones for most of the considered density models. The widths of the observed profiles of Ly-$\\alpha$ and Mg X are well reproduced by most of the considered electron density stratifications, while for the O VI doublet only few stratifications give satisfying results. The densities deduced from SOHO data result in O VI profiles whose widths and intensity ratio are relatively close to the values observed by UVCS although only isotropic velocity distributions are employed. These density profiles also reproduce the other considered observables with good accuracy. Thus the need for a strong anisotropy of the velocity distribution (i.e. a temperature anisotropy) is not so clear cut as previous investigations of UVCS data suggested. ... ", "machine_text": " We present a method to probe the electron density distribution in the solar corona using the off-limb observation of the solar photosphere. We utilize the fact that the sensitivity of the shape of the solar off-limb line profiles to the variation of the electron density distribution is different in the direction parallel and perpendicular to the solar limbs. Our method is based on the assumption that the off-limb line profile is insensitive to the variation of the electron density in the direction parallel to the solar limbs, while it is sensitive to the variation of the electron density in the direction perpendicular to the solar limbs. The assumption is valid if the electron density distribution is isotropic along the line of sight and if the effect of the temperature distribution along the line of sight is negligible. We show that the off-limb line profile can be used to probe the electron density distribution in the direction perpendicular to the solar limbs if the angle between the electron density gradient and the line of sight is known. We show that the off-limb line profile can be used to constrain the structure of the electron density distribution in the corona if the distribution is stratified along the line of sight. We discuss the implications of our results for the measurement of the solar electron density distribution with off-limb observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal Stability of Metallic Single-Walled Carbon Nanotubes: An O(N)\n  Tight-Binding Molecular Dynamics Simulation Study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1625, "human_text": "  Order(N) Tight-Binding Molecular Dynamics (TBMD) simulations are performed to investigate the thermal stability of (10,10) metallic Single-Walled Carbon Nanotubes (SWCNT). Periodic boundary conditions (PBC) are applied in axial direction. Velocity Verlet algorithm along with the canonical ensemble molecular dynamics (NVT) is used to simulate the tubes at the targeted temperatures. The effects of slow and rapid temperature increases on the physical characteristics, structural stability and the energetics of the tube are investigated and compared. Simulations are carried out starting from room temperature and the temperature is raised in steps of 300K. Stability of the simulated metallic SWCNT is examined at each step before it is heated to higher temperatures. First indication of structural deformation is observed at 600K. For higher heat treatments the deformations are more pronounced and the bond breaking temperature is reached around 2500K. Gradual (slow) heating and thermal equilibrium (fast heating) methods give the value of radial thermal expansion coefficient in the temperature range between 300K-600K as 0.31x10^{-5}(1/K) and 0.089x10^{-5}(1/K), respectively. After 600K, both methods give the same value of 0.089x10^{-5}(1/K). The ratio of the total energy per atom with respect to temperature is found to be 3x10^{-4} eV/K. ", "machine_text": "  We present a first-principles-based tight-binding molecular dynamics (TB-MD) study of the thermodynamic stability of metallic single-walled carbon nanotubes (SWCNTs) with a random number of vacancies, i.e., holes, along their circumference. We consider a large number of randomly generated SWCNTs with up to N = 10 vacancies, and determine their respective stabilities by computing the total energy of each system. We find that the number of stable SWCNTs drops sharply as the number of vacancies increases. Our results agree with previous empirical findings, and suggest that the number of stable SWCNTs decreases exponentially as a function of the number of vacancies. The largest number of vacancies for which we find a stable SWCNT is N = 4. We also investigate the effect of a given vacancy on the stability of the SWCNTs, and find that the presence of a vacancy greatly decreases the stability of the SWCNTs. Our findings are consistent with the idea that vacancies in SWCNTs weaken their structural integrity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structural relaxation around substitutional Cr3+ in MgAl2O4. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0878, "human_text": "  The structural environment of substitutional Cr3+ ion in MgAl2O4 spinel has been investigated by Cr K-edge Extended X-ray Absorption Fine Structure (EXAFS) and X-ray Absorption Near Edge Structure (XANES) spectroscopies. First-principles computations of the structural relaxation and of the XANES spectrum have been performed, with a good agreement to the experiment. The Cr-O distance is close to that in MgCr2O4, indicating a full relaxation of the first neighbors, and the second shell of Al atoms relaxes partially. These observations demonstrate that Vegard's law is not obeyed in the MgAl2O4-MgCr2O4 solid solution. Despite some angular site distortion, the local D3d symmetry of the B-site of the spinel structure is retained during the substitution of Cr for Al. Here, we show that the relaxation is accomodated by strain-induced bond buckling, with angular tilts of the Mg-centred tetrahedra around the Cr-centred octahedron. By contrast, there is no significant alteration of the angles between the edge-sharing octahedra, which build chains aligned along the three four-fold axes of the cubic structure. ", "machine_text": "  We have performed an atomistic study of structural relaxation around substitutional Cr3+ in MgAl2O4. The electronic structure of Cr3+ in the Mg-rich regions was calculated by density-functional theory, and the resulting orbitals were used to calculate the formation energies of Cr3+ in the various possible sites in MgAl2O4. The results of this calculation were used as input to a subsequent molecular dynamics simulation of structural relaxation, in which the atomic positions of the substitutional Cr3+ were allowed to relax in response to the electrostatic and steric interactions with their surroundings. The final atomic positions were used to calculate the binding energy of Cr3+, which was then compared to the formation energy to determine the degree of structural relaxation that had occurred. We found that the Cr3+ ions were able to achieve a high degree of structural relaxation, with the average binding energy being only slightly higher than the formation energy. This indicates that the Cr3+ ions are well-packed and have a stable structure within the MgAl2O4 matrix.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Charge Ordering in Half-Doped Manganites: Weak Charge Disproportion and\n  Leading Mechanisms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1834, "human_text": "  The apparent contradiction between the recently observed weak charge disproportion and the traditional Mn$^{3+}$/Mn$^{4+}$ picture of the charge-orbital orders in half-doped manganites is resolved by a novel Wannier states analysis of the LDA$+U$ electronic structure. Strong electron itinerancy in this charge-transfer system significantly delocalizes the occupied low-energy \"Mn$^{3+}$\" Wannier states such that charge leaks into the \"Mn$^{4+}$\"-sites. Furthermore, the leading mechanisms of the charge order are quantified via our first-principles derivation of the low-energy effective Hamiltonian. The electron-electron interaction is found to play a role as important as the electron-lattice interaction. \\ignore{A general picture of doped holes in strongly correlated charge-transfer systems is presented and applied to the study of charge order in half-doped manganites, using a novel Wannier states analysis of the LDA$+U$ electronic structure. While residing primarily in the oxygen atoms, the doped holes form additional effective $e_g$ orbitals at the low-energy scale, leading to an effective Mn$^{3+}$/Mn$^{4+}$ valence picture that enables weak charge disproportion, resolving the current serious contradictions between the recent experimental observations of charge distribution and traditional models. Furthermore, the leading mechanisms of the observed charge order are quantified via our first-principles derivation of the low-energy effective Hamiltonian ", "machine_text": " We have performed a systematic study of the evolution of charge ordering and magnetic phase diagram in  half-doped manganites with a low Curie temperature by varying the manganese concentration. Our results show that a substantial charge ordering instability region exists in these manganites, and the ordering is always anti-phase to the magnetic ordering. We have discovered a novel charge ordering state in a low magnetic field, in which the charge disproportion is very weak and the charge transfer is nearly local, in a mechanism we call charge ordering by spin-dependent localization (CSBL). Our results reveal that CSBL is the leading charge ordering mechanism in these manganites, and the weak charge disproportion in this state results from the competition between charge ordering and spin ordering. We also found that the non-magnetic charge ordering state can be stabilized by a large magnetic field, and the resulting charge disproportion is enhanced by the spin-orbital coupling in the magnetic state. Our results provide a novel platform for the study of charge ordering and spin-orbital coupling in metallic manganites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new Generation of Spectrometer Calibration Techniques based on Optical\n  Frequency Combs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0763, "human_text": "  Typical astronomical spectrographs have a resolution ranging between a few hundred to 200.000. Deconvolution and correlation techniques are being employed with a significance down to 1/1000 th of a pixel. HeAr and ThAr lamps are usually used for calibration in low and high resolution spectroscopy, respectively. Unfortunately, the emitted lines typically cover only a small fraction of the spectrometer's spectral range. Furthermore, their exact position depends strongly on environmental conditions. A problem is the strong intensity variation between different (intensity ratios {>300). In addition, the brightness of the lamps is insufficient to illuminate a spectrograph via an integrating sphere, which in turn is important to calibrate a long-slit spectrograph, as this is the only way to assure a uniform illumination of the spectrograph pupil.   Laboratory precision laser spectroscopy has experienced a major advance with the development of optical frequency combs generated by pulsed femto-second lasers. These lasers emit a broad spectrum (several hundred nanometers in the visible and near infra-red) of equally-spaced \"comb\" lines with almost uniform intensity (intensity ratios typically <10). Self-referencing of the laser establishes a precise ruler in frequency space that can be stabilized to the 10e-18 uncertainty level, reaching absolute frequency inaccuracies at the 10e-12 level per day when using the Global Positioning System's (GPS) time signal as the reference. The exploration of the merits of this new technology holds the promise for broad-band, highly accurate and reproducible calibration required for reliable operation of current and next generation astronomic spectrometers. ", "machine_text": "  A new Generation of Spectrometer Calibration Techniques based on Optical Frequency Combs  Spectrometry is a powerful and widely used analytical tool in many scientific disciplines for the precise determination of the spectral distribution of a signal. In recent years, the requirements on the spectral resolution of spectrometers have increased tremendously, reaching the sub-femtosecond domain for some applications. To achieve this, the use of optical frequency combs has been proposed and demonstrated. However, the practical implementation of the method is not straightforward, as it requires a precise knowledge of the spectral properties of the optical frequency comb. In this article, we review and discuss recent progress in the field of optical frequency comb-based spectrometer calibration. In particular, we focus on the techniques that have been developed to determine the spectral envelope of the optical frequency comb, which is a key parameter for the correct interpretation of the experimental data. We also discuss the problem of the frequency stability of the optical frequency comb and the techniques that have been developed to stabilize it. Finally, we present a brief overview of the current state-of-the-art of optical frequency comb-based spectrometry and highlight open questions and future research directions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Intrinsically X-ray Weak Quasar PHL 1811. II. Optical and UV Spectra\n  and Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.094, "human_text": "  This is the second of two papers reporting observations and analysis of the unusually bright (m_b=14.4), luminous (M_B=-25.5), nearby (z=0.192) narrow-line quasar PHL 1811. The first paper reported that PHL 1811 is intrinsically X-ray weak, and presented a spectral energy distribution (SED). Here we present HST STIS optical and UV spectra, and ground-based optical spectra. The optical and UV line emission is very unusual. There is no evidence for forbidden or semiforbidden lines. The near-UV spectrum is dominated by very strong FeII and FeIII, and unusual low-ionization lines such as NaID and CaII H&K are observed. High-ionization lines are very weak; CIV has an equivalent width of 6.6A, a factor of ~5 smaller than measured from quasar composite spectra. An unusual feature near 1200A can be deblended in terms of Ly\\alpha, NV, SiII, and CIII* using the blueshifted CIV profile as a template. Photoionization modeling shows that the unusual line emission can be explained qualitatively by the unusually soft SED. Principally, a low gas temperature results in inefficient emission of collisionally excited lines, including the semiforbidden lines generally used as density diagnostics. The emission resembles that of high-density gas; in both cases this is a consequence of inefficient cooling. PHL 1811 is very unusual, but we note that quasar surveys are generally biased against finding similar objects. ", "machine_text": " We present an analysis of the optical and UV spectra of the intrinsically X-ray weak quasar PHL 1811. The optical spectrum is very blue with a high continuum luminosity, which is typical of a quasar in the initial phase of accretion outbursts. A 1-yr continuum variability monitoring shows that the quasar varies by a factor of ~3 in optical luminosity on timescales of days. We have detected an accretion episode in January 2006, when the continuum emission increased by a factor of ~3 in 2 months. The UV continuum is an order of magnitude fainter than the optical continuum, and it is heavily absorbed by the dust clouds in the quasar's host galaxy. We have derived the mean molecular weight of the gas in the accretion region to be 44.4 \u00b1 2.0 atomic units. A 1-yr monitoring of the CO absorption lines in the quasar's host galaxy shows that the molecular gas kinematics is very chaotic and may be driven by the quasar's outbursts. We also present an analysis of the chemical composition of the gas in the accretion region. The gas is relatively rich in carbon and deficient in hydrogen and helium, which is consistent with the gas being accreted from the quasar's host galaxy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Rich methane premixed laminar flames doped by light unsaturated\n  hydrocarbons - Part I : allene and propyne. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0375, "human_text": "  The structure of three laminar premixed rich flames has been investigated: a pure methane flame and two methane flames doped by allene and propyne, respectively. The gases of the three flames contain 20.9% (molar) of methane and 33.4% of oxygen, corresponding to an equivalence ratio of 1.25 for the pure methane flame. In both doped flames, 2.49% of C3H4 was added, corresponding to a ratio C3H4/CH4 of 12% and an equivalence ratio of 1.55. The three flames have been stabilized on a burner at a pressure of 6.7 kPa using argon as dilutant, with a gas velocity at the burner of 36 cm/s at 333 K. The concentration profiles of stable species were measured by gas chromatography after sampling with a quartz microprobe. Quantified species included carbon monoxide and dioxide, methane, oxygen, hydrogen, ethane, ethylene, acetylene, propyne, allene, propene, propane, 1,2-butadiene, 1,3-butadiene, 1-butene, isobutene, 1-butyne, vinylacetylene, and benzene. The temperature was measured using a PtRh (6%)-PtRh (30%) thermocouple settled inside the enclosure and ranged from 700 K close to the burner up to 1850 K. In order to model these new results, some improvements have been made to a mechanism previously developed in our laboratory for the reactions of C3-C4 unsaturated hydrocarbons. The main reaction pathways of consumption of allene and propyne and of formation of C6 aromatic species have been derived from flow rate analyses. ", "machine_text": " We have performed a detailed experimental investigation of rich methane premixed laminar flames doped by light unsaturated hydrocarbons - allene and propyne. Two kinds of burners were used: a Reynolds-numbers based burner and a constant-pressure burner. We have measured the extinction limits for these flames in the presence of various hydrocarbon doping concentrations, the flame temperature, and the radical species concentrations. We have found that the extinction limit for these flames is not affected by the doping and is limited by the fuel-to-air ratio. The temperature of the flame core is not affected by the doping, but the temperature of the unburned mixture fraction is significantly decreased. The increase of the radical species concentrations in the burned mixture fraction is not significant. We have found that the consumption of the doping hydrocarbons is relatively fast, the half-time of allene being about 1ms. In the burned mixture fraction the concentrations of 2-hydroxy-2-methyl-2-propanenal (HMPA) and of 3-methyl-2-butanone (MBO) are significantly increased, while the concentrations of peroxy radicals are not affected. We have performed a comparison between these flames and propane-doped methane flames. We have found that the extinction limits of these two kinds of flames are similar, but the flame temperature and the radical species concentrations are different.  We have also performed a comparison between the combustion of these light unsaturated hydrocarbons in air and in methane. We have found that the consumption rates of these hydrocarbons are much higher in methane than in air, the half-times being about 0.1ms and 1s, respectively. We have also found that the concentrations of HMPA and MBO are very similar in both media, while the concentrations of peroxy radicals are much higher in air.  These results are discussed in the framework of the current literature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generalized Brjuno functions associated to $\\alpha$-continued fractions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.169, "human_text": "  For \\alpha in the interval [0,1], we consider the one-parameter family of \\alpha-continued fraction maps, which include the Gauss map (\\alpha=1) and the nearest integer (\\alpha=1/2) and by-excess (\\alpha=0) continued fraction maps. To each of these expansions, and to each choice of a positive function u on the interval I_\\alpha=(0,max(\\alpha,1-\\alpha)) we associate a generalized Brjuno function B_(\\alpha,u)(x). For \\alpha=1/2 or \\alpha=1, and u(x)=-\\log(x), these functions were introduced by Yoccoz in his work on the linearization of holomorphic maps. Their regularity properties, including BMO regularity and their extension to the complex plane, have been thoroughly investigated. We compare the functions obtained with different values of \\alpha and we prove that the set of (\\alpha,u)-Brjuno numbers does not depend on the choice of \\alpha provided that \\alpha>0. We then consider the case \\alpha=0, u(x)=-\\log(x) and we prove that x is a Brjuno number (for \\alpha> 0) if and only if both x and -x are Brjuno numbers for \\alpha=0. ", "machine_text": " We introduce generalized Bruno functions associated to $\\alpha$-continued fractions. These generalized Bruno functions are useful in obtaining a combinatorial interpretation of the $\\alpha$-continued fractions. Further, we show that certain special classes of generalized Bruno functions are related to the $\\alpha$-continued fractions.  The motivation for this work is to provide an combinatorial interpretation of the $\\alpha$-continued fractions which will be useful in attacking the Brun's problem.  The key ideas and methodology used in this work are as follows: we introduce generalized Bruno functions associated to $\\alpha$-continued fractions; these generalized Bruno functions are useful in obtaining a combinatorial interpretation of the $\\alpha$-continued fractions.  The results obtained in this work are as follows: we show that certain special classes of generalized Bruno functions are related to the $\\alpha$-continued fractions.  This work attempts to solve the following problem: given a positive integer $n$, how many partitions of the set $\\{1, 2, \\ldots, n\\}$ with distinct parts does Brun's problem ask us to count? We show that the number of such partitions is equal to the number of $\\alpha$-continued fractions with distinct terms.  This work has practical applications in attacking Brun's problem.  This work has theoretical applications in developing a generalization of Brun's problem to the case of non-distinct parts.  This work suggests future research in the direction of developing a generalization of Brun's problem to the case of non-distinct parts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High Precision CTE-Measurement of SiC-100 for Cryogenic Space-Telescopes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1515, "human_text": "  We present the results of high precision measurements of the thermal expansion of the sintered SiC, SiC-100, intended for use in cryogenic space-telescopes, in which minimization of thermal deformation of the mirror is critical and precise information of the thermal expansion is needed for the telescope design. The temperature range of the measurements extends from room temperature down to $\\sim$ 10 K. Three samples, #1, #2, and #3 were manufactured from blocks of SiC produced in different lots. The thermal expansion of the samples was measured with a cryogenic dilatometer, consisting of a laser interferometer, a cryostat, and a mechanical cooler. The typical thermal expansion curve is presented using the 8th order polynomial of the temperature. For the three samples, the coefficients of thermal expansion (CTE), $\\bar{\\alpha}_{#1}$, $\\bar{\\alpha}_{#2}$, and $\\bar{\\alpha}_{#3}$ were derived for temperatures between 293 K and 10 K. The average and the dispersion (1 $\\sigma$ rms) of these three CTEs are 0.816 and 0.002 ($\\times 10^{-6}$/K), respectively. No significant difference was detected in the CTE of the three samples from the different lots. Neither inhomogeneity nor anisotropy of the CTE was observed. Based on the obtained CTE dispersion, we performed an finite-element-method (FEM) analysis of the thermal deformation of a 3.5 m diameter cryogenic mirror made of six SiC-100 segments. It was shown that the present CTE measurement has a sufficient accuracy well enough for the design of the 3.5 m cryogenic infrared telescope mission, the Space Infrared telescope for Cosmology and Astrophysics (SPICA). ", "machine_text": "  Summary: We present high precision thermal expansion coefficient measurements of SiC-100 for temperatures down to 50 K. The measurements were performed in the frame of the ESA/CNES CryoPix project to qualify SiC-100 for cryogenic space telescope applications. The thermal expansion coefficient was determined with a relative uncertainty as low as 1.5 ppb/K using a silicon carbide mastersky. We show that SiC-100 has a higher thermal expansion coefficient than ZERODUR but a much higher thermal conductivity. The high thermal conductivity causes a strong temperature dependence of the measured thermal expansion coefficient. We derived a temperature dependent correction curve for the thermal expansion coefficient which can be used to reduce the measurement uncertainty to 0.5 ppb/K. We also present the first test results of a new types of SiC-100: SiC-100 thin disk and SiC-100 bonded to a silicon carbide core. Both types are potential candidates for future cryogenic space telescope applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Sloan Digital Sky Survey Quasar Catalog IV. Fifth Data Release. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0806, "human_text": "  We present the fourth edition of the Sloan Digital Sky Survey (SDSS) Quasar Catalog. The catalog contains 77,429 objects; this is an increase of over 30,000 entries since the previous edition. The catalog consists of the objects in the SDSS Fifth Data Release that have luminosities larger than M_i = -22.0 (in a cosmology with H_0 = 70 km/s/Mpc, Omega_M = 0.3, and Omega_Lambda = 0.7) have at least one emission line with FWHM larger than 1000 km/s, or have interesting/complex absorption features, are fainter than i=15.0, and have highly reliable redshifts. The area covered by the catalog is 5740 sq. deg. The quasar redshifts range from 0.08 to 5.41, with a median value of 1.48; the catalog includes 891 quasars at redshifts greater than four, of which 36 are at redshifts greater than five. Approximately half of the catalog quasars have i < 19; nearly all have i < 21. For each object the catalog presents positions accurate to better than 0.2 arcsec. rms per coordinate, five-band (ugriz) CCD-based photometry with typical accuracy of 0.03 mag, and information on the morphology and selection method. The catalog also contains basic radio, near-infrared, and X-ray emission properties of the quasars, when available, from other large-area surveys. The calibrated digital spectra cover the wavelength region 3800--9200A at a spectral resolution of ~2000. The spectra can be retrieved from the public database using the information provided in the catalog. The average SDSS colors of quasars as a function of redshift, derived from the catalog entries, are presented in tabular form. Approximately 96% of the objects in the catalog were discovered by the SDSS. ", "machine_text": "  We present the SDSS Quasar Catalog IV, Fifth Data Release (Q4). The catalog contains photometric redshifts for 112,\u00e9tartimely-interval quasars observed with the SDSS through 2007 February, with fainter quasars observed through 2009 January. Q4 includes all quasars in the SDSS Data Release 7 (DR7) and in the SDSS Legacy Survey, with the exception of a small number of quasars with very low significance (false-alarm) detections. Q4 also includes quasars from the SDSS's supernova survey, SN Ia, and from the SDSS's extended redshift survey, eBOSS. The quasars in these datasets were observed in the same areas of the sky as the SDSS's main galaxy redshift survey, and have the same two-dimensional (2D) coverage as Q3, with the same Galactic latitude (|b| > 2.5\u00b0) and in most of the same survey areas as Q3. Thus, the sky coverage of quasars in Q4 is similar to that in Q3, but with a significantly larger number of quasars. The quasars in Q4 have been divided into three subsets, based on the optical brightness and redshift distribution of the quasars. Q4R is a randomly subset of the quasars in Q4; Q4S is a subset of quasars selected to have similar optical brightness, redshift distribution, and sky coverage to those in Q3; Q4T is a subset of quasars selected to have similar optical brightness and sky coverage to those in Q3, but with a different (and larger) redshift distribution than Q3. This report describes the selection criteria for the quasars in Q4, and contains tables giving the properties of the quasars in the subsets, Q4R, Q4S, and Q4T.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetar Nature and the Outburst Mechanism of a Transient Anomalous\n  X-ray Pulsar. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3713, "human_text": "  Anomalous X-ray Pulsars (AXPs) belong to a class of neutron stars believed to harbor the strongest magnetic fields in the universe, as indicated by their energetic bursts and their rapid spindowns. However, an unambiguous measurement of their surface field strengths has not been made to date. It is also not known whether AXP outbursts result from changes in the neutron star magnetic field or crust properties. Here we report a spectroscopic measurement of the surface magnetic field strength of an AXP, XTE J1810$-$197, and solidify its magnetar nature. The field strength obtained from detailed spectral analysis and modeling, B = (2.72$\\pm$0.03)$\\times10^{14}$ G, is remarkably close to the value inferred from the rate of spindown of this source and remains nearly constant during numerous observations spanning over an order of magnitude in source flux. The surface temperature, on the other hand, declines steadily and dramatically following the 2003 outburst of this source. Our findings demonstrate that heating occurs in the upper neutron star crust during an outburst and sheds light on the transient behaviour of AXPs. ", "machine_text": " We present observations of the transient anomalous X-ray pulsar XTE J1810$-$197. We find that the accretion phase occurs in pulses, with a frequency that decreases by a factor of ~2 between each pulse. This suggests that the inner accretion disc is not being driven by a steady-state process, but is instead related to the orbital period of a companion. We determine the properties of the companion by fitting a simple model to the observations. We find that the companion has an orbital period of $\\sim$9 hours, which is consistent with a free oscillation period for a particle in the accretion disc, and an orbital decay of $\\sim$5.5 hours, which could be due to tidal interactions. The companion was likely captured by the primary star several thousand years ago. The simple model we use to describe the observations only includes the two fundamental orbital frequencies, but additional terms could be added to describe non-linear effects. We discuss the effect of the accretion disc viscosity on the observed phenomenology. The simple model is in good agreement with the observations, but a more complete model would be necessary to understand the underlying physical mechanism. We discuss how such a model might be constructed, based on the physical properties of the accretion disc and the companion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SQUID-based instrumentation for ultra-low-field MRI. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0661, "human_text": "  Magnetic resonance imaging at ultra-low fields (ULF MRI) is a promising new imaging method that uses SQUID sensors to measure the spatially encoded precession of pre-polarized nuclear spin populations at a microtesla-range measurement field. In this work, a seven-channel SQUID system designed for simultaneous 3D ULF MRI and magnetoencephalography (MEG) is described. The system includes seven second-order SQUID gradiometers, characterized by magnetic field resolutions of 1.2 - 2.8 fT/rtHz. It is also equipped with five sets of coils for 3D Fourier imaging with pre-polarization. Essential technical details of the design are discussed. The system's ULF MRI performance is demonstrated by multi-channel 3D images of a preserved sheep brain acquired at 46 microtesla measurement field with pre-polarization at 40 mT. The imaging resolution is 2.5 mm x 2.5 mm x 5 mm. The ULF MRI images are compared to images of the same brain acquired using conventional high-field MRI. Different ways to improve imaging SNR are discussed. ", "machine_text": "  Introduction  We have previously reported on the design and implementation of a SQUID-based system for ultra-low-field MRI that has the potential to bring the benefits of MRI to a new class of applications that include molecular and functional imaging. Our initial results demonstrate the potential of SQUID-based instrumentation for ultra-low-field MRI, however, several issues must be addressed in order to make this approach practical. In this work, we focus on two of these issues: signal-to-noise ratio and image artifacts.  Methodology  We have designed a system of parallel SQUID arrays that is capable of eliminating the need for a flux-lock loop and thereby reducing the noise in the detected signal. This system is currently being constructed and will be the subject of future publications. In addition, we have developed a technique for suppressing the image artifacts caused by uniform magnetic fields. This technique is based on the use of a reference channel that measures the uniform field and a filtering procedure that removes the uniform field from the image.  Results  We have evaluated the image quality obtained with the SQUID-based system and the effectiveness of the filtering procedure in suppressing the image artifacts. The results of this evaluation indicate that this approach is feasible for producing high quality images.  Discussion  The results reported in this paper demonstrate that SQUID-based instrumentation for ultra-low-field MRI is a viable approach for producing high quality images. Further work is needed to optimize the design of the SQUID array and the filtering procedure in order to achieve the best possible image quality. In addition, this work has demonstrated that SQUID-based instrumentation can be used to measure the uniform field and thereby enable the suppression of this artifact. This capability is important for producing high quality images and is an area of active research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Produit d'entrelacement et action triangulaire d'alg\\`ebres de Lie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.384, "human_text": "  Formal actions of Lie algebras over vector spaces are introduced in a purely algebraic way, as a mimic of infinitesimal operations of Banach Lie algebras over Banach analytic manifolds. In analogy with the case of abstract groups, complete wreath products and triangular actions are then defined for Lie algebras acting \"en cascade\" over vector spaces. Finally, a Kaloujnine-Krasner type theorem for Lie algebra extensions is proved.   -----   En mimant les lois d'op\\'erations infinit\\'esimales des alg\\`ebres de Lie sur les vari\\'et\\'e s analytiques banachiques, on introduit de mani\\`ere purement alg\\`ebrique la notion d'action formelle d'une alg\\`ebre de Lie sur un espace vectoriel. Ensuite, par analogie avec le cas des groupes abstraits, et en faisant op\\'erer les alg\\`ebres de Lie \"en cascade\", on d\\'efinit produit d'entrelacement (\"wreath product\") et action triangulaire pour les alg\\`ebres de Lie. On d\\'emontre enfin un th\\'eor\\`eme du type Kaloujnine-Krasner pour les extensions d'alg\\`ebres de Lie. ", "machine_text": "  We construct a general formalism for the determination of products of interplays and the action of triangles of Lie algebras. We apply this formalism to the particular cases of the Heisenberg and killing algebras, and we give a geometric interpretation of the action of the triangles of these algebras on certain spaces of quantum W pumps.  Let $\\Gamma$ and $\\Gamma'$ be Lie algebras; let $\\Gamma$ be simple. We set $\\Phi: \\Gamma\\to \\Gamma'$ to be the unique homomorphism of $\\Gamma$ onto $\\Gamma'$ which satisfies the following property: for every $X$ in $\\Gamma$, the image $\\Phi(X)$ is contained in the radical of $\\Gamma'$. If $\\Phi$ is an isomorphism of $\\Gamma$ onto $\\Gamma'$, then $\\Gamma$ and $\\Gamma'$ are said to be isomorphic. We can now state the main results of this paper.  We prove the following result.  \\[theorem0\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then $\\Gamma$ and $\\Gamma'$ are isomorphic to simple Lie algebras.  We also prove the following result.  \\[theorem1\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then the killing form $B$ of $\\Gamma$ is induced by the killing form $B'$ of $\\Gamma'$.  We also show that, if $\\Gamma$ is isomorphic to $\\Gamma'$, then the isomorphism $\\Phi$ satisfies the following property.  \\[theorem2\\] Let $\\Gamma$ and $\\Gamma'$ be Lie algebras. If $\\Gamma$ is isomorphic to $\\Gamma'$, then the isomorphism $\\Phi$ preserves the root system of $\\Gamma$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-infrared polarimetric study of the bipolar nebula IRAS 19312+1950. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2741, "human_text": "  We obtained H-band polarimetric data of IRAS 19312+1950 using the near-infrared camera (CIAO) on the 8 m Subaru telescope. In order to investigate the physical properties of the central star and the nebula, we performed dust radiative transfer modeling and compared the model results with the observed spectral energy distributions (SEDs), the radial profiles of the total intensity image, and the fraction of linear polarization map. The total intensity image shows a nearly spherical core with ~3\" radius, an S-shaped arm extending ~10\" in the northwest to southeast direction, and an extended lobe towards the southwest. The polarization map shows a centro-symmetric vector alignment in almost the entire nebula and low polarizations along the S-shaped arm. These results suggest that the nebula is accompanied by a central star, and the S-shaped arm has a physically ring-like structure. From our radiative transfer modeling, we estimated the stellar temperature, the bolometric luminosity, and the current mass-loss rate to be 2800 K, 7000 L_sun, and 5.3x10^{-6} M_sun yr^{-1}, respectively. Taking into account previous observational results, such as the detection of SiO maser emissions and silicate absorption feature in the 10 $\\mu$m spectrum, our dust radiative transfer analysis based on our NIR imaging polarimetry suggests that (1) the central star of IRAS 19312+1950 is likely to be an oxygen-rich, dust-enshrouded AGB star and (2) most of the circumstellar material originates from other sources (e.g. ambient dark clouds) rather than as a result of mass loss from the central star. ", "machine_text": "  We present a study of the bipolar nebula IRAS 19312+1950, which is the product of the latest stellar evolution of the ONeMg WD 50ql. This object has been the subject of much attention because of its very low temperature, its large mass-loss rate, and its potential to provide clues about the accretion history of magnetic white dwarfs. We present new near-infrared polarimetric images, which we have combined with previous data to produce a more complete map of the emission-line region. These data show a strong indication of circumstellar polarization, which we attribute to theollapse of the magnetic white dwarf. The white dwarf's magnetic field is able to extract rotational energy from the gas, producing a torque that brakes the accretion. This leads to a less violent accretion history and, consequently, to a lower mass-loss rate than would be expected from an unrestrained accretion flow. We show that this braking torque has decreased since the last outburst, probably because the white dwarf's magnetic field has become more distant from the accretion flow. We discuss this mechanism in the framework of the magnetic braking model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hadronization in semi-inclusive deep-inelastic scattering on nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.327, "human_text": "  A series of semi-inclusive deep-inelastic scattering measurements on deuterium, helium, neon, krypton, and xenon targets has been performed in order to study hadronization. The data were collected with the HERMES detector at the DESY laboratory using a 27.6 GeV positron or electron beam. Hadron multiplicities on nucleus A relative to those on the deuteron, R_A^h, are presented for various hadrons (\\pi^+, \\pi^-, \\pi^0, K^+, K^-, p, and \\bar{p}) as a function of the virtual-photon energy \\nu, the fraction z of this energy transferred to the hadron, the photon virtuality Q^2, and the hadron transverse momentum squared p_t^2. The data reveal a systematic decrease of R_A^h with the mass number A for each hadron type h. Furthermore, R_A^h increases (decreases) with increasing values of \\nu (z), increases slightly with increasing Q^2, and is almost independent of p_t^2, except at large values of p_t^2. For pions two-dimensional distributions also are presented. These indicate that the dependences of R_A^{\\pi} on \\nu and z can largely be described as a dependence on a single variable L_c, which is a combination of \\nu and z. The dependence on L_c suggests in which kinematic conditions partonic and hadronic mechanisms may be dominant. The behaviour of R_A^{\\pi} at large p_t^2 constitutes tentative evidence for a partonic energy-loss mechanism. The A-dependence of R_A^h is investigated as a function of \\nu, z, and of L_c. It approximately follows an A^{\\alpha} form with \\alpha \\approx 0.5 - 0.6. ", "machine_text": "  Hadronization in semi-inclusive deep-inelastic scattering on nuclei. We have studied the hadronization mechanism in the framework of the Standard Model (SM) in semi-inclusive deep-inelastic collisions between nuclei and relativistic heavy nuclei at high energies. The evolution of the hadron gas produced in these collisions is governed by the ductility of the nuclei, which is related to the nuclei' size, and by the energy distribution of the hadrons produced in the collisions. We have developed a formalism which describes the hadronization process in these collisions in a unified way, in the framework of the SM, and which takes into account the energy evolution of the hadrons as well as the ductility of the nuclei. Our results show that the hadronization process is different in the two cases, i.e. for relativistic heavy nuclei and for nuclei, and that the difference is due to the different mechanisms which have to saturate in the two cases. Our results also show that the hadron gas produced in these collisions is (ifi the collisions are \"hard\") always thermal, independently of the nucleus' size, and that the hadron gas produced in collisions between relativistic heavy nuclei is less likely to be turbulent than the one produced in collisions between nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetic Fields of Classical T Tauri Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2923, "human_text": "  We report new magnetic field measurements for 14 classical T Tauri stars (CTTSs). We combine these data with one previous field determination in order to compare our observed field strengths with the field strengths predicted by magnetospheric accretion models. We use literature data on the stellar mass, radius, rotation period, and disk accretion rate to predict the field strength that should be present on each of our stars according to these magnetospheric accretion models. We show that our measured field values do not correlate with the field strengths predicted by simple magnetospheric accretion theory. We also use our field strength measurements and literature X-ray luminosity data to test a recent relationship expressing X-ray luminosity as a function of surface magnetic flux derived from various solar feature and main sequence star measurements. We find that the T Tauri stars we have observed have weaker than expected X-ray emission by over an order of magnitude on average using this relationship. We suggest the cause for this is actually a result of the very strong fields on these stars which decreases the efficiency with which gas motions in the photosphere can tangle magnetic flux tubes in the corona. ", "machine_text": " We present a detailed study of the magnetic fields of 21 classical T Tauri stars, 14 of which are members of the TW Hydrae Association. Our observations are made with the Very Long Baseline Array (VLBA) at 1.3 GHz and resolve the stars' magnetospheres to an average spatial resolution of 30 Milliarcseconds. We find that the magnetic fields are directed radially inwards, are less than 10 MG, and have an average field strength of 6.2 MG. The field distribution is very non-uniform, with super-granulation (with sizes between 10 and 20 Mm) being the dominant feature. The fields show large-scale longitudinal and latitudinal structure, probably due to magneto-convection, and in several cases strong magnetic spots are present. We discuss our results in the framework of a simple model of magneto-convection in rotating stars, and present a physical interpretation of our observations. We find that the magnetic field generation is probably due to a combination of internal convection and a slow rotation rate, and that magneto-convection is an efficient mechanism for driving mass-loss from these stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical Coupled-Channel Model of $\\pi N$ Scattering in the W $\\leq$ 2\n  GeV Nucleon Resonance Region. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1615, "human_text": "  As a first step to analyze the electromagnetic meson production reactions in the nucleon resonance region, the parameters of the hadronic interactions of a dynamical coupled-channel model, developed in {\\it Physics Reports 439, 193 (2007)}, are determined by fitting the $\\pi N$ scattering data. The channels included in the calculations are $\\pi N$, $\\eta N$ and $\\pi\\pi N$ which has $\\pi\\Delta$, $\\rho N$, and $\\sigma N$ resonant components. The non-resonant meson-baryon interactions of the model are derived from a set of Lagrangians by using a unitary transformation method. One or two bare excited nucleon states in each of $S$, $P$, $D$, and $F$ partial waves are included to generate the resonant amplitudes in the fits. The parameters of the model are first determined by fitting as much as possible the empirical $\\pi N$ elastic scattering amplitudes of SAID up to 2 GeV. We then refine and confirm the resulting parameters by directly comparing the predicted differential cross section and target polarization asymmetry with the original data of the elastic $\\pi^{\\pm} p \\to \\pi^{\\pm} p$ and charge-exchange $\\pi^- p \\to \\pi^0 n$ processes. The predicted total cross sections of $\\pi N$ reactions and $\\pi N\\to \\eta N$ reactions are also in good agreement with the data. Applications of the constructed model in analyzing the electromagnetic meson production data as well as the future developments are discussed. ", "machine_text": " We develop a dynamically coupled-channel model to study $\\pi N$ scattering in the W $\\leq$ 2 GeV Nucleon Resonance Region. The model includes the following channels: elastic $\\pi N$, $\\pi N$ quasi-elastic, and inelastic $\\pi N$ with $\\pi$ and $N$ exchanged. We consider the channels to be coupled in the $\\langle \\rangle$-space. The model is solved exactly and the results are presented as a sum over all the $\\pi N$-Partners in the coupled-channel basis set. We show that the exact results for the $\\pi N$ quasi-elastic and inelastic channels can be obtained as limits of the elastic $\\pi N$ and inelastic $\\pi N$ with $\\pi$ and $N$ exchanged channels, respectively, as the strength of the coupling between the channels goes to zero. The $\\pi N$ quasi-elastic and inelastic channels are further decomposed into the channels with $\\pi$ and $N$ exchanged. The resulting coupled-channel amplitudes are compared with the results obtained from the single-channel basis-set. The effects of the hadron-mesh-validation on the results are also investigated.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pure inductive limit state and Kolmogorov's property. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1987, "human_text": "  Let $(\\clb,\\lambda_t,\\psi)$ be a $C^*$-dynamical system where $(\\lambda_t: t \\in \\IT_+)$ be a semigroup of injective endomorphism and $\\psi$ be an $(\\lambda_t)$ invariant state on the $C^*$ subalgebra $\\clb$ and $\\IT_+$ is either non-negative integers or real numbers. The central aim of this exposition is to find a useful criteria for the inductive limit state $\\clb \\raro^{\\lambda_t} \\clb$ canonically associated with $\\psi$ to be pure. We achieve this by exploring the minimal weak forward and backward Markov processes associated with the Markov semigroup on the corner von-Neumann algebra of the support projection of the state $\\psi$ to prove that Kolmogorov's property [Mo2] of the Markov semigroup is a sufficient condition for the inductive state to be pure. As an application of this criteria we find a sufficient condition for a translation invariant factor state on a one dimensional quantum spin chain to be pure. This criteria in a sense complements criteria obtained in [BJKW,Mo2] as we could go beyond lattice symmetric states. ", "machine_text": " We consider the problem of characterizing the limiting behavior of a sequence of independent trials with successes and failures, when the probability of success converges to a limit value as the number of trials grows indefinitely large. We show that, under suitable assumptions, the limiting behavior is always described by a compound probability distribution, in which the probability of failure is given by a limiting distribution and the probability of success is given by a shifted and scaled version of the limiting distribution. This generalizes previous results in the literature which considered the special case of a random walk with probabilities of success and failure which are equal and constant. We also show that the limiting distribution has the Kolmogorov property if the original probability of success has this property. That is, the limiting distribution is equal to the limiting distribution of the sum of independent trials with the limiting distribution and with probability one-half.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: HS1857+5144: A hot and young pre-cataclysmic variable. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.178, "human_text": "  We report the discovery of a new white dwarf/M dwarf binary, HS1857+5144, identified in the Hamburg Quasar Survey (HQS). Time-resolved optical spectroscopy and photometry were carried out to determine the properties of this new cataclysmic variable progenitor pre-CV). The light curves of HS1857+5144 display a sinusoidal variation with a period of Porb=383.52 min and peak-to-peak amplitudes of 0.7 mag and 1.1 mag in the B-band and R-band, respectively. The large amplitude of the brightness variation results from a reflection effect on the heated inner hemisphere of the companion star, suggesting a very high temperature of the white dwarf. Our radial velocity study confirms the photometric period as the orbital period of the system. A model atmosphere fit to the spectrum of the white dwarf obtained at minimum light provides limits to its mass and temperature of Mwd=~0.6-1.0 Msun and Twd=~70000-100000 K, respectively. The detection of HeII 4686 absorption classifies the primary star of HS1857+5144 as a DAO white dwarf. Combining the results from our spectroscopy and photometry, we estimate the mass of the companion star and the binary inclination to be Msec=~0.15-0.30 Msun and i=~45-55 deg, respectively. We classify HS1857+5144 as one of the youngest pre-CV known to date. The cooling age of the white dwarf suggests that the present system has just emerged from a common envelope phase ~10^5 yr ago. HS1857+5144 will start mass transfer within or below the 2-3h period gap. ", "machine_text": "  HS1857+5144: A hot and young pre-cataclysmic variable  We present photometric and spectroscopic observations of the pre-cataclysmic variable (PCV) HS1857+5144 obtained during a recent outburst. The system is a member of the galactic globular cluster M3, and is one of the most massive and rapidly rotating PCVs known. We find that the accretion phase lasts several thousand seconds, which is much longer than typical for PCVs. We observe a large number of small-amplitude eclipses during the accretion phase, which we attribute to the fact that the accretion disc is far from being axisymmetric. We estimate the pre- outburst orbital period to be \u223c70 min, and the spin period, which is slightly longer, to be \u223c73 min. The observed spin-up time is much longer than the orbital period, indicating that the system is in a strongly three-frequency Resonance. The total mass and the orbital and spin periods are consistent with a single massive accretion disc, as opposed to a system with two accretion discs in orbit around a common barycenter, which was previously suggested to explain some peculiarities of this system. We discuss the possible physical origin of the non-axisymmetric structure of the accretion disc, and suggest that the long spin-up time is due to the large moment of inertia of the disc, in combination with the relatively weak accretion torque.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Critical Behaviour of Irreversible Reaction Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0419, "human_text": "  An introductory review on the critical behaviour of some irreversible reaction systems is given. The study of these systems has attracted great attention during the last decades due to, on the one hand, the rich and complex underlying physics, and on the other hand, their relevance for numerous technological applications in heterogeneous catalysis, corrosion and coating, development of microelectronic devices, etc. The review is focuses on recent advances in the understanding of irreversible phase transitions (IPT's) providing a survey of the theoretical development of the field during the last decade, as well as a detailed discussion of relevant numerical simulations. The Langevin formulation for the treatment of second-order IPT's is discussed. Different Monte Carlo approaches are also presented in detail and the finite-size scaling analysis of second-order IPT's is described. Special attention is devoted to the description of recent progress in the study of first-order IPT's observed upon catalytic oxidation of carbon monoxide and the reduction of nitrogen monoxide, using lattice gas reaction models. Only brief comments are given on other reactions such as the oxidation of hydrogen, ammonia synthesis, etc. Also, a discussion of relevant experiments is presented and measurement are compared with the numerical results. Furthermore, promising areas for further research and open questions are also addressed. ", "machine_text": " We investigate the critical behaviour of irreversible reaction systems. We consider both steady-state and dynamical criticality, and study the relationship between the two. We find that steady-state criticality may be understood in terms of a generalised Nyquist diagram, which we call a criticality diagram. A criticality diagram is derived from a generalised Lotka-Volterra model, which is itself derived from a master equation. We show that the criticality diagram has three distinct regions. We call the boundary between the first and second regions the criticity line, and the boundary between the second and third regions the supercriticality line. We find that the criticality diagram can be used to understand the critical behaviour of a wide range of irreversible reaction systems, including systems that have been previously studied using the singularity theory of Cannon and Articles. We also find that the concept of criticality can be extended to discrete-time dynamical systems, and that a criticality diagram can be defined for such systems. We show that the boundary between the first and second regions of the criticality diagram is the discrete-time equivalent of the criticity line, and that the boundary between the second and third regions is the discrete-time equivalent of the supercriticality line.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new, very massive modular Liquid Argon Imaging Chamber to detect low\n  energy off-axis neutrinos from the CNGS beam. (Project MODULAr). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1422, "human_text": "  The paper is considering an opportunity for the CERN/GranSasso (CNGS) neutrino complex, concurrent time-wise with T2K and NOvA, to search for theta_13 oscillations and CP violation. Compared with large water Cherenkov (T2K) and fine grained scintillators (NOvA), the LAr-TPC offers a higher detection efficiency and a lower backgrounds, since virtually all channels may be unambiguously recognized. The present proposal, called MODULAr, describes a 20 kt fiducial volume LAr-TPC, following very closely the technology developed for the ICARUS-T60o, and is focused on the following activities, for which we seek an extended international collaboration:   (1) the neutrino beam from the CERN 400 GeV proton beam and an optimised horn focussing, eventually with an increased intensity in the framework of the LHC accelerator improvement program;   (2) A new experimental area LNGS-B, of at least 50000 m3 at 10 km off-axis from the main Laboratory, eventually upgradable to larger sizes. A location is under consideration at about 1.2 km equivalent water depth;   (3) A new LAr Imaging detector of at least 20 kt fiducial mass. Such an increase in the volume over the current ICARUS T600 needs to be carefully considered. It is concluded that a very large mass is best realised with a set of many identical, independent units, each of 5 kt, \"cloning\" the technology of the T600. Further phases may foresee extensions of MODULAr to meet future physics goals.   The experiment might reasonably be operational in about 4/5 years, provided a new hall is excavated in the vicinity of the Gran Sasso Laboratory and adequate funding and participation are made available. ", "machine_text": " We describe a new very massive modular liquid argon imaging chamber which will be used to search for low energy off-axis neutrinos from the CNGS beam. The main motivation for the research is to improve the sensitivity to low energy neutrinos from the CNGS beam over the current state-of-the-art detectors which will lead to a precise measurement of the neutrino-nucleon cross section at low energy. The key idea is to use a large volume of liquid argon as the detection medium, to use 3D array of flash lamps as the illumination system and to use a 3D array of photo-detectors to register the tracks of nuclear particles. We describe the main design features of the detector and the results of a series of measurements which were carried out to test the design and to achieve better understanding of the physical processes which occur in the detector. The main result of the project is the design of the detector which is optimized for the proposed measurement and which will be used for the future neutrino experiments. We also discuss several other scientific projects which will be carried out with the detector and which are important for the physics program of the LDE neutrino group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis on Heavy Quarkonia Transitions with Pion Emission in Terms of\n  the QCD Multipole Expansion and Determination of Mass Spectra of Hybrids. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2074, "human_text": "  One of the most important tasks in high energy physics is search for the exotic states, such as glueball, hybrid and multi-quark states. The transitions $\\psi(ns)\\to \\psi(ms)+\\pi\\pi$ and $\\Upsilon(ns)\\to \\Upsilon(ms)+\\pi\\pi$ attract great attentions because they may reveal characteristics of hybrids. In this work, we analyze those transition modes in terms of the theoretical framework established by Yan and Kuang. It is interesting to notice that the intermediate states between the two gluon-emissions are hybrids, therefore by fitting the data, we are able to determine the mass spectra of hybrids. The ground hybrid states are predicted as 4.23 GeV (for charmonium) and 10.79 GeV (for bottonium) which do not correspond to any states measured in recent experiments, thus it may imply that very possibly, hybrids mix with regular quarkonia to constitute physical states. Comprehensive comparisons of the potentials for hybrids whose parameters are obtained in this scenario with the lattice results are presented. ", "machine_text": " We propose an analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The motivation for this work is to understand the non-relativistic theory of heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The key ideas and methodology of this work are based on the non-relativistic theory of heavy quarkonia transitions with pion emission. The results obtained in this work are the mass spectra of hybrids and the analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The problem this work attempts to solve is to understand the non-relativistic theory of heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion. The practical application of this work is the determination of the mass spectra of hybrids. The theoretical application of this work is the analysis on heavy quarkonia transitions with pion emission in terms of the QCD multipole expansion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flaming, bright galaxies along the filaments of A2744. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0273, "human_text": "  The existence of a clumpy, large-scale filamentary structure is at the basis of the current paradigm of cosmic formation and evolution of clusters. The star-formation history of galaxies falling into a cluster is altered as a result of the environmental stresses. We investigate the relation between substructure and properties of the galaxy population in a 30'x30' region centered on the massive merging cluster A2744 at z~0.3. Multi-object spectroscopy at low resolution and BVR photometry are used to detect the presence of substructure through a Dressler-Schectman analysis and the photometric redshift technique, respectively. Galaxies at the same photometric redshift of the cluster are divided into red and blue according to their distribution in the B-R vs. R colour-magnitude diagram. We identify two large-scale filaments associated with A2744. Along these filaments, the blue-to-red galaxy number ratio increases together with the cluster-centric distance but peaks slightly beyond the cluster virial radius. The filaments host a population of bright, large (i.e. more luminous than R* for the main body of the cluster and with angular sizes of 13-22 $h_{70}^{-1}$ kpc) blue galaxies that is hardly found among galaxies lying in a neighbouring low-density environment at the same redshift of the cluster. These results can be interpreted as a manifestation of galaxy harassment. ", "machine_text": "  Flaming, bright galaxies along the filaments of A2744  We present a detailed optical study of the rich clusters A2058 and A2744, which contain many spiral galaxies of very low surface brightness. We find that the spiral galaxies in both clusters are not only optically but also physically associated with the clusters' large-scale structure, following the clusters' filaments and clumps. In addition, the spiral galaxies show a strong tendency to align along the cluster's largest filaments, but only in those clusters in which the dominant galaxy population is also highly aligned. We discuss the possibility that the spiral galaxies are actively forming in the clusters' filaments, and that their alignment is due to the influence of the large-scale structure and the resulting distribution of matter and angular momentum. We find that in A2744 the alignment of the spiral galaxies is rather well explained by the distribution of the large-scale structure, but that in A2058 the distribution of the structure is less well described by the alignment of the spiral galaxies. We show that in A2058 the spiral galaxies tend to align with the clusters' small-scale structure, while in A2744 they align with the clusters' large-scale structure. We discuss the physical mechanism responsible for the alignment of the spiral galaxies with the clusters' large-scale structure in A2744.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mean-Field Magnetohydrodynamics of Accretion Disks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0421, "human_text": "  We consider the accretion process in a disk with magnetic fields that are dragged in from the interstellar medium by gravitational collapse. Two diffusive processes are at work in the system: (1) \"viscous\" torques exerted by turbulent and magnetic stresses, and (2) \"resistive\" redistribution of mass with respect to the magnetic flux arising from the imperfect conduction of current. In steady state, self-consistency between the two rates of drift requires that a relationship exists between the coefficients of turbulent viscosity and turbulent resistivity. Ignoring any interactions with a stellar magnetosphere, we solve the steady-state equations for a magnetized disk under the gravitational attraction of a mass point and threaded by an amount of magnetic flux consistent with calculations of magnetized gravitational collapse in star formation. Our model mean-field equations have an exact analytical solution that corresponds to magnetically diluted Keplerian rotation about the central mass point. The solution yields the strength of the magnetic field and the surface density as functions of radial position in the disk and their connection with the departure from pure Keplerian rotation in representative cases. We compare the predictions of the theory with the available observations concerning T Tauri stars, FU Orionis stars, and low- and high-mass protostars. Finally, we speculate on the physical causes for high and low states of the accretion disks that surround young stellar objects. One of the more important results of this study is the physical derivation of analytic expressions for the turbulent viscosity and turbulent resistivity. ", "machine_text": "  We consider the problem of viscous accretion onto a compact object from a large reservoir of gas, with the object and the gas at different temperatures. We solve the resulting viscous magnetohydrodynamic (MHD) equations in a mean-field approximation. We find that when the gas is at a lower temperature than the object, the accretion flow is turbulent and the turbulence is quenched by the temperature gradient in the direction of the flow, consistent with observations of accretion disks around black holes. The turbulence is characterized by a velocity distribution function with two different power-law exponents, one in the bulk of the disk and the other at the edge. We also find that the temperature distribution in the disk is log-normal and that the standard deviation of the temperature distribution is proportional to the temperature difference between the gas and the object. When the gas is at a higher temperature than the object, we find that the accretion flow is steady and stable, consistent with the observed accretion flow in the solar wind. We discuss the relevance of our results to the problem of accretion control.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraining dark energy via baryon acoustic oscillations in the\n  (an)isotropic light-cone power spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0354, "human_text": "  The measurement of the scale of the baryon acoustic oscillations (BAO) in the galaxy power spectrum as a function of redshift is a promising method to constrain the equation-of-state parameter of the dark energy w. To measure the scale of the BAO precisely, a substantial volume of space must be surveyed. We test whether light-cone effects are important and whether the scaling relations used to compensate for an incorrect reference cosmology are in this case sufficiently accurate. We investigate the degeneracies in the cosmological parameters and the benefits of using the two-dimensional anisotropic power spectrum. Finally, we estimate the uncertainty with which w can be measured by proposed surveys at redshifts of about z=3 and z=1, respectively.   In the simulated survey we find that light-cone effects are small and that the simple scaling relations used to correct for the cosmological distortion work fairly well even for large survey volumes. The analysis of the two-dimensional anisotropic power spectra enables an independent determination to be made of the apparent scale of the BAO, perpendicular and parallel to the line of sight. This is essential for two-parameter w-models, such as the redshift-dependent dark energy model w=w_0+(1-a)w_a. Using Planck priors for the matter and baryon density and Delta(H_0)=5% for the Hubble constant, we estimate that the BAO measurements of future surveys around z=3 and z=1 will be able to constrain, independently of other cosmological probes, a constant w to ~ 12% and ~ 11% (68% c.l.), respectively. ", "machine_text": "  We present a formalism to constrain the dark energy density through its signature on the anisotropic power spectrum of the matter distribution in a galaxy cluster. The formalism is based on the comparison of the measured power spectrum with the one expected from an isotropic distribution of matter in a harmonic potential well. The potential well is created by the baryon acoustic oscillations (BAO) of the matter distribution. The BAO scale is determined from the observed correlation function and used to set the scale of the potential well. We show that the difference between the measured and the predicted power spectrum is sensitive to the dark energy density and can be used to set a bound on the dark energy density. We find that the current observations are consistent with a dark energy density that is less than a certain value, which depends on the BAO scale. The BAO scale can be determined from current observations with an accuracy of about 10%. We discuss the current constraints on the dark energy density and the prospects of future observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The interplay between radio galaxies and cluster environment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0574, "human_text": "  By combining the REFLEX and NORAS cluster datasets with the NVSS radio catalogue, we obtain a sample of 145, z<0.3, X-ray selected clusters brighter than 3 10^(-12) erg/s/cm^2 that show a central radio emission above 3 mJy. For virial masses M_vir<~10^(14.5) M_sun, 11 clusters out of 12 (corresponding to 92% of the systems) are inhabited by a central radio source. This fraction decreases with higher masses as M_vir^(-0.4) and suggests that the majority of X-ray selected clusters host in their centre a radio source brighter than about 10^(20) W/Hz/sr. A division of the sample into clusters harbouring either point-like or an extended radio-loud AGN reveals that the steepening of the L_X-T relation for low-temperature clusters is strongly associated with the presence of central radio objects with extended jets and/or lobe structures. In the latter case, L_X\\propto T^(4) while for point-like sources one recovers an approximately self-similar relation L_X\\propto T^(2.3). Monte Carlo simulations show that the steepening of the L_X-T relation is not caused by clusters being under-luminous in the X-ray band, but rather by overheating, most likely caused by the interplay between the extended radio structures and the intracluster medium. In the case of low-mass systems, we also find a tight correlation between radio luminosity and cluster temperature. The effects of the central radio source on the thermal state of a cluster become less important with increasing cluster mass. (Abridged) The luminosity distribution of the cluster radio population differs from that of all radio sources, as there is a deficit of low-luminosity (L_R<~10^(22) W/Hz/sr) objects, while the number of high-luminosity ones is boosted. The net effect on the radio luminosity function is of a flattening at all luminosities L_R<~ 10^(24) W/Hz/sr. ", "machine_text": "  We present here results of a systematic numerical study of the interplay between the dynamics of radio galaxies and the cluster environment. We find that the cluster potential can significantly alter the distribution of radio galaxies in the cluster, in particular in the outskirts where the influence of the cluster is the strongest. We also find that a lack of cluster influence on radio galaxies, as is the case in the Local Group, results in a flatter radio galaxy distribution. Our results suggest that in clusters with a steep radio galaxy distribution, the cluster environment has a strong influence on the radio galaxies, while in clusters with a flat distribution the cluster environment has little influence. We also discuss a possible connection between the distribution of radio galaxies in clusters and the cluster mass distribution. Our results are consistent with a picture where the dynamics of radio galaxies is influenced by the cluster environment, in particular by the distribution of mass in the cluster, but also by other cluster properties, such as the strength of the radio source.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-photon transitions in hydrogen and cosmological recombination. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3033, "human_text": "  We study the two-photon process for the transitions ns --> 1s and nd --> 1s in hydrogen up to large n. For n<=20 we provide simple analytic fitting formulae to describe the non-resonant part of the two-photon emission profiles. Combining these with the analytic form of the cascade-term yields a simple and accurate description of the full two-photon decay spectrum, which only involves a sum over a few intermediate states. We demonstrate that the cascade term naturally leads to a nearly Lorentzian shape of the two-photon profiles in the vicinity of the resonances. However, due to quantum-electrodynamical corrections, the two-photon emission spectra deviate significantly from the Lorentzian shape in the very distant wings of the resonances. We investigate up to which distance the two-photon profiles are close to a Lorentzian and discuss the role of the interference term. We then analyze how the deviation of the two-photon profiles from the Lorentzian shape affects the dynamics of cosmological hydrogen recombination. Since in this context the escape of photons from the Lyman-alpha resonance plays a crucial role, we concentrate on the two-photon corrections in the vicinity of the Lyman-alpha line. Our computations show that the changes in the ionization history due to the additional two-photon process from high shell (n>2) likely do not reach the percent-level. For conservative assumptions we find a correction DN_e/N_e~-0.4% at redshift z~1160. This is numerically similar to the result of another recent study; however, the physics leading to this conclusion is rather different. In particular, our calculations of the effective two-photon decay rates yield significantly different values, where the destructive interference of the resonant and non-resonant terms plays a crucial role in this context (abridged) ", "machine_text": " We consider two-photon transitions in hydrogen and their role in the cosmological recombination history of the Universe. Two-photon transitions in hydrogen are uniquely determined by the fine structure constant, the proton-to-electron mass ratio, and the Dirac constant of the electron. We show that in the presence of a strong magnetic field, two-photon transitions in hydrogen are completely suppressed, in agreement with the observation that the cosmic microwave background does not show any signature of magnetic fields stronger than a few micro-gauss. This result suggests that any attempt to explain the origin of magnetic fields by mechanisms acting on hydrogen alone are likely to be unsuccessful. We also show that two-photon transitions in hydrogen can have a significant effect on the recombination history of the Universe, but only if the electron-to-photon ratio is extremely large. In this case, two-photon transitions can either completely suppress or accelerate recombination, depending on the strength of the magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Aid to Percutaneous Renal Access by Virtual Projection of the Ultrasound\n  Puncture Tract onto Fluoroscopic Images. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4412, "human_text": "  Background and Purpose: Percutaneous renal access in the context of percutaneous nephrolithotomy (PCNL) is a difficult technique, requiring rapid and precise access to a particular calix. We present a computerized system designed to improve percutaneous renal access by projecting the ultrasound puncture tract onto fluoroscopic images. Materials and Methods: The system consists of a computer and a localizer allowing spatial localization of the position of the various instruments. Without any human intervention, the ultrasound nephrostomy tract is superimposed in real time onto fluoroscopic images acquired in various views. Results: We tested our approach by laboratory experiments on a phantom. Also, after approval by our institution's Ethics Committee, we validated this technique in the operating room during PCNL in one patient. Conclusion: Our system is reliable, and the absence of image-processing procedures makes it robust. We have initiated a prospective study to validate this technique both for PCNL specialists and as a learning tool. ", "machine_text": "  We have developed a new method for percutaneous renal access, using virtual projection of the ultrasound puncture tract onto fluoroscopic images. In order to obtain the projection, the ultrasound image and the fluoroscopic image are simultaneously displayed, allowing the puncture to be performed on the basis of the fusion image. In this study, the puncture tracts were projected onto the fluoroscopic images in three different ways. The first method used a simple linear transformation, whereas the other two methods used a more sophisticated transformation that allowed the tract to be curved. To evaluate the accuracy of the projection, a phantom study was performed in which the distance between the tip of a wire inserted into the phantom and its projected image on the fluoroscopic image was measured. The results showed that the projection of the puncture tract was very useful for obtaining the correct puncture site, and that the two curved transformation methods gave better results than the linear method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: J-class operators and hypercyclicity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3354, "human_text": "  The purpose of the present work is to treat a new notion related to linear dynamics, which can be viewed as a \"localization\" of the notion of hypercyclicity. In particular, let $T$ be a bounded linear operator acting on a Banach space $X$ and let $x$ be a non-zero vector in $X$ such that for every open neighborhood $U\\subset X$ of $x$ and every non-empty open set $V\\subset X$ there exists a positive integer $n$ such that $T^{n}U\\cap V\\neq\\emptyset$. In this case $T$ will be called a $J$-class operator. We investigate the class of operators satisfying the above property and provide various examples. It is worthwhile to mention that many results from the theory of hypercyclic operators have their analogues in this setting. For example we establish results related to the Bourdon-Feldman theorem and we characterize the $J$-class weighted shifts. We would also like to stress that even non-separable Banach spaces which do not support topologically transitive operators, as for example $l^{\\infty}(\\mathbb{N})$, do admit $J$-class operators. ", "machine_text": "  We introduce and study a class of operators, called J-class operators, that generalize the hypercyclic operators introduced by groinig in the context of operator theory. The main motivation for this work is to understand the common properties of the hypercyclic and J-class operators, which seem to be rather different in their definitions. Our main results are the following: (i) We show that the J-class operators form a linear subspace of the direct sum of the Banach algebras of all J-class operators. (ii) We show that the J-class operators are closed under the formation of the direct sum, the Cartan product, and the symplectic product. (iii) We show that the J-class operators are (url) finite-dimensional. (iv) We show that the J-class operators are generated by the elements of the form , where is the minimal polynomial of , and the complex conjugate of . (v) We show that the J-class operators form a Banach algebra, and that they are isomorphic to the algebra of all operators on the space that commute with a given J-class operator. (vi) We show that any J-class operator is a limit of a sequence of hypercyclic operators. (vii) We show that any hypercyclic operator is a limit of a sequence of J-class operators. (viii) We show that any finite-dimensional, irreducible representation of the J-class operators is isomorphic to a representation of the hypercyclic operators. (ix) We show that the J-class operators form a poset.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase structure of a surface model on dynamically triangulated spheres\n  with elastic skeletons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0493, "human_text": "  We find three distinct phases; a tubular phase, a planar phase, and the spherical phase, in a triangulated fluid surface model. It is also found that these phases are separated by discontinuous transitions. The fluid surface model is investigated within the framework of the conventional curvature model by using the canonical Monte Carlo simulations with dynamical triangulations. The mechanical strength of the surface is given only by skeletons, and no two-dimensional bending energy is assumed in the Hamiltonian. The skeletons are composed of elastic linear-chains and rigid junctions and form a compartmentalized structure on the surface, and for this reason the vertices of triangles can diffuse freely only inside the compartments. As a consequence, an inhomogeneous structure is introduced in the model; the surface strength inside the compartments is different from the surface strength on the compartments. However, the rotational symmetry is not influenced by the elastic skeletons; there is no specific direction on the surface. In addition to the three phases mentioned above, a collapsed phase is expected to exist in the low bending rigidity regime that was not studied here. The inhomogeneous structure and the fluidity of vertices are considered to be the origin of such variety of phases. ", "machine_text": " We consider a geometric surface model defined on dynamically triangulated spheres with elastic skeletons. The motivation for this work is to provide a robust and well-defined geometrically continuous surface model in the absence of any a-priori assumptions on the geometry of the data. We show that the surface is well-defined and robust by proving that it is insensitive to small additions or removals of vertices and edges in the underlying triangle mesh. We show that this surface is also geometrically meaningful by proving that it has a well-defined and continuous normal vector field. We further prove that the surface model is isometric to the originally input mesh in the sense that it preserves the angles between adjacent triangles. We show that this surface model can be used to develop a simple, yet effective algorithm for computing geodesic paths on the surface. We implement this algorithm and show that the computed geodesic paths are sensitive to small perturbations of the surface model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dirichlet or Potts ?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.245, "human_text": "  When modeling the distribution of a set of data by a mixture of Gaussians, there are two possibilities: i) the classical one is using a set of parameters which are the proportions, the means and the variances; ii) the second is to consider the proportions as the probabilities of a discrete valued hidden variable. In the first case a usual prior distribution for the proportions is the Dirichlet which accounts for the fact that they have to sum up to one. In the second case, to each data is associated a hidden variable for which we consider two possibilities: a) assuming those variables to be i.i.d. We show then that this scheme is equivalent to the classical mixture model with Dirichlet prior; b) assuming a Markovian structure. Then we choose the simplest markovian model which is the Potts distribution. As we will see this model is more appropriate for the case where the data represents the pixels of an image for which the hidden variables represent a segmentation of that image. The main object of this paper is to give some details on these models and different algorithms used for their simulation and the estimation of their parameters.   Key Words: Mixture of Gaussians, Dirichlet, Potts, Classification, Segmentation. ", "machine_text": "   Dirichlet or Potts ? ====================  We consider the problem of estimating the number of non-zero components of a complex-valued random vector $X \\sim \\mathcal{N}(0,\\Sigma)$ where $\\Sigma$ is a positive-definite matrix. We show that the estimator $\\nu(X)$, defined as the number of positive components of $X$, has an approximate normal distribution with $\\sigma^2 = \\frac{1}{2}\\nu(X)$ as variance. This variance is independent of the dimension $d$ and the number $n$ of components of $X$ and does not increase with the number of components. This is in contrast to the usual $\\chi^2$-test for the number of components which has a variance $2(n-d)$. We show that the approximation becomes exact if the random vector $X$ has only a finite number of components or if the components are independent. We also derive a simple expression for the distribution of the estimator $\\nu(X)$ in terms of the distribution of $X^*$ and theDeterminant function. This allows to give a simple and transparent derivation of the distribution of $\\nu(X)$ in terms of Dirichlet and Potts (or Wronskian) functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two Energy Release Processes for CMEs: MHD Catastrophe and Magnetic\n  Reconnection. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3886, "human_text": "  It remains an open question how magnetic energy is rapidly released in the solar corona so as to create solar explosions such as solar flares and coronal mass ejections (CMEs). Recent studies have confirmed that a system consisting of a flux rope embedded in a background field exhibits a catastrophic behavior, and the energy threshold at the catastrophic point may exceed the associated open field energy. The accumulated free energy in the corona is abruptly released when the catastrophe takes place, and it probably serves as the main means of energy release for CMEs at least in the initial phase. Such a release proceeds via an ideal MHD process in contrast with nonideal ones such as magnetic reconnection. The catastrophe results in a sudden formation of electric current sheets, which naturally provide proper sites for fast magnetic reconnection. The reconnection may be identified with a solar flare associated with the CME on one hand, and produces a further acceleration of the CME on the other. On this basis, several preliminary suggestions are made for future observational investigations, especially with the proposed KuaFu satellites, on the roles of the MHD catastrophe and magnetic reconnection in the magnetic energy release associated with CMEs and flares. ", "machine_text": "  We present a detailed kinetic analysis of the energy release in the formation of coronal mass ejections (CMEs). We consider two energy release processes: the magnetic reconnection and the magnetohydrodynamic (MHD) catastrophe. We evaluate the energy released in the form of particle kinetic energy and in the form of thermal energy. We solve the resistive magnetohydrodynamic equations with the help of the Wissink-Olive model for the density and the glorified k-Ohm's law for the resistivity. The solution is stable against the inverse cube law for the resistivity. We consider two different parameter regimes: (1) small dynamic pressure and large magnetic field and (2) large dynamic pressure and small magnetic field. We solve the equations in a resistive MHD approximation. The obtained solutions are in good agreement with observations. We find that in both regimes the dominant energy release process is the MHD catastrophe. We also found the energy released in the form of particle kinetic energy is significant only in the regime (1). We discuss the implications of our results for the energy budget of CMEs. We also discuss the problem of the low-frequency (LCF) generation in the context of our model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Pair of Bootes: A New Milky Way Satellite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1378, "human_text": "  As part of preparations for a southern sky search for faint Milky Way dwarf galaxy satellites, we report the discovery of a stellar overdensity in the Sloan Digital Sky Survey Data Release 5, lying at an angular distance of only 1.5 degrees from the recently discovered Bo{\\\"o}tes dwarf. The overdensity was detected well above statistical noise by employing a sophisticated data mining algorithm and does not correspond to any catalogued object. Overlaid isochrones using stellar population synthesis models show that the color-magnitude diagram of that region has the signature of an old (12 Gyr), metal-poor (${\\rm Fe/H}\\approx-2.0$) stellar population at a tentative distance of 60 kpc, evidently the same heliocentric distance as the Bo\\\"otes dwarf. We estimate the new object to have a total magnitude of $M_{V}\\sim-3.1\\pm1.1$ mag and a half-light radius of $r_{h}=4'.1\\pm1'.6$ ($72\\pm28$ pc) placing it in an apparent $40<r_{h}<100$ pc void between globular clusters and dwarf galaxies, occupied only by another recently discovered Milky Way Satellite, Coma Berenices. ", "machine_text": "  We present a new low-mass satellite of the Milky Way, discovered by the Gaia spacecraft. This object, which we name \"Bootes,\" has a Galactic orbit inclined at an angle of about 75 degrees to the plane of the Galactic disk, and it has a peculiar velocity of about 200 km/s, almost three times that of the Local Standard of Rest. This velocity is similar to that of the recently discovered satellite Leo, but unlike that object, Bootes has a proper motion of about 10 mas/yr, which means that it has not yet been gravitationally bound by the Galaxy and thus is a free satellite. We estimate that Bootes has a mass of about 10^5 solar masses (M_{\u26ab}\u22c5R\u2081\u2080 \u2248 2.4 kpc$^{-1}$), a value that is not only similar to Leo's but also to that of the Large and Small Magellanic Clouds. We discuss the possibility that Bootes, like Leo, may be a dwarf spheroidal satellite, but we also point out that its large peculiar velocity and relatively large proper motion imply a different dynamical history from that of Leo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Oscillation thresholds for \"strinking outwards\" reeds coupled to a\n  resonator. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4242, "human_text": "  This paper considers a \"striking outwards\" reed coupled to a resonator. This expression, due to Helmholtz, is not discussed here : it corresponds to the most common model of a lip-type valve, when the valve is assumed to be a one degree of freedom oscillator. The presented work is an extension of the works done by Wilson and Beavers (1974), Tarnopolsky (2000). The range of the playing frequencies is investigated. The first results are analytical : when no losses are present in the resonator, it is proven that the ratio between the threshold frequency and the reed resonance frequency is found to be necessarily within the interval between unity and the square root of 3. This is a musical sixth. Actually the interval is largely smaller, and this is in accordance with e.g. the results by Cullen et al.. The smallest blowing pressure is found to be directly related to the quality factor of the reed. Numerical results confirm these statements, and are discussed in comparison with previous ones by Cullen et al (2000). ", "machine_text": " We consider the effect of a resonator on the transient response of a flexible cantilever \"strinking outwards\" reed. The transient response is a superposition of the oscillations of the reed and the resonator. We show that the transient response can be described by two different ways, depending on the relative magnitude of the natural frequency of the reed and that of the resonator. If the natural frequency of the resonator is much smaller than that of the reed, the transient response can be described by a single wavelength of the reed's natural frequency. If the resonator's natural frequency is not much smaller than that of the reed, the transient response is a superposition of the waveforms of the two natural frequencies, with a beat frequency given by the difference between the two natural frequencies. We evaluate the threshold value of the resonator's natural frequency for which the transient response switches from the single-wavelength description to the superposition description. We show that this threshold is given by the condition that the resonator's natural frequency is equal to twice the reed's natural frequency. We also derive a simple expression for the magnitude of the beat frequency in the superposition description.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observations towards early-type stars in the ESO-POP survey: II --\n  searches for intermediate and high velocity clouds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1315, "human_text": "  We present CaII K and TiII optical spectra of early-type stars taken mainly from the UVES Paranal Observatory Project, plus HI 21-cm spectra from the Vila-Elisa and Leiden-Dwingeloo surveys, which are employed to obtain distances to intermediate and high velocity clouds. HI emission at a velocity of -117 km/s towards the sightline HD 30677 with NHI=1.7x10^19 cm-2 has no corresponding CaII K absorption, which has a signal-to-noise (S/N) ratio of 610. The star has a spectroscopically determined distance of 2.7-kpc, and hence sets this as a firm lower distance limit towards Anti-Centre cloud ACII. Towards another sightline (HD 46185), HI at +122 km/s and NHI=1.2x10^19 cm-2 is seen. The CaII K spectrum has a S/N = 780, although no absorption is observed at the cloud velocity. This similarly places a firm lower distance limit of 2.9-kpc towards this parcel of gas that may be an intermediate velocity cloud. The lack of intermediate velocity (IV) CaII K absorption towards HD 196426 at a S/N = 500 reinforces a lower distance limit of 700-pc towards this part of Complex gp, where NHI is 1.1x10^19 cm-2 and velocity is +78 km/s. Additionally, no IV CaII K is seen in absorption in the spectrum of HD 19445, which is strong in HI with NHI=8x10^19 cm-2 at -42 km/s, placing a firm although uninteresting lower distance limit of 39-pc to this part of IV South. Finally, no HV CaII K absorption is seen towards HD 115363 at a S/N = 410, placing a lower distance of 3.2-kpc towards the HVC gas at velocity of +224 km/s and NHI=5.2x10^19 cm-2. This gas is in the same region of the sky as complex WE (Wakker 2001), but at higher velocities. The non-detection of CaII K absorption sets a lower distance of 3.2-kpc towards the HVC, which is unsurprising if this feature is indeed related to the Magellanic System. ", "machine_text": "  We present the second part of a two-part study of the gas content of 29 bright early-type stars in the solar neighbourhood, selected from the ESO Proper Motion Survey (ESO-POP). The first part, containing the results of a high-resolution molecular line survey, was published in ApJ 532, 951 (2000). In this part we present a systematic search for intermediate and high velocity clouds using absorption lines of the CO molecule. We find that four of our stars (including the Sun) are clearly associated with such clouds. In the case of two of these clouds, the association is very strong, and the clouds are probably part of the Local Bubble. We find that the CO lines are rather weak and uncertain, and we were unable to identify clouds around several of the stars with strong molecular hydrogen lines. We discuss our non-detections in the light of various models, and suggest that (i) a substantial fraction of early-type stars may be associated with high-velocity clouds, (ii) these clouds may be relatively small, and (iii) high-resolution molecular line surveys are probably the best way to search for such clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ray-tracing and physical-optics analysis of the aperture efficiency in a\n  radio telescope. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3379, "human_text": "  The performance of telescope systems working at microwave or visible/IR wavelengths is typically described in terms of different parameters according to the wavelength range. Most commercial ray tracing packages have been specifically designed for use with visible/IR systems and thus, though very flexible and sophisticated, do not provide the appropriate parameters to fully describe microwave antennas, and thus to compare with specifications. In this work we demonstrate that the Strehl ratio is equal to the phase efficiency when the apodization factor is taken into account. The phase efficiency is the most critical contribution to the aperture efficiency of an antenna, and the most difficult parameter to optimize during the telescope design. The equivalence between the Strehl ratio and the phase efficiency gives the designer/user of the telescope the opportunity to use the faster commercial ray-tracing software to optimize the design. We also discuss the results of several tests performed to check the validity of this relationship that we carried out using a ray-tracing software, ZEMAX and a full Physical Optics software, GRASP9.3, applied to three different telescope designs that span a factor of $\\simeq 10 in terms of D/lambda. The maximum measured discrepancy between phase efficiency and Strehl ratio varies between $\\simeq 0.4 and 1.9 up to an offset angle of >40 beams, depending on the optical configuration, but it is always less than 0.5 where the Strehl ratio is >0.95. ", "machine_text": "  We present a ray-tracing and physical-optics analysis of the aperture efficiency in a radio telescope. We derive an analytical expression for the aperture efficiency in terms of the optical path length. We obtain a good agreement between our analytical expression and previously published results obtained by other methods. Our derivation is based on a physical-optics analysis of the wave propagation in the telescope. We obtain the distribution of the optical path length in the telescope by ray-tracing. We use this distribution in our physical-optics analysis. We confirm the validity of our approach by comparing our results with previously published results obtained by other methods. We also present a simple and accurate expression for the relative aperture efficiency as a function of the optical path length in the case of a telescope with a single dish. Our expression for the relative aperture efficiency can be easily used to calculate the signal-to-noise ratio in a radio telescope as a function of the optical path length.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spinons and triplons in spatially anisotropic frustrated\n  antiferromagnets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2012, "human_text": "  The search for elementary excitations with fractional quantum numbers is a central challenge in modern condensed matter physics. We explore the possibility in a realistic model for several materials, the spin-1/2 spatially anisotropic frustrated Heisenberg antiferromagnet in two dimensions. By restricting the Hilbert space to that expressed by exact eigenstates of the Heisenberg chain, we derive an effective Schr\\\"odinger equation valid in the weak interchain-coupling regime. The dynamical spin correlations from this approach agree quantitatively with inelastic neutron measurements on the triangular antiferromagnet Cs_2CuCl_4. The spectral features in such antiferromagnets can be attributed to two types of excitations: descendents of one-dimensional spinons of individual chains, and coherently propagating \"triplon\" bound states of spinon pairs. We argue that triplons are generic features of spatially anisotropic frustrated antiferromagnets, and arise because the bound spinon pair lowers its kinetic energy by propagating between chains. ", "machine_text": "  We investigate the relation between the spin- and triplet-flavor of massive ( Nuevaola-BO1957 and Heisenberg-OULAMP ) and massless ( ABENGOA-DELGADO-OLIVA-RODRIGUEZ-VAZQUEZ-CUENCA ) triplons in spatially anisotropic frustrated antiferromagnets. The formalism is based on the notion of tripletons (or triplons) and spinons, which are respectively the massive and massless excitation associated with the triplet and spin degrees of freedom of the magnetic system. We show that the triplon-spinon correspondence is different in a frustrated antiferromagnet than in a regular one, due to the appearance of exotic massive and massless excitations, named here massive and massless triplons, in the thermodynamic limit. In particular, the massive triplon is a genuinely massive excitation, while the massless triplon is a genuine massless excitation, but with a finite lifetime. We show further that the lifetime of the massless triplon is related to the dynamical properties of the spin degree of freedom, in contrast to the massless spinon, for which this degree of freedom is always frozen.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A general approach to statistical modeling of physical laws:\n  nonparametric regression. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0089, "human_text": "  Statistical modeling of experimental physical laws is based on the probability density function of measured variables. It is expressed by experimental data via a kernel estimator. The kernel is determined objectively by the scattering of data during calibration of experimental setup. A physical law, which relates measured variables, is optimally extracted from experimental data by the conditional average estimator. It is derived directly from the kernel estimator and corresponds to a general nonparametric regression. The proposed method is demonstrated by the modeling of a return map of noisy chaotic data. In this example, the nonparametric regression is used to predict a future value of chaotic time series from the present one. The mean predictor error is used in the definition of predictor quality, while the redundancy is expressed by the mean square distance between data points. Both statistics are used in a new definition of predictor cost function. From the minimum of the predictor cost function, a proper number of data in the model is estimated. ", "machine_text": " We introduce a general approach to statistical modeling of physical laws based on nonparametric regression. The approach is motivated by the fact that the process of scientific discovery often involves identifying a relationship between physical quantities and then quantitatively characterizing the relationship. We focus on regression-based methods because they are well-suited for exploring nonlinear relationships and because they are used extensively in statistics to model data. Our approach is general and can be applied to any system in which the quantities of interest can be measured experimentally. We demonstrate the effectiveness of our approach by applying it to three problems in physics: (1) we show how to use regression to learn the functional form of an unknown physical law from data, (2) we show how to use regression to fit a physical law to data in a way that reduces the impact of noise on the resulting fit, and (3) we show how to use regression to identify a physical law that describes a data set, even when the form of the physical law is not known in advance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the merging timescale of luminous red galaxies, or, where\n  do all the halos go?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.052, "human_text": "  In the LCDM cosmology dark matter halos grow primarily through the accretion of smaller halos. Much of the mass in a halo of 10^14Msun comes in through accretion of ~10^13Msun halos. If each such halo hosted one luminous red galaxy (LRG) then the accretion of so many halos is at odds with the observed number of LRGs in clusters unless these accreted LRGs merge or disrupt on relatively short timescales (~2Gyr). These timescales are consistent with classical dynamical friction arguments, and imply that 2-3 LRGs have merged or disrupted within each halo more massive than 10^14Msun by z=0. The total amount of stellar mass brought into these massive halos by z=0 is consistent with observations once the intracluster light (ICL) is included. If disrupted LRGs build up the ICL, then the hierarchical growth of massive halos implies that a substantial amount of ICL should also surround satellite LRGs, as suggested by recent observations of the Virgo cluster. Finally, we point out that these results are entirely consistent with a non-evolving clustering strength and halo occupation distribution, and note that observations of the latter in fact support the hypothesis that merging/disruption of massive galaxies does indeed take place at late times. ", "machine_text": "  We present a simple model of the evolution of Luminous Red Galaxies (LRGs) that simultaneously addresses several outstanding issues in the study of this galaxy population, including the question of whether the population is old or young, and the origin of the distinctive morphologies of LRG galaxies. The model consists of a semi-realistic galaxy formation and evolution model coupled with a simple model of LRG formation based on the virialization of massive gas clouds. The model is used to investigate the merging history of LRG galaxies, and in particular, the time since the last major merger. We find that the observed merging timescales are consistent with the predicted merging timescales based on our simple model, except for a few extreme cases. This provides strong evidence that the merging history of LRG galaxies is not different from that of galaxies in general, despite the distinctive morphologies of LRG galaxies. We also use the model to investigate the relation between the mass of the nuclear bulge and the merging timescale, and find that a simple relation is consistent with observations, suggesting that massive nuclear bulges form as a consequence of a major merger. The model has several testable predictions, and suggests several possible ways in which future work can further constrain the merging history of LRG galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Carrier-carrier entanglement and transport resonances in semiconductor\n  quantum dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2312, "human_text": "  We study theoretically the entanglement created in a scattering between an electron, incoming from a source lead, and another electron bound in the ground state of a quantum dot, connected to two leads. We analyze the role played by the different kinds of resonances in the transmission spectra and by the number of scattering channels, into the amount of quantum correlations between the two identical carriers. It is shown that the entanglement between their energy states is not sensitive to the presence of Breit-Wigner resonances, while it presents a peculiar behavior in correspondence of Fano peaks: two close maxima separated by a minimum, for a two-channel scattering, a single maximum for a multi-channel scattering. Such a behavior is ascribed to the different mechanisms characterizing the two types of resonances. Our results suggest that the production and detection of entanglement in quantum dot structures may be controlled by the manipulation of Fano resonances through external fields. ", "machine_text": "  We investigate the role of carrier-carrier entanglement and transport resonances in the transport properties of semiconductor quantum dots. We consider a spherical quantum dot attached to the leads, which are attached to the substrates, and a finite-sized quantum dot in a similar configuration, which are placed in a disorder bath. We found that both quantum dots can be in an entanglement-induced negative-temperature state below a certain critical temperature, and the state is very stable against temperature variations. We also found the finite-sized quantum dot to be in a state with very long coherence time, and the dynamics in this state is completely different from the coherent state with low entanglement. We show that these results can be explained by a simple model, in which a certain number of carriers are 'trapped' at the dot-lead interface and their spatial distribution is influenced by entanglement and transport resonances. We also derived a simple formula for the entanglement-induced negative-temperature state. Our results provide a route to engineer non-trivial states in quantum dot systems by using carrier-carrier entanglement and transport resonances.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dyson Indices and Hilbert-Schmidt Separability Functions and\n  Probabilities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3723, "human_text": "  A confluence of numerical and theoretical results leads us to conjecture that the Hilbert-Schmidt separability probabilities of the 15- and 9-dimensional convex sets of complex and real two-qubit states (representable by 4 x 4 density matrices rho) are 8/33 and 8/17, respectively. Central to our reasoning are the modifications of two ansatze, recently advanced (quant-ph/0609006), involving incomplete beta functions B_{nu}(a,b), where nu= (rho_{11} rho_{44})/(rho_{22} rho_{33}). We, now, set the separability function S_{real}(nu) propto B_{nu}(nu,1/2},2) =(2/3) (3-nu) sqrt{nu}. Then, in the complex case -- conforming to a pattern we find, manifesting the Dyson indices (1, 2, 4) of random matrix theory-- we take S_{complex}(nu) propto S_{real}^{2} (nu). We also investigate the real and complex qubit-qutrit cases. Now, there are two Bloore ratio variables, nu_{1}= (rho_{11} rho_{55})(rho_{22} rho_{44}), nu_{2}= (rho_{22} rho_{66})(rho_{33} rho_{55}), but they appear to remarkably coalesce into the product, eta = nu_1 nu_2 = rho_{11} \\rho_{66}}{\\rho_{33} \\rho_{44}}, so that the real and complex separability functions are again univariate in nature. ", "machine_text": "  We study two different approaches to nonlinear estimation for Gaussian noise data. The first approach is based on the use of the Dyson indices, and the second approach is based on the use of Hilbert-Schmidt separability functions and the theory of probability. The motivation for the research is that the use of indices and functions in this way allows us to estimate the parameters of the nonlinear system with the minimum amount of computation. In addition, these approaches are naturally suited to be implemented on a computer. The key idea in the research is the use of the properties of the different types of indices and functions. The methodology used is to consider different possible ways of using the indices and functions, and to evaluate the performance of each method by using simulation. The results obtained are that both approaches can be used to estimate the parameters of the nonlinear system with a small amount of computation, and that the use of the indices is more suitable for systems with a small number of parameters, while the use of the functions is more suitable for systems with a large number of parameters. The problem that the work attempts to solve is to find a way to estimate the parameters of a nonlinear system with a small amount of computation, and the work provides a solution to this problem. The practical application of the work is that it provides a way to estimate the parameters of a nonlinear system with a small amount of computation. The theoretical application of the work is that it provides a way to understand the relationship between the indices and the functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Challenging the Cosmological Constant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1977, "human_text": "  We outline a dynamical dark energy scenario whose signatures may be simultaneously tested by astronomical observations and laboratory experiments. The dark energy is a field with slightly sub-gravitational couplings to matter, a logarithmic self-interaction potential with a scale tuned to $\\sim 10^{-3} {\\rm eV}$, as is usual in quintessence models, and an effective mass $m_\\phi$ influenced by the environmental energy density. Its forces may be suppressed just below the current bounds by the chameleon-like mimicry, whereby only outer layers of mass distributions, of thickness $1/m_\\phi$, give off appreciable long range forces. After inflation and reheating, the field is relativistic, and attains a Planckian expectation value before Hubble friction freezes it. This can make gravity in space slightly stronger than on Earth. During the matter era, interactions with nonrelativistic matter dig a minimum close to the Planck scale. However, due to its sub-gravitational matter couplings the field will linger away from this minimum until the matter energy density dips below $\\sim 10^{-12} {\\rm eV}^4$. Then it starts to roll to the minimum, driving a period of cosmic acceleration. Among the signatures of this scenario may be dark energy equation of state $w \\ne -1$, stronger gravity in dilute mediums, that may influence BBN and appear as an excess of dark matter, and sub-millimeter corrections to Newton's law, close to the present laboratory limits. ", "machine_text": "  We present a cosmological model that challenges the need for a cosmological constant in a universe with a flat space-time. Our model comprises a modified Einstein-Maxwell-Chern-Weinberg action with a cosmological constant that is absent from the dynamics, thus making the evolution of space-time effectively homeless. We show that this model is capable of producing the large-scale structure of the universe observed today, including the cosmic microwave background radiation, the large-scale galaxy distribution, and the cosmic hydrogen abundance, without the need for a cosmological constant or any other ad-hoc mechanism. We also show that the model can produce a broad range of small-scale structure, including the power spectrum of galaxies, galaxy spin-trails, and the distribution of intergalactic hydrogen, without recourse to a scale-invariant cosmological constant or any other ad-hoc mechanism. We show that the model's dynamics is driven by a combination of the ad-hoc cosmological constant and the dynamics of the Einstein-Maxwell-Chern-Weinberg action, which results in a universe that is scale-invariant and therefore free from the scale- hierarchies that appear in the data. Our model thus provides a simple and elegant explanation for the origin of the large-scale structure of the universe and the small-scale structure within it, without the need for a cosmological constant or any other ad-hoc mechanism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Low-temperature and high-temperature approximations for\n  penetrable-sphere fluids. Comparison with Monte Carlo simulations and\n  integral equation theories. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1069, "human_text": "  The two-body interaction in dilute solutions of polymer chains in good solvents can be modeled by means of effective bounded potentials, the simplest of which being that of penetrable spheres (PSs). In this paper we construct two simple analytical theories for the structural properties of PS fluids: a low-temperature (LT) approximation, that can be seen as an extension to PSs of the well-known solution of the Percus-Yevick (PY) equation for hard spheres, and a high-temperature (HT) approximation based on the exact asymptotic behavior in the limit of infinite temperature. Monte Carlo simulations for a wide range of temperatures and densities are performed to assess the validity of both theories. It is found that, despite their simplicity, the HT and LT approximations exhibit a fair agreement with the simulation data within their respective domains of applicability, so that they complement each other. A comparison with numerical solutions of the PY and the hypernetted-chain approximations is also carried out, the latter showing a very good performance, except inside the core at low temperatures. ", "machine_text": "  We develop low-temperature and high-temperature approximations for the statistical mechanic of fluids composed of penetrable spheres. Theseapproximations are shown to capture the essential features of the system, and are used to study the transition from the low-temperature to the high-temperaturephase. A simple model in which the radius of the spheres is taken to be proportional to the thermal length is used to determine the dynamic structure factor andthe specific heat. The accuracy of the low-temperature approximation is shown to be very good, provided that the thermal length is not too small. The high-temperatureapproximation is less accurate, but is still useful for fluids with very large thermal lengths. The low-temperature approximation is used to derive an integral equationfor the dynamic structure factor. The high-temperature approximation is used to obtain a simplified version of this integral equation. Both integral equations are shownto be in good agreement with Monte Carlo simulations, over a wide range of volume fractions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy dependence of jet transport parameter and parton saturation in\n  quark-gluon plasma. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1352, "human_text": "  We study the evolution and saturation of the gluon distribution function in the quark-gluon plasma as probed by a propagating parton and its effect on the computation of jet quenching or transport parameter $\\hat{q}$. For thermal partons, the saturation scale $Q^2_s$ is found to be proportional to the Debye screening mass $\\mu_D^2$. For hard probes, evolution at small $x=Q^2_s/6ET$ leads to jet energy dependence of $\\hat{q}$. We study this dependence for both a conformal gauge theory in weak and strong coupling limit and for (pure gluon) QCD. The energy dependence can be used to extract the shear viscosity $\\eta$ of the medium since $\\eta$ can be related to the transport parameter for thermal partons in a transport description. We also derive upper bounds on the transport parameter for both energetic and thermal partons. The later leads to a lower bound on shear viscosity-to-entropy density ratio which is consistent with the conjectured lower bound $\\eta/s\\geq 1/4\\pi$. We also discuss the implications on the study of jet quenching at the BNL Relativistic Heavy Ion Collider and the CERN Large Hadron Collider and the bulk properties of the dense matter. ", "machine_text": " We investigate the energy dependence of the transport parameter and the phenomenon of parton saturation in relativistic heavy ion collisions from the point of view of a simplified microscopic model. The model consists of a lattice with a quark-gluon plasma (QGP) and a thermalized gas of lorentzian fragments, both interacting with each other and with the lattice. The model is analyzed by a numerical solution of the resulting Boltzmann equation. The energy dependence of the transport parameter is in qualitative agreement with the data of the Heavy Ion Russia (HIR) Collaboration, although our approach does not take into account the energy dependent QGP evolution and the strong anisotropy of the collisional dynamics. We show that the energy dependence of the transport parameter can be well described by a power law with an index of about 2.5. Our results for the saturation effect are in agreement with the HIR data, if the energy dependent evolution of the QGP is included in the description. We find that the anisotropy of the collisional dynamics is a crucial factor to describe the energy dependence of the transport parameter.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: J/psi Production in an Equilibrating Partonic System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0668, "human_text": "  Any color singlet or octet ccbar pair is created at short distances and then expands to a full size of J/psi. Such a dynamical evolution process is included here in calculations for the J/psi number distribution as a function of transverse momentum and rapidity in central Au-Au collisions at both RHIC and LHC energies. The ccbar pairs are produced in the initial collision and in the partonic system during the prethermal and thermal stages through the partonic channels ab to ccbar [{2S+1}L_J] and ab to ccbar [{2S+1}L_J]x, and then they dissociate in the latter two stages. Dissociation of ccbar in the medium occurs via two reactions: (a) color singlet ccbar plus a gluon turns to color octet ccbar, (b) color octet ccbar plus a gluon persists as color octet. There are modest yields of ccbar in the prethermal stage at RHIC energy and through the reactions ab to ccbar [{2S+1}L_J] at LHC energy for partons with large average momentum in the prethermal stage at both collider energies and in the thermal stage at LHC energy. Production from the partonic system competes with the suppression of the initial yield in the deconfined medium. Consequently, a bulge within -1.5<y<1.5 has been found for the J/psi number distribution and the ratio of J/psi number distributions for Au-Au collisions to nucleon-nucleon collisions. This bulge is caused by the partonic system and is thus an indicator of a deconfined partonic medium. Based on this result we suggest the rapidity region worth measuring in future experiments at RHIC and LHC to be -3<y<3. ", "machine_text": " We study the production of J/psi mesons in an equilibrating partonic system with the help of a particle-to-hole conversion model. The basic assumption of the model is that the partonic system can be represented by a one-particle picture and that the massless quarkonia are produced by a  radial-node conversion mechanism. The model has several parameters that can be adjusted to fit the data. The most important one is the ratio of the momentum transfer to the kinetic energy, which is related to the phase transition between the hadronization and the equilibration stages. The other parameters include the magnitude of the P-factor and the annihilation cross section of the quarkonia. By fitting the model to the data of J/psi meson production in  ultraperipheral collisions of  heavy ions we find that the parameter values are consistent with the model prediction that the equilibrating partonic system is mainly composed of a single (on-shell) parton and that the annihilation of quarkonia is a  very fast process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fifteen Years of High-Resolution Radio Imaging of Supernova 1987A. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0057, "human_text": "  Supernova 1987A in the Large Magellanic Cloud provides a spectacularly detailed view of the aftermath of a core-collapse explosion. The supernova ejecta initially coasted outward at more than 10% of the speed of light, but in 1990 were observed to decelerate rapidly as they began to encounter dense circumstellar material expelled by the progenitor star. The resulting shock has subsequently produced steadily brightening radio synchrotron emission, which is resolved by the Australia Telescope Compact Array (ATCA) into an expanding limb-brightened shell. Here we present 15 years of ATCA imaging of Supernova 1987A, at an effective angular resolution of 0.4 arcsec. We find that the radio remnant has accelerated in its expansion over this period, from approx 3600 km/s in 1992 to approx 5200 km/s at the end of 2006. The published diameters of the evolving X-ray shell have been ~15% smaller than the corresponding radio values, but a simultaneous Fourier analysis of both radio and X-ray data eliminates this discrepancy, and yields a current diameter for the shell in both wave-bands of approx 1.7 arcsec. An asymmetric brightness distribution is seen in radio images at all ATCA epochs: the eastern and western rims have higher fluxes than the northern and southern regions, indicating that most of the radio emission comes from the equatorial plane of the system, where the progenitor star's circumstellar wind is thought to be densest. The eastern lobe is brighter than and further from the supernova site than the western lobe, suggesting an additional asymmetry in the initial distribution of supernova ejecta. ", "machine_text": "  We present high-resolution (\u03bb/D \u223c 100\u20131000) radio images of the superbubble surrounding the supernova (SN) 1987A. These images show the superbubble in great detail, including many features that were not previously visible at lower resolutions. The superbubble is asymmetric, with a large-scale lobe extending east-northeastward for \u223c 70 pc and a second, smaller-scale lobe extending north-northwestward for \u223c 35 pc. A number of small-scale structures are visible within the superbubble, including a prominent north-south-oriented chain of 3\u20134 arcminute-scale knots. We have found three new jets, bringing the total number of jets in the superbubble to nine. The sources of these jets are not the surviving companion star but instead are likely to be either accretion shock regions or the outer surface of the remnant stellar core. Two of the new jets are north-south-oriented and are collimated along magnetic field lines. The third jet is unique in that it is not collimated but instead is a bipolar flow with a complex structure. We have identified three regions of possible X-ray emission within the superbubble, although none of these regions is spatially coincident with the radio sources. The most likely explanation for the X-ray emission is the interaction of the superbubble with the ambient interstellar medium. We have derived a total mass for the superbubble of \u223c 5  \u00d7 10 36 grams, \u223c 1.4 times the mass of the Sun. This is the most accurate mass estimate to date. The mass is comprised of a inner-bubble region with a higher density and a much lower total mass than the outer superbubble region. We discuss several mechanisms that may have driven the evolution of the superbubble and estimate the rate of mass loss from the superbubble. We find that the mass loss is likely to have been dominated by two-body interactions and that the rate of mass loss has decreased considerably over the past 15 years.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the circumstellar SiO maser emission in R Leo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0682, "human_text": "  The study of the innermost circumstellar layers around AGB stars is crucial to understand how these envelopes are formed and evolve. The SiO maser emission occurs at a few stellar radii from the central star, providing direct information on the stellar pulsation and on the chemical and physical properties of these regions. Our data also shed light on several aspects of the SiO maser pumping theory that are not well understood yet. We aim to determine} the relative spatial distribution of the 43 GHz and 86 GHz SiO maser lines in the oxygen-rich evolved star R Leo. We have imaged with milliarcsecond resolution, by means of Very Long Baseline Interferometry, the 43 GHz (28SiO v=1, 2 J=1-0 and 29SiO v=0 J=1-0) and 86 GHz (28SiO v=1 J=2-1 and 29SiO v=0 J=2-1) masing regions. We confirm previous results obtained in other oxygen-rich envelopes. In particular, when comparing the 43 GHz emitting regions, the 28SiO v=2 transition is produced in an inner layer, closer to the central star. On the other hand, the 86 GHz line arises in a clearly farther shell. We have also mapped for the first time the 29SiO v=0 J=1-0 emission in R Leo. The already reported discrepancy between the observed distributions of the different maser lines and the theoretical predictions is also found in R Leo. ", "machine_text": "  We present an analysis of the spatial distribution of the 43 GHz and 86 GHz SiO maser lines in the oxygen-rich evolved star R Leo. Our data confirm the presence of a maser spot, which we associate with a spatial accumulation of SiO, likely in a region of high density. We show that this spot is stable on timescales of years, as it must be to explain previous observations, but that its location is not fixed with respect to the stellar position, as has been suggested. Instead, it precesses around the star with a timescale that is roughly two orders of magnitude longer than the orbital period. We derive a simple model in which this precession is caused by the gravitational influence of a massive companion, and we use this model to constrain the masses of the two stars to be 1.95 $M_{\\odot}$ and 1.1 $M_{\\odot}$. This is consistent with the known masses of the main star and its companion, but we have no evidence that this is the correct model: other explanations, such as a migrating spot or a bipolar configuration, are also consistent with the data. We have also measured for the first time the 43 GHz maser line in the companion, but detected no significant emission at 86 GHz.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Pseudogap and charge density waves in two dimensions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1544, "human_text": "  An interaction between electrons and lattice vibrations (phonons) results in two fundamental quantum phenomena in solids: in three dimensions it can turn a metal into a superconductor whereas in one dimension it can turn a metal into an insulator. In two dimensions (2D) both superconductivity and charge-density waves (CDW) are believed to be anomalous. In superconducting cuprates, critical transition temperatures are unusually high and the energy gap may stay unclosed even above these temperatures (pseudogap). In CDW-bearing dichalcogenides the resistivity below the transition can decrease with temperature even faster than in the normal phase and a basic prerequisite for the CDW, the favourable nesting conditions (when some sections of the Fermi surface appear shifted by the same vector), seems to be absent. Notwithstanding the existence of alternatives to conventional theories, both phenomena in 2D still remain the most fascinating puzzles in condensed matter physics. Using the latest developments in high-resolution angle-resolved photoemission spectroscopy (ARPES) here we show that the normal-state pseudogap also exists in one of the most studied 2D examples, dichalcogenide 2H-TaSe2, and the formation of CDW is driven by a conventional nesting instability, which is masked by the pseudogap. Our findings reconcile and explain a number of unusual, as previously believed, experimental responses as well as disprove many alternative theoretical approaches. The magnitude, character and anisotropy of the 2D-CDW pseudogap are intriguingly similar to those seen in superconducting cuprates. ", "machine_text": "  We study pseudogap and charge density wave (CDW) phases in a model Hamiltonian for a two-dimensional (2D) lattice system with long-range interactions. We show that the pseudogap phase is associated with a breakdown of the CDW instability. We consider a general class of lattice Hamiltonians which includes the cuprate and organic conductors as well as several model Hamiltonians for which the CDW instability has been studied before. Our results are consistent with the picture that the pseudogap is a phase in which the system is locally in a CDW state, but the long-range Coulomb interactions are strong enough to destroy the global CDW order. The transition temperature to the pseudogap phase is found to be proportional to the square of the Coulomb interaction strength. We also found a strong dependence on the lattice structure, which indicates that the pseudogap phase is related to a disordered CDW state.   Pseudogap and charge density waves in two dimensions, , arXiv:cond-mat/0703.0353v1, 3 Aug. 2007.  We study pseudogap and charge density wave (CDW) phases in a model Hamiltonian for a two-dimensional (2D) lattice system with long-range interactions. We show that the pseudogap phase is associated with a breakdown of the CDW instability. We consider a general class of lattice Hamiltonians which includes the cuprate and organic conductors as well as several model Hamiltonians for which the CDW instability has been studied before. Our results are consistent with the picture that the pseudogap is a phase in which the system is locally in a CDW state, but the long-range Coulomb interactions are strong enough to destroy the global CDW order. The transition temperature to the pseudogap phase is found to be proportional to the square of the Coulomb interaction strength. We also found a strong dependence on the lattice structure, which indicates that the pseudogap phase is related to a disordered CDW state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Detecting and Characterizing Planetary Systems with Transit Timing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0632, "human_text": "  In the coming decades, research in extrasolar planets aims to advance two goals: 1) detecting and characterizing low-mass planets increasingly similar to the Earth, and 2) improving our understanding of planet formation. We present a new planet detection method that is capable of making large advances towards both of these objectives and describe a modest network of telescopes that is able to make the requisite observations. In a system where a known planet transits its host star, a second planet in that system will cause the time between transits to vary. These transit timing variations can be used to infer the orbital elements and mass of the perturbing planet even if it has a mass that is smaller than the mass of the Earth. This detection technique complements other techniques because it is most sensitive in mean-motion resonances where, due to degeneracies, other techniques have reduced sensitivity. Small ground-based observatories have already exceeded the photometric precision necessary to detect sub-Earth mass planets. However, TTV planet searches are currently limited by the relatively small number of high-precision transit data and insufficient observing time on existing telescopes. These issues will be compounded as the number of known transiting planets suitable for TTV study will increase substantially in the near future. A relatively modest investment in a ground-based network of small ($\\sim 0.5 {\\rm m}$ telescopes could provide the needed coverage and so dramatically increase the effectiveness of transit timing observations. ", "machine_text": "  Detecting and Characterizing Planetary Systems with Transit Timing  We present a new method to detect planetary systems and to estimate the orbital elements and masses of the components thereof. We monitor the timing of transits of a star by its planet or planets. If the system is orbitally stable, the transit times will repeat with a high degree of accuracy. In a system with many planets, the method can also be used to estimate the masses of the planets. We present an analysis of the transit timing of the exoplanet system Kepler-36. We find that the masses of the two largest planets can be estimated to within a factor of 2, provided that the orbits are known to within 2%. We present a simple method to derive the orbits, which relies on the measurement of only two transits for a system containing three or more planets. For the Kepler-36 system, we show that this method is sufficiently precise to derive the masses of the two largest planets. We show that transit timing can be used to detect multi-planetary systems, and to estimate the masses of the planets therein.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Photon Dominated Region Modeling of Barnard 68. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0913, "human_text": "  We use the Barnard 68 dark globule as a test case for a spherically symmetric PDR model exposed to low-UV radiation fields. With a roughly spherical morphology and an accurately determined density profile, Barnard 68 is ideal for this purpose. The processes governing the energy balance in the cloud surface are studied in detail. We compare the spherically symmetric PDR model by Stoerzer, Stutzki & Sternberg (1996) to observations of the three lowest rotational transitions of 12CO, 13CO J = 2-1 and J = 3-2 as well as the [CI] 3P_1-3P_0 fine structure transition. We study the role of Polycyclic Aromatic Hydrocarbons (PAHs) in the chemical network of the PDR model and consider the impact of depletion as well as of a variation of the external FUV field. We find it difficult to simultaneously model the observed 12CO and 13CO emission. The 12CO and [CI] emission can be explained by a PDR model with a external FUV field of 1-0.75 chi_0, but this model fails to reproduce the observed 13CO by a factor of ~2. Adding PAHs to the chemical network increases the [CI] emission by 50% in our model but makes [CII] very faint. CO depletion only slightly reduces the 12CO and 13CO line intensity (by <10% and <20%, respectively). Predictions for the [CII] 2P_3/2-2P_1/2, [CI] 3P_2-3P_1 and 12CO J= 5-4 and 4-3 transitions are presented. This allows a test of our model with future observations (APEX, NANTEN2, HERSCHEL, SOFIA). ", "machine_text": "  The structure and evolution of the photon-dominated region (PDR) of Barnard 68 are investigated using a large suite of observations obtained with the Hubble Space Telescope. We find that the PDR has a complex and dynamic structure, with a bright rim and a series of bright knots along the inner edge. The PDR also shows a non-axisymmetric structure, with a bright bar-like feature along the west-west direction. We find that the PDR has a smoothly varying surface brightness, with a brightness distribution that is well described by a power law with a high power law index. The PDR has a total mass of 1.1 kpc $M_{\\rm gas}$, which is much larger than the half-light radius of 0.28 kpc. We show that a simple model in which the gas is treated as isothermal and homogenous can quantitatively reproduce the basic features of the PDR, but a more sophisticated model that takes into account the temperature distribution is needed to reproduce the complex structure of the inner edge. We also investigate the distribution of ionized gas in the PDR, and find that it is well described by a two-temperature model with a temperature ratio of 2.2, which is consistent with the predictions of simple theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Personalizing Image Search Results on Flickr. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1676, "human_text": "  The social media site Flickr allows users to upload their photos, annotate them with tags, submit them to groups, and also to form social networks by adding other users as contacts. Flickr offers multiple ways of browsing or searching it. One option is tag search, which returns all images tagged with a specific keyword. If the keyword is ambiguous, e.g., ``beetle'' could mean an insect or a car, tag search results will include many images that are not relevant to the sense the user had in mind when executing the query. We claim that users express their photography interests through the metadata they add in the form of contacts and image annotations. We show how to exploit this metadata to personalize search results for the user, thereby improving search performance. First, we show that we can significantly improve search precision by filtering tag search results by user's contacts or a larger social network that includes those contact's contacts. Secondly, we describe a probabilistic model that takes advantage of tag information to discover latent topics contained in the search results. The users' interests can similarly be described by the tags they used for annotating their images. The latent topics found by the model are then used to personalize search results by finding images on topics that are of interest to the user. ", "machine_text": "  Personalizing Image Search Results on Flickr  We present an algorithm to personalize image search results on Flickr. We identify four factors that affect users' interaction with search results: visual features of images, textual features of captions and tags, the user's search history, and the social context of the user and the image. We then present a series of experiments to evaluate the impact of these factors on users' engagement with search results. Our experiments use a combination of controlled crowdsourced experiments on Amazon Mechanical Turk and analysis of user data from the Flickr search engine. We find that (1) there is no single dominant factor that improves engagement with search results; (2) personalized search results that take into account multiple factors can be significantly better than the non-personalized results; and (3) there exist \"best\" combinations of factors for different types of queries. We discuss the practical and theoretical implications of our work, and future research directions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Estimation of experimental data redundancy and related statistics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0162, "human_text": "  Redundancy of experimental data is the basic statistic from which the complexity of a natural phenomenon and the proper number of experiments needed for its exploration can be estimated. The redundancy is expressed by the entropy of information pertaining to the probability density function of experimental variables. Since the calculation of entropy is inconvenient due to integration over a range of variables, an approximate expression for redundancy is derived that includes only a sum over the set of experimental data about these variables. The approximation makes feasible an efficient estimation of the redundancy of data along with the related experimental information and information cost function. From the experimental information the complexity of the phenomenon can be simply estimated, while the proper number of experiments needed for its exploration can be determined from the minimum of the cost function. The performance of the approximate estimation of these statistics is demonstrated on two-dimensional normally distributed random data. ", "machine_text": "  Motivation We present a new methodology for the estimation of the number of hidden factors in experimental data, based on the principles of information theory. Our approach is different from previous methods in three important aspects: (i) it is applicable to datasets of arbitrary size, (ii) it is not dependent on any specific model, and (iii) it provides a natural way to assess the amount of information in the data and to detect and quantify experimental noise. Application to a genetic dataset We demonstrate the efficacy of our new methodology by applying it to a real dataset of gene expression measurements in which we seek to uncover the true number of hidden factors that explain the observed variation in the data. Our analysis shows that the true number of factors is likely to be much smaller than the number of variables in the data, suggesting that a large proportion of the variation may be due to experimental noise. We show how our method can be used to detect and quantify this noise, and to identify the most informative features in the data. Conclusion Our new methodology for the estimation of experimental data redundancy is broadly applicable to any type of data and any size dataset, and provides a natural way to assess the amount of information in the data and to detect and quantify experimental noise. We demonstrate the efficacy of our approach by applying it to a real dataset of gene expression measurements, and show that our method is able to identify the most informative features in the data and to detect and quantify experimental noise.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: VLBI observations of nineteen GHz-Peaked-Spectrum radio sources at 1.6\n  GHz. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.031, "human_text": "  Aims and Methods: We present the results of VLBI observations of nineteen GHz-Peaked-Spectrum (GPS) radio sources at 1.6 GHz. Of them, 15 sources are selected from the Parkes Half Jansky (PHJ) sample (Snellen 2002), 4 others are from our previous observation list. We aimed at imaging the structure of GPS sources, searching for Compact Symmetric Objects (CSOs) and studying the absorption for the convex radio spectra of GPS sources.   Results: We obtained total intensity 1.6 GHz VLBI images of 17 sources for the first time. Of them, 80% show mini-double-lobe radio structure, indicating that they are CSOs or candidates, and their host AGNs could be edge-on to us. This result suggests that there is a high incidence of mini double-lobe sources (or CSOs) in the PHJ sample. The sources J0323+0534, J1135-0021, J1352+0232, J2058+0540, J2123-0112 and J2325-0344 with measured redshift, showing double-lobe structure with sizes of <1 kpc, are classified as CSOs. Three sources J1057+0012, J1600-0037 and J1753+2750 are considered as core-jet sources according to their morphologies and flux variability. ", "machine_text": " We present very long baseline interferometry (VLBI) observations of the nineteen GHz-Peaked-Spectrum ( nineteen GPS) radio sources at 1.6 GHz. We observed twenty-one of the thirty-nine known sources in the 1.6 GHz band, and detected twelve of them. We found that the GPS sources in the 1.6 GHz band are much less bright than in the 3.5 GHz band, but their spectral indices are, in general, flatter. We determined the angular sizes of the detected sources, and found that they are generally larger than those detected in the 3.5 GHz band. We estimated the thermal centroids of the sources, and compared the directions of the optical and radio centroids. We found that the optical and radio centroids are not coincident, but are offset by 6 \u00b1 1 arcsec on average. The offset does not show any correlation with the optical or radio brightness, or with the spectral index of the radio source. We also found that the fraction of the radio source's flux contributed by the thermal emission is 5-10%. We discuss the results in the framework of a model in which the GPS sources are the relics of a thermal filament, and the non-coincidence of the centroids is explained by the fact that the optical and radio filaments are not exactly parallel.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Intervening Metal Systems in GRB and QSO sight-lines: The Mgii and Civ\n  Question. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0706, "human_text": "  Prochter et al. 2006 recently found that the number density of strong intervening 0.5<z<2 MgII absorbers detected in gamma-ray burst (GRB) afterglow spectra is nearly 4 times larger than in QSO spectra. We have conducted a similar study using CIV absorbers. Our CIV sample, consisting of a total of 20 systems, is drawn from 3 high resolution and high to moderate S/N VLT/UVES spectra of 3 long-duration GRB afterglows, covering the redshift interval 1.6< z<3.1. The column density distribution and number density of this sample do not show any statistical difference with the same quantities measured in QSO spectra. We discuss several possibilities for the discrepancy between CIV and MgII absorbers and conclude that a higher dust extinction in the MgII QSO samples studied up to now would give the most straightforward solution. However, this effect is only important for the strong MgII absorbers. Regardless of the reasons for this discrepancy, this result confirms once more that GRBs can be used to detect a side of the universe that was unknown before, not necessarily connected with GRBs themselves, providing an alternative and fundamental investigative tool of the cosmic evolution of the universe. ", "machine_text": "  We present a simple method to estimate the galaxy number density in the disk of our Milky Way by counting galaxies in an annulus in the direction of the Galactic Rim. Our galaxy census is based on a high signal-to-noise ratio galaxy redshift survey performed with the 6.5 m Magellan Telescopes and covers the redshift range 0.155 < z_gal < 1.33. We find a number density of 2.7 \u00b1 0.9 galaxies per square degree, which translates into an intergalactic volume filling factor of \u03b7_V = 1.9 \u00b1 1.4%. This result is in good agreement with previous estimates based on the 2 Micron All-Sky Survey and with a semi-analytic model of galaxy formation. Our high signal-to-noise ratio data also allow us to study the distribution of galaxies in the Galactic halo. We find that the observed distribution is consistent with a galactic fountain model with a radial galaxy number density that increases smoothly with distance from the Galactic disk before declining abruptly at large distances. The radial galaxy number density is well described by a power law with an index of -1.3 \u00b1 0.2. We have searched for strong galaxy-galaxy lensing in the same survey data. We find three candidates, but none of them could be confirmed by further analysis. We also present a new method to estimate the distance to the Galactic Center based on the position of the sunlit side of the disk. We find that this method produces a distance to the Galactic Center that is in good agreement with other independent measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum spin liquid states in the two dimensional kagome\n  antiferromagnets, ZnxCu4-x(OD)6Cl2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2279, "human_text": "  A three-dimensional system of interacting spins typically develops static long-range order when it is cooled. If the spins are quantum (S = 1/2), however, novel quantum paramagnetic states may appear. The most highly sought state among them is the resonating valence bond (RVB) state in which every pair of neighboring quantum spins form entangled spin singlets (valence bonds) and the singlets are quantum mechanically resonating amongst all the possible highly degenerate pairing states. Here we provide experimental evidence for such quantum paramagnetic states existing in frustrated antiferromagnets, ZnxCu4-x(OD)6Cl2, where the S = 1/2 magnetic Cu2+ moments form layers of a two-dimensional kagome lattice. We find that in Cu4(OD)6Cl2, where distorted kagome planes are weakly coupled to each other, a dispersionless excitation mode appears in the magnetic excitation spectrum below ~ 20 K, whose characteristics resemble those of quantum spin singlets in a solid state, known as a valence bond solid (VBS), that breaks translational symmetry. Doping nonmagnetic Zn2+ ions reduces the distortion of the kagome lattice, and weakens the interplane coupling but also dilutes the magnetic occupancy of the kagome lattice. The VBS state is suppressed and for ZnCu3(OD)6Cl2 where the kagome planes are undistorted and 90% occupied by the Cu2+ ions, the low energy spin fluctuations in the spin liquid phase become featureless. ", "machine_text": "  We have performed a systematic study of the magnetic properties of the two-dimensional (2D) Kagome antiferromagnets, ZnxCu4-x(OD)6Cl2 (x = 0.4, 0.6, 0.8, and 1). The 0.4 < x < 0.6 compounds are the first 2D antiferromagnets that host quantum spin liquid (QSL) states, which are robust against large magnetic fields and temperatures. The 0.4 < x < 0.6 compounds are also the first 2D antiferromagnets that host QSL states with Ising-like (Fg = 2) and dimer-like (Fg = 1) interactions. We have identified three types of QSL states in the 0.4 < x < 0.6 compounds: a thermodynamically stable state in the absence of a magnetic field, a state that is induced by a magnetic field and is thermodynamically stable when the field is removed, and a state that is induced by a magnetic field but is not thermodynamically stable when the field is removed. We have also investigated the effect of a large magnetic field on the QSL states by changing the x value in the 0.4 < x < 0.6 compounds. Our results suggest that the x value has a strong effect on the types of QSL states that are present in the 0.4 < x < 0.6 compounds. We have also performed a systematic study of the magnetic properties of the 2D Kagome antiferromagnet, Zn0.6Cu0.4(OD)6Cl2, in order to determine the effect of a large magnetic field on the QSL states. Our results suggest that the QSL states in this compound are less stable than the QSL states in the 0.4 < x < 0.6 compounds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Extraction of Freshwater and Energy from Atmosphere. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2571, "human_text": "  Author offers and researches a new, cheap method for the extraction of freshwater from the Earth atmosphere. The suggected method is fundamentally dictinct from all existing methods that extract freshwater from air. All other industrial methods extract water from a saline water source (in most cases from seawater). This new method may be used at any point in the Earth except Polar Zones. It does not require long-distance freshwater transportation. If seawater is not utilized for increasing its productivity, this inexpensive new method is very environment-friendly. The author method has two working versions: (1) the first variant the warm (hot) atmospheric air is lifted by the inflatable tube in a high altitude and atmospheric steam is condenced into freswater: (2) in the second version, the warm air is pumped 20-30 meters under the sea-surface. In the first version, wind and solar heating of air are used for causing air flow. In version (2) wind and propeller are used for causing air movment.   The first method does not need energy, the second needs a small amount. Moreover, in variant (1) the freshwater has a high pressure (>30 or more atm.) and can be used for production of energy such as electricity and in that way the freshwater cost is lower. For increasing the productivity the seawater is injected into air and solar air heater may be used. The solar air heater produces a huge amount of electricity as a very powerful electricity generation plant. The offered electricity installation in 100 - 200 times cheaper than any common electric plant of equivalent output.   Key words: Extraction freshwater, method of getting freshwater, receiving energy from atmosphere, powerful renewal electric plant. ", "machine_text": "  Title: Extraction of Freshwater and Energy from Atmosphere  Motivation:  The motivation of this work is to explore the possibility of extracting freshwater and energy from the atmosphere. The increasing demand for freshwater and energy, along with the limitations of traditional resources, have made it necessary to explore alternative sources.  Key ideas and methodology:  The key idea of this work is to use a combination of solar energy and atmospheric water to produce freshwater and energy. The method involves using solar energy to power a water desalination process, which produces freshwater and salt. The salt is then used as a fuel to produce energy, which can be used to power the desalination process.  The methodology for this work involves the design and construction of a solar-powered desalination system, which uses salt as a fuel to produce energy. The system is designed to be efficient and cost-effective, and to produce a high yield of freshwater and energy.  Results obtained:  The results of this work show that it is possible to extract freshwater and energy from the atmosphere using a combination of solar energy and atmospheric water. The system designed and constructed for this work was found to be effective in producing freshwater and energy, and to be efficient and cost-effective.  Problem this work attempts to solve:  The problem this work attempts to solve is the increasing demand for freshwater and energy, and the limitations of traditional resources.  Practical or theoretical applications from findings or implications for future research:  The practical applications of this work include the potential for the system designed and constructed for this work to be used to produce freshwater and energy on a large scale. The theoretical applications of this work include the potential for the use of atmospheric water as a renewable resource for the production of freshwater and energy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Millimeter dust continuum emission unveiling the true mass of giant\n  molecular clouds in the Small Magellanic Cloud. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3257, "human_text": "  CO observations have been so far the best way to trace molecular gas in external galaxies, but at low metallicity the gas mass deduced could be largely underestimated. At present, the kinematic information of CO data cubes are used to estimate virial masses and trace the total mass of the molecular clouds. Millimeter dust emission can also be used as a dense gas tracer and could unveil H2 envelopes lacking CO. These different tracers must be compared in different environments. This study compares virial masses to masses deduced from millimeter emission, in two GMC samples: the local molecular clouds in our Galaxy and their equivalents in the Small Magellanic Cloud (SMC), one of the nearest low metallicity dwarf galaxy. In our Galaxy, mass estimates deduced from millimeter emission are consistent with masses deduced from gamma ray analysis and trace the total mass of the clouds. Virial masses are systematically larger (twice on average) than mass estimates from millimeter dust emission. This difference decreases toward high masses and has already been reported in previous studies. In the SMC however, molecular cloud masses deduced from SIMBA millimeter observations are systematically higher (twice on average for conservative values of the dust to gas ratio and dust emissivity) than the virial masses from SEST CO observations. The observed excess can not be accounted for by any plausible change of dust properties. Taking a general form for the virial theorem, we show that a magnetic field strength of ~15 micro Gauss in SMC clouds could provide additional support to the clouds and explain the difference observed. Masses of SMC molecular clouds have therefore been underestimated so far. Magnetic pressure may contribute significantly to their support. ", "machine_text": " We present the results of a far-infrared dust continuum survey of the Small Magellanic Cloud (SMC), aimed at assessing the relative masses of its giant molecular clouds (GMCs) by means of the dust-to-gas ratio. Our analysis benefits from the unique combination of high angular resolution and sensitivity provided by single-dish telescopes operating at millimeter wavelengths. We found that the dust-to-gas ratios of the SMC's main GMCs are, on average, 5-10% of the values found in the Milky Way's Galactic globular clusters. This result challenges the traditional assumption that these clouds are dominated by molecular hydrogen and suggests that a significant fraction of the gas in these clouds is in the form of dust. We discuss this result in the context of recent theoretical work that suggests a strong correlation between the mass of a molecular cloud and the rate at which it forms stars. Our findings suggest that the physical conditions that regulate the conversion of gas to dust may have a strong influence on the star formation rate in molecular clouds, potentially explaining the wide range of star formation rates observed in galactic and extragalactic molecular clouds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Determination of Low-Energy Parameters of Neutron--Proton Scattering on\n  the Basis of Modern Experimental Data from Partial-Wave Analyses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1024, "human_text": "  The triplet and singlet low-energy parameters in the effective-range expansion for neutron--proton scattering are determined by using the latest experimental data on respective phase shifts from the SAID nucleon--nucleon database. The results differ markedly from the analogous parameters obtained on the basis of the phase shifts of the Nijmegen group and contradict the parameter values that are presently used as experimental ones. The values found with the aid of the phase shifts from the SAID nucleon--nucleon database for the total cross section for the scattering of zero-energy neutrons by protons, $\\sigma_{0}=20.426 $b, and the neutron--proton coherent scattering length, $f=-3.755 $fm, agree perfectly with the experimental cross-section values obtained by Houk, $\\sigma_{0}=20.436\\pm 0.023 $b, and experimental scattering-length values obtained by Houk and Wilson, $f=-3.756\\pm 0.009 $fm, but they contradict cross-section values of $\\sigma_{0}=20.491\\pm 0.014 $b according to Dilg and coherent-scattering-length values of $f=-3.7409\\pm 0.0011 $fm according to Koester and Nistler. ", "machine_text": " We have developed a new method for the determination of low-energy parameters of neutron\u2013proton (n\u2013p) scattering on the basis of modern experimental data from partial-wave analyses. The main idea of the method is to use the information on the n\u2013p scattering in the partial-wave regime to determine the width of the dominant partial wave, the so-called partial-wave width (PWW). We show that, in the framework of the Einstein\u2013Bohr theory, the PWW is related to the width of the p-wave resonance in the scattering amplitude. Therefore, the PWW can be determined from the analysis of the experimental data on the p-wave intensity in the partial-wave regime. We demonstrate that this method does not require the assumption of a small parameter, which describes the p-wave contribution to the total cross section in the partial-wave regime. Hence, our method can be used to determine the PWW in the case of a large p-wave contribution to the total cross section. We show that our method is equivalent to the common method based on the analysis of the structure functions in the partial-wave regime. We also discuss the limitations of the method and the cases in which our method can give a reliable result, while the method based on the structure functions can fail.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Towards an Explicit Model of D-brane Inflation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.036, "human_text": "  We present a detailed analysis of an explicit model of warped D-brane inflation, incorporating the effects of moduli stabilization. We consider the potential for D3-brane motion in a warped conifold background that includes fluxes and holomorphically-embedded D7-branes involved in moduli stabilization. Although the D7-branes significantly modify the inflaton potential, they do not correct the quadratic term in the potential, and hence do not cause a uniform change in the slow-roll parameter eta. Nevertheless, we present a simple example based on the Kuperstein embedding of D7-branes, z_1=constant, in which the potential can be fine-tuned to be sufficiently flat for inflation. To derive this result, it is essential to incorporate the fact that the compactification volume changes slightly as the D3-brane moves. We stress that the compactification geometry dictates certain relationships among the parameters in the inflaton Lagrangian, and these microscopic constraints impose severe restrictions on the space of possible models. We note that the shape of the final inflaton potential differs from projections given in earlier studies: in configurations where inflation occurs, it does so near an inflection point. Finally, we comment on the difficulty of making precise cosmological predictions in this scenario. This is the companion paper to arXiv:0705.3837. ", "machine_text": " We propose a model of D-brane inflation based on the idea that a D-brane is a boundary of a \"membrane\" that has an interior bulk region, and the bulk region \"warps\" in a manner that is controlled by the three-form curvature. This allows us to formulate the model in terms of an explicit bulk function that describes the warping of the bulk region. This formulation has several advantages. First, the bulk function describes a single, continuous, and explicit function, which can be more intuitive and more tractable analytically than the convention of treating the bulk as a disjoint sum of different bulk regions. Second, this approach is better suited for exploring the connection between D-brane inflation and higher-dimensional bulk inflation. In particular, we show that the bulk function has the structure of a three-form, which relates the D-brane inflation to higher-dimensional bulk inflation. Third, we show that the bulk function is related to the geometry of a D-brane particle, and in particular, to its four- momentum, which allows us to formulate the bulk function as the four-momentum of a D-brane particle. This provides a framework for incorporating the dynamics of D-brane particles into the model. We explore several aspects of the model, including the behavior of the bulk function, the evolution of the D-brane particles, and the interactions of the D-brane particles with each other and with the bulk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 3D Radiative Hydrodynamics for Disk Stability Simulations: A Proposed\n  Testing Standard and New Results. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2532, "human_text": "  Recent three-dimensional radiative hydrodynamics simulations of protoplanetary disks report disparate disk behaviors, and these differences involve the importance of convection to disk cooling, the dependence of disk cooling on metallicity, and the stability of disks against fragmentation and clump formation. To guarantee trustworthy results, a radiative physics algorithm must demonstrate the capability to handle both the high and low optical depth regimes. We develop a test suite that can be used to demonstrate an algorithm's ability to relax to known analytic flux and temperature distributions, to follow a contracting slab, and to inhibit or permit convection appropriately. We then show that the radiative algorithm employed by Meji\\'a (2004) and Boley et al. (2006) and the algorithm employed by Cai et al. (2006) and Cai et al. (2007, in prep.) pass these tests with reasonable accuracy. In addition, we discuss a new algorithm that couples flux-limited diffusion with vertical rays, we apply the test suite, and we discuss the results of evolving the Boley et al. (2006) disk with this new routine. Although the outcome is significantly different in detail with the new algorithm, we obtain the same qualitative answers. Our disk does not cool fast due to convection, and it is stable to fragmentation. We find an effective $\\alpha\\approx 10^{-2}$. In addition, transport is dominated by low-order modes. ", "machine_text": "  We present 3D radiative hydrodynamics codes for optically thick environments developed in two independent programming languages, Jameson (JAM) and Fortran (FHR), suitable for numerical studies of stellar disk stability. We focus on the physical basis and numerical implementations of the radiative transfer and hydrodynamic solvers in both codes. We propose a standard testing protocol which we use to compare the two codes with a view to checking the numerical stability and accuracy of the radiative transfer solutions in the presence of non-negligible velocity fields, in both simple cases and more realistic scenarios. We discuss the impact of different physical  parametrizations on the numerical solutions, with a particular view to the stability of axisymmetric turbulence. We present new results in the form of global scalings for the temperature and density fluctuations in axisymmetric turbulence, which we compare with previous 1D results. We find that the inclusion of a non-negligible radiative transfer, in addition to the hydrodynamic contributions, significantly alters the shape of the fluctuation spectrum, with a stantial increase in the variance of the temperature field, while the density variance is only slightly increased.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamics of interacting Brownian particles: a diagrammatic formulation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3645, "human_text": "  We present a diagrammatic formulation of a theory for the time dependence of density fluctuations in equilibrium systems of interacting Brownian particles. To facilitate derivation of the diagrammatic expansion we introduce a basis that consists of orthogonalized many-particle density fluctuations. We obtain an exact hierarchy of equations of motion for time-dependent correlations of orthogonalized density fluctuations. To simplify this hierarchy we neglect contributions to the vertices from higher-order cluster expansion terms. An iterative solution of the resulting equations can be represented by diagrams with three and four-leg vertices. We analyze the structure of the diagrammatic series for the time-dependent density correlation function and obtain a diagrammatic interpretation of reducible and irreducible memory functions. The one-loop self-consistent approximation for the latter function coincides with mode-coupling approximation for Brownian systems that was derived previously using a projection operator approach. ", "machine_text": "  We consider the dynamics of interacting Brownian particles in a viscous fluid, with an external driving force that may also be a Brownian motion. We develop a diagrammatic formulation of the problem in terms of a single master variable related to the average velocity of the particles. We then solve this formulation to obtain an analytical expression for the evolution of the master variable, which can be regarded as a 'hydrodynamic limit' of the dynamics of the system. The results obtained show that this formulation is capable of describing several different aspects of the dynamics of the system, and has several interesting and important applications. In particular, we show that a generalized Fisher information metric can be constructed from the solution of the master equation, and that this metric has a simple form in the limit of small Reynolds number. We also show that the master variable has a simple and general expression in terms of a kinetic energy, which is a generalization of the usual kinetic energy of the particles. This allows us to derive a generalized dynamics for the system, which includes a term that arises from the interaction between the particles, and which is an analog of the classical correlation function. We analyze this term and show that it has several interesting and important properties, which are related to the behavior of the system as a whole, rather than to the behavior of individual particles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relaxation of a dewetting contact line Part 1: A full-scale hydrodynamic\n  calculation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3576, "human_text": "  The relaxation of a dewetting contact line is investigated theoretically in the so-called \"Landau-Levich\" geometry in which a vertical solid plate is withdrawn from a bath of partially wetting liquid. The study is performed in the framework of lubrication theory, in which the hydrodynamics is resolved at all length scales (from molecular to macroscopic). We investigate the bifurcation diagram for unperturbed contact lines, which turns out to be more complex than expected from simplified 'quasi-static' theories based upon an apparent contact angle. Linear stability analysis reveals that below the critical capillary number of entrainment, Ca_c, the contact line is linearly stable at all wavenumbers. Away from the critical point the dispersion relation has an asymptotic behaviour sigma~|q| and compares well to a quasi-static approach. Approaching Ca_c, however, a different mechanism takes over and the dispersion evolves from |q| to the more common q^2. These findings imply that contact lines can not be treated as universal objects governed by some effective law for the macroscopic contact angle, but viscous effects have to be treated explicitly. ", "machine_text": " We present a full-scale calculation of the hydrodynamic interactions in a dewetting contact line. The calculation is based on a three-dimensional (3D) representation of the fluid flow in the contact line, in contrast to the conventional two-dimensional (2D) description. We solve the 3D flow equation with the 3D contact line interface in a vertically averaged system. The resulting equation is a quasilinear elliptic equation with a singular boundary condition on the contact line. We solve this equation by an alternating direction implicit (ADI) method. To validate the calculation, we compare the results with those obtained from a 2D calculation. We find that the 3D calculation predicts a contact angle smaller than the one obtained from the 2D calculation. The difference between the 3D and 2D predictions increases with the ratio of the wetting layer thickness to the contact radius. Our 3D calculation also predicts a dewetting contact line velocity that is smaller than the one obtained from the 2D calculation. We discuss these differences and their physical origins.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Jet-disturbed molecular gas near the Seyfert 2 nucleus in M51. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0947, "human_text": "  Previous molecular gas observations at arcsecond-scale resolution of the Seyfert 2 galaxy M51 suggest the presence of a dense circumnuclear rotating disk, which may be the reservoir for fueling the active nucleus and obscures it from direct view in the optical. However, our recent interferometric CO(3-2) observations show a hint of a velocity gradient perpendicular to the rotating disk, which suggests a more complex structure than previously thought. To image the putative circumnuclear molecular gas disk at sub-arcsecond resolution to better understand both the spatial distribution and kinematics of the molecular gas. We carried out CO(2-1) and CO(1-0) line observations of the nuclear region of M51 with the new A configuration of the IRAM Plateau de Bure Interferometer, yielding a spatial resolution lower than 15 pc. The high resolution images show no clear evidence of a disk, aligned nearly east-west and perpendicular to the radio jet axis, as suggested by previous observations, but show two separate features located on the eastern and western sides of the nucleus. The western feature shows an elongated structure along the jet and a good velocity correspondence with optical emission lines associated with the jet, suggesting that this feature is a jet-entrained gas. The eastern feature is elongated nearly east-west ending around the nucleus. A velocity gradient appears in the same direction with increasingly blueshifted velocities near the nucleus. This velocity gradient is in the opposite sense of that previously inferred for the putative circumnuclear disk. Possible explanations for the observed molecular gas distribution and kinematics are that a rotating gas disk disturbed by the jet, gas streaming toward the nucleus, or a ring with another smaller counter- or Keplarian-rotating gas disk inside. ", "machine_text": "  We present multiwavelength observations of the jet-disturbed molecular gas near the Seyfert 2 nucleus in M51. We combine far-infrared data from the Herschel Space Telescope with submillimeter data from the SCUBA-2 camera on the James Clerk Maxwell Telescope to reveal the distribution of molecular gas, in order to better understand the relationship between the nuclear starburst and the infalling molecular clouds. We find that the bulk of the molecular gas is not contained within the galactic plane, but is instead distributed in a large, off-plane region. The gas in this region is not gravitationally bound to the galaxy and is potentially available to be accreted by the M51 nucleus. We further find that this gas is heated by a non-nuclear source, most likely an oblique jet arising from the nuclear starburst. The gas is cooled as it flows towards the plane, forming a wake behind the jet. We explain this cooling in terms of a simple model in which the gas is cooled by the expanding bubble of the heated gas, similar to the way in which the density and temperature of a gas is reduced when it is inflated inside a balloon. This model provides a natural explanation for the cooling of the gas and the lack of strong far-infrared emission from the gas in the plane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Glimpsing through the high redshift neutral hydrogen fog. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1053, "human_text": "  We analyze the transmitted flux in a sample of 17 QSOs spectra at 5.74<zem<6.42 to obtain tighter constraints on the volume-averaged neutral hydrogen fraction, xHI, at z~6. We study separately the narrow transmission windows (peaks) and the wide dark portions (gaps) in the observed absorption spectra. By comparing the statistics of these spectral features with Lyalpha forest simulations, we conclude that xHI evolves smoothly from 10^{-4.4} at z=5.3 to 10^{-4.2} at z=5.6, with a robust upper limit xHI<0.36 at z=6.3. The frequency and physical sizes of the peaks imply an origin in cosmic underdense regions and/or in HII regions around faint quasars or galaxies. In one case (the intervening HII region of the faint quasar RD J1148+5253 at z=5.70 along the LOS of SDSS J1148+5251 at z=6.42) the increase of the peak spectral density is explained by the first-ever detected transverse proximity effect in the HI Lyalpha forest; this indicates that at least some peaks result from a locally enhanced radiation field. We then obtain a strong lower limit on the foreground QSO lifetime of tQ>11 Myr. The observed widths of the peaks are found to be systematically larger than the simulated ones. Reasons for such discrepancy might reside either in the photoionization equilibrium assumption or in radiative transfer effects. ", "machine_text": " We present a study of a large sample of galaxies in the COSMOS field, selected to be nearly invisible in the observed optical and NIR bands, with the aim of gleaning information about the properties of the galaxies and the intergalactic medium in which they are embedded. We find that the galaxies in the sample are, on average, twice as massive as galaxies in the local volume, but have a luminosity and star formation rate typical of galaxies in the local volume. The observed distribution in redshift space is well described by a model in which the volume density of the neutral intergalactic medium varies inversely with the square of the redshift. This indicates that the high-redshift universe is significantly opaque to hydrogen radiation. We show that this is consistent with a model in which the intergalactic medium consists of a small number of very dense regions, embedded in a large volume of relatively empty space, and suggest that the high-redshift intergalactic medium may consist of a small number of relatively massive filaments. We discuss the implications of this finding for galaxy formation at high redshift.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Profinite complexes of curves, their automorphisms and anabelian\n  properties of moduli stacks of curves. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0859, "human_text": "  Let ${\\cal M}_{g,[n]}$, for $2g-2+n>0$, be the D-M moduli stack of smooth curves of genus $g$ labeled by $n$ unordered distinct points. The main result of the paper is that a finite, connected \\'etale cover ${\\cal M}^\\l$ of ${\\cal M}_{g,[n]}$, defined over a sub-$p$-adic field $k$, is \"almost\" anabelian in the sense conjectured by Grothendieck for curves and their moduli spaces.   The precise result is the following. Let $\\pi_1({\\cal M}^\\l_{\\ol{k}})$ be the geometric algebraic fundamental group of ${\\cal M}^\\l$ and let ${Out}^*(\\pi_1({\\cal M}^\\l_{\\ol{k}}))$ be the group of its exterior automorphisms which preserve the conjugacy classes of elements corresponding to simple loops around the Deligne-Mumford boundary of ${\\cal M}^\\l$ (this is the \"$\\ast$-condition\" motivating the \"almost\" above). Let us denote by ${Out}^*_{G_k}(\\pi_1({\\cal M}^\\l_{\\ol{k}}))$ the subgroup consisting of elements which commute with the natural action of the absolute Galois group $G_k$ of $k$. Let us assume, moreover, that the generic point of the D-M stack ${\\cal M}^\\l$ has a trivial automorphisms group. Then, there is a natural isomorphism: $${Aut}_k({\\cal M}^\\l)\\cong{Out}^*_{G_k}(\\pi_1({\\cal M}^\\l_{\\ol{k}})).$$ This partially extends to moduli spaces of curves the anabelian properties proved by Mochizuki for hyperbolic curves over sub-$p$-adic fields. ", "machine_text": "  We give a survey of the results on profinite complexes of curves, their automorphisms, and anabelian properties of moduli stacks of curves, with an eye towards applications to the study of higher-level stacks.   The motivation for this work is the geometric and topological properties of moduli stacks of curves in the projective plane, which were extensively studied by S. Abu-Shammala, A. Blumental, P. Grothendieck, J. Kristler, and M. Kac. We focus on the tools and methods used to study these properties. In particular, we present a description of the category of profinite complexes of curves in terms of marked pleats on an affine plane-curve, and show that it is equivalent to the category of profinite complexes of constructive sheaves on a curve. We also show that the category of profinite complexes of constructive sheaves on a curve is isomorphic to the category of profinite complexes of constructive sheaves on a complete interlocked domain.   As an application of these results, we show that the anabelian properties of moduli stacks of curves are closely related to the anabelian properties of constructive sheaves on a curve. In particular, we show that the category of constructive sheaves on a curve is an abelian category, and that the tensor product of constructive sheaves on a curve is isomorphic to the category of constructive sheaves on a complete interlocked domain.   We also show that the category of constructive sheaves on a curve is a full subcategory of the category of mixed modules for a relative Levi-Civita stereotype, and that the tensor product of constructive sheaves on a curve is isomorphic to the full subcategory of mixed modules for a relative Levi-Civita stereotype generated by constructive sheaves.   Finally, we show that the category of profinite complexes of constructive sheaves on a curve is equivalent to the category of profinite complexes of mixed modules for a relative Levi-Civita stereotype.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Neutrino Decays and Neutrino Electron Elastic Scattering in Unparticle\n  Physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0302, "human_text": "  Following Georgi's unparticle scheme, we examine the effective couplings between neutrinos and unparticle operators. As an immediate consequence, neutrinos become unstable and can decay into the unparticle stuff. Assuming the dimension transmutation scale is around $\\Lambda^{}_{\\cal U} \\sim 1 ~{\\rm TeV}$, we implement the cosmological limit on the neutrino lifetime to constrain the neutrino-unparticle couplings for different scaling dimensions $d$. In addition, provided that the electron-unparticle coupling is restricted due to the precise measurement of the anomalous magnetic moment of electron, we calculate the unparticle contribution to the neutrino-electron elastic scattering. It is more important to jointly deal with the couplings of the unparticle to the standard model particles rather than separately. Taking into account both electron- and neutrino-unparticle couplings, we find that the scaling dimension of the scalar unparticle should lie in the narrow range $1 < d < 2$ by requiring the observables to be physically meaningful. However, there is no consistent range of $d$ for the vector unparticle operator. ", "machine_text": " We give a microscopic derivation of theosaurus elastic scattering and neutrino decay in the framework of unparticle physics. The lorentz structure of the\u521d journeys is derived from the correlation functions of theAfrican Symposium structure. TheStudies elastic scattering and neutrino decay are described by the backward Matrix elements of the symposium Lorentz structures. We obtained the Diaries elastic scattering and neutrino decay equations in the framework of unparticle physics, and the corresponding flavors and the Speaker Sudra sectors are also obtained. Thenew elastic scattering and neutrino decay equations are more complicated than thestringy ones. We have solved theTransportation elastic scattering and neutrino decay equations in the framework of unparticle physics. The Transport literature elastic scattering and neutrino decay rates are obtained. The Transportelastic scattering and neutrino decay equations are solved in the framework of unparticle physics. The new elastic scattering and neutrino decay rates are obtained and compared with the stringy ones.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy Density-Flux Correlations in an Unusual Quantum State and in the\n  Vacuum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.197, "human_text": "  In this paper we consider the question of the degree to which negative and positive energy are intertwined. We examine in more detail a previously studied quantum state of the massless minimally coupled scalar field, which we call a ``Helfer state''. This is a state in which the energy density can be made arbitrarily negative over an arbitrarily large region of space, but only at one instant in time. In the Helfer state, the negative energy density is accompanied by rapidly time-varying energy fluxes. It is the latter feature which allows the quantum inequalities, bounds which restrict the magnitude and duration of negative energy, to hold for this class of states. An observer who initially passes through the negative energy region will quickly encounter fluxes of positive energy which subsequently enter the region. We examine in detail the correlation between the energy density and flux in the Helfer state in terms of their expectation values. We then study the correlation function between energy density and flux in the Minkowski vacuum state, for a massless minimally coupled scalar field in both two and four dimensions. In this latter analysis we examine correlation functions rather than expectation values. Remarkably, we see qualitatively similar behavior to that in the Helfer state. More specifically, an initial negative energy vacuum fluctuation in some region of space is correlated with a subsequent flux fluctuation of positive energy into the region. We speculate that the mechanism which ensures that the quantum inequalities hold in the Helfer state, as well as in other quantum states associated with negative energy, is, at least in some sense, already ``encoded'' in the fluctuations of the vacuum. ", "machine_text": " We present a quantum-optical scheme for generating a two-mode squeezed vacuum state with a prescribed energy density in one of the two modes. The scheme relies on a cross-gain modulation between a squeezed state of one color and a vacuum state of another color in a parametric amplifier. This approach is general and can be applied to any combination of frequencies for which a parametric amplifier with suitable nonlineity is available. We analyze the scheme in detail for the case of a yellow-green laser (frequency-doubled neodymium-yttrium-aluminium-garnet laser) and a red laser (HeNe laser). In this case, the cross-gain modulation is achieved by means of a Michelson interferometer with a Mach-Zehnder interferometer in one arm. We present a simple and general formula for the efficiency of the scheme as a function of the pump power and the interferometric settings. The efficiency can be made large by tuning the Michelson interferometer to obtain constructive interference in the parametric amplifier arm that contains the squeezed state. We also derive a simple formula for the energy flux in one of the two modes of the produced squeezed vacuum state. We analyze the formula and discuss the regime of parameter values in which the energy flux is finite. We finally present a simple formula for the energy density-flux product in the aforementioned regime. We show that this formula results in a unique value for the energy density-flux product in the squeezed vacuum state, which differs from the corresponding value in a classical vacuum state. We discuss possible physical meanings of this difference and its implications for the statistical properties of the vacuum state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is there Evidence for a Hubble bubble? The Nature of Type Ia Supernova\n  Colors and Dust in External Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0367, "human_text": "  We examine recent evidence from the luminosity-redshift relation of Type Ia Supernovae (SNe Ia) for the $\\sim 3 \\sigma$ detection of a ``Hubble bubble'' -- a departure of the local value of the Hubble constant from its globally averaged value \\citep{Jha:07}. By comparing the MLCS2k2 fits used in that study to the results from other light-curve fitters applied to the same data, we demonstrate that this is related to the interpretation of SN color excesses (after correction for a light-curve shape-color relation) and the presence of a color gradient across the local sample. If the slope of the linear relation ($\\beta$) between SN color excess and luminosity is fit empirically, then the bubble disappears. If, on the other hand, the color excess arises purely from Milky Way-like dust, then SN data clearly favors a Hubble bubble. We demonstrate that SN data give $\\beta \\simeq 2$, instead of the $\\beta \\simeq 4$ one would expect from purely Milky-Way-like dust. This suggests that either SN intrinsic colors are more complicated than can be described with a single light-curve shape parameter, or that dust around SN is unusual. Disentangling these possibilities is both a challenge and an opportunity for large-survey SN Ia cosmology. ", "machine_text": " We present a method for identifying and characterizing the regions surrounding galaxies which are responsible for the observed large-scale flows of galaxies in the local volume. We find a good agreement between the regions identified as responsible for the large-scale flows and those found to contain a large number of galaxies with colors similar to those of galaxies in the local volume. In addition, we find that the surface density of these regions increases in a way that is consistent with the observed large-scale flows. We also find that the local volume contains a large number of regions with high surface density and with colors similar to those of galaxies in the local volume, but that it does not contain regions with low surface density and with colors similar to those of galaxies in the local volume. This is consistent with the hypothesis that the local volume is contained within a large-scale structure, and that the large-scale flows observed in the local volume are due to the infall of matter from regions outside the local volume. We discuss several implications of our results for theories of structure formation and for the understanding of the large-scale structure of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantification of discreteness effects in cosmological N-body\n  simulations: II. Evolution up to shell crossing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3697, "human_text": "  We apply a recently developed perturbative formalism which describes the evolution under their self-gravity of particles displaced from a perfect lattice to quantify precisely, up to shell crossing, the effects of discreteness in dissipationless cosmological N-body simulations. We give simple expressions, explicitly dependent on the particle density, for the evolution of power in each mode as a function of red-shift. For typical starting red-shifts the effect of finite particle number is to {\\it slow down} slightly the growth of power compared to that in the fluid limit (e.g. by about ten percent at half the Nyquist frequency), and to induce also dispersion in the growth as a function of direction at a comparable level. In the limit that the initial red-shift tends to infinity, at fixed particle density, the evolution in fact diverges from that in the fluid limit (described by the Zeldovich approximation). Contrary to widely held belief, this means that a simulation started at a red-shift much higher than the red-shift of shell crossing actually gives a worse, rather than a better, result. We also study how these effects are modified when there is a small-scale regularization of the gravitational force. We show that such a smoothing may reduce the anisotropy of the discreteness effects, but it then {\\it increases} their average effect. This behaviour illustrates the fact that the discreteness effects described here are distinct from those usually considered in this context, due to two-body collisions. Indeed the characteristic time for divergence from the collisionless limit is proportional to $N^{2/3}$, rather than $N/ \\log N$ in the latter case. ", "machine_text": " We quantify the effects of discreteness in N-body simulations of the formation of dark matter haloes in a universe that evolves up to the formation of the first galaxy cluster. We consider a standard toy model of the evolution of the universe, with a parameter that allows us to tune the effects of discreteness. We vary this parameter to study the transition from a discrete to a continuous description of the evolution of the universe. We find that, in the limit of a small parameter, the discrete evolution is equivalent to the continuous one, apart from a contribution that we attribute to the particle horizon. We quantify this contribution and find that it is small for the volumes considered in the toy model. Therefore, we conclude that the discrete evolution of the matter distribution is not affected by the particle horizon, provided that the volume is large enough. We also show that the formation of structure is only slightly affected by the discreteness of the evolution, except for the first generations of haloes, where the effects can be significant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Product Formulae for Ozsvath-Szabo 4-manifold Invariants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0339, "human_text": "  We give formulae for the Ozsvath-Szabo invariants of 4-manifolds X obtained by fiber sum of two manifolds M_1, M_2 along surfaces S_1, S_2 having trivial normal bundle and genus g>0. The formulae follow from a general theorem on the Ozsvath-Szabo invariants of the result of gluing two 4-manifolds along a common boundary, which is phrased in terms of relative invariants of the pieces. These relative invariants take values in a version of Heegaard Floer homology with coefficients in modules over certain Novikov rings; the fiber sum formula follows from the theorem that this \"perturbed\" version of Heegaard Floer theory recovers the usual Ozsvath-Szabo invariants, when the 4-manifold in question has b^+>1. The construction allows an extension of the definition of the Ozsvath-Szabo invariants to 4-manifolds having b^+ = 1 depending on certain choices, in close analogy with Seiberg-Witten theory. The product formulae lead quickly to calculations of the Ozsvath-Szabo invariants of various 4-manifolds; in all cases the results are in accord with the conjectured equivalence between the Ozsvath-Szabo and Seiberg-Witten invariants. ", "machine_text": "  We give product formulae for the Ozsvath-Szabo 4-manifold invariants of 3- and 4-dimensional representations of Lie groups. We show that these formulae generalize in an appropriate manner the product formulae ofWCNextTheorem:If $G$ is a locally compact second countable group and $V$ is a finite dimensional representation of $G$ then there is a decomposition $V=\\oplus$ of irreducible representations of $G$. The isomorphism class of $V$ determines an equivalence class of $G$-signed locally compact second countable groups, up to a class of Trivial groups. The decomposition is unique up to equivalence and order. We prove the product formula for the Ozsvath-Szabo invariants of a finite dimensional representation of a locally compact second countable group in the following steps: (1) We give a product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n\\leq 4$. (2) We prove that the product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n\\leq 4$, holds also in the case when the dimension of the representation is $n>4$. (3) We prove that the product formula for the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in the case when the dimension of the representation is $n>4$, holds also in the case when the dimension of the representation is $n\\leq 4$. As an application, we give a description of the Ozsvath-Szabo 4-manifold invariants of a finite dimensional representation of a locally compact second countable group in terms of the canonical action of the group on the regular part of the representation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mid-Infrared Fine Structure Line Ratios in Active Galactic Nuclei\n  Observed with Spitzer IRS: Evidence for Extinction by the Torus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0547, "human_text": "  We present the first systematic investigation of the [NeV] (14um/24um) and [SIII] (18um/33um) infrared line flux ratios, traditionally used to estimate the density of the ionized gas, in a sample of 41 Type 1 and Type 2 active galactic nuclei (AGNs) observed with the Infrared Spectrograph on board Spitzer. The majority of galaxies with both [NeV] lines detected have observed [NeV] line flux ratios consistent with or below the theoretical low density limit, based on calculations using currently available collision strengths and ignoring absorption and stimulated emission. We find that Type 2 AGNs have lower line flux ratios than Type 1 AGNs and that all of the galaxies with line flux ratios below the low density limit are Type 2 AGNs. We argue that differential infrared extinction to the [NeV] emitting region due to dust in the obscuring torus is responsible for the ratios below the low density limit and we suggest that the ratio may be a tracer of the inclination angle of the torus to our line of sight. Because the temperature of the gas, the amount of extinction, and the effect of absorption and stimulated emission on the line ratios are all unknown, we are not able to determine the electron densities associated with the [NeV] line flux ratios for the objects in our sample. We also find that the [SIII] emission from the galaxies in our sample is extended and originates primarily in star forming regions. Since the emission from low-ionization species is extended, any analysis using line flux ratios from such species obtained from slits of different sizes is invalid for most nearby galaxies. ", "machine_text": " We present here the results of a study of the mid-infrared fine structure line ratios in 98 active galactic nuclei (AGN) observed with Spitzer IRS. The observations were made with the Multiband Imaging Photometer for Spitzer (MIPS) and the InfraRed Array Camera (IRAC), with an average sensitivity of 5sigma on an integration time of $\\sim30$ ks. The sample is complete for galaxies with $M_{\\rm gas} > 10^{10} M_{\\odot}$ and $10^{42} M_{\\odot} \\ year^{-1}$, with $L_{\\rm IR} > 10^{43}$ erg s$^{-1}$, and is almost complete for galaxies with $M_{\\rm gas} \\sim 10^{10}$ M$_{\\odot}$, $L_{\\rm IR} \\sim 10^{42}$ erg s$^{-1}$. We find that the fine structure line ratio $\\lambda_{\\rm rest} / \\lambda_{\\rm complex}$ is on average 1.5 +- 0.5. This is significantly different from the ratio of 1.0 predicted by simple models in which the line-forming region is assumed to be a uniform disc. The observed line ratio varies smoothly with both the ionization timescale and the black hole spin velocity. The standard deviation of the line ratio is $\\sim 0.6$. We show that simple models of a non-uniform line-forming region can explain the observations, provided that the line-forming region is either a flared torus or a disc with a hole at the centre. We discuss our results in the context of other observations of the ionization structure in AGN, and in terms of the size and density distribution of the line-forming region. We show that the simplest model that explains our observations is a flared torus with a hole at the centre, and we discuss the implications of this for future observations of this important region.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Information Rate of MIMO Systems with Finite Rate Channel State\n  Feedback and Power On/Off Strategy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2273, "human_text": "  This paper quantifies the information rate of multiple-input multiple-output (MIMO) systems with finite rate channel state feedback and power on/off strategy. In power on/off strategy, a beamforming vector (beam) is either turned on (denoted by on-beam) with a constant power or turned off. We prove that the ratio of the optimal number of on-beams and the number of antennas converges to a constant for a given signal-to-noise ratio (SNR) when the number of transmit and receive antennas approaches infinity simultaneously and when beamforming is perfect. Based on this result, a near optimal strategy, i.e., power on/off strategy with a constant number of on-beams, is discussed. For such a strategy, we propose the power efficiency factor to quantify the effect of imperfect beamforming. A formula is proposed to compute the maximum power efficiency factor achievable given a feedback rate. The information rate of the overall MIMO system can be approximated by combining the asymptotic results and the formula for power efficiency factor. Simulations show that this approximation is accurate for all SNR regimes. ", "machine_text": " We investigate the information rate of a multiple-input multiple-output (MIMO) system with a finite rate channel state information feedback and a power on/off strategy. We first derive a simple expression for the information rate, which turns out to be a special case of a general formula. The derived formula is valid for any number of transmit and receive antennas, provided that the channel state information feedback rate is greater than the number of transmit antennas. In addition, we show that in the case of a large number of antennas, the derived formula is also valid when the feedback rate is equal to the number of transmit antennas. In this case, we obtain the well-known diversity-multiplexing trade-off curve. We then propose a simple power on/off strategy that can achieve the same performance as the strategy that maximizing the information rate. The proposed strategy is to switch on the transmit antennas in turn, and to use the switched on antennas to send independent codewords. We analyze the proposed strategy by using the general formula for the information rate. We then show that the proposed strategy achieves the maximum information rate for any number of transmit and receive antennas, provided that the channel state information feedback rate is greater than the number of transmit antennas. In addition, we show that the proposed strategy achieves the maximum information rate when the feedback rate is equal to the number of transmit antennas, provided that the number of receive antennas is greater than the number of transmit antennas.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of two superconducting transitions in the specific heat of\n  PrOs$_4$Sb$_{12}$: Effects of crystal grinding. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4659, "human_text": "  Specific heat, dc- and ac-magnetic susceptibility are reported for a large single crystal of PrOs$_4$Sb$_{12}$ and, after grinding, its powder. The room temperature effective paramagnetic moment of the crystal was consistent with the Pr$^{3+}$ ionic configuration and full occupancy of the Pr-sublattice. The crystal showed two distinct anomalies in the specific heat and an overall discontinuity in $C/T$ of more than 1000 mJ/K$^2$mol. The upper transition (at $T_{c1}$) was rounded, in an agreement with previous reports. The anomaly at $T_{c2}$ was very sharp, consistent with a good quality of the crystal. We observed a shoulder in $\\chi$' and two peaks in $\\chi$'' below $T_{c1}$. However, there were no signatures in $\\chi$' of the lower temperature transition. PrOs$_4$Sb$_{12}$ is extremely sensitive to grinding, which suppresses the upper superconducting transition in both the specific heat and magnetic susceptibility. $\\Delta C/T_{c}$ was reduced to 140 mJ/K$^2$ mol in the powdered sample. Existing data on ground, polished, and sliced crystals suggests the existence of a length scale of order 100 $\\mu$, characterizing the higher temperature superconducting phase. ", "machine_text": " We have performed a systematic study of the evolution of the superconducting (SC) order parameter and critical magnetic field in PrOs$_4$Sb$_{12}$ by means of measurements of the specific heat. These were carried out on samples which had been ground to various degrees. We found that the critical magnetic field for the magnetic-field-induced SC transition increases with decreasing particle size, in spite of the fact that the magnetic susceptibility is depressed by the same effect. The nature of the two SC transitions in the specific heat is discussed in the framework of a simple model which takes into account the finite size of the particles and the formation of bound pairs. We show that the depression of the magnetic susceptibility has a different origin from the increase in the critical magnetic field for the magnetic-field-induced SC transition. We also found that the electrical resistivity shows a clear signature of the transition to the normal conducting state at the glass transition temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strongly modulated transmission of a spin-split quantum wire with local\n  Rashba interaction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0107, "human_text": "  We investigate the transport properties of ballistic quantum wires in the presence of Zeeman spin splittings and a spatially inhomogeneous Rashba interaction. The Zeeman interaction is extended along the wire and produces gaps in the energy spectrum which allow electron propagation only for spinors lying along a certain direction. For spins in the opposite direction the waves are evanescent far away from the Rashba region, which plays the role of the scattering center. The most interesting case occurs when the magnetic field is perpendicular to the Rashba field. Then, the spins of the asymptotic wavefunctions are not eigenfunctions of the Rashba Hamiltonian and the resulting coupling between spins in the Rashba region gives rise to sudden changes of the transmission probability when the Fermi energy is swept along the gap. After briefly examining the energy spectrum and eigenfunctions of a wire with extended Rashba coupling, we analyze the transmission through a region of localized Rashba interaction, in which a double interface separates a region of constant Rashba interaction from wire leads free from spin-orbit coupling. For energies slightly above the propagation threshold, we find the ubiquitous occurrence of transmission zeros (antiresonances) which are analyzed by matching methods in the one-dimensional limit. We find that a a minimal tight-binding model yields analytical transmission lineshapes of Fano antiresonance type. More general angular dependences of the external magnetic field is treated within projected Schroedinger equations with Hamiltonian matrix elements mixing wavefunction components. Finally, we consider a realistic quantum wire where the energy subbands are coupled via the Rashba intersubband coupling term and discuss its effect on the transmission zeros. ", "machine_text": "  We study a quantum wire with a local Rashba interaction that is subjected to a perpendicular magnetic field. The low-lying electronic states, which are completely spin-split in the absence of the field, become weakly or even strongly modulated as the field is increased. We show that this unusual effect is due to a competition between the local Rashba interaction and the magnetic field, which results in the appearance of an additional, non-trivial band structure with respect to the elementary bands of the unmodulated case. Our main tool is a microscopic tight-binding model that is capable of describing the full range of the strength of the local Rashba interaction. We find that a substantial enhancement of the transmission of the spin-split states can be achieved by a proper choice of the parameters of the model, and that the effect is particularly pronounced for a strong local Rashba interaction and a large magnetic field. Our results suggest that a proper design of the local Rashba interaction may be beneficial for spintronic applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for a kaonic nuclear state via $^4$He$(K^-, N)$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0297, "human_text": "  Very recently, we have performed a couple of experiments, {\\it{KEK PS-E549/E570}}, for the detailed study of the strange tribaryon $S^0(3115)$ obtained in {\\it{KEK PS-E471}}. These experiments were performed to accumulate much higher statistics with improved experimental apparatusespecially for the better proton spectroscopy of the $^4$He({\\it{stopped K}}$^-$, {\\it{N}}) reaction. In contrast to the previous proton spectrum, no narrow ($\\sim$ 20 MeV) peak structure was found either in the inclusive $^4$He({\\it{stopped K}}$^-$, {\\it{p}}) or in the semi-inclusive $^4$He({\\it{stopped K}}$^-$, {\\it{p}}$X^\\pm$) reaction channel, which is equivalent to the previous $E471$ event trigger condition. Detailed analysis of the present data and simulation shows that the peak, corresponding to $S^0(3115)$, has been an experimental artifact. Present analysis does not exclude the possible existence of a much wider structure. To be sensitive to such structure and for better understanding of the non-mesonic $K^-$ absorption reaction channel, detailed analysis of the data is in progress. ", "machine_text": " We report on a search for a kaonic nuclear state in $^4$He$(K^-, N)$. The motivation for this work is based on the recent observation of a significant population of $^4$He in the hyperon channel by the H1 experiment, in spite of the fact that the $^4$He$(K^-, N)$ final state is known to be highly suppressed compared to the $^4$He$(K^0, N)$ final state. To explain this observation we consider a model in which the $^4$He$(K^-, N)$ state is a compound state with $^4$He$(K^0, N)$ and $^3$He$(K^-, N)$, and in which the $^4$He$(K^0, N)$ state is a true nuclear state while the $^3$He$(K^-, N)$ state is a kaonic state. The model predicts a significant population of $^4$He in the hyperon channel, in spite of the fact that the $^4$He$(K^-, N)$ state is highly suppressed. We present here results of a search for a kaonic state in $^4$He$(K^-, N)$, based on a data sample collected with the BaBar detector at the PEP2 storage ring. We find no evidence for such a state, and set a 90% C.L. upper limit on the fraction of $^4$He in $^4$He$(K^-, N)$ of $2.4 \\times 10^{-3}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Characterization of the Soluble Nanoparticles Formed through Coulombic\n  Interaction of Bovine Serum Albumin with Anionic Graft Copolymers at Low pH. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3707, "human_text": "  A static light scattering (SLS) study of bovine serum albumin (BSA) mixtures with two anionic graft copolymers of poly (sodium acrylate-co-sodium 2-acrylamido-2-methyl-1-propanesulphonate)-graft-poly (N, N-dimethylacrylamide), with a high composition in poly (N, N-dimethylacrylamide) (PDMAM) side chains, revealed the formation of oppositely charged complexes, at pH lower than 4.9, the isoelectric point of BSA. The core-corona nanoparticles formed at pH = 3.00, were characterized. Their molecular weight and radius of gyration were determined by SLS, while their hydrodynamic radius was determined by dynamic light scattering. Small angle neutron scattering measurements were used to determine the radius of the insoluble complexes, comprising the core of the particles. The values obtained indicated that their size and aggregation number of the nanoparticles, were smaller when the content of the graft copolymers in neutral PDMAM side chains was higher. Such particles should be interesting drug delivery candidates, if the gastrointestinal tract was to be used. ", "machine_text": "  We investigated the formation of soluble nanoparticles through the Coulombic interaction of bovine serum albumin (BSA) with anionic graft copolymers in aqueous solutions at low pH. The average particle size and the zeta potential of the nanoparticles were determined by dynamic light scattering (DLS), and the morphology of the nanoparticles was examined by transmission electron microscopy (TEM). The results showed that the nanoparticles formed through the Coulombic interaction of BSA with anionic graft copolymers were approximately spherical in shape, and the average particle size was less than 100 nm. The zeta potential of the nanoparticles was highly negative, which was attributed to the anionic groups on the surface of the nanoparticles. The results also showed that the morphology of the nanoparticles was uniform and that they were well dispersed in the solution. We conclude that the Coulombic interaction of BSA with anionic graft copolymers is a potential method for the formation of stable, soluble nanoparticles at low pH.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the morphologies, gas fractions, and star formation rates of small\n  galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.021, "human_text": "  We use a series of N-body/smoothed particle hydrodynamics simulations and analytic arguments to show that the presence of an effective temperature floor in the interstellar medium at T_F ~ 10^4 K naturally explains the tendency for low-mass galaxies to be more spheroidal, more gas rich, and less efficient in converting baryons into stars than larger galaxies. The trend arises because gas pressure support becomes important compared to angular momentum support in small dark matter haloes. We suggest that dwarf galaxies with rotational velocities ~ 40 km/s do not originate as thin discs, but rather are born as thick, puffy systems. If accreted on to larger haloes, tenuous dwarfs of this kind will be more susceptible to gas loss or tidal transformation than scaled-down versions of larger spirals. For a constant temperature floor, pressure support becomes less important in large haloes, and this produces a tendency for massive isolated galaxies to have thinner discs and more efficient star formation than their less massive counterparts, as observed. ", "machine_text": "  We present a morphological catalog of 667 nearby (Mpc) galaxies, drawn from the 2 Micron All-Sky Survey (2MASS), that have morphologies similar to those of the satellites of the Milky Way and of the Small Magellanic Cloud. We find that the kinematics of these galaxies is well described by a combination of a uniform step function and a radial distribution, which is likely to be due to the infall of these galaxies onto the Galactic and Magellanic clouds. We use the 2MASS photometry to estimate the gas fraction of these galaxies, and find that it is a strong function of morphology: late-type galaxies tend to have a higher gas fraction than early-type galaxies. We also find that the gas fractions of galaxies in the thick disk population are significantly higher than those in the thin disk, and that the gas fraction decreases with galactic radius in both the Milky Way and the Small Magellanic Cloud. These results are consistent with the thick-thin disk structure of the Milky Way, and suggest that the Small Magellanic Cloud may also have a thick-thin structure. We find that the gas fraction has a strong correlation with the star formation rate, with the highest star formation rates occurring in galaxies with gas fractions in the range 0.4-1. We also find that the relation between star formation rate and gas fraction is well described by a power law with a negative power of -0.5. Our results suggest that the relation between gas fraction and star formation rate may be determined by the competition between the gas infall and the radiative feedback from the stellar population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Refuting the Pseudo Attack on the REESSE1+ Cryptosystem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0492, "human_text": "  We illustrate through example 1 and 2 that the condition at theorem 1 in [8] dissatisfies necessity, and the converse proposition of fact 1.1 in [8] does not hold, namely the condition Z/M - L/Ak < 1/(2 Ak^2) is not sufficient for f(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a logic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4 to be invalid. Demonstrate through ex.4 and 5 that each or the combination of qu+1 > qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) + f(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4 and alg.2 based on table 1 are disordered and wrong logically. Further, manifest through a repeated experiment and ex.5 that the data at table 2 is falsified, and the example in [8] is woven elaborately. We explain why Cx = Ax * W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To the signature fraud, we point out that [8] misunderstands the existence of T^-1 and Q^-1 % (M-1), and forging of Q can be easily avoided through moving H. Therefore, the conclusion of [8] that REESSE1+ is not secure at all (which connotes that [8] can extract a related private key from any public key in REESSE1+) is fully incorrect, and as long as the parameter Omega is fitly selected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure. ", "machine_text": " We refute the pseudo attack on the REESSE1+ cryptosystem. Our motivation is that the pseudo attack can cause a false impression about the security of REESSE1+. The key idea is that the pseudo attack uses a fake (i.e. not truly random) entropy source. We show that as long as the entropy source is not revealed, an attacker can only suspect that it is not truly random. We also show that even if the entropy source is revealed, the pseudo attack does not help to break REESSE1+. As a by-product, we show that the standardize step in the pseudo attack is not necessary. Our methodology is to consider a simple instantiation of REESSE1+ with a standardize step, and show that this instantiation is secure, regardless of whether the pseudo attack is applied or not. Our results are that REESSE1+ is secure, regardless of whether the pseudo attack is applied or not. We also show that the pseudo attack does not help to break any generic instantiation of REESSE1+. As a practical application, our results imply that the pseudo attack does not threaten the security of REESSE1+, even if the entropy source is not truly random. As a theoretical application, our results imply that the pseudo attack is not a generic attack on allRAND-based (or BP-based) cryptosystems, even if the entropy source is not truly random.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Efficient Multidimensional Data Redistribution for Resizable Parallel\n  Computations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2146, "human_text": "  Traditional parallel schedulers running on cluster supercomputers support only static scheduling, where the number of processors allocated to an application remains fixed throughout the execution of the job. This results in under-utilization of idle system resources thereby decreasing overall system throughput. In our research, we have developed a prototype framework called ReSHAPE, which supports dynamic resizing of parallel MPI applications executing on distributed memory platforms. The resizing library in ReSHAPE includes support for releasing and acquiring processors and efficiently redistributing application state to a new set of processors. In this paper, we derive an algorithm for redistributing two-dimensional block-cyclic arrays from $P$ to $Q$ processors, organized as 2-D processor grids. The algorithm ensures a contention-free communication schedule for data redistribution if $P_r \\leq Q_r$ and $P_c \\leq Q_c$. In other cases, the algorithm implements circular row and column shifts on the communication schedule to minimize node contention. ", "machine_text": " We present a multidimensional data redistribution scheme for dynamically redistributing a large amount of data among multiple processors in a parallel computation. Our scheme is motivated by the need to support dynamic resizing of parallel computations, in which the number of processors may be increased or decreased during the course of the computation. We focus on minimizing the amount of data movement required to support such resizing, while also minimizing the amount of space required to store the redistributed data. Our approach is to use a hierarchical redistributing strategy, in which processors at one level of the hierarchy are used to redistribute data among processors at the next level of the hierarchy. This strategy is applied iteratively until the data is finally redistributed among the processors at the lowest level of the hierarchy. The data redistribution is designed to be efficient, in the sense that each processor receives a large fraction of the data that it will need to compute its portion of the solution, while also minimizing the amount of data stored on each processor. We evaluate the efficiency of our scheme by measuring the amount of data movement and space required for the redistribution, as well as the overhead imposed by the redistribution process. We also present a simple model of the redistributing process, which is used to predict the efficiency of the redistribution process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Deformation principle and further geometrization of physics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3003, "human_text": "  The space-time geometry is considered to be a physical geometry, i.e. a geometry described completely by the world function. All geometrical concepts and geometric objects are taken from the proper Euclidean geometry. They are expressed via the Euclidean world function \\sigma_E and declared to be concepts and objects of any physical geometry, provided the Euclidean world function \\sigma_E is replaced by the world function \\sigma of the physical geometry in question. The set of physical geometries is more powerful, than the set of Riemannian geometries, and one needs to choose a true space-time geometry. In general, the physical geometry is multivariant (there are many vectors which are equivalent to a given vector, but are not equivalent between themselves). The multivariance admits one to describe quantum effects as geometric effects and to consider existence of elementary particles as a geometrical problem, when the possibility of the physical existence of an elementary geometric object in the form of a physical body is determined by the space-time geometry. Multivariance admits one to describe discrete and continuous geometries, using the same technique. A use of physical geometry admits one to realize the geometrical approach to the quantum theory and to the theory of elementary particles. ", "machine_text": " We propose a new deformation principle of physics based on the \" principle of least action \". The action is here defined as a functional of the densities of the basic physical quantities in the configuration space. The principle of least action is equivalent to the Euler-Lagrange equation in the usual formulation of classical mechanics, but has also a general meaning, independent of the Lagrangian formalism. We show that this new deformation principle is consistent with the principles of relativity and quantum mechanics, and we propose a further geometrization of the physical laws based on this principle. In particular, we show that the fundamental physical laws can be obtained by a local minimum of the action functional, under the assumptions that the dynamics is described by a flow in the configuration space, and that the action is invariant under proper deformations of the configuration space. As an application, we show that the principle of least action is equivalent to the Hamiltonian principle in the case of a flow with a given symmetry.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Midlatitude Cirrus Clouds and Multiple Tropopauses from a 2002-2006\n  Climatology over the SIRTA Observatory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2517, "human_text": "  This study present a comparison of lidar observations of midlatitude cirrus clouds over the SIRTA observatory between 2002 and 2006 with multiple tropopauses (MT) retrieved from radiosounding temperature profiles. The temporal variability of MT properties (frequency, thickness) are discussed. Results show a marked annual cycle, with MT frequency reaching its lowest point in May (~18% occurrence of MT) and slowly rising to more than 40% in DJF. The average thickness of the MT also follows an annual cycle, going from less than 1 km in spring to 1.5 km in late autumn. Comparison with lidar observations show that cirrus clouds show a preference for being located close below the 1st tropopause. When the cloud top is above the 1st tropopause (7% of observations), in 20% of cases the cloud base is above it as well, resulting in a cirrus cloud \"sandwiched\" between the two tropopauses. Compared to the general distribution of cirrus, cross-tropopause cirrus show a higher frequency of large optical depths, while inter-tropopause cirrus show almost exclusively low optical depths (Tau < 0.03 in 90% of cases) typical of subvisible clouds. Results suggest the occurrence of inter-tropopause cirrus clouds is correlated with the frequency of multiple tropopauses. ", "machine_text": "  Midlatitude Cirrus Clouds and Multiple Tropopauses from a 2002-2006 Climatology over the SIRTA Observatory  We present a climatology of cirrus clouds and multiple tropopauses observed over the SIRTA Observatory in France, based on four years of lidar observations (2002-2006). Cirrus clouds are found to occupy a large part of the atmosphere above the observatory, with a significant vertical structure. The lidar ratio, defined as the backscattered signal per unit of aerosol optical depth, exhibits a maximum at around 7 km and another one at around 9 km, indicative of the presence of two cloud decks. These cloud decks are also found to have different optical depths, as diagnosed from the fit of a two-layer cloud model to the observations. The high optical depth of the upper cloud deck implies that this cirrus layer has a strong radiative effect on the atmosphere. We show that the temperature of the cirrus clouds increases with height, in qualitative agreement with a positive cloud-top-warming effect. The temperature of the lower cloud deck is instead relatively constant with height, suggesting that it is well mixed. We attribute this to the strong wind shear in the atmosphere. We found that the multiple tropopauses are present in more than 90% of the year, and they are responsible for the large amount of cirrus clouds. Our results suggest that these cirrus clouds are rather long-lived, since they are present in the afternoon as well as in the evening. The multiple tropopauses are also found to be highly correlated with the large-scale dynamics, such as the North Atlantic Oscillation and the Siberian High. We conclude that the multiple tropopauses are a prominent feature of the midlatitude atmosphere, and they have important implications on the transport and the radiative properties of the atmosphere.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral type dependent rotational braking and strong magnetic flux in\n  three components of the late-M multiple system LHS 1070. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2139, "human_text": "  We show individual high resolution spectra of components A, B, and C of the nearby late-M type multiple system LHS 1070. Component A is a mid-M star, B and C are known to have masses at the threshold to brown dwarfs. From our spectra we measure rotation velocities and the mean magnetic field for all three components individually. We find magnetic flux on the order of several kilo-Gauss in all components. The rotation velocities of the two late-M objects B and C are similar (vsini = 16km/s), the earlier A component is spinning only at about half that rate. This suggests weakening of net rotational braking at late-M spectral type, and that the lack of slowly rotating late-M and L dwarfs is real. Furthermore, we found that magnetic flux in the B component is about twice as strong as in component C at similar rotation rate. This indicates that rotational braking is not proportional to magnetic field strength in fully convective objects, and that a different field topology is the reason for the weak braking in low mass objects. ", "machine_text": "  We present photometric and spectroscopic observations of the pre-main sequence M1 dwarf LHS 1070 in an attempt to constrain the evolutionary state of this triple system. The two closer components, LHS 1070 A and B, display the characteristics of young, solar-type objects in a close orbit with a short orbital period (83 min), while the more distant component, LHS 1070 C, displays a spectral type that is unusual for a solar twin, with a relatively strong magnetic field (B = 2.6 kG) and a line-of-sight velocity that implies a mass fraction of >70% (by comparison, the solar ratio is approximately 1%). We find that the observed physical properties of the system are consistent with a bound system with the following evolutionary state: LHS 1070 A and B are in a wide orbit around a cool dwarf star (M1) with a low magnetic field (B < 1.5 kG) and a period of approximately 2 kyr. The M1 dwarf has a mass fraction of <30% and has been leaking angular momentum to its companions in a prograde fashion, resulting in the current wide orbit and short orbital period. The low magnetic field of the M1 dwarf is the result of either an initial field that has been diluted by the accretion of a non-magnetic companion or the simple cooling and shrinking of the initial magnetic field as the M1 dwarf has evolved off the main sequence. We have identified only one other triple system with a similar orbital configuration (LHS 3844), although we note that the current orbits in LHS 3844 are not well known. We discuss a number of other possible evolutionary states that are consistent with the available observations. In particular, we suggest that the system has probably evolved from a configuration with two or more brown dwarfs in a wide orbit around a more massive object (M>M1) and that the brown dwarfs have been captured into a much tighter orbit as a result of gravitational interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Koszul duality in deformation quantization, I. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2381, "human_text": "  Let $\\alpha$ be a polynomial Poisson bivector on a finite-dimensional vector space $V$ over $\\mathbb{C}$. Then Kontsevich [K97] gives a formula for a quantization $f\\star g$ of the algebra $S(V)^*$. We give a construction of an algebra with the PBW property defined from $\\alpha$ by generators and relations. Namely, we define an algebra as the quotient of the free tensor algebra $T(V^*)$ by relations $x_i\\otimes x_j-x_j\\otimes x_i=R_{ij}(\\hbar)$ where $R_{ij}(\\hbar)\\in T(V^*)\\otimes\\hbar \\mathbb{C}[[\\hbar]]$, $R_{ij}=\\hbar \\Sym(\\alpha_{ij})+\\mathcal{O}(\\hbar^2)$, with one relation for each pair of $i,j=1...\\dim V$. We prove that the constructed algebra obeys the PBW property, and this is a generalization of the Poincar\\'{e}-Birkhoff-Witt theorem. In the case of a linear Poisson structure we get the PBW theorem itself, and for a quadratic Poisson structure we get an object closely related to a quantum $R$-matrix on $V$. At the same time we get a free resolution of the deformed algebra (for an arbitrary $\\alpha$).   The construction of this PBW algebra is rather simple, as well as the proof of the PBW property. The major efforts should be undertaken to prove the conjecture that in this way we get an algebra isomorphic to the Kontsevich star-algebra. ", "machine_text": "  We show that the deformation quantization functor for Poisson Lie algebras preserves the Koszul duality between polynomials and polynomial constraints on the derived category. As an application we give a description of the Poisson Wakforum subtropical algebra in terms of a polynomial constraint on the derived category.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Luminosity function of binary X-ray sources calculated using the\n  Scenario Machine. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.286, "human_text": "  Using the ``Scenario Machine'' we have carried out a population synthesis of X-ray binaries for the purpose of modelling of X-ray luminosity functions (XLFs) in different types of galaxies: star burst, spiral, and elliptical. This computer code allows to calculate, by using Monte Carlo simulations, the evolution of a large ensemble of binary systems, with proper accounting for the spin evolution of magnetized neutron stars.   We show that the XLF has no universal type. It depends on the star formation rate in the galaxy. Also it is of importance to take into account the evolution of binary systems and life times of X-ray stages in theoretical models of such functions. We have calculated cumulative and differential XLFs for the galaxy with the constant star formation rate. Also we have calculated cumulative luminosity functions for different intervals of time after the star formation burst in the galaxy and curves depicting the evolution of the X-ray luminosity after the star formation burst in the galaxy. ", "machine_text": "  We present a method to estimate the luminosity function of a collection of binary X-ray sources in an uniform manner. The method is based on the Scenario Machine, a computer program that generates synthetic observations of a collection of binary X-ray sources given a specified luminosity function. We use the observed properties of a sample of X-ray binaries to constrain the shape of the luminosity function and generate the corresponding synthetic observations. We then compare the synthetic observations with the observed ones, thereby measuring the statistical significance of the observed properties and their correlations. We find that a power law with an index of 1.2 is consistent with the observations, with a statistical significance of 3.5 standard deviations. We also find that the observed correlation between the orbital period and the binary mass is significant (3.1 standard deviations) and that the mass function is well described by a power law with an index of 2.0. We discuss the implications of our results for models of X-ray binary formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Variation of the Amati Relation with the Cosmological Redshift: a\n  Selection Effect or an Evolution Effect?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3128, "human_text": "  Because of the limit in the number of gamma-ray bursts (GRBs) with available redshifts and spectra, all current investigations on the correlation among GRB variables use burst samples with redshifts that span a very large range. The evolution and selection effects have thus been ignored, which might have important influence on the results. In this Letter, we divide the 48 long-duration GRBs in Amati (2006, 2007) into four groups with redshift from low to high, each group contains 12 GRBs. Then we fit each group with the Amati relation $\\log E_\\iso = a + b \\log E_\\p$, and check if the parameters $a$ and $b$ evolve with the GRB redshift. We find that $a$ and $b$ vary with the mean redshift of the GRBs in each group systematically and significantly. Monte-Carlo simulations show that there is only $\\sim 4$ percent of chance that the variation is caused by the selection effect arising from the fluence limit. Hence, our results may indicate that GRBs evolve strongly with the cosmological redshift. ", "machine_text": "  We have recently investigated the variation of the Amati relation with the cosmological redshift, and found that the probability distribution of the amplitudes of the galaxy redshifts is not in accordance with the prediction of the Amati relation. We have interpreted this result as a possible selection effect due to the fact that we consider only galaxies with known redshifts in our sample, and thus the relation might not hold for galaxies without measured redshifts. We have also pointed out that an evolution effect might have contributed to the discrepancy between the prediction of the Amati relation and the observations. The evolution effect could have acted during the period of the Universe when the galaxies in our sample have been formed, and the evolution speed of the relation might have been higher than the evolution speed of the galaxies. We have discussed that the evolution effect can be tested by a detailed study of the variation of the Amati relation with the galaxy age and with the surface or volume density of the ambient medium. Here we briefly comment on the problem.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Interpreting and predicting the yield of transit surveys: Giant planets\n  in the OGLE fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1919, "human_text": "  Transiting extrasolar planets are now discovered jointly by photometric surveys and by radial velocimetry. We want to determine whether the different data sets are compatible between themselves and with models of the evolution of extrasolar planets. We simulate directly a population of stars corresponding to the OGLE transit survey and assign them planetary companions based on radial velocimetry discoveries. We use a model of the evolution and structure of giant planets assuming a variable fraction of heavy elements. The output list of detectable planets of the simulations is compared to the real detections. We confirm that the radial velocimetry and photometric survey data sets are compatible within the statistical errors, assuming that planets with periods between 1 and 2 days are approximately 5 times less frequent than planets with periods between 2 and 5 days. We show that evolution models fitting present observational constraints predict a lack of small giant planets with large masses. We also identify distinct populations of planets: those with short periods (P < 10d) are only found in orbit around metal-rich stars with [Fe/H] > -0.07. We further confirm the relative absence of low-mass giant planets at small orbital distances. ", "machine_text": "  Interpreting and predicting the yield of transit surveys: Giant planets in the OGLE fields  We present a method for predicting the yield of transit surveys targeting giant planets around solar-type stars. We consider the selection effect caused by the survey configuration, such as the choice of the stellar sample and the observing season. We show that the selection effect can be understood by assuming that the observed giants are at the same orbital distance from their host stars as the planet. We evaluate the efficiency of a survey to detect low-mass giant planets by applying our method to the ongoing OGLE survey. We find that giant planets with a mass lower than 1.7 Jupiter masses can be detected with a probability higher than 99% over a survey duration of 5 years for an OGLE-like survey with 10^4 stars in its target area. We show that the OGLE survey has already detected such low-mass giants in at least 13 stars. We discuss the selection effects acting on our observations, and the implications of our method on upcoming giant planet transit surveys.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Local purity distillation with bounded classical communication. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4089, "human_text": "  Local pure states are an important resource for quantum computing. The problem of distilling local pure states from mixed ones can be cast in an information theoretic paradigm. The bipartite version of this problem where local purity must be distilled from an arbitrary quantum state shared between two parties, Alice and Bob, is closely related to the problem of separating quantum and classical correlations in the state and in particular, to a measure of classical correlations called the one-way distillable common randomness. In Phys. Rev. A 71, 062303 (2005), the optimal rate of local purity distillation is derived when many copies of a bipartite quantum state are shared between Alice and Bob, and the parties are allowed unlimited use of a unidirectional dephasing channel. In the present paper, we extend this result to the setting in which the use of the channel is bounded. We demonstrate that in the case of a classical-quantum system, the expression for the local purity distilled is efficiently computable and provide examples with their tradeoff curves. ", "machine_text": "  We consider the problem of distilling a weak solution of a pure solvent into a solvent of higher purity. We suppose that the initial solution is distilled in a single vessel, and that the distillate is collected in a reservoir. The reservoir is connected to a secondary condenser that receives the vapor of the pure solvent from the reservoir. We assume that the amount of vapor is finite and that the solution and the reservoir are well mixed. We show that this distillation process can be described by a simple model. The model consists of a system of ordinary differential equations, where the solution is the composition of the solution and the vapor in the reservoir. The initial conditions of the system are related to the initial solution, and the final condition is that the solution in the reservoir reaches the desired purity level. We show that this model has a unique solution, and we study the parameter regions in which the solution exists and is stable. In particular, we find that the distillate purity level is lower if the vapor in the reservoir is not controlled. We also analyze the model from the perspective of communication theory. We show that the distillation process can be described by a simple symbolic model using bounded classical communication.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical implementation and entanglement distribution in Gaussian valence\n  bond states. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.158, "human_text": "  We study Gaussian valence bond states of continuous variable systems, obtained as the outputs of projection operations from an ancillary space of M infinitely entangled bonds connecting neighboring sites, applied at each of $N$ sites of an harmonic chain. The entanglement distribution in Gaussian valence bond states can be controlled by varying the input amount of entanglement engineered in a (2M+1)-mode Gaussian state known as the building block, which is isomorphic to the projector applied at a given site. We show how this mechanism can be interpreted in terms of multiple entanglement swapping from the chain of ancillary bonds, through the building blocks. We provide optical schemes to produce bisymmetric three-mode Gaussian building blocks (which correspond to a single bond, M=1), and study the entanglement structure in the output Gaussian valence bond states. The usefulness of such states for quantum communication protocols with continuous variables, like telecloning and teleportation networks, is finally discussed. ", "machine_text": "  We propose and experimentally realize a novel method to produce Gaussian valence bond states, which are a generalization of the concept of Gaussian bosons to the case of massive particles. Our method is based on the idea of dressing a certain class of multipartite entangled states, called Paragraph 2 states, in a laser field. We show that such dressed states are well-approximated by Gaussian functions, and thus are suitable to be used as qubits in quantum information processing. In particular, we investigate a simple scheme for quantum teleportation and gate operations, and show that it is possible to perform these operations by using only Gaussian valence bond states, without the need for any other intermediate qubit registers. We also propose a method to distribute entanglement between different such qubit registers, which is particularly useful in the context of large-scale quantum computers. Our experimental realization of the proposed schemes is based on the use of ultra-cold atomic gases, and we report on the successful implementation of the schemes using our experimental apparatus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Two-dimensional N=(2,2) super Yang-Mills theory on computer. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1392, "human_text": "  We carry out preliminary numerical study of Sugino's lattice formulation \\cite{Sugino:2004qd,Sugino:2004qdf} of the two-dimensional $\\mathcal{N}=(2,2)$ super Yang-Mills theory (2d $\\mathcal{N}=(2,2)$ SYM) with the gauge group $\\SU(2)$. The effect of dynamical fermions is included by re-weighting a quenched ensemble by the pfaffian factor. It appears that the complex phase of the pfaffian due to lattice artifacts and flat directions of the classical potential are not problematic in Monte Carlo simulation. Various one-point supersymmetric Ward-Takahashi (WT) identities are examined for lattice spacings up to $a=0.5/g$ with the fixed physical lattice size $L=4.0/g$, where $g$ denotes the gauge coupling constant in two dimensions. WT identities implied by an exact fermionic symmetry of the formulation are confirmed in fair accuracy and, for most of these identities, the quantum effect of dynamical fermions is clearly observed. For WT identities expected only in the continuum limit, the results seem to be consistent with the behavior expected from supersymmetry, although we do not see clear distintion from the quenched simulation. We measure also the expectation values of renormalized gauge-invariant bi-linear operators of scalar fields. ", "machine_text": "  We study the two-dimensional N=(2,2) super Yang-Mills theory on the computer. We use the NumPy library to perform the lattice sum calculations, and use the Feynman-Kac formula to evaluate the sum. We find the critical value of the mass parameter for which the theory is confining, and the massless limit. The results agree with the previous analytical results. We also find the evolutions of the massless states, and find that the half-+\"-state has a faster evolution than the full-+\"-state. This is consistent with the previous result by Bazarov and Taylor, but contrary to the suggestion by lord_k layouts. We find the critical value of the non-Abelian fusion parameter for which the theory is symmetric, and the fusionless limit. The results agree with the previous analytical results. We also find the evolutions of the massless states, and find that the half-+\"-state has a faster evolution than the full-+\"-state. This is consistent with the previous result by Bazarov and Taylor, but contrary to the suggestion by lord_k layouts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase resolved measurements of stimulated emission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2296, "human_text": "  The development of the semiconductor quantum cascade laser (QCL) [1] has enabled bright coherent sources operating at frequencies between the optical (>100 THz) and electronic (<0.5 THz) ranges opening this frequency region for fundamental science investigations [2-5] as well as for applications [6]. However, detailed information about the internal processes in QCLs and their ultrafast dynamics are needed for their further development towards high output power, longer wavelengths and stable pulsed operation. We introduce a novel approach to study the gain and dynamics of a terahertz (THz) QCL [7] using phase resolved measurements of the stimulated emission. This is enabled by direct recording of the emitted electric field with <100 fs time resolution. For the case of the THz QCL we demonstrate the validity of the quantum mechanical description of the laser. We show for the first time the real bandwidth of the terahertz gain medium, the current dependence of this gain, and the losses associated with the wave propagation in the laser waveguide. ", "machine_text": "  We have developed a new technique for measuring the time-evolution of the molecular hyperfine spin order with millisecond precision, by monitoring the evolution of the stimulated emission from a flash of laser light as it is turned off. We show that this technique can be used to measure the dynamics of the spin order in several different molecular systems, and that the dynamics of the spin order is in general different from the much faster electronic dynamics. We also show that by using a combination of different laser pulses it is possible to follow the evolution of the spin order from its initial state, through a number of different spin-ordered states, and finally back to the initial state. This allows us to study the dynamics of the spin order in a number of different situations, and we find that the dynamics is in general very different for different molecular systems. We also show that the dynamics of the spin order can be very different in different portions of a single molecular system, so that it is necessary to use a number of different laser pulses in order to fully characterize the dynamics of the spin order in a given molecular system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vector mesons from AdS/TC to the LHC. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2205, "human_text": "  With the use of the AdS/CFT dictionary, a five-dimensional effective description of dynamical electro-weak symmetry breaking with walking behavior is constructed. The minimal model contains only two new parameters, the confinement scale and the effective coupling of the new strong sector. This parameter space is restricted by the precision electro-weak constraints and by the requirement that the five-dimensional coupling be perturbative (corresponding to the large-N regime in four-dimensional language). The lightest observable new states are a set of four nearly degenerate spin-1 states with the same quantum numbers as the standard-model electro-weak gauge bosons, and masses in the few TeV range. Their decay rate is dominated by two-fermion final states. The number of pp -> mu mu and pp -> mu nu events is studied as a function of the LHC integrated luminosity and of the two free parameters. Discovery at the LHC is possible over a significant part of the allowed parameter space up to masses of 4 TeV already with 10/fm of integrated luminosity. ", "machine_text": " We study the production of vector mesons at hadron colliders within the framework of the effective Lagrangian approach. We consider the leading pion pion scattering contribution as well as the secondary vector meson production and the inclusive direct production. In all cases the contribution of a top-quark initiated process is calculated and compared to the Standard Model prediction. We find a significant deviation from the Standard Model which can be described by an additional vector meson coupling to the top-quark. In our scenario the new vector meson coupling is generated through the spontaneous symmetry breaking of a larger group which includes the top-quark and the new vector meson. This scenario is in agreement with the general prediction that new physics can be expected at high energies or large momenta. The parameters of the new vector meson coupling can be constrained by the available data. We discuss the possibility that the new vector meson coupling is related to the non-renormalizable dynamics of the strong interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Trade-off between Processing Gains of an Impulse Radio UWB System in\n  the Presence of Timing Jitter. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3408, "human_text": "  In time hopping impulse radio, $N_f$ pulses of duration $T_c$ are transmitted for each information symbol. This gives rise to two types of processing gain: (i) pulse combining gain, which is a factor $N_f$, and (ii) pulse spreading gain, which is $N_c=T_f/T_c$, where $T_f$ is the mean interval between two subsequent pulses. This paper investigates the trade-off between these two types of processing gain in the presence of timing jitter. First, an additive white Gaussian noise (AWGN) channel is considered and approximate closed form expressions for bit error probability are derived for impulse radio systems with and without pulse-based polarity randomization. Both symbol-synchronous and chip-synchronous scenarios are considered. The effects of multiple-access interference and timing jitter on the selection of optimal system parameters are explained through theoretical analysis. Finally, a multipath scenario is considered and the trade-off between processing gains of a synchronous impulse radio system with pulse-based polarity randomization is analyzed. The effects of the timing jitter, multiple-access interference and inter-frame interference are investigated. Simulation studies support the theoretical results. ", "machine_text": "  We investigate the impact of timing jitter on the performance of an impulse radio ultra-wideband (IR-UWB) system in a multipath environment. We show that the timing jitter has a negative impact on the bit error rate (BER) and the packet error rate (PER) when the channel is influenced by strong multipath reflections. In particular, for a given impulse position modulation (IPM) symbol duration, we show that the timing jitter can cause interferences between the multipath components, leading to an increase in the BER and PER. To quantify this effect, we propose a metric called the processing gain penalty due to timing jitter (PGPT). We show that the PGPT can be used to predict the performance of an IR-UWB system in the presence of timing jitter, and we provide a simple expression for the PGPT in the case of a single-tone carrier. We also investigate the impact of timing jitter on the performance of an IR-UWB system in the presence of narrowband interference (NBI). We show that the timing jitter can cause the NBI to move in time, leading to an increase in the BER and PER. To quantify this effect, we propose a metric called the processing gain penalty due to timing jitter and NBI (PGPTI). We show that the PGPTI can be used to predict the performance of an IR-UWB system in the presence of timing jitter and NBI, and we provide a simple expression for the PGPTI in the case of a single-tone carrier.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Elongated Structure of the Hercules dSph from Deep LBT Imaging. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1669, "human_text": "  We present a deep, wide-field photometric survey of the newly-discovered Hercules dwarf spheroidal galaxy, based on data from the Large Binocular Telescope. Images in B, V and r were obtained with the Large Binocular Camera covering a 23' times 23' field of view to a magnitude of ~25.5 (5 sigma). This permitted the construction of colour-magnitude diagrams that reach approximately 1.5 magnitudes below the Hercules main sequence turnoff. Three-filter photometry allowed us to preferentially select probable Hercules member stars, and examine the structure of this system at a previously unattained level. We find that the Hercules dwarf is highly elongated (3:1), considerably more so than any other dSph satellite of the Milky Way except the disrupting Sagittarius dwarf. While we cannot rule out that the unusual structure is intrinsic to Hercules as an equilibrium system, our results suggest tidal disruption as a likely cause of this highly elliptical structure. Given the relatively large Galactocentric distance of this system (132 +/- 12 kpc), signs of tidal disruption would require the Hercules dwarf to be on a highly eccentric orbit around the Milky Way. ", "machine_text": "  We present a deep imaging survey for the Hercules double star cluster (dSph) with the Large Binocular Telescope (LBT). We have obtained two sets of images with the LBT Multi-Object Spectrograph (LMOS), one with the near-infrared filter and one with the mid-infrared filter, both at an average depth of ~25 mag. We have combined the two sets of images to produce a single image in which the near-infrared stars are marked in blue and the mid-infrared stars are marked in red. We have analyzed the resulting image to obtain the structural parameters of the dSph. We find that the main body of the dSph has an elongated structure with a projected axis of 37.6 pc and a total extent of 71.8 pc. We also find a number of substructures in the dSph, including several chains of stars, a compact subcluster, and a number of single stars. The largest of the single stars is likely to be the escaped member of the dSph. The properties of the substructures are consistent with the effects of three-body interactions within the dSph. We discuss the properties of the Hercules dSph in the context of other elongated dSphs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Position-Velocity Diagrams for the Maser Emission coming from a\n  Keplerian Ring. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0819, "human_text": "  We have studied the maser emission from a thin, planar, gaseous ring in Keplerian rotation around a central mass observed edge-on. The absorption coefficient within the ring is assumed to follow a power law dependence with the distance from the central mass as, k=k0r^{-q}. We have calculated position-velocity diagrams for the most intense maser features, for different values of the exponent q. We have found that, depending on the value of q, these diagrams can be qualitatively different. The most intense maser emission at a given velocity can either come mainly from regions close to the inner or outer edges of the amplifying ring or from the line perpendicular to the line of sight and passing through the central mass (as is commonly assumed). Particularly, when q>1 the position-velocity diagram is qualitatively similar to the one observed for the water maser emission in the nucleus of the galaxy NGC 4258. In the context of this simple model, we conclude that in this object the absorption coefficient depends on the radius of the amplifying ring as a decreasing function, in order to have significant emission coming from the inner edge of the ring. ", "machine_text": "  We present here the analysis of the position-velocity diagrams for the Maser emission coming from a Keplerian ring. Our analysis shows that such diagrams are sensitive to the three-dimensional structure of the background stars and the masing region. We have developed a model which allows us to study the structure of the rings from the analysis of the diagrams, in the same way as has been done for the colliding-wind binary stars. The model consists in considering that the masers are located on an evacuated circular ring, which is being distorted by the gravitational field of the central star. We have compared the model predictions with the data for the circle overlaid on the HSQSO field, and found a good agreement between the two. We have also compared the results of the model with the data for the POSS Ring. Our analysis shows that the data can be described within the framework of the model, if the ring is not distorted, but is rather slightly displaced towards the North-West. We discuss this result in the framework of a possible three-dimensional structure for the POSS Ring, involving a collision between two rings.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The dust temperatures of the prestellar cores in the rho Oph main cloud\n  and in other star forming regions: consequences for the core mass function. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2941, "human_text": "  We estimate the dust temperatures of the clumps in the rho Oph main cloud taking into account the 3D geometry of the region, and external heating from the interstellar radiation field and from HD147879,a nearby luminous B2V star, which is believed to dominate the radiation field in the region. We find that the regions where prestellar cores are observed (i.e. at optical visual extinctions >7 mag) are colder than ~10-11K. These dust temperatures are smaller than those which previous studies of the same region have assumed. We use the new dust temperatures to estimate the masses of the prestellar cores in the rho Oph main cloud from mm observations, and we find core masses that are larger than previous estimates by a factor of ~2-3. This affects the core mass function (CMF) of the region; we find that the mass at which the core mass spectrum steepens from a slope alpha~1.5 to a slope alpha~2.5 has moved from ~0.5 Msun to ~1Msun. In contrast with the CMF in other star forming regions (e.g. Orion), there is no indication for a turnover down to the completeness limit (~0.2Msun), but the CMF may flatten at around ~0.4Msun. We generalize our results to the prestellar cores in Taurus and in Orion. In Taurus the ambient radiation field heating the prestellar cores is believed to be weaker than than that in rho Oph. Hence, the dust temperatures of the cores in Taurus are expected to be below ~ 10-11 K.In Orion the radiation field is believed to be 10^3 times stronger than the standard interstellar radiation field. Based on this assumption we estimate that the dust temperatures of the prestellar cores in Orion are around ~20-30K. ", "machine_text": "  We present observations of the dust temperatures of the prestellar cores in the rho Ophiuchi main cloud and in other star forming regions. The data were obtained with the heterodyne LiFT instrument, mounted on the Herschel-IRS instrument on the Herschel Space Telescope, during the Herschel Open Time Programme \"The Dust Temperature of Pre-Stellar Cores\" (HOPT 34). The observations consist of 23 galaxies in the Local Volume Experiment (LVE) and four clouds in the Orion region: the rho Ophiuchi main cloud, the Orion molecular cloud, the Running Man Nebula, and the Cartwheel Nebula. We find that the core mass function in the rho Ophiuchi main cloud follows the Salpeter function with a core mass of $1-3M_{\\odot}$ and a Salpeter parameter $\\alpha_{\\rm{core}}\\sim 2.5$, while the core mass function in the Orion region follows the Kruckenberg function with a core mass of $0.2-1M_{\\odot}$ and a Salpeter parameter $\\alpha_{\\rm{core}}\\sim 1.5$. This implies that the rho Ophiuchi main cloud has a lower mass than the Orion region, which is in agreement with other independent observations. We also find that the temperatures in the cores are correlated with the local metallicity, with the cores in the Galactic plane (Z=0.001-0.02) being on average warmer than the cores in the extragalactic clouds (Z=0.0001-0.001).", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Excluded volume, local structural cooperativity,and the polymer physics\n  of protein folding rates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0185, "human_text": "  A coarse-grained variational model is used to investigate the polymer dynamics of barrier crossing for a diverse set of two-state folding proteins. The model gives reliable folding rate predictions provided excluded volume terms that induce minor structural cooperativity are included in the interaction potential. In general, the cooperative folding routes have sharper interfaces between folded and unfolded regions of the folding nucleus and higher free energy barriers. The calculated free energy barriers are strongly correlated with native topology as characterized by contact order. Increasing the rigidity of the folding nucleus changes the local structure of the transition state ensemble non-uniformly across the set of protein studied. Neverthless, the calculated prefactors k0 are found to be relatively uniform across the protein set, with variation in 1/k0 less than a factor of five. This direct calculation justifies the common assumption that the prefactor is roughly the same for all small two-state folding proteins. Using the barrier heights obtained from the model and the best fit monomer relaxation time 30ns, we find that 1/k0 (1-5)us (with average 1/k0 4us). This model can be extended to study subtle aspects of folding such as the variation of the folding rate with stability or solvent viscosity, and the onset of downhill folding. ", "machine_text": " We introduce a simple physical model of excluded volume and local structural cooperativity to study the effects of these factors on the polymer physics of protein folding. Our results show a direct, qualitative connection between excluded volume and the polymer physics of protein folding, in terms of the behavior of the freely-jointed chain model. We show that excluded volume is equivalent to a increase of the internal energy of the freely-jointed chain model, that is, a positive bend energy. We derive a simple approximation for the effect of excluded volume on the folding rate, which we term the \"local cooperativity approximation\". This approximation is exact for a large class of simple protein structures. Our results show that the folding rate is proportional to the square of the number of residues in the protein, which is consistent with the observation that proteins with a larger number of residues fold more slowly. We also show that proteins with a higher local cooperativity fold more slowly. Our results suggest that local structural cooperativity and excluded volume are the dominant factors in the polymer physics of protein folding, and they have a large impact on the folding rates of proteins.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: First proper motions of thin dust filaments at the Galactic Center. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3675, "human_text": "  Context: L'-band (3.8 micron) images of the Galactic Center show a large number of thin filaments in the mini-spiral, located west of the mini-cavity and along the inner edge of the Northern Arm. One possible mechanism that could produce such structures is the interaction of a central wind with the mini-spiral. Additionally, we identify similar features that appear to be associated with stars. Aims: We present the first proper motion measurements of the thin dust filaments observed in the central parsec around SgrA* and investigate possible mechanisms that could be responsible for the observed motions. Methods: The observations have been carried out using the NACO adaptive optics system at the ESO VLT. The images have been transformed to a common coordinate system and features of interest were extracted. Then a cross-correlation technique could be performed in order to determine the offsets between the features with respect to their position in the reference epoch. Results: We derive the proper motions of a number of filaments and 2 cometary shaped dusty sources close (in projection) to SgrA*. We show that the shape and the motion of the filaments does not agree with a purely Keplerian motion of the gas in the potential of the supermassive black hole at the position of SgrA*. Therefore, additional mechanisms must be responsible for their formation and motion. We argue that the properties of the filaments are probably related to an outflow from the disk of young mass-losing stars around SgrA*. In part, the outflow may originate from the black hole itself. We also present some evidence and theoretical considerations that the outflow may be collimated. ", "machine_text": "  First proper motions of thin dust filaments at the Galactic Center The structure and dynamics of the Galactic Center are important clues to understanding the evolution of our Galaxy. We present proper motion measurements for 34 thin dust filaments (tdf) in the Galactic Center region using data from the Two Micron All Sky Survey and the SDSS. The tdfs have ages on the order of 10 Myr and their proper motions are between 2 and 8 km/s. We find that the younger tdfs (ages $< 1.5$ Gyr) have proper motions that are systematically higher than the older tdfs, with a mean excess of $\\sim 3$ km/s. We also find that the proper motion distribution of the tdfs is different from that of the Galactic stars, with a higher fraction of tdfs having proper motions in the range $-1$ to $+1$ km/s. This may indicate that the tdfs have a different origin than the Galactic disk, and it may imply a Galactic breakup event in the past. We discuss our results in the context of models for the formation and evolution of the Galactic Center.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Compact X-ray Source 1E 1547.0-5408 and the Radio Shell\n  G327.24-0.13: A New Proposed Association between a Candidate Magnetar and a\n  Candidate Supernova Remnant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1054, "human_text": "  We present X-ray, infrared and radio observations of the field centered on X-ray source 1E 1547.0-5408 in the Galactic Plane. A new Chandra observation of this source shows it is unresolved at arc-second resolution, and a new XMM observation shows that its X-ray spectrum is best described by an absorbed power-law and blackbody model. A comparison of the X-ray flux observed from this source between 1980 and 2006 reveals that its absorbed 0.5-10 keV X-ray flux decreased from ~2x10^-12 ergs cm-2 s-1 to ~3x10^-13 ergs cm-2 during this period. The most recent XMM observation allows us to put a 5 sigma confidence upper limit of 14% for the 0.5-10 keV peak-to-peak pulsed fraction. A near-infrared observation of this field shows a source with magnitude Ks = 15.9+/-0.2 near the position of 1E 1547.0-5408, but the implied X-ray to infrared flux ratio indicates the infrared emission is from an unrelated field source, allowing us to limit the IR magnitude of 1E 1547.0-5408 to >17.5. Archival radio observations reveal that 1E 1547.0-5408 sits at the center of a faint, small (4' diameter) radio shell, G327.24-0.13, which is possibly a previously unidentified supernova remnant. The X-ray properties of 1E 1547.0-5408 suggest that this source is a magnetar - a young neutron star whose X-ray emission is powered by the decay of its extremely strong magnetic field. The spatial coincidence between this source and G327.24-0.13 suggests that 1E 1547.0-5408 is associated with a young supernova remnant, supporting a neutron star interpretation. Additional observations are needed to confirm the nature of both 1E 1547.0-5408 and G327.24-0.13, and to determine if these sources are associated. If so, this pair will be an important addition to the small number of known associations between magnetars and supernova remnants. ", "machine_text": " We present new observations of the candidate magnetic white dwarf 1E 1547.0-5408 and the nearby supernova remnant G327.24-0.13, which together form the X-ray transient designated CompXsr1. We find that the white dwarf's spin-down power is consistent with a relatively long spin period of 41.3 ms, and we show that the accretion rate has decreased by a factor of 4 since the source was discovered in August 2013. These observations are consistent with a scenario in which the accretion onto the white dwarf has ceased, in spite of the continued presence of an accretion disc around the white dwarf. We propose that the supernova remnant G327.0-0.13 is the probable origin of the CompXsr1 outburst, and that the supernova explosion has pushed the white dwarf to the edge of the remnant, causing the white dwarf to begin accreting matter from the remnant. This is consistent with the observed radial distribution of the radio emission from G327.0-0.13, which is elongated along the direction of the white dwarf's orbit around the remnant. We show that a previously proposed association between the white dwarf 1E 1547.0-5408 and the young stellar object 1E 22594500-613 cannot be correct, on the basis of both the white dwarf's spin period and the relative motions of the white dwarf and the young stellar object.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A double main sequence turn-off in the rich star cluster NGC 1846 in the\n  Large Magellanic Cloud. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.336, "human_text": "  We report on HST/ACS photometry of the rich intermediate-age star cluster NGC 1846 in the Large Magellanic Cloud, which clearly reveals the presence of a double main sequence turn-off in this object. Despite this, the main sequence, sub-giant branch, and red giant branch are all narrow and well-defined, and the red clump is compact. We examine the spatial distribution of turn-off stars and demonstrate that all belong to NGC 1846 rather than to any field star population. In addition, the spatial distributions of the two sets of turn-off stars may exhibit different central concentrations and some asymmetries. By fitting isochrones, we show that the properties of the colour-magnitude diagram can be explained if there are two stellar populations of equivalent metal abundance in NGC 1846, differing in age by approximately 300 Myr. The absolute ages of the two populations are ~1.9 and ~2.2 Gyr, although there may be a systematic error of up to +/-0.4 Gyr in these values. The metal abundance inferred from isochrone fitting is [M/H] ~ -0.40, consistent with spectroscopic measurements of [Fe/H]. We propose that the observed properties of NGC 1846 can be explained if this object originated via the tidal capture of two star clusters formed separately in a star cluster group in a single giant molecular cloud. This scenario accounts naturally for the age difference and uniform metallicity of the two member populations, as well as the differences in their spatial distributions. ", "machine_text": " We present photometric and spectroscopic observations of the rich star cluster NGC 1846 in the Large Magellanic Cloud. Our main result is the detection of a double main sequence turn-off in the cluster. The main sequence in stellar clusters is defined by the relationship between the spectral type and the effective temperature of a star. The main sequence turn-off (MSTO) is the point where the most massive stars become too hot to produce hydrogen fusion in their cores and are therefore no longer on the main sequence. These very massive stars then become supergiants. We found a significant overabundance of massive supergiant stars in NGC 1846. The cluster is young, so the massive stars are still in the main sequence. Therefore, the MSTO must have been reached recently, which implies that the massive stars have been burning for a shorter time than the lower mass stars. The observed MSTO, together with the cluster's young age, therefore suggests a two-fold process of star formation in NGC 1846: first the low-mass stars formed, and then the massive stars formed later. We discuss our results in the framework of simple theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hot Jupiters in binary star systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0732, "human_text": "  Radial velocity surveys find Jupiter mass planets with semi-major axes a less than 0.1 AU around ~1% of solar-type stars; counting planets with $a$ as large as 5 AU, the fraction of stars having planets reaches ~ 10% {Marcy,Butler}. An examination of the distribution of semi-major axes shows that there is a clear excess of planets with orbital periods around 3 or 4 days, corresponding to a~0.03$ AU, with a sharp cutoff at shorter periods (see Figure 1). It is believed that Jupiter mass planets form at large distances from their parent stars; some fraction then migrate in to produce the short period objects. We argue that a significant fraction of the `hot Jupiters' (a<0.1 AU) may arise in binary star systems in which the orbit of the binary is highly inclined to the orbit of the planet. Mutual torques between the two orbits drive down the minimum separation or periapse r_p between the planet and its host star (the Kozai mechanism). This periapse collapse is halted when tidal friction on the planet circularizes the orbit faster than Kozai torque can excite it. The same friction then circularizes the planet orbit, producing hot Jupiters with the peak of the semimajor axis distribution lying around 3 days. For the observed distributions of binary separation, eccentricity and mass ratio, roughly 2.5% of planets with initial semimajor axis a_p ~ 5au will migrate to within 0.1au of their parent star. Kozai migration could account for 10% or more of the observed hot Jupiters. ", "machine_text": "  Hot Jupiters in binary star systems We present phase-resolved spectroscopy and photometry of the giant planets in the hot Jupiter systems TWA 5 and TWA 7. The observations were made with the Hubble Space Telescope (HST) during the course of the Hubble Outer Planet Quest (OPQ) program. We find that both giants are inflated hot Jupiters, with equilibrium temperatures of \u22481000 K and \u22481280 K for TWA 5b and TWA 7b, respectively. The measured angular sizes of the giants are in good agreement with those obtained from models in which the giants are treated as perfect gases, but in disagreement with models in which the effects of interior structure are included. The radii of both giants are larger than predicted by theoretical models, but this discrepancy can be explained by small-scale mixing of heavy elements in the interior. We find that the kinematics of the giant planets are consistent with a perfectly coplanar orbit, and thus the giant planets in these systems do not exhibit significant orbital decay. We discuss these findings in the context of hot Jupiter system evolution, and consider the prospects for observing giant planet thermodynamics with the upcoming James Webb Space Telescope.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mapping the Youngest Galaxies to Redshift One. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0643, "human_text": "  We describe results of a narrow band search for ultra-strong emission line galaxies (USELs) with EW(H beta) > 30 A. 542 candidate galaxies are found in a half square degree survey using two ~100 Angstrom 8150 A and 9140 A filters with Subaru/SuprimeCam. Followup spectroscopy for randomly selected objects in the sample with KeckII/DEIMOS shows they consist of [OIII] 5007, [OII] 3727, and H alpha selected strong-emission line galaxies at intermediate redshifts (z < 1), and Ly alpha emitting galaxies at high-redshift (z >> 5). We determine the H beta luminosity functions and the star formation density of the USELs, which is 5-10% of the value found from ultraviolet continuum objects at z=0-1, suggesting they correspond to a major epoch in galaxy formation at these redshifts. Many USELs show the temperature-sensitive [OIII] 4363 auroral lines and about a dozen have oxygen abundances characteristic of eXtremely Metal Poor Galaxies (XMPGs). These XMPGs are the most distant known today. Our high yield rate of XMPGs suggests this is a powerful method for finding such populations. The lowest metallicity measured in our sample is 12+log(O/H) = 7.06 (6.78-7.44), close to the minimum metallicity found in local galaxies. The luminosities, metallicities and star formation rates of USELs are consistent with the strong emitters being start-up intermediate mass galaxies and suggest that galaxies are still forming in relatively chemically pristine sites at z < 1. ", "machine_text": "  Mapping the Youngest Galaxies to Redshift One  We present the results of a narrow band imaging survey for galaxies in the first year of the Universe. We describe the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research.  The first galaxies in the Universe are thought to have formed during the Epoch of Reionization, a period that spanned from the end of the Neutral Era, when the Universe was filled with hydrogen and helium atoms, to the period when the first galaxies were forming. We present the results of a narrow band imaging survey for galaxies in the first year of the Universe. Our survey uses narrow band filters, in the range of $8 - 10 \\AA, and a 3'x3' field of view to search for galaxies in the first hundred million years of the Universe. We find three galaxies in our survey that are candidate galaxies from this era. We determine the redshift of these galaxies to be between $z=8.6 - 10.4$. These galaxies are found in a region of the sky that is richest in the intergalactic hydrogen gas that was the target of the Hubble Deep Field survey. Our galaxies are much fainter than the galaxies found by Hubble, which are at redshifts of $z \\sim 1.5$. This implies that galaxies were still forming in relatively chemically pristine sites at these high redshifts. We discuss the implications of these galaxies on the epoch of reionization and the future of the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complex marginal deformations of D3-brane geometries, their Penrose\n  limits and giant gravitons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2067, "human_text": "  We apply the Lunin--Maldacena construction of gravity duals to beta-deformed gauge theories to a class of Type IIB backgrounds with U(1)^3 global symmetry, which include the multicenter D3-brane backgrounds dual to the Coulomb branch of N=4 super Yang-Mills and the rotating D3-brane backgrounds dual to the theory at finite temperature and chemical potential. After a general discussion, we present the full form of the deformed metrics for three special cases, which can be used for the study of various aspects of the marginally-deformed gauge theories. We also construct the Penrose limits of the solutions dual to the Coulomb branch along a certain set of geodesics and, for the resulting PP--wave metrics, we examine the effect of beta-deformations on the giant graviton states. We find that giant gravitons exist only up to a critical value of the sigma-deformation parameter, are not degenerate in energy with the point graviton, and remain perturbatively stable. Finally, we probe the sigma-deformed multicenter solutions by examining the static heavy-quark potential by means of Wilson loops. We find situations that give rise to complete screening as well as linear confinement, with the latter arising is an intriguing way reminiscent of phase transitions in statistical systems. ", "machine_text": " We consider the geometry of certain complex structures in D3-branes, which are non-trivial generalizations of Calabi-Yau or Anti-de Sitter 3-branes. These structures can be thought of as arising from creating an edge or a handle on a D3-brane. We show that, although the bulk geometry is not changed by these manipulations, the field theory on the boundary of the brane is dramatically altered. In particular, we show that these geometries are related to certain Limit Deformations of D3-branes which are known to have enormous practical importance in string theory. We show that the bulk geometry of these Limit Deformations is related to the bulk geometry of the original D3-branes in a natural way, and that the field theory on the boundary is related to the geometry of the original D3-brane in a rather more complicated fashion. In the case that the D3-brane is a Calabi-Yau brane, we show that the related Limit Deformation is a giant graviton with a (possibly complex) radius which is directly related to the (real) volume of the original Calabi-Yau brane. We also consider the case of an Anti-de Sitter brane, and show that the related Limit Deformation is a giant graviton with a real radius which is directly related to the (real) volume of the original Anti-de Sitter brane. We finally discuss some open questions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Shelling-type orderings of regular CW-complexes and acyclic matchings of\n  the Salvetti complex. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3107, "human_text": "  Motivated by the work of Salvetti and Settepanella we introduce certain total orderings of the faces of any shellable regular CW-complex (called `shelling-type orderings') that can be used to explicitly construct maximum acyclic matchings of the poset of cells of the given complex. Building on an application of this method to the classical zonotope shellings we describe a class of maximum acyclic matchings for the Salvetti complex of a linear complexified arrangement. To do this, we introduce and study a new combinatorial stratification of the Salvetti complex. For the obtained acyclic matchings we give an explicit description of the critical cells that depends only on the chosen linear extension of the poset of regions. It is always possible to choose the linear extension so that the critical cells can be explicitly constructed from the chambers of the arrangement via the bijection to no-broken-circuit sets defined by Jewell and Orlik. Our method can be generalized to arbitraty oriented matroids. ", "machine_text": "  We study the category of shellable ordering of finite regular CW-complexes and the category of acyclic matchings of the Salvetti complex. We show that these two categories are equivalent. As a byproduct, we give a description of the category of shellable orderings in terms of rational numbers.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Star-forming Region NGC 346 in the Small Magellanic Cloud with\n  Hubble Space Telescope ACS Observations. II. Photometric Study of the\n  Intermediate-Age Star Cluster BS 90. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2942, "human_text": "  We present the results of our investigation of the intermediate-age star cluster BS 90, located in the vicinity of the HII region N 66 in the SMC, observed with HST/ACS. The high-resolution data provide a unique opportunity for a very detailed photometric study performed on one of the rare intermediate-age rich SMC clusters. The complete set of observations is centered on the association NGC 346 and contains almost 100,000 stars down to V ~28 mag. In this study we focus on the northern part of the region, which covers almost the whole stellar content of BS 90. We construct its stellar surface density profile and derive structural parameters. Isochrone fits on the CMD of the cluster results in an age of about 4.5 Gyr. The luminosity function is constructed and the present-day mass function of BS 90 has been obtained using the mass-luminosity relation, derived from the isochrone models. We found a slope between -1.30 and -0.95, comparable or somewhat shallower than a typical Salpeter IMF. Examination of the radial dependence of the mass function shows a steeper slope at larger radial distances, indicating mass segregation in the cluster. The derived half-mass relaxation time of 0.95 Gyr suggests that the cluster is mass segregated due to its dynamical evolution. From the isochrone model fits we derive a metallicity for BS 90 of [Fe/H]=-0.72, which adds an important point to the age-metallicity relation of the SMC. We discuss our findings on this relation in comparison to other SMC clusters. ", "machine_text": "  We present a photometric study of the intermediate-age star cluster BS 90 in the star-forming region NGC 346 in the Small Magellanic Cloud. We used archival Hubble Space Telescope/Advanced Camera for Surveys observations of cluster members and HST/WFPC2 images of the ionization structure to select a subset of 72 cluster members in the field which are free from the influence of the ionization structure. We then obtained high-resolution echelle spectra of these objects with the Hubble Space Telescope/High Resolution Spectrograph and used the resulting absolute photometry to investigate the cluster properties. We find that the cluster is at an intermediate age between the young (log(T/yr) \u223c 8) and old (log(T/yr) \u223c 4) clusters in the region. We estimate the cluster age to be log(T/yr) \u223c 6.2 \u00b1 1.1, assuming a distance to the Small Magellanic Cloud of 50 \u00b1 5 kpc. We find that the cluster is coeval with the superbubbles and contains a relatively large number of Wolf-Rayet stars. The cluster has a power law density distribution with a radial scale of 1.4 \u00b1 0.1 kpc. We discuss the cluster in the context of recent theories of star formation in OB associations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Single Transverse-Spin Asymmetry in Hadronic Dijet Production. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1196, "human_text": "  We study the single transverse-spin asymmetry for dijet production in hadronic collisions in both the collinear QCD factorization approach and the Brodsky-Hwang-Schmidt model. We show that a nonvanishing asymmetry is generated by both initial-state and final-state interactions, and that the final-state interactions dominate. We find that in the leading kinematic region where the transverse momentum imbalance of the two jets, q_\\perp = P_{1\\perp}+P_{2\\perp}, is much less than the momentum of either jet, the contribution from the lowest non-trivial perturbative order to both the spin-averaged and the spin-dependent dijet cross sections can be factorized into a hard part that is a function only of the averaged jet momentum P_\\perp = (P_{1\\perp}-P_{2\\perp})/2, and perturbatively generated transverse momentum dependent (TMD) parton distributions. We show that the spin asymmetry at this non-trivial perturbative order can be described by the TMD parton distributions defined in either semi-inclusive DIS or the Drell-Yan process. We derive the same hard parts from both the collinear factorization approach and in the context of the Brodsky-Hwang-Schmidt model, verifying that they are not sensitive to details of the factorized long distance physics. ", "machine_text": " We present the first three-dimensional measurement of the transverse-spin asymmetry (TSA) in hadronic Dijet production in the forward region, at a longitudinal momentum distribution of the Dijet pairs in the range 0.4<p_T<1.1 GeV/c, and an average Dijet pair production rate of 3.3 events per \u03bcB\u00b7GeV. We use a data sample collected with the BaBar detector at the PEP2 storage ring, corresponding to 232 million $ppbar$ pairs. The results are consistent with the hypothesis that the TSA is related to the three-dimensional structure of the produced hadrons, in that it is larger for more compact systems. We show that the TSA is consistent with the hadron pairs being produced by a direct collision between the $ppbar$ pairs, with a TSA of $(0.09\\pm 0.09) \\times 10^{-3}$ and a relative TSA magnitude of $0.71\\pm 0.03$. This is in agreement with theoretical predictions based on the semi-classical Boltzmann equation. We also present evidence that the TSA is smaller when the hadron pairs are produced by an intermediate hadron, with a TSA of $(0.38\\pm 0.17) \\times 10^{-3}$ and a relative TSA magnitude of $0.91\\pm 0.09$. We discuss the results in the framework of the standard quark model and show that a quarkonia-inspired model with an additional quark degree of freedom can also explain our data without any fine-tuning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black-body components in Gamma-Ray Bursts spectra?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3438, "human_text": "  We study 7 Gamma Ray Bursts (GRBs), detected both by the BATSE instrument, on-board the Compton Gamma Ray Observatory, and by the Wide Field Camera (WFC), on-board BeppoSAX. These bursts have measured spectroscopic redshifts and are a sizeable fraction of the bursts defining the correlation between the peak energy E_peak (i.e. the peak of the vFv spectrum) and the total prompt isotropic energy E_iso (the so called \"Amati\" relation). Recent theoretical interpretations of this correlation assume that black-body emission dominates the time resolved spectra of GRBs, even if, in the time integrated spectrum, its presence may be hidden by the change of its temperature and by the dilution of a possible non-thermal power law component. We perform a time resolved spectral analysis, and show that the sum of a power-law and a black-body gives acceptable fits to the time dependent spectra within the BATSE energy range, but overpredicts the flux in the WFC X-ray range. Moreover, a fit with a cutoff power-law plus a black-body is consistent with the WFC data, but the black-body component contributes a negligible fraction of the total flux. On the contrary, we find that fitting the spectra with a Band model or a simple cutoff power-law model yields an X-ray flux and spectral slope which well matches the WFC spectra. ", "machine_text": "  We find that a black-body model can successfully describe the non-Fluke spectrum of a Gamma-Ray Burst (GRB) if the burst has a spectral index that is generally greater than -1. This result is consistent with a simple physical model in which the black-body radiation is due to thermal re-radiation from the photosphere, and the cut-off power-law component is due to simple geometric effects. We have derived a simple analytic expression for the cut-off power-law component in terms of the black-body temperature, the burst's spectral index, and a parameter which represents the geometric truncation of the spectrum. We find that this parameter has a value between 1 and 2 for all observed GRBs, and take this to be an indication that the emission region has a generally Gaussian size distribution. This has implications for models in which the burst emission region is tightly coupled to the surrounding accretion disc. We show that a simple black-body model can provide a good description of the observed GRB spectra without the need to invoke either a fluke component or a cut-off power-law component, and discuss the implications of this for the physical models of GRB emission regions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal inertia of near-Earth asteroids and implications for the\n  magnitude of the Yarkovsky effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1915, "human_text": "  Thermal inertia determines the temperature distribution over the surface of an asteroid and therefore governs the magnitude the Yarkovsky effect. The latter causes gradual drifting of the orbits of km-sized asteroids and plays an important role in the delivery of near-Earth asteroids (NEAs) from the main belt and in the dynamical spreading of asteroid families. At present, very little is known about the thermal inertia of asteroids in the km size range. Here we show that the average thermal inertia of a sample of NEAs in the km-size range is 200 $\\pm$ 40 J m&#8722;2 s&#8722;0.5 K&#8722;1. Furthermore, we identify a trend of increasing thermal inertia with decreasing asteroid diameter, D. This indicates that the dependence of the drift rate of the orbital semimajor axis on the size of asteroids due to the Yarkovsky effect is a more complex function than the generally adopted D^(&#8722;1) dependence, and that the size distribution of objects injected by Yarkovsky-driven orbital mobility into the NEA source regions is less skewed to smaller sizes than generally assumed. We discuss how this fact may help to explain the small difference in the slope of the size distribution of km-sized NEAs and main-belt asteroids. ", "machine_text": "  Thermal inertia of near-Earth asteroids and implications for the magnitude of the Yarkovsky effect  The Yarkovsky effect describes the small but steady force that affects the orbit of a small near-Earth asteroid (NEA) due to the asteroid's gradual rotation and the change in the amount of sunlight absorbed on its surface. Scientists have been able to estimate the Yarkovsky effect for most NEAs. However, the thermal inertia of the surface of a large NEA can be very high, especially for those with a thick regolith layer, which makes the calculation of the Yarkovsky effect more uncertain.   We use a simple model to investigate the effects of thermal inertia on the Yarkovsky effect. We consider the case of an NEA with a regolith layer several meters thick. We find that the standard method used to estimate the Yarkovsky effect yields a larger value for an object with high thermal inertia than for one with low thermal inertia. We show that this is due to the standard method failing to take into account the cooling rate of the interior of the object. We correct this deficiency and show that the corrected Yarkovsky effect for an object with high thermal inertia is in fact smaller than for an object with low thermal inertia. We also investigate the effect of surface thermal inertia on the spin-up rate of an NEA, due to the Yarkovsky effect, and find that this is very small.  We conclude that the Yarkovsky effect is not likely to have a large effect on the orbits of large, high-thermal-inertia NEAs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Particle-vibration coupling within covariant density functional theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1044, "human_text": "  Covariant density functional theory, which has so far been applied only within the framework of static and time dependent mean field theory is extended to include Particle-Vibration Coupling (PVC) in a consistent way. Starting from a conventional energy functional we calculate the low-lying collective vibrations in Relativistic Random Phase Approximation (RRPA) and construct an energy dependent self-energy for the Dyson equation. The resulting Bethe-Salpeter equation in the particle-hole ($ph$) channel is solved in the Time Blocking Approximation (TBA). No additional parameters are used and double counting is avoided by a proper subtraction method. The same energy functional, i.e. the same set of coupling constants, generates the Dirac-Hartree single-particle spectrum, the static part of the residual $ph$-interaction and the particle-phonon coupling vertices. Therefore a fully consistent description of nuclear excited states is developed. This method is applied for an investigation of damping phenomena in the spherical nuclei with closed shells $^{208}$Pb and $^{132}$Sn. Since the phonon coupling terms enrich the RRPA spectrum with a multitude of $ph\\otimes$phonon components a noticeable fragmentation of the giant resonances is found, which is in full agreement with experimental data and with results of the semi-phenomenological non-relativistic approach. ", "machine_text": " We propose a modification to the covariant density functional theory (CDFT) that enables the treatment of small vibrations in the presence of a finite array of point-like scatterers. The motivation for this work is the problem of particle-vibration coupling in photonic crystals, where the oscillations of the semiconductor lattice are driven by the presence of acoustic waves, and the resulting lattice vibrations scatter light. We show that the standard CDFT Hamiltonian is ill-defined when the array of scatterers is finite, because the expansion in the basis of the reciprocal space is incomplete. Our modification remedies this problem by introducing a finite basis set of non-periodic reciprocal space functions that are in one-to-one correspondence with the finite array of scatterers. Within this basis set, we can expand the reciprocal space- bathecd field in a complete set of orthogonal functions that are in general not eigenvectors of the Hamiltonian. The use of this general basis set enables us to evaluate the two-particle correlation functions, and to quantify the effect of the vibrations on the transport properties of the system. We show that our method is applicable to both finite and infinite systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: National Scientific Facilities and Their Science Impact on\n  Non-Biomedical Research. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1797, "human_text": "  H-index, proposed by Hirsch is a good indicator of the impact of a scientist's research. When evaluating departments, institutions or labs, the importance of h-index can be further enhanced when properly calibrated for size. Particularly acute is the issue of federally funded facilities whose number of actively publishing scientists frequently dwarfs that of academic departments. Recently Molinari and Molinari developed a methodology that shows the h-index has a universal growth rate for large numbers of papers, allowing for meaningful comparisons between institutions.   An additional challenge when comparing large institutions is that fields have distinct internal cultures, with different typical rates of publication and citation; biology is more highly cited than physics, which is more highly cited than engineering. For this reason, this study has focused on the physical sciences, engineering, and technology, and has excluded bio-medical research. Comparisons between individual disciplines are reported here to provide contextual framework. Generally, it was found that the universal growth rate of Molinari and Molinari holds well across all the categories considered, testifying to the robustness of both their growth law and our results.   The overall goal here is to set the highest standard of comparison for federal investment in science; comparisons are made with the nations preeminent private and public institutions. We find that many among the national facilities compare favorably in research impact with the nations leading universities. ", "machine_text": " We have developed a suite of analyses to better understand the science impacts of national scientific facilities (NSF), a major category of big science infrastructure. We have identified a wide variety of impacts, including both intended and unintended impacts, that are both scientific and non-scientific in nature. We find that the largest facilities have the greatest impacts, in terms of both the number and the size of the impacts. We have identified a variety of factors that are associated with larger impacts, including the presence of in-house staff scientists, the use of competitive grant awards to drive the research agenda, the use of partnerships to leverage the facility, the use of a peer review system to allocate facility resources, the engagement of faculty from multiple universities, and the targeting of large-scale, long-term science questions. We also find that a large fraction of the impacts of NSF facilities are difficult to attribute to any particular researcher, laboratory, or institution, suggesting the importance of considering the impacts of facilities as a whole, in addition to the impacts of individual scientists, laboratories, or institutions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmogenic neutrinos as a probe of the transition from Galactic to\n  extragalactic cosmic rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0979, "human_text": "  There are two promising scenarios that explain the ankle, which is a dip in the spectrum of cosmic rays at $\\sim 10^{19}$ eV. A scenario interprets the ankle as the transition from Galactic to extragalactic cosmic rays ({\\it ankle-transition scenario}), while the other is that the dip caused by pair production on the cosmic microwave background radiation ({\\it proton-dip scenario}). In this paper, we consider whether cosmogenic neutrinos can be a clue to judge which scenario is favored. We calculated the fluxes of cosmogenic neutrinos following these scenarios with plausible physical parameter sets, and found several important features as follows. First of all, the neutrino flux at $\\sim 10^{20}$ eV becomes much higher in the ankle-transition scenario as long as the maximum energy of the cosmic rays at sources is sufficiently high. On the other hand, the neutrino spectrum has a characteristic peak at $\\sim 10^{16}$ eV in the proton-dip scenario on the condition that extragalactic protons significantly contribute to the observed cosmic rays down to $10^{17}$ eV. Thus, we conclude cosmogenic neutrinos should give us a clue to judge which scenario is favored, unless these features are masked by the neutrino background coming from possible, powerful neutrino sources such as AGNs and GRBs. We also found an interesting feature that the neutrino flux at $\\sim 10^{18}$ eV depends only on the cosmological evolution of the cosmic ray sources. That means cosmogenic neutrinos with the energy bring us information on the cosmological evolution of the sources of ultra-high energy cosmic rays. Finally, we compare the fluxes of cosmogenic neutrinos with the expected sensitivity curves of several neutrino detectors, and conclude the detection of cosmogenic neutrinos in the near future is promising. ", "machine_text": " We present a new method to determine the relative contribution of the three major sources of cosmic rays (CRs): the sun, the galaxy, and extragalactic objects. The method is based on the detection of cosmogenic neutrinos, which are produced in the neutrino-nucleon collisions that occur as CRs traverse the interstellar medium. We show that, in contrast to the large uncertainty in the current determination of the extragalactic CRs based on the measurement of the helium-3 (3He) abundance in meteorites, the neutrino method provides a direct and precise measurement of the extragalactic component. We evaluate the prospects of detecting the neutrinos with a detector in the ice cap over the Antarctica, and determine the necessary exposure to obtain a precise measurement of the extragalactic CRs. The main scientific motivation of the neutrino method is to provide a precise determination of the transition between the galactic and extragalactic CRs, which is important for the understanding of the formation of the CRs, the interstellar medium, and the chemical evolution of the Galaxy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Light nuclei in galactic globular clusters : constraints on the\n  self-enrichment scenario from nucleosynthesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3331, "human_text": "  Hydrogen-burning is the root cause of the star-to-star abundance variations of light nuclei in Galactic globular clusters (GC). In the present work we constrain the physical conditions that gave rise to the observed abundance patterns of Li, C, N, O, Na, Mg, Al, as well as Mg isotopes in the typical case of NGC6752. We perform nucleosynthesis calculations at constant temperature, adopting realistic initial abundances for the proto-cluster gas. We use a detailed nuclear reaction network and state-of-the-art nuclear reaction rates. Although simplistic, our analysis provides original results and new constraints on the self-enrichment scenario for GCs. Our parametrized calculations allow us to determine a narrow range of temperature where the observed extreme abundances of all light elements and isotopes in NGC6752 are nicely reproduced simultaneously. This agreement is obtained after mixing of the H-processed material with 30 % of unprocessed gas. The observed C-N, O-Na, Mg-Al, Li-Na and F-Na anticorrelations, as well as the behaviour of the Mg isotopes can be recovered by assuming mixing with even larger dilution factors. Li production by the stars that build up the other abundance anomalies is not mandatory in the case of NGC 6752. Observations of O, Na, Mg and Al constrain the temperature range for H-burning; such temperatures are encountered in the two main candidate ``polluters'' proposed for GCs, namely massive AGBs and the most massive main-sequence stars. (Abridged). ", "machine_text": " We present constraints on the self-enrichment scenario for light nuclei in galactic globular clusters from nucleosynthesis. We consider the chemical evolution of the cluster as a function of the cluster's age and the primordial abundance of the light nuclei. We find that the enrichment process is very fast at the beginning, but that the cluster is still able to retain the signature of its primordial abundance, despite having a different overall composition. This is because the relative abundances of the light nuclei are very well conserved during the evolution of the cluster. The main sinks of the light nuclei are the formation of heavy nuclei and the ejection of the cluster's gas. We also show that the difference between the cluster's primordial and current abundances has a different origin for each light nucleus, and that this origin is related to the size of the clusters. Our results are consistent with the chemical evolution of the clusters being mainly governed by the relative abundances of the light nuclei, and not by the absolute abundances of these nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unequal dimensional small balls and quantization on Grassmann Manifolds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2278, "human_text": "  The Grassmann manifold G_{n,p}(L) is the set of all p-dimensional planes (through the origin) in the n-dimensional Euclidean space L^{n}, where L is either R or C. This paper considers an unequal dimensional quantization in which a source in G_{n,p}(L) is quantized through a code in G_{n,q}(L), where p and q are not necessarily the same. It is different from most works in literature where p\\equiv q. The analysis for unequal dimensional quantization is based on the volume of a metric ball in G_{n,p}(L) whose center is in G_{n,q}(L). Our chief result is a closed-form formula for the volume of a metric ball when the radius is sufficiently small. This volume formula holds for Grassmann manifolds with arbitrary n, p, q and L, while previous results pertained only to some special cases. Based on this volume formula, several bounds are derived for the rate distortion tradeoff assuming the quantization rate is sufficiently high. The lower and upper bounds on the distortion rate function are asymptotically identical, and so precisely quantify the asymptotic rate distortion tradeoff. We also show that random codes are asymptotically optimal in the sense that they achieve the minimum achievable distortion with probability one as n and the code rate approach infinity linearly. Finally, we discuss some applications of the derived results to communication theory. A geometric interpretation in the Grassmann manifold is developed for capacity calculation of additive white Gaussian noise channel. Further, the derived distortion rate function is beneficial to characterizing the effect of beamforming matrix selection in multi-antenna communications. ", "machine_text": "  We show that on a Grassmann manifold the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls differs. This answers a question of Denisov- Rocco-S Meyers, but in our setting the result is more general, in the sense that we do not assume that the odd-dimensional balls are contained in the even-dimensional submanifolds.  Let $\\Goo$ be a real Grassmann manifold and let $\\Gmm$ be its symmetric product. We show that the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls of $\\Gmm$ differs.  The idea is to use the Grassmannian description of $\\Gmm$ in terms of the symmetric and anti-symmetric $\\delta$-Neumann functions on $\\Goo$. If $\\Goo$ is the space of symmetric $\\delta$-Neumann functions, then $\\Gmm$ is the Grassmannian of symmetric $\\delta$-Neumann functions, seen as a subspace of the space of symmetric $\\delta$-Neumann functions on $\\Goo^{2}$.  We give an example of a Grassmann manifold with an anti-symmetric $\\delta$-Neumann function, and show that the quantization of the symmetric and anti-symmetric Fearless symmetry transformations of the odd-dimensional small balls of $\\Gmm$ differs. As an application, we give a description of the odd-dimensional small balls of $\\Gmm$ in terms of the anti-symmetric $\\delta$-Neumann functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Disclinations, dislocations and continuous defects: a reappraisal. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3055, "human_text": "  Disclinations, first observed in mesomorphic phases, are relevant to a number of ill-ordered condensed matter media, with continuous symmetries or frustrated order. They also appear in polycrystals at the edges of grain boundaries. They are of limited interest in solid single crystals, where, owing to their large elastic stresses, they mostly appear in close pairs of opposite signs. The relaxation mechanisms associated with a disclination in its creation, motion, change of shape, involve an interplay with continuous or quantized dislocations and/or continuous disclinations. These are attached to the disclinations or are akin to Nye's dislocation densities, well suited here. The notion of 'extended Volterra process' takes these relaxation processes into account and covers different situations where this interplay takes place. These concepts are illustrated by applications in amorphous solids, mesomorphic phases and frustrated media in their curved habit space. The powerful topological theory of line defects only considers defects stable against relaxation processes compatible with the structure considered. It can be seen as a simplified case of the approach considered here, well suited for media of high plasticity or/and complex structures. Topological stability cannot guarantee energetic stability and sometimes cannot distinguish finer details of structure of defects. ", "machine_text": " We have developed a new method for the determination of dislocations in electron diffraction, based on the analysis of the Kikuchi patterns. The method is sensitive to the dislocation density, independent of the dislocation distribution, and does not require an empirical calibration curve. We have applied the method to a single crystal of YBa2Cu3O7, a good conductor, in which the dislocation density has been previously determined by theReachfug technique. Our results agree with the previous determination, but, in addition, we have found that the dislocations are not distributed randomly, but tend to be arranged in a preferred direction, which we attribute to the influence of the magnetic field. We have also determined the dislocation density in a single crystal of SrTiO3, a bad conductor, and in a polycrystalline sample of YBa2Cu3O7. In both cases, the dislocation density was much higher than in the single crystal. We discuss our results in the framework of the theory of dislocations in ionic crystals.  The main result of this work is the development of a new method for the determination of dislocations in ionic crystals, based on the analysis of the Kikuchi patterns in electron diffraction. The method is sensitive to the dislocation density, independent of the dislocation distribution, and does not require an empirical calibration curve. We have applied the method to a single crystal of YBa2Cu3O7 and to a single crystal of SrTiO3, and in both cases we have found that the dislocations are not distributed randomly, but tend to be arranged in a preferred direction, which we attribute to the influence of the magnetic field in the case of YBa2Cu3O7, and to the influence of the strain in the case of SrTiO3. We have also determined the dislocation density in a polycrystalline sample of YBa2Cu3O7, and in this case the dislocation density was much higher than in the single crystal. We discuss our results in the framework of the theory of dislocations in ionic crystals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A New Proof of Pappus's Theorem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3424, "human_text": "  Any stretching of Ringel's non-Pappus pseudoline arrangement when projected into the Euclidean plane, implicitly contains a particular arrangement of nine triangles. This arrangement has a complex constraint involving the sines of its angles. These constraints cannot be satisfied by any projection of the initial arrangement. This is sufficient to prove Pappus's theorem. The derivation of the constraint is via systems of inequalities arising from the polar coordinates of the lines. These systems are linear in r for any given theta, and their solubility can be analysed in terms of the signs of determinants. The evaluation of the determinants is via a normal form for sums of products of sines, giving a powerful system of trigonometric identities. The particular result is generalized to arrangements derived from three edge connected totally cyclic directed graphs, conjectured to be sufficient for a complete analysis of angle constraining arrangements of lines, and thus a full response to Ringel's slope conjecture. These methods are generally applicable to the realizability problem for rank 3 oriented matroids. ", "machine_text": "  We present a new and elementary proof of Pappus's theorem, namely that any Pappus system (a system of three circles in general position in the plane such that all three circles are orthogonal to each other) is equivalent to the orthogonal projection of a certain tetrahedron on the plane. Our proof does not use the tools of projective geometry, as do all previous proofs, but proceeds by establishing a one-to-one correspondence between Pappus systems and certain \"off-center\" equilateral triangles. We show that any Pappus system can be obtained from such an \"off-center\" equilateral triangle by a sequence of reflections and rotations, and that this sequence has the same effect on the equilateral triangle as does the orthogonal projection of a tetrahedron onto the plane. Our proof is based on the properties of reflections in circles and on the observation that four reflections in circles, or equivalently, four orthogonal projections of a tetrahedron onto the plane, can be obtained by means of a single isometric reflection in the plane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A rigidity theorem for the mapping class group action on the space of\n  unmeasured foliations on a surface. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1837, "human_text": "  Let $S$ be a surface of finite type which is not a sphere with at most four punctures, a torus with at most two punctures, or a closed surface of genus two. Let $\\mathcal{MF}$ be the space of equivalence classes of measured foliations of compact support on $S$ and let $\\mathcal{UMF}$ be the quotient space of $\\mathcal{MF}$ obtained by identifying two equivalence classes whenever they can be represented by topologically equivalent foliations, that is, forgetting the transverse measure. The extended mapping class group $\\Gamma^*$ of $S$ acts as by homeomorphisms of $\\mathcal{UMF}$. We show that the restriction of the action of the whole homeomorphism group of $\\mathcal{UMF}$ on some dense subset of $\\mathcal{UMF}$ coincides with the action of $\\Gamma^*$ on that subset. More precisely, let $\\mathcal{D}$ be the natural image in $\\mathcal{UMF}$ of the set of homotopy classes of not necessarily connected essential disjoint and pairwise nonhomotopic simple closed curves on $S$. The set $\\mathcal{D}$ is dense in $\\mathcal{UMF}$, it is invariant by the action of $\\Gamma^*$ on $\\mathcal{UMF}$ and the restriction of the action of $\\Gamma^*$ on $\\mathcal{D}$ is faithful. We prove that the restriction of the action on $\\mathcal{D}$ of the group $\\mathrm{Homeo}(\\mathcal{UMF})$ coincides with the action of $\\Gamma^*(S)$ on that subspace. ", "machine_text": "  We prove a rigidity theorem for the mapping class group action on the space of unmeasured foliations on a surface. Let $\\pi:S^1\\to M$ be a covering space action. We show that the induced action on the space of unmeasured foliations is given by a mapping class group element. As an application, we give a description of the fixed points of this action.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Higher K-theory via universal invariants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.242, "human_text": "  Using the formalism of Grothendieck's derivators, we construct `the universal localizing invariant of dg categories'. By this, we mean a morphism U_l from the pointed derivator associated with the Morita homotopy theory of dg categories to a triangulated strong derivator M^loc such that U_l commutes with filtered homotopy colimits, preserves the point, sends each exact sequence of dg categories to a triangle and is universal for these properties. Similary, we construct the `the universal additive invariant of dg categories', i.e. the universal morphism of derivators U_a to a strong triangulated derivator M^add which satisfies the first two properties but the third one only for split exact sequences. We prove that Waldhausen K-theory appears as a mapping space in the target of the universal additive invariant. This is the first conceptual characterization of Quillen-Waldhausen's K-theory since its definition in the early 70's. As an application we obtain for free the higher Chern characters from K-theory to cyclic homology. ", "machine_text": "  We give a short survey of some of the main results of the theory of K-theory, as developed by Grothendieck and his school. We present the material in an informal way, attempting to explain the main ideas and to give the reader an intuition for the theory, rather than a rigorous and complete account of the various results. We describe the main ingredients of the theory of K-theory, and explain how the theory developed from attempts to understand the structure of algebraic varieties. We explain the connection between K-theory and the theory of linear algebra, and we survey the basic results of the theory of K-modules. We explain how K-theory can be used to produce new invariants of algebraic varieties, and we survey some of the main results of this theory, including the basic results of the theory of universal K-invariants. We explain how K-theory can be used to study the relation between geometry and algebraic topology, and we survey the basic results of the theory of K-theories of topology. We explain the connection between K-theory and the theory of finite dimensional representations of groups, and we survey the basic results of the theory of K-modules for groups. We explain the connection between K-theory and the theory of Shalev-Schaler type theorems, and we survey the basic results of the theory of K-theory for metric spaces.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SN 2005hj: Evidence for Two Classes of Normal-Bright SNe Ia and\n  Implications for Cosmology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4467, "human_text": "  HET Optical spectra covering the evolution from about 6 days before to about 5 weeks after maximum light and the ROTSE-IIIb unfiltered light curve of the \"Branch-normal\" Type Ia Supernova SN 2005hj are presented. The host galaxy shows HII region lines at redshift of z=0.0574, which puts the peak unfiltered absolute magnitude at a somewhat over-luminous -19.6. The spectra show weak and narrow SiII lines, and for a period of at least 10 days beginning around maximum light these profiles do not change in width or depth and they indicate a constant expansion velocity of ~10,600 km/s. We analyzed the observations based on detailed radiation dynamical models in the literature. Whereas delayed detonation and deflagration models have been used to explain the majority of SNe Ia, they do not predict a long velocity plateau in the SiII minimum with an unvarying line profile. Pulsating delayed detonations and merger scenarios form shell-like density structures with properties mostly related to the mass of the shell, M_shell, and we discuss how these models may explain the observed SiII line evolution; however, these models are based on spherical calculations and other possibilities may exist. SN 2005hj is consistent with respect to the onset, duration, and velocity of the plateau, the peak luminosity and, within the uncertainties, with the intrinsic colors for models with M_shell=0.2 M_sun. Our analysis suggests a distinct class of events hidden within the Branch-normal SNe Ia. If the predicted relations between observables are confirmed, they may provide a way to separate these two groups. We discuss the implications of two distinct progenitor classes on cosmological studies employing SNe Ia, including possible differences in the peak luminosity to light curve width relation. ", "machine_text": " We present observations of SN 2005hj, a nearby, bright, and well-observed Type Ia supernova. The light curve is well described by a sum of two exponential curves with a superimposed tail. The best-fit parameters are a peak absolute magnitude of -15.07 mag, a total light-emission duration of ~140 d, and a supernova (SN) mass of 1.3 \u00a0M\u2299. These properties are consistent with those of a normal-bright SN Ia. Our analysis indicates that the radiative tail, which contributes >10% to the total light budget, has a power law index of -0.9 and a duration of 70 d. We show that this radiative tail has a nearly constant decay rate, which implies that the temperature of the accretion disk is constant during the entire course of the explosion. We argue that this is inconsistent with the commonly held assumption that the accretion disk is fed with material from the rotating shell of the pre-explosion evolved star. We suggest that this disk is fed with material from the inner circumstellar layer, and that the inner layer is heated by radioactive decay and not by the accretion torque. This suggests that the mechanism of explosion in SNe of this class is different from that of the majority of normal-bright SNe. We discuss the implications of this difference for the mechanism of accretion, the understanding of radiative transfer, and the use of SNe as standard candles. We show that the combined light curve of SN 2005hj is consistent with the recent theoretical predictions of Miao et al. (2004), but our analysis suggests that their model needs to be modified. Finally, we argue that the observed properties of SN 2005hj are consistent with a single-zone structure for the accretion disk, and we show that a two-zone structure leads to a worse fit to the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coriolis force corrections to g-mode spectrum in 1D MHD model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2923, "human_text": "  The corrections to g-mode frequencies caused by the presence of a central magnetic field and rotation of the Sun are calculated. The calculations are carried out in the simple one dimensional magnetohydrodynamical model using the approximations which allow one to find the purely analytical spectra of magneto-gravity waves beyond the scope of the JWKB approximation and avoid in a small background magnetic field the appearance of the cusp resonance which locks a wave within the radiative zone. These analytic results are compared with the satellite observations of the g-mode frequency shifts which are of the order one per cent as given in the GOLF experiment at the SoHO board. The main contribution turns out to be the magnetic frequency shift in the strong magnetic field which obeys the used approximations. In particular, the fixed magnetic field strength 700 KG results in the mentioned value of the frequency shift for the g-mode of the radial order n=-10. The rotational shift due to the Coriolis force appears to be small and does not exceed a fracton of per cent, \\alpha_\\Omega < 0.003. ", "machine_text": " We consider a one-dimensional magnetohydrodynamic model with self-consistently generated mean flow and a superposed turbulent velocity field. We derive a system of nonlinear partial differential equations for the statistical quantities of the model which is shown to be capable of describing several basic hydrodynamic and gyrokinetic phenomena in a statistically steady state regime. After an appropriate regularization, the problem is shown to have a unique solution which is related to the solution of the Navier-Stokes equations with a small but constant temperature gradient and a linear, inviscid, temperature dependent term describing the action of the Coriolis force. We evaluate the Coriolis force spectrum and show that it is related to the power spectrum of the velocity field. Our model is capable of describing various physical situations, such as a pure laminar flow, a flow with a constant mean velocity and a linear temperature gradient, a flow with a constant mean velocity and a parabolic temperature gradient, a flow with a variable mean velocity and a linear temperature gradient, and a turbulent flow. We analyze the influence of the physical parameters of the model on the shape of the solution and we discuss the differences with the case of a stationary fluid. Finally, we comment on the possible physical meanings of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is the Concentration of Dark Matter Halos at Virialization Universal ?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0856, "human_text": "  Several recent studies suggest a correlation between dark matter halo mass and the shape of the density profile. We re-analyze simulations from Ricotti (2003) in which such a correlation was proposed. We use a standard analysis of the halo density profiles and compare the old simulations to new ones performed with Gadget2, including higher resolution runs. We confirm Ricotti's result that, at virialization, the central log slopes alpha, at 5%-10% of the virial radius are correlated with the halo mass and that the halo concentration is a universal constant. Our results do not contradict the majority of published papers: when using a split power law to fit the density profiles, due to the alpha-concentration degeneracy, the fits are consistent with halos having a universal shape with alpha=1 or 1.5 and concentrations that depend on the mass, in agreement with results published elsewhere.   Recently, several groups have found no evidence for convergence of the inner halo profile to a constant power law. The choice of a split power law parameterization used in this letter is motivated by the need to compare our results to previous ones and is formally valid because we are not able to resolve regions where the slope of the fitting function reaches its asymptotic constant value. Using a non-parameterized technique, we also show that the density profiles of dwarf galaxies at z ~ 10 have a log slope shallower than 0.5 within 5% of the virial radius. ", "machine_text": "  We present a simple model of the evolution of dark matter halos from the formation to the virialization stage. Our main result is that the concentration of the dark matter halos, as a function of mass, is universal in the sense that it is independent of the detailed structure of the halos. We show this by comparing our model to the observations of galaxy clusters and to the results of numerical simulations. The model is based on the idea that the formation of structure in the universe can be described by the competition between the growth of halos and the increase of the mean density in the Universe. Our model predicts that the number density of halos is proportional to the volume density of the Universe. This is in agreement with observations, and it implies that the mass of a halo is proportional to the volume of the Universe. In addition, the model predicts that the density profile of a halo is independent of its mass. We discuss the implications of our result for structure formation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Point-contact spectroscopy of the antiferromagnetic superconductor\n  HoNi2B2C in the normal and superconducting state. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3405, "human_text": "  Point-contact (PC) spectroscopy measurements on antiferromagnetic (AF) (T_N=5.2K) HoNi2B2C single crystals in the normal and two different superconducting (SC) states (T_c=8.5K and $T_c^*=5.6K) are reported. The PC study of the electron-boson(phonon) interaction (EB(P)I) spectral function reveals pronounced phonon maxima at 16, 22 and 34meV. For the first time the high energy maxima at about 50meV and 100meV are resolved. Additionally, an admixture of a crystalline-electric-field (CEF) excitations with a maximum near 10meV and a `magnetic` peak near 3meV are observed. The contribution of the 10-meV peak in PC EPI constant \\lambda_PC is evaluated as 20-30%, while contribution of the high energy modes at 50 and 100meV amounts about 10% for each maxima, so the superconductivity might be affected by CEF excitations. The SC gap in HoNi2B2C exhibits a standard single-band BCS-like dependence, but vanishes at $T_c^*=5.6K<T_c, with 2\\Delta/kT_c^*=3.9. The strong coupling Eliashberg analysis of the low-temperature SC phase with T_c^*=5.6K =T_N, coexisting with the commensurate AF structure, suggests a sizable value of the EPI constant \\lambda_s=0.93. We also provide strong support for the recently proposed by us ''Fermi surface (FS) separation'' scenario for the coexistence of magnetism and superconductivity in magnetic borocarbides, namely, that the superconductivity in the commensurate AF phase survives at a special (nearly isotropic) FS sheet without an admixture of Ho 5d states. Above T_c^* the SC features in the PC characteristics are strongly suppressed pointing to a specific weakened SC state between T_c* and T_c. ", "machine_text": "  We report point-contact spectroscopy of the superconductor HoNi2B2C in the normal and superconducting state. The superconducting state shows the same spectral features as the normal state, but with a larger spectral gap and a different temperature dependence of the spectral energy. We show that the energy gap in the superconducting state can be explained by a mechanism of thermal activation of the normal state transition. Our results suggest that the electronic structure of this heavy-fermion superconductor is very similar in the normal and superconducting state.  We have developed a new method for point-contact spectroscopy which does not require a metal tip but instead uses a semiconductor tip which is lightly doped with donors. This method, which we have called Point-Contact Spectroscopy by Non-Tunneling Current (PCSNT), has several advantages over the usual method of point-contact spectroscopy using a metal tip. It is much easier to make a good point contact with a semiconductor tip than with a metal tip, since the semiconductor tip can be made very sharp and has a much higher thermal stability. In addition, the PCSNT method can be used to study the electrical properties of the normal state as well as the superconducting state, whereas the usual method can only be used for the superconducting state.  We have used the PCSNT method to study the electronic structure of the normal state and the superconducting state of the heavy-fermion superconductor HoNi2B2C. We found that the superconducting state has a different spectral energy distribution than the normal state, with a larger spectral gap, but that the shape of the spectral features is very similar in the two states. We have explained the larger spectral gap in the superconducting state by a mechanism of thermal activation of the normal state transition. Our results suggest that the electronic structure of this heavy-fermion superconductor is very similar in the normal and superconducting state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On over-reflection and generation of Gravito-Alfven waves in solar-type\n  stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3919, "human_text": "  The dynamics of linear perturbations is studied in magnetized plasma shear flows with a constant shearing rate and with gravity-induced stratification. The general set of linearized equations is derived and the two-dimensional case is considered in detail. The Boussinesq approximation is used in order to examine relatively small-scale perturbations of low-frequency modes: Gravito-Alfven waves (GAW) and Entropy Mode (EM) perturbations. It is shown that for flows with arbitrary shearing rate there exists a finite time interval of non-adiabatic evolution of the perturbations. The non-adiabatic behavior manifests itself in a twofold way, viz. by the over-reflection of the GAWs and by the generation of GAWs from EM perturbations. It is shown that these phenomena act as efficient transformers of the equilibrium flow energy into the energy of the perturbations for moderate and high shearing rate solar plasma flows. Efficient generation of GAW by EM takes place for shearing rates about an order of magnitude smaller than necessary for development of a shear instability. The latter fact could have important consequences for the problem of angular momentum redistribution within the Sun and solar-type stars. ", "machine_text": " We investigate the generation of gravito-Alfven waves (GAWs) in solar-type stars. We find that the outward-propagating GAWs can be generated by over-reflection of Alfv\u00e9n waves (AWs) at the inner edge of the boundary layer (BL) when the forcing is directed along the star's rotation axis. We also find that the generation rate is sensitive to the stellar rotation frequency, and that the inner BL can become unstable to the generation of GAWs when the forcing frequency is close to the rotation frequency. We show that the quasistationary structure of the unstable BL is characterized by the presence of a standing GAW, and that the transition to the unstable state is accompanied by a change in the dominant mode of the GAW from a pure Alfv\u00e9nic mode to a damped Alfv\u00e9nic mode with a substantial slow-mode component. The properties of the unstable BL are consistent with the formation of a rotating barrel structure. We find that the standing GAW is stable against the AWs that are generated by the forcing. Therefore, the outer edge of the BL can be considered as a boundary for the GAWs, and the BL itself as a waveguide for the AWs. Within this picture, we derive a simple expression for the coupling coefficient between the forcing and the generated GAWs. We also derive a simple expression for the critical frequency, below which the inner BL becomes unstable to the generation of GAWs. We show that these expressions are consistent with the available numerical and theoretical results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effects of the anomaly on the two-flavor QCD chiral phase transition. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0617, "human_text": "  We use strongly coupled lattice QED with two flavors of massless staggered fermions to model the physics of pions in two-flavor massless QCD. Our model has the right chiral symmetries and can be studied efficiently with cluster algorithms. In particular we can tune the strength of the QCD anomaly and thus study its effects on the chiral phase transition. Our study confirms the widely accepted view point that the chiral phase transition is first order in the absence of the anomaly. Turning on the anomaly weakens the transition and turns it second order at a critical anomaly strength. The anomaly strength at the tricritical point is characterized using $r = (M_{\\eta'}-M_{\\pi})/\\rho_{\\eta'}$ where $M_{\\eta'}, M_{\\pi}$ are the screening masses of the anomalous and regular pions and $\\rho_{\\eta'}$ is the mass-scale that governs the low energy fluctuations of the anomalous symmetry. We estimate that $r \\sim 7 $ in our model. This suggests that a strong anomaly at the two-flavor QCD chiral phase transition is necessary to wash out the first order transition. ", "machine_text": " We study the effects of the anomaly on the two-flavor QCD chiral phase transition. We consider a general definition of the chiral transition temperature, and evaluate the conditions for the anomaly to have a significant effect on the transition. We show that the anomaly can delay the transition, and can even lead to a transition to a phase where the fermionic generators are not balanced. The conditions for this to occur are rather general, and in particular do not require a particular form for the potential between the two fermionic generators. We also derive a general criterion for the transition temperature to be sensitive to the anomaly. We then study the particular case of a point-coupling potential, and evaluate the conditions for a transition temperature to exist in this case. We show that these conditions are rather general, and in particular do not require the anomaly to be large. We finally study the effect of a small anomaly on the thermodynamic properties of the chiral transitions, and in particular on the order parameter and on the critical temperature. We show that small anomalies can have a significant effect on these quantities, even when they do not delay the transition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the nature of optical nuclei in FR I radio-galaxies from ACS/HST\n  imaging polarimetry. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1944, "human_text": "  We obtained optical imaging polarimetry with the ACS/HRC aboard the HST of the 9 closest radio-galaxies in the 3C catalogue with an FR I morphology. The nuclear sources seen in direct HST images in these galaxies are found to be highly polarized with levels in the range ~2-11 % with a median value of 7 %. We discuss the different mechanisms that produce polarized emission and conclude that the only viable interpretation is a synchrotron origin for the optical nuclei. This idea is strengthened by the analogy with the polarization properties of BL Lac objects, providing also further support to the FRI/BL Lac unified model. This confirms previous suggestions that the dominant emission mechanism in low luminosity radio-loud AGN is related to non-thermal radiation produced by the base of their jets. In addition to the nuclear polarization (and to the large scale optical jets), polarization is detected co-spatially with the dusty circumnuclear disks, likely due to dichroic transmission; the polarization vectors are tangential to the disks as expected when the magnetic field responsible for the grains alignment is stretched by differential rotation. We explored the possibility to detect the polarimetric signature of a misaligned radiation beam in FR I, expected in our sources in the frame of the FR I/ BL Lac unification. We did not find this effect in any of the galaxies, but our the results are not conclusive on whether a misaligned beam is indeed present in FR I. ", "machine_text": "  We present high-resolution imaging polarimetry of the nuclei of 25 nearby radio galaxies in the first (and most nearby) radio galaxy filament, using data obtained with the Advanced Camera for Surveys (ACS) onboard the Hubble Space Telescope (HST). We find that the light emitted by the nuclear regions is highly polarized, with the percentage of linearly polarized light (PL) ranging from 60% to 80%. The degree of circular polarization (CP) of the light emitted by the nuclei is large ( ranging from 20% to 50% when defined as the fraction of the total light that is polarized in a right-handed direction), indicating that the geometry of the emission is very likely dominated by torus-like structures. We find that the nuclei of radio galaxies in the first filament, in particular those with higher optical luminosity, have a higher degree of polarization in their optical light than the nuclei of radio galaxies in the second filament, even after controlling for distance, radio power, and optical luminosity. Our results suggest that in addition to the torus-like structures revealed by the high degree of CP, the nuclear regions of radio galaxies also contain large amounts of polarized light that is ordered along the direction of the jet, probably due to interaction of the relativistic jet with the torus. We find a correlation between the magnetic field strength measured in the radio band and the degree of CP in the optical band, suggesting that the magnetic field is responsible for the CP structure. Our results also suggest that in radio galaxies the large-scale organization of the magnetic field is likely to be correlated with the large-scale structure of the torus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing dark energy with steerable wavelets through correlation of WMAP\n  and NVSS local morphological measures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0626, "human_text": "  Using local morphological measures on the sphere defined through a steerable wavelet analysis, we examine the three-year WMAP and the NVSS data for correlation induced by the integrated Sachs-Wolfe (ISW) effect. The steerable wavelet constructed from the second derivative of a Gaussian allows one to define three local morphological measures, namely the signed-intensity, orientation and elongation of local features. Detections of correlation between the WMAP and NVSS data are made with each of these morphological measures. The most significant detection is obtained in the correlation of the signed-intensity of local features at a significance of 99.9%. By inspecting signed-intensity sky maps, it is possible for the first time to see the correlation between the WMAP and NVSS data by eye. Foreground contamination and instrumental systematics in the WMAP data are ruled out as the source of all significant detections of correlation. Our results provide new insight on the ISW effect by probing the morphological nature of the correlation induced between the cosmic microwave background and large scale structure of the Universe. Given the current constraints on the flatness of the Universe, our detection of the ISW effect again provides direct and independent evidence for dark energy. Moreover, this new morphological analysis may be used in future to help us to better understand the nature of dark energy. ", "machine_text": " We propose a new method to probe dark energy by correlating local galaxy density and local galaxy morphology measures extracted from the WMAP and NVSS surveys, respectively. Our method is based on the use of steerable wavelets, which enable us to optimally extract the relevant information from the two surveys. We show that our procedure is sensitive to the dark energy density in a manner that is independent of the specific choice of galaxy density and morphology measures. We find that the cross-correlation function of our optimally extracted density and morphology measures peaks at a dark energy density of omega_0 = -1.01 +/- 0.06 (h = 150 Mpc), in good agreement with the value extracted from the cosmic microwave background anisotropy. Our confidence level is better than 5sigma. We show that our procedure is sensitive to local variations of the dark energy density in a manner that is consistent with a Taylor-scale expansion of the Universe. We also show that our procedure is largely insensitive to the specific choice of galaxy density and morphology measures, as long as they are extracted with the use of steerable wavelets. We discuss the implications of our findings for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Socioeconomic Networks with Long-Range Interactions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0024, "human_text": "  We study a modified version of a model previously proposed by Jackson and Wolinsky to account for communicating information and allocating goods in socioeconomic networks. In the model, the utility function of each node is given by a weighted sum of contributions from all accessible nodes. The weights, parameterized by the variable $\\delta$, decrease with distance. We introduce a growth mechanism where new nodes attach to the existing network preferentially by utility. By increasing $\\delta$, the network structure evolves from a power-law to an exponential degree distribution, passing through a regime characterised by shorter average path length, lower degree assortativity and higher central point dominance. In the second part of the paper we compare different network structures in terms of the average utility received by each node. We show that power-law networks provide higher average utility than Poisson random networks. This provides a possible justification for the ubiquitousness of scale-free networks in the real world. ", "machine_text": "  We investigate a class of random socioeconomic networks with long-range interactions, which are motivated by many real-world social and information networks, where both local and non-local connections are important. We find that these networks are characterized by a few strongly connected nodes (or communities), which are connected to each other by a small number of links, and many weakly connected nodes, which are connected mostly to the strongly connected nodes by a large number of links. This is in sharp contrast to the properties of random networks without long-range interactions, where the degree distribution is power law and the average path length is small. We find that the PageRank algorithm is inefficient in these networks, because it is designed to operate on networks with many local connections. We develop a simple modification of the PageRank algorithm that takes into account the non-local connections, and show that this modified algorithm is more efficient in discovering the strongly connected nodes. Our results suggest that the community detection methods based on the local interactions may be further improved by taking into account the non-local interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: L'Univers en expansion et probl\\`emes d'\\'energie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1248, "human_text": "  In this paper we first construct a mathematical model for the Universe expansion that started up with the original Big Bang. Next, we discuss the problematic of the mechanical and physical laws invariance regarding the spatial frame exchanges. We then prove the (theoretical) existence of a variable metric $g_t$, depending on time and satisfying to a simplified Einstein equation, so that all free ordinary trajectories are geodesics. This is done by considering the classical Galileo-Newtonian space and time relation, by using generalized Newtonian principles and adding the approved physical new ones (as covariance principle, Mach principle, the Einstein equivalence principle ...) in order to establish a new cosmological model of the dynamical Universe as being $(U(t))_{t\\geq 0}=(B_e(O,t),g_t)_{t\\geq 0}$, where $B_e(O,t)$ is the Euclidean ball of radius $t$ in $\\mathbb R^3$. The cosmological metric $g_t$ is totally determined, at time $t$, by the mass energy distribution $E_t(X)$ on $B_e(O,t)$. We study also the black holes phenomenon and we prove that the total and global cosmological energy distribution $E_t(X)$ satisfies to the wave equation whose solutions are characterized by pseudo-frequencies depending on time and related to the spectrum of the Dirichlet problem on the unit ball $B_e(O,1)$ for the Laplace-Beltrami operator -$\\Delta$. Our model is consistent in the sense that all Newtonian and classical physical laws are valid as particular cases in classical situations. Then, we show that all basic results of Modern Physics are still valid without using the second postulate of special relativity nor the uncertainty principle. ", "machine_text": "  We present a brief survey of the physical problem of the energy of the expanding universe, with emphasis on the problem of the energy density of the universe and the conditions for its stability. We show that the evolution of the energy of the universe is governed by the principle of energy conservation, and that the energy of the universe is always positive. We discuss the problem of the energy of the universe in the context of the theory of general relativity, and we show that the energy of the universe is bounded from below. We discuss the problem of the stability of the energy of the universe, and we show that the energy of the universe is stable if the principle of energy conservation is satisfied. We show that the energy of the universe is not stable if the principle of energy conservation is not satisfied. We discuss the problem of the energy of the universe in the context of the theory of quantum mechanics, and we show that the energy of the universe is not quantized. We discuss the problem of the energy of the universe in the context of the theory of thermodynamics, and we show that the energy of the universe is not a state function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Very High Energy Gamma-ray Radiation from the Stellar-mass Black Hole\n  Cygnus X-1. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1505, "human_text": "  We report on the results from the observations in very high energy band (VHE, E_gamma > 100 GeV) of the black hole X-ray binary (BHXB) Cygnus X-1. The observations were performed with the MAGIC telescope, for a total of 40 hours during 26 nights, spanning the period between June and November 2006. Searches for steady gamma-ray signals yielded no positive result and upper limits to the integral flux ranging between 1 and 2% of the Crab nebula flux, depending on the energy, have been established. We also analyzed each observation night independently, obtaining evidence of gamma-ray signals at the 4.0 standard deviations (sigma) significance level (3.2 sigma after trial correction) for 154 minutes effective on-time (EOT) on September 24 between 20h58 and 23h41 UTC, coinciding with an X-ray flare seen by RXTE, Swift and INTEGRAL. A search for faster-varying signals within a night resulted in an excess with a significance of 4.9 sigma (4.1 sigma after trial correction) for 79 minutes EOT between 22h17 and 23h41 UTC. The measured excess is compatible with a point-like source at the position of Cygnus X-1, and excludes the nearby radio nebula powered by its relativistic jet. The differential energy spectrum is well fitted by an unbroken power-law described by dN/(dA dt dE) = (2.3+- 0.6) x 10^{-12} (E/1 TeV)^{-3.2 +- 0.6}. This is the first experimental evidence of VHE emission from a stellar-mass black hole, and therefore from a confirmed accreting X-ray binary. ", "machine_text": " We present observations of very high energy (VHE, E>100 keV) gamma-ray radiation from the stellar-mass black hole candidate Cygnus X-1. The observations were made with the VHE sensitive imaging atmospheric Cherenkov telescope (IACT) ZTF-magnometer (ZTF-m) and cover a period of more than ten years, from 2007 to 2017. We find that the VHE gamma-ray flux from Cygnus X-1 is highly variable, with a peak flux density of  \u223c 4 \u2212 10 counts per detector per hour (ch/det/hr) and an average flux density of  \u223c 1.3 ch/det/hr during the period of observations. These values correspond to a total VHE gamma-ray luminosity of  \u223c 4.1  \u2217 1036 erg s\u22121 and an average VHE gamma-ray luminosity of  \u223c 1.4  \u2217 1036 erg s\u22121 during the period of observations. We find that the VHE gamma-ray emission from Cygnus X-1 is likely due to the accretion disc around the black hole, in agreement with the predictions of magnetized drum-up models. Our results suggest that the accretion disc around stellar-mass black holes is able to produce a significant amount of VHE gamma-ray radiation, even in the presence of a strong magnetic field, and that much of this VHE gamma-ray radiation is absorbed by the accretion disc itself.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A map of the day-night contrast of the extrasolar planet HD 189733b. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0993, "human_text": "  \"Hot Jupiter\" extrasolar planets are expected to be tidally locked because they are close (<0.05 astronomical units, where 1 AU is the average Sun-Earth distance) to their parent stars, resulting in permanent daysides and nightsides. By observing systems where the planet and star periodically eclipse each other, several groups have been able to estimate the temperatures of the daysides of these planets. A key question is whether the atmosphere is able to transport the energy incident upon the dayside to the nightside, which will determine the temperature at different points on the planet's surface. Here we report observations of HD 189733, the closest of these eclipsing planetary systems, over half an orbital period, from which we can construct a 'map' of the distribution of temperatures. We detected the increase in brightness as the dayside of the planet rotated into view. We estimate a minimum brightness temperature of 973 +/- 33 K and a maximum brightness temperature of 1212 +/- 11 K at a wavelength of 8 microns, indicating that energy from the irradiated dayside is efficiently redistributed throughout the atmosphere, in contrast to a recent claim for another hot Jupiter. Our data indicate that the peak hemisphere-integrated brightness occurs 16$\\pm$6 degrees before opposition, corresponding to a hot spot shifted east of the substellar point. The secondary eclipse (when the planet moves behind the star) occurs 120 +/- 24 s later than predicted, which may indicate a slightly eccentric orbit. ", "machine_text": "  A map of the day-night contrast of the extrasolar planet HD 189733b  We present photometric measurements of the day-night contrast of the extrasolar planet HD 189733b, as observed with the Hubble Space Telescope. We find that the contrast is very sensitive to the spatial distribution of clouds in the atmosphere. If the clouds are distributed in a ring, the contrast is high and symmetric, but if the clouds are only located near the equator, the contrast is much lower and asymmetric. We have developed a simple model that can reproduce our observations provided that the clouds are located above the equatorial region. This model suggests that clouds form at high latitudes and then move towards the equator. Our results are consistent with a wind field that is aligned with the equator and that has a speed between 5 and 10 m/s. We also present a map of the surface gravity, obtained from the same observations. The gravity map shows several large continents and many small islands. The distribution of continents and islands is consistent with a scenario in which the planet is rotatingsynchronously.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the orbital periods of the AM CVn stars HP Librae and V803 Centauri. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0402, "human_text": "  We analyse high-time-resolution spectroscopy of the AM CVn stars HP Librae and V803 Centauri, taken with the New Technology Telescope (NTT) and the Very Large Telescope (VLT) of the European Southern Observatory, Chile.   We present evidence that the literature value for V803 Cen's orbital period is incorrect, based on an observed `S-wave' in the binary's spectrogram. We measure a spectroscopic period P=1596.4+/-1.2s of the S-wave feature, which is significantly shorter than the 1611-second periods found in previous photometric studies. We conclude that the latter period likely represents a `superhump'. If one assumes that our S-wave period is the orbital period, V803 Cen's mass ratio can be expected to be much less extreme than previously thought, at q~0.07 rather than q~0.016. This relaxes the constraints on the masses of the components considerably: the donor star does then not need to be fully degenerate, and the mass of the accreting white dwarf no longer has to be very close to the Chandrasekhar limit.   For HP Lib, we similarly measure a spectroscopic period P=1102.8+/-0.2s. This supports the identification of HP Lib's photometric periods found in the literature, and the constraints upon the masses derived from them. ", "machine_text": "  We present photometric observations of the short-period horizontal-branch (HB) stars HP Librae and V803 Centauri, which allow a precise determination of their orbital periods. The observations cover several orbital revolutions and were obtained under uniform conditions for both stars. We find that the orbital period of HP Librae is 87.12 \u00b1 0.09 min, which is 11.4 \u00b1 0.9% longer than the period determined from the orbital elements derived from spectroscopy. The corresponding systematic effect on the orbital elements is within the formal uncertainty of the spectroscopic measurements. We discuss this period discrepancy with the help of recent models of the orbital evolution of these stars. We also present a detailed study of the full- amplitude behavior of the HB-star modulation in HP Librae. The observed modulation amplitude shows a clear signature of an exponential radial-distance variation superimposed on a linear one. We determine the characteristic parameters of both amplitude variations, and discuss the physical origin of the observed radial-distance variations. We find that the mass-loss rate during the evolution of the system is at most 2.3% of the total stellar mass per 1000 yr. The derived value is lower than the mass-loss rate derived from the observed orbital-elements evolution. We discuss the observed properties of HP Librae and V803 Centauri within the framework of recent theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What happened to the Cosmological QCD Phase Transition?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4149, "human_text": "  The scenario that some first-order phase transitions may have taken place in the early Universe offers us one of the most intriguing and fascinating questions in cosmology. Indeed, the role played by the latent \"heat\" or energy released in the phase transition is highly nontrivial and may lead to some surprising, important results. In this paper, we take the wisdom that the cosmological QCD phase transition, which happened at a time between 10^(-5) sec and 10^(-4) sec or at the temperature of about 150 MeV and accounts for confinement of quarks and gluons to within hadrons, would be of first order. To get the essence out of the scenario, it is sufficient to approximate the true QCD vacuum as one of degenerate theta-vacua and when necessary we try to model it effectively via a complex scalar field with spontaneous symmetry breaking. We examine how and when \"pasted\" or \"patched\" domain walls are formed, how long such walls evolve in the long run, and we believe that the significant portion of dark matter could be accounted for in terms of such domain-wall structure and its remnants. Of course, the cosmological QCD phase transition happened in the way such that the false vacua associated with baryons and many other color-singlet objects did not disappear (that is, using the bag-model language, there are bags of radius 1.0 fermi for the baryons) - but the amount of the energy remained in the false vacua is negligible. The latent energy released due to the conversion of the false vacua to the true vacua, in the form of \"pasted\" or \"patched\" domain walls in the short run and their numerous evolved objects, should make the concept of the \"radiation-dominated\" epoch, or of the \"matter-dominated\" epoch to be re-examined. ", "machine_text": " We present a model that explains the disappearance of the cosmological quark-deconfined phase transition. The model consists of a simpleeffective potential which at large distance approximates the quark-meson coupling constant and at small distance is an increasing function of the quark-meson coupling constant. The derivative of the potential is anaffine function of the quark-meson coupling constant. We show that this potential has a local minimum at a critical value of the quark-meson coupling constant, which depends only on the ratio of the quark-to-meson masses. We calculate the dependedietric contribution to the effective potential and show that it is negative for a large range of values of the quark-meson coupling constant. This corresponds to the stable deconfined phase. We calculate the dependencquoise function and show that it is positive for a large range of values of the quark-meson coupling constant. This corresponds to the unstable quark-deconfined phase. We show that the stable and unstable phases coexist for a finite range of values of the quark-meson coupling constant. Outside this range the stable phase is unique. We derive a general condition for the disappearance of the quark-deconfined phase transition which does not depend on the specific choice of the effective potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constraints on the electroweak chiral Lagrangian from the precision data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2277, "human_text": "  In the framework of the effective field theory method, we use the experimental data and the perturbative unitarity bounds to determine the values and uncertainty of all the 11 chiral coefficients ($\\al_i, i=0, ..., 10$) of the standard electroweak chiral Lagrangian. Up to linear terms in $\\al_i$, we provide the one-loop renormalization group equations of all the chiral coefficients, which are calculated in the Feynman-'t Hooft gauge using the modified minimal subtraction scheme. With the improved renormalization group equations to sum over the logarithmic corrections, we analyze the current experimental uncertainty of oblique correction parameters, $S(\\Lambda)$ and $T(\\Lambda)$. We find that, due to the large uncertainty in the triple gauge-boson coupling measurements, the parameter space of positive $S(\\Lambda)$ for $\\Lambda > 1$ TeV is still allowed by the current experimental data. $T(\\Lambda)$ tends to increase with $\\Lambda$ even in the presence of the operators that contribute to the triple and quartic gauge-boson couplings. ", "machine_text": " We consider the precision constraints on the electroweak chiral Lagrangian from the mass spectra of light quarks and charged leptons. The motivation for this work is the recent observation of the neutrino mass-squared difference from the T2K and the latest Super-Kamiokande experiments, which can constrain the left-right asymmetry in the early Universe to be no more than 1%. We show that the standard model (SM) chiral Lagrangian, which generates a $\\sim 1$% asymmetry in the Universe, is compatible with the current constraints from the neutrino data, and it is also consistent with the results from the $\\overline{B}$-Factory and the LHC, provided that the standard model (SM) Yukawa parameters are small. On the other hand, if the neutrino mass-squared difference is further constrained to be less than the current limit, we find that the SM chiral Lagrangian needs to be fine-tuned in the right direction to accommodate the neutrino data, and it is inconsistent with the results from the $\\overline{B}$-Factory and the LHC. We also show that the constraints from the precision data can be satisfied by a right-handed neutrino with a mass-squared difference as small as $\\sim 10$-40% of the electron mass-squared, provided that the Yukawa parameters are small. We also show that the standard model chiral Lagrangian is consistent with the masses of light quarks and charged leptons if the Yukawa parameters are small, while the minimal chiral Lagrangian is inconsistent with the mass spectra of quarks and leptons if the Yukawa parameters are large. We also discuss the possibility that the chiral Lagrangian is constrained by the standard model data, while it is free from the extra-dimensional gravitational effects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Physisorption of Nucleobases on Graphene. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1316, "human_text": "  We report the results of our first-principles investigation on the interaction of the nucleobases adenine (A), cytosine (C), guanine (G), thymine (T), and uracil (U) with graphene, carried out within the density functional theory framework, with additional calculations utilizing Hartree--Fock plus second-order Moeller-Plesset perturbation theory. The calculated binding energy of the nucleobases shows the following hierarchy: G > T ~ C ~ A > U, with the equilibrium configuration being very similar for all five of them. Our results clearly demonstrate that the nucleobases exhibit significantly different interaction strengths when physisorbed on graphene. The stabilizing factor in the interaction between the base molecule and graphene sheet is dominated by the molecular polarizability that allows a weakly attractive dispersion force to be induced between them. The present study represents a significant step towards a first-principles understanding of how the base sequence of DNA can affect its interaction with carbon nanotubes, as observed experimentally. ", "machine_text": " We report a systematic investigation of the strength and specificity of the interaction between graphene and the four major DNA nucleobases, performed using a combination of density functional theory calculations and experiments. We find that the interaction strength decreases in the order G>A>T>C, with the van der Waals interaction energy being the dominant contribution to the interaction energy for all bases. The largest change in the C\u2013H\u22ef\u03c0 interaction energy upon base adsorption is found to be the main reason for the decrease in the strength of the interaction in the order G>A>T>C. Our results suggest that the strength of the interaction between graphene and nucleobases is not sufficient to form a stable hybrid in which the base would be covalently bound to the graphene sheet. We also show that the selective interaction between graphene and adenine is caused by the large change in the C\u2013H\u22ef\u03c0 interaction energy, in addition to the van der Waals interaction, and is not due to a unique molecular property of adenine.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mixed-up trees: the structure of phylogenetic mixtures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4328, "human_text": "  In this paper we apply new geometric and combinatorial methods to the study of phylogenetic mixtures. The focus of the geometric approach is to describe the geometry of phylogenetic mixture distributions for the two state random cluster model, which is a generalization of the two state symmetric (CFN) model. In particular, we show that the set of mixture distributions forms a convex polytope and we calculate its dimension; corollaries include a simple criterion for when a mixture of branch lengths on the star tree can mimic the site pattern frequency vector of a resolved quartet tree. Furthermore, by computing volumes of polytopes we can clarify how ``common'' non-identifiable mixtures are under the CFN model. We also present a new combinatorial result which extends any identifiability result for a specific pair of trees of size six to arbitrary pairs of trees. Next we present a positive result showing identifiability of rates-across-sites models. Finally, we answer a question raised in a previous paper concerning ``mixed branch repulsion'' on trees larger than quartet trees under the CFN model. ", "machine_text": "  Mixed-up trees: the structure of phylogenetic mixtures.  The study of mixture data has recently become a topic of intense interest in statistical physics, statistical genetics, and computer science. We review some results on the structure of phylogenetic mixtures from our own work and that of others, and discuss some open problems. We also introduce a new model that captures several features of phylogenetic mixtures that are not captured by the traditional model of mixtures of rooted trees. This model can be thought of as a generalization of the traditional model to the setting of unrooted trees, but it also has a direct interpretation in terms of a game between a \"top down\" and a \"bottom up\" process that compete to build a phylogenetic tree. The game has a unique solution that is characterized by a simple condition on the degree of the leaves. We show that this condition is satisfied for a wide class of real data sets. We also show that the simplest non-trivial case of our model, the setting of a constant degree for all leaves, is closely related to the setting of a single rooted tree with an internal node, and that the statistics of this setting satisfy the same restrictions as the statistics of a rooted tree.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Transverse Polarization of Lambda and Lambda-bar Hyperons in Quasireal\n  Photoproduction. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3133, "human_text": "  The HERMES experiment has measured the transverse polarization of Lambda and Lambda-bar hyperons produced inclusively in quasireal photoproduction at a positron beam energy of 27.6 GeV. The transverse polarization of the Lambda hyperon is found to be positive while the observed Lambda-bar polarization is compatible with zero. The transverse polarization values averaged over the kinematic acceptance of HERMES are 0.078 +/- 0.006(stat) +/- 0.012(syst) and -0.025 +/- 0.015(stat) +/- 0.018(syst) for Lambda and Lambda-bar hyperons, respectively. The dependences of Lambda and Lambda-bar polarizations on the fraction $\\zeta$ of the beam's light-cone momentum carried by the hyperon and on the hyperon's transverse momentum $p_T$ were investigated. The measured Lambda polarization rises linearly with $p_T$ and exhibits a different behavior for low and high values of $\\zeta$, which approximately correspond to the backward and forward regions in the center-of-mass frame of the $\\gamma^*N$ reaction. ", "machine_text": " We present the first three-dimensional measurement of the transverse polarization of quasireal photoproduction of the Lambda and Lambda-bar hyperons. The measurement was made with the BaBar detector at the PEP-II asymmetric-energy e+e- accelerator at SLAC. We find the transverse polarization fraction to be larger than previously measured with the PEP-II Removeable Pole (RPP) detector at the same accelerator. The large rate of unpolarized photoproduction at small transverse momenta, and the large fraction of longitudinal polarization at large transverse momenta are in agreement with the predictions of theLarry- Missile- Banana (LMB) model. A possible explanation for the discrepancy between the current result and the previous result from the RPP detector is that the longitudinal polarization of the emissive radiation in the LMB model is smaller than observed.  We also present a model for the transverse polarization of the photoproduction of the Lambda and Lambda-bar hyperons based on the assumption that the polarization is governed by the same mechanisms that govern the polarization of the light emitted by a linear accelerator. This model successfully predicts the polarization dependence on the transverse momenta and the longitudinal polarization fractions observed in both the RPP and the BaBar measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nanostructure and velocity of field-driven solid-on-solid interfaces\n  moving under a phonon-assisted dynamic. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0652, "human_text": "  The nanoscopic structure and the stationary propagation velocity of (1+1)-dimensional solid-on-solid interfaces in an Ising lattice-gas model, which are driven far from equilibrium by an applied force, such as a magnetic field or a difference in (electro)chemical potential, are studied by an analytic nonlinear-response approximation together with kinetic Monte Carlo simulations. Here we consider the case that the system is coupled to a two-dimensional phonon bath. In the resulting dynamic, transitions that conserve the system energy are forbidden, and the effects of the applied force and the interaction energies do not factorize (a so-called hard dynamic). In full agreement with previous general theoretical results we find that the local interface width changes dramatically with the applied force. However, in contrast with other hard dynamics, this change is nonmonotonic in the driving force. However, significant differences between theory and simulation are found near two special values of the driving force, where certain transitions allowed by the solid-on-solid model become forbidden by the phonon-assisted dynamic. Our results represent a significant step toward providing a solid physical foundation for kinetic Monte Carlo simulations. ", "machine_text": " We investigate the nanoscale structure and dynamics of solid-on-solid interfaces driven by a combination of an electric field and a mechanical strain, using molecular dynamics simulations in the framework of the waitress model. The applied electric field is found to be efficiently concentrated at the solid-on-solid interface, in a way that is different for each of the three distinct phases that the system can be in: the contact phase, the reticular phase, and the so-called Lupas phase. In the contact phase, the electric field is concentrated in a single plane at the bottom of the contacts, while in the reticular and Lupas phases the field is more uniformly distributed throughout the bulk of the material. The local distribution of the electric field in these different phases has a strong effect on the subsequent dynamics of the system, especially in the early stages of the field-driven process, and determines the final nanostructure of the solid-on-solid interface. We find that the applied electric field can have a strong entropically driven dynamics, in addition to the already present thermal fluctuations. The strength of this additional contribution depends on the local distribution of the electric field, as well as on the symmetry of the nanostructure. We also analyze the influence of the applied strain on the dynamics of the system. The analysis of the relaxation pathways shows that the combination of the electric field and the strain can have a strong influence on the structural changes that the system can undergo, as well as on the kinetically allowed pathways.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coupling between magnetic ordering and structural instabilities in\n  perovskite biferroics: A first-principles study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1251, "human_text": "  We use first-principles density functional theory-based calculations to investigate structural instabilities in the high symmetry cubic perovskite structure of rare-earth (R $=$ La, Y, Lu) and Bi-based biferroic chromites, focusing on $\\Gamma$ and $R$ point phonons of states with para-, ferro-, and antiferromagnetic ordering. We find that (a) the structure with G-type antiferromagnetic ordering is most stable, (b) the most dominant structural instabilities in these oxides are the ones associated with rotations of oxygen octahedra, and (c) structural instabilities involving changes in Cr-O-Cr bond angle depend sensitively on the changes in magnetic ordering. The dependence of structural instabilities on magnetic ordering can be understood in terms of how super-exchange interactions depend on the Cr-O-Cr bond angles and Cr-O bond lengths. We demonstrate how adequate buckling of Cr-O-Cr chains can favour ferromagnetism. Born effective charges (BEC) calculated using the Berry phase expression are found to be anomalously large for the A-cations, indicating their chemical relevance to ferroelectric distortions. ", "machine_text": " We present a first-principles study of the effects of structural instabilities on the magnetic properties of perovskite biferroics. We consider four different types of structural instability which can be captured by the Stillinger-Gr\u00fcneisen, Taylor, Cosmolly and Anti-phase domains models. We find that in all the cases the magnetic properties are significantly affected by the structural distortion, but the nature of this effect is very different in the various systems. In some cases the structural distortion has a large impact on the magnetic properties and can be used to achieve unique effects like a giant Barkhausen effect or a very large and fast switching of the magnetic susceptibility. In other cases the structural effect is small and has a small impact on the magnetic properties. We also find that the nature of the magnetic ordering is affected by the structural instability. In particular we find a strong effect on the kind of magnetic ordering which is stabilized over a wide range of temperatures. We also find a strong effect on the internal magnetic fields which are induced by the magnetic ordering. Our results suggest that in all the cases the structural instability and the magnetic instability are tightly coupled and that the structural instability can be used to achieve unique magnetic properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of Electron Interaction on Statistics of Conductance Oscillations\n  in Open Quantum Dots: Does the Dephasing Time Saturate?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0125, "human_text": "  We perform self-consistent quantum transport calculations in open quantum dots taking into account the effect of electron interaction. We demonstrative that in the regime of the ultralow temperatures $2\\pi k_BT\\lesssim\\Delta$ ($\\Delta $ being the mean level spacing), the electron interaction strongly affects the conductance oscillations and their statistics leading to a drastic deviation from the corresponding predictions for noninteracting electrons. In particular, it causes smearing of conductance oscillations, which is similar to the effect of temperature or inelastic scattering. For $2\\pi k_BT\\gtrsim\\Delta$ the influence of electron interaction on the conductance becomes strongly diminished. Our calculations (that are free from phenomenological parameters of the theory) are in good quantitative agreement with the observed ultralow temperature statistics (Huibers \\textit{et al.}, Phys. Rev. Lett. \\textbf{81}, 1917 (1998)). Our findings question a conventional interpretation of the ultralow temperature saturation of the coherence time in open dots which is based on the noninteracting theories where the electron interaction is neglected and the agrement with the experiment is achieved by introducing additional phenomenological channels of dephasing. ", "machine_text": " We study the effect of electron-electron interaction on the statistics of conductance oscillations in a quantum dot with two resonant energy levels. We consider a model in which the dot is weakly coupled to a linear reservoir and the driving is provided by a bias current applied to the reservoir. Our theory is based on the combination of a master equation for the probability distribution of the occupation of the quantum dot with an extension of the Einstein-Jacobi theory of quasi-periodic stochastic processes to the case of a non-Markovian system. The model parameters are adjusted to match the experimental data for a number of experiments. We show that the theory predicts a number of interesting features of the statistics of the conductance oscillations, in particular a decrease of the standard deviation of the conductance amplitude as a function of the dephasing time. Our predictions are consistent with a number of experimental observations, but do not agree with other experiments in which the dephasing time is large. We discuss possible physical reasons for this disagreement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonstationary random acoustic and electromagnetic fields as wave\n  diffusion processes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0525, "human_text": "  We investigate the effects of relatively rapid variations of the boundaries of an overmoded cavity on the stochastic properties of its interior acoustic or electromagnetic field. For quasi-static variations, this field can be represented as an ideal incoherent and statistically homogeneous isotropic random scalar or vector field, respectively. A physical model is constructed showing that the field dynamics can be characterized as a generalized diffusion process. The Langevin--It\\^{o} and Fokker--Planck equations are derived and their associated statistics and distributions for the complex analytic field, its magnitude and energy density are computed. The energy diffusion parameter is found to be proportional to the square of the ratio of the standard deviation of the source field to the characteristic time constant of the dynamic process, but is independent of the initial energy density, to first order. The energy drift vanishes in the asymptotic limit. The time-energy probability distribution is in general not separable, as a result of nonstationarity. A general solution of the Fokker--Planck equation is obtained in integral form, together with explicit closed-form solutions for several asymptotic cases. The findings extend known results on statistics and distributions of quasi-stationary ideal random fields (pure diffusions), which are retrieved as special cases. ", "machine_text": " We consider a nonstationary random field, modeled as a wide-band random process with a power-law spectrum, subjected to an integral transform, that maps the field into a new field with a different power-law spectrum. The transform can be viewed as an unstable wave-diffusion process, which allows the investigation of the statistical properties of the nonstationary field in the context of the wave-diffusion theory. The random field is shown to be characterized by a stationary power spectrum, that describes the distribution of its energy, and a nonstationary power spectrum, that describes the statistical properties of its time evolution. We show that the nonstationary power spectrum can be obtained from the stationary power spectrum, by means of a simple relationship, and that it describes a wave-diffusion process with a dynamic coefficient related to the stationary power spectrum. A good characterization of the nonstationary random field is given by the wavespeed, that describes the speed at which the random field propagates, and the width of the random field, that describes the size of the random fluctuations. We show that these parameters can be related to the stationary and nonstationary power spectra by means of a simple formula. The wavespeed and the width of the random field can be used to define a new random field, called the random wavespeed field, that describes the speed and the size of the random fluctuations. The random wavespeed field is characterized by a power-law spectrum, that describes the distribution of its energy, and a nonstationary power spectrum, that describes the statistical properties of its time evolution. We show that the nonstationary power spectrum can be obtained from the power-law spectrum, by means of a simple relationship, and that it describes a wave-diffusion process with a dynamic coefficient related to the power-law spectrum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of thermally stimulated luminescence and conductivity without\n  quasiequilibrium approximation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3497, "human_text": "  Thermally stimulated luminescence (TSL) and conductivity (TSC) are considered using the classical insulator model that assumes one kind of the active trap, one kind of inactive deep trap, and one kind of the recombination center. Kinetic equations describing the model are solved numerically without and with the use of the quasiequilibrium (QE) approximation. The QE state parameter qI,, the relative recombination probability g, and a new parameter called quasi-stationary (QS) state parameter q*=qIg are used for the analysis of the TSL and TSC. The TSL and TSC curves and the temperature dependences of qI, q*, g, the recombination lifetime, and the occupancies of active traps and recombination centers are numerically calculated for five sets of kinetic parameters and different heating rates. These calculation results show that: (1) the upper limit of the heating rate for presence of the QS state appears at higher heating rate than that for the QE state when the retrapping process is present, and (2) the TSL (TSC) curves in the QS state have the properties similar to those for the TSL (TSC) curves in the QE state. Approximate formulas for calculation of the parameters qI and q* in the initial range of the TSL and TSC curves are derived and used in the heating-rate methods, proposed in this work, for determination of those parameters from the calculated TSL curves. ", "machine_text": "  We present an analysis of the transient photoconductivity and thermally stimulated luminescence (TSL) of amorphous silicon based on a model of the recombination and thermalization of photo-excited carriers in the amorphous silicon band-gap. Our formalism provides a rigorous thermodynamic framework for the analysis of the transient photoconductivity and TSL, without the assumption of thermal equilibrium, and can be used to study the transient photoconductivity and TSL under various experimental conditions, such as different excitation regimes and measurement procedures. The resulting equations for the transient photoconductivity and TSL can be solved analytically, in a closed form, for a wide range of parameters. The results obtained are in good agreement with both the available experimental data and previous theoretical treatments of the transient photoconductivity and TSL, which used the quasiequilibrium approximation. In particular, our results reproduce the recently reported discrepancy between the transient photoconductivity and steady-state photoconductivity, in the range of intermediate excited-state lifetimes, for the amorphous silicon model systems. Our analysis also reveals a new effect, the dependence of the transient photoconductivity and TSL on the thermalization time, which has not been reported before.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unconventional superconducting pairing by conventional phonons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2697, "human_text": "  The common wisdom that the phonon mechanism of electron pairing in the weak-coupling Bardeen-Cooper-Schrieffer (BCS) superconductors leads to conventional s-wave Cooper pairs is revised. An inevitable anisotropy of sound velocity in crystals makes the phonon-mediated attraction of electrons non-local in space providing unconventional Cooper pairs with a nonzero orbital momentum in a wide range of electron densities. As a result of this anisotropy quasi-two dimensional charge carriers undergo a quantum phase transition from an unconventional d-wave superconducting state to a conventional s-wave superconductor with more carriers per unit cell. In the opposite strong-coupling regime rotational symmetry breaking appears as a result of a reduced Coulomb repulsion between unconventional bipolarons dismissing thereby some constraints on unconventional pairing in the Bose-Einstein condensation (BEC) limit. The conventional phonons, and not superexchange, are shown to be responsible for the d-wave symmetry of cuprate superconductors, where the on-site Coulomb repulsion is large. ", "machine_text": "  We show that phonons, in a certain range of phonon frequencies, can provide an effective pairing mechanism for superconductivity, without the need of any additional charge transfer between the superconducting layers. We demonstrate this by studying the superconducting properties of a multilayered thin film structure of dielectric and superconducting YBa2Cu3O7\u2212\u03b4 (YBCO) and Y2BaCuO5 (Y211) layers, grown on a buffer layer of LaAlO3 and an SrTiO3 substrate. The dielectric YBCO layer was found to enhance the superconductivity in the Y211 layer, when the phonon frequencies in the YBCO layer are tuned in a certain range. We explain this enhancement by the formation of a pseudogap state in the Y211 layer, induced by a phonon-phonon coupling between the superconducting layers. Our results suggest that a careful design of the structural properties of the superconducting material, which affects the phonon spectrum, may provide an alternative way to design high-T_c superconducting materials by utilizing conventional charge carriers and phonons, without the need of the relatively more difficult to achieve charge transfer pairing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gravitational Stability of Circumnuclear Disks in Elliptical Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0005, "human_text": "  A significant fraction of nearby elliptical galaxies are known to have high density gas disks in their circumnuclear (CN) region (0.1 to a few kpc). Yet, ellipticals, especially luminous ones, show little signs of recent star formation (SF). To investigate the possible cause of the dearth of SF in these systems, we study the gravitational stability of CN gas disks embedded within the potentials of both the stellar bulge and the central massive black hole (BH) in ellipticals. We find that CN disks in higher mass galaxies are generally more stable than those in lower mass galaxies, because higher mass galaxies tend to have more massive BHs and more centrally concentrated stellar density profiles. We also consider the case in which the central stellar density profile has a core, which is often observed for ellipticals whose total stellar mass is higher than about 10^11 Msun. Such a cored stellar density profile leads to more unstable CN disks than the power-law density profile characteristic of less massive galaxies. However, the more massive BHs in high-mass galaxies act to stabilize the CN disk. Our results demonstrate that the gravitational potentials of both the central BH and the stellar component should be taken into account when studying the properties of CN disks, as their stability is sensitive to both the BH mass and the stellar density profile. Our results could explain the observed trend that less luminous ellipticals have a greater tendency to exhibit ongoing SF than giant ellipticals. ", "machine_text": "  We study the stability of circumnuclear disks in elliptical galaxies. We find that the gravitational instability of such disks is driven by the global structure of the host galaxy, and is not affected by the local properties of the disk itself. We show that the critical circum- disk density, above which the disk will be gravitationally unstable, is proportional to the square of the effective gravity at the disk's inner boundary. Our analysis reveals that the mass of the disk's inner boundary must be at least 5% of the host galaxy's total mass, in order for the disk to be gravitationally stable. We show that this condition is met only for disks with inner boundaries that are at least 1-2 effective radii away from the galaxy's center. We also find that the dynamical friction acting on the disk by the galactic potential can be as large as the viscous torque internal to the disk, and that it is this dynamical friction that eventually drives the disk to become unstable. Based on our analysis, we conclude that circumnuclear disks with inner boundaries located closer than about 1-2 effective radii to the center of the host galaxy are dynamically unstable, and will be unable to survive for significant lengths of time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The LuckyCam Survey for Very Low Mass Binaries II: 13 new M4.5-M6.0\n  Binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1812, "human_text": "  We present results from a high-angular-resolution survey of 78 very low mass (VLM) binary systems with 6.0 <= V-K colour <= 7.5 and proper motion >= 0.15 arcsec/yr. 21 VLM binaries were detected, 13 of them new discoveries. The new binary systems range in separation between 0.18 arcsec and 1.3 arcsec. The distance-corrected binary fraction is 13.5% (+6.5%/-4%), in agreement with previous results. 9 of the new binary systems have orbital radii > 10 AU, including a new wide VLM binary with 27 AU projected orbital separation. One of the new systems forms two components of a 2300 AU separation triple system. We find that the orbital radius distribution of the binaries with V-K < 6.5 in this survey appears to be different from that of redder (lower-mass) objects, suggesting a possible rapid change in the orbital radius distribution at around the M5 spectral type. The target sample was also selected to investigate X-ray activity among VLM binaries. There is no detectable correlation between excess X-Ray emission and the frequency and binary properties of the VLM systems. ", "machine_text": " We present the second part of the LuckyCam Survey for very low mass binaries. In this work we present 13 new M4.5-M6.0 binarians. We have also updated the mass function for the first part of the survey. The new mass function can be found in the supplemental material of the first part of the survey. With the current sample we can derive the mass function for M4.0-M5.0 objects. The sample contains bins with 13 objects and the most massive star in the system is between 1.01 and 1.36 solar masses. The most massive system in the sample has a systemic mass of 2.01 solar masses, a period of 87.1 minutes, and a semi-major axis of 9.8 solar radii. The median relative solar radii of the systems is 1.12, while the median orbital period is 78.9 minutes. The mass function for M4.0-M5.0 is well described by a power law with a cut-off mass of M\u22c5host = 1.89 \u00b1 0.08 solar masses, which corresponds to an age of 12.6 Gyr. We find a correlation between the orbital elements and the host star mass. The correlation between the semi-major axis and the host star mass can be described by a power law with a cut-off semi-major axis of a\u22c5host = 7.45 \u00b1 0.75 solar radii, which corresponds to an age of 12.2 Gyr. The correlation between the orbital period and the host star mass can be described by a power law with a cut-off orbital period of P\u22c5host = 61.03 \u00b1 12.68 minutes, which corresponds to an age of 11.6 Gyr. This correlation can be used to derive an age estimate for a given very low mass binary system. We found a median orbital period of 78.9 minutes. Systems with longer orbital periods are likely to be older than the ones with shorter orbital periods. We estimated the age of the sample to be 11.6 \u00b1 1.4 Gyr. The derived mass function for M4.0-M5.0 can be used to derive the age of a given very low mass binary. The best fit age is 12.6 Gyr.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galaxy Colours in the AKARI Deep SEP Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.186, "human_text": "  We investigate the segregation of the extragalactic population via colour criteria to produce an efficient and inexpensive methodology to select specific source populations as a function of far-infrared flux. Combining galaxy evolution scenarios and a detailed spectral library of galaxies, we produce simulated catalogues incorporating segregation of the extragalactic population into component types (Normal, star-forming, AGN) via color cuts. As a practical application we apply our criteria to the deepest survey to be undertaken in the far-infrared with the AKARI (formerly ASTRO-F) satellite. Using the far-infrared wavebands of the Far-Infrared Surveyor (FIS, one of the focal-plane instruments on AKARI) we successfully segregate the normal, starburst and ULIRG populations. We also show that with additional MIR imaging from AKARI's Infrared Camera (IRC), significant contamination and/or degeneracy can be further decreased and show a particular example of the separation of cool normal galaxies and cold ULIRG sources. We conclude that our criteria provide an efficient means of selecting source populations (including rare luminous objects) and produce colour-segregated source counts without the requirement of time intensive ground-based follow up to differentiate between the general galaxy population. ", "machine_text": "  We present colour-magnitude diagrams (CMDs) for a sample of galaxies selected from the AKARI Deep SEP Survey. The sample consists of galaxies in the redshift range 0.005 < z_reio < 1.5 with SEP luminosities in the range 10^36 - 10^37 erg s^-1, of which 50 are active galaxies and 50 are galaxies in the local volume. We use the AKARI archive to extract the necessary photometry and spectroscopy, and fit the resulting CMDs with a single broken power law. We then compare the galaxy colours in the local volume to those of the active galaxies, and find that the colours of the most luminous galaxies in the two samples are consistent with the colours of galaxies in the local volume, but that the colours of the less luminous galaxies in the active galaxy sample are consistent with a different relation, suggesting that the most luminous galaxies in the active galaxy sample are likely to be local galaxies, while the faintest galaxies in the active galaxy sample are likely to be distant galaxies. We discuss this conclusion in the context of the cosmological model, and find that a model in which the star formation density is scale invariant requires that the most luminous galaxies in the active galaxy sample be local galaxies, while a model in which the star formation density is scale dependent requires that the faintest galaxies in the active galaxy sample be distant galaxies. We discuss the implications of this result for galaxy formation in hierarchical structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing outer boundary treatments for the Einstein equations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0782, "human_text": "  Various methods of treating outer boundaries in numerical relativity are compared using a simple test problem: a Schwarzschild black hole with an outgoing gravitational wave perturbation. Numerical solutions computed using different boundary treatments are compared to a `reference' numerical solution obtained by placing the outer boundary at a very large radius. For each boundary treatment, the full solutions including constraint violations and extracted gravitational waves are compared to those of the reference solution, thereby assessing the reflections caused by the artificial boundary. These tests use a first-order generalized harmonic formulation of the Einstein equations. Constraint-preserving boundary conditions for this system are reviewed, and an improved boundary condition on the gauge degrees of freedom is presented. Alternate boundary conditions evaluated here include freezing the incoming characteristic fields, Sommerfeld boundary conditions, and the constraint-preserving boundary conditions of Kreiss and Winicour. Rather different approaches to boundary treatments, such as sponge layers and spatial compactification, are also tested. Overall the best treatment found here combines boundary conditions that preserve the constraints, freeze the Newman-Penrose scalar Psi_0, and control gauge reflections. ", "machine_text": " We study the effectiveness of boundary treatments for the Einstein equations. In particular, we consider the effects of placing an impenetrable boundary, a boundary with a cosine profile, and a penetrable boundary on the solutions to the Einstein equations for a Schwarzschild black hole and a Kerr black hole, respectively. We find that, in contrast to the traditional view, the choice of the outer boundary treatment does not have any significant effect on the shape of the inner horizon, but it does affect the shape of the outer horizon. For the Schwarzschild black hole, we show that a boundary with a cosine profile is effective in producing a spherical outer horizon, whereas an impenetrable boundary is not. For the Kerr black hole, we show that a boundary with a cosine profile is again effective in producing a spherical outer horizon, but a penetrable boundary is effective only if the boundary is very close to the black hole. We also study the energy evolution of the black holes and find that the energy evolution is affected by the outer boundary treatment. For the Schwarzschild black hole, the energy evolution is the same for all the outer boundary treatments considered. For the Kerr black hole, however, the energy evolution depends on the outer boundary treatment. In particular, we show that the energy of the Kerr black hole monotonically decreases in time if the outer boundary is penetrable, but it does not decrease monotonically if the outer boundary is either impenetrable or with a cosine profile. We also show that the energy of the Kerr black hole is strictly decreasing if the outer boundary is with a cosine profile but not strictly decreasing if the outer boundary is impenetrable or penetrable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Room temperature coexistence of large electric polarization and magnetic\n  order in BiFeO3 single crystals. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0404, "human_text": "  From an experimental point of view, room temperature ferroelectricity in BiFeO3 is raising many questions. Electric measurements made a long time ago on solid-solutions of BiFeO3 with Pb(Ti,Zr)O3 indicate that a spontaneous electric polarization exists in BiFeO3 below the Curie temperature TC=1143K. Yet in most reported works, the synthesised samples are too conductive at room temperature to get a clear polarization loop in the bulk without any effects of extrinsic physical or chemical parameters. Surprisingly, up to now there has been no report of a P(E) (polarization versus electric field) loop at room temperature on single crystals of BiFeO3. We describe here our procedure to synthesize ceramics and to grow good quality sizeable single crystals by a flux method. We demonstrate that BiFeO3 is indeed ferroelectric at room-temperature through evidence by Piezoresponse Force Microscopy and P(E) loops. The polarization is found to be large, around 60 microC/cm2, a value that has only been reached in thin films. Magnetic measurements using a SQUID magnetometer and Mossbauer spectroscopy are also presented. The latter confirms the results of NMR measurements concerning the anisotropy of the hyperfine field attributed to the magnetic cycloidal structure. ", "machine_text": "  We report the observation of a large electric polarization and magnetic order coexistence in single crystals of BiFeO3. The large electric polarization can be tuned by both the magnetic field and the temperature, and it is very stable against the temperature changes. The static and dynamic magnetic properties and the relationship between the electric polarization and the magnetic field are studied. Our results may be useful for the design and development of novel magnetic-non-magnetic nanocomposite materials.  The structural, magnetic and electric properties of BiFeO3 have attracted increasing attention due to its potential application in magnetic-non-magnetic nanocomposite materials. Single crystals of BiFeO3 were reported to possess a large electric polarization, which could be tuned by both the magnetic field and the temperature. However, the coexistence of large electric polarization and magnetic order in BiFeO3 has not yet been reported, although it is crucial for the design and development of novel magnetic-non-magnetic nanocomposite materials. In this work, we report the observation of a large electric polarization and magnetic order coexistence in single crystals of BiFeO3. The large electric polarization can be tuned by both the magnetic field and the temperature, and it is very stable against the temperature changes. The static and dynamic magnetic properties and the relationship between the electric polarization and the magnetic field are studied. Our results may be useful for the design and development of novel magnetic-non-magnetic nanocomposite materials.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Calibration of the GLAST Burst Monitor detectors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2184, "human_text": "  The GLAST Burst Monitor (GBM) will augment the capabilities of GLAST for the detection of cosmic gamma-ray bursts by extending the energy range (20 MeV to > 300 GeV) of the Large Area Telescope (LAT) towards lower energies by 2 BGO-detectors (150 keV to 30 MeV) and 12 NaI(Tl) detectors (10 keV to 1 MeV). The physical detector response of the GBM instrument for GRBs is determined with the help of Monte Carlo simulations, which are supported and verified by on-ground calibration measurements, performed extensively with the individual detectors at the MPE in 2005. All flight and spare detectors were irradiated with calibrated radioactive sources in the laboratory (from 14 keV to 4.43 MeV). The energy/channel-relations, the dependences of energy resolution and effective areas on the energy and the angular responses were measured. Due to the low number of emission lines of radioactive sources below 100 keV, calibration measurements in the energy range from 10 keV to 60 keV were performed with the X-ray radiometry working group of the Physikalisch-Technische Bundesanstalt (PTB) at the BESSY synchrotron radiation facility, Berlin. ", "machine_text": "  We describe results of a program to calibrate the GLAST Burst Monitor (GBM) detectors. The GBM detectors comprise a ring of 24 parallel-connected Cadmium-Zinc-Telluride (CZT) detectors surrounding the GLAST gamma-ray detectors. Each CZT detector has a single-pixel readout circuit, and thus the GBM detectors act as a single pixel image sensor with a spatial resolution of 2.5 degrees. The GBM detectors are used to identify cosmic-ray bursts and to measure the total rate of cosmic rays in the energy range above 100 keV. We describe methods to reduce the time to detect a burst from several seconds to a few milliseconds, to improve the ability to detect bursts that occur close to the time that a gamma-ray burst triggers the GLAST detectors. We also describe methods to improve the spatial resolution of the GBM detectors, by combining the signals from the individual CZT detectors in a way that reduces both the noise and the spatial sensitivity to single-pixel failures. We present measured spatial and temporal responses of the GBM detectors, and we discuss how the responses depend on the selected combination of signals from the individual CZT detectors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Difermion condensates in vacuum in 2-4D four-fermion interaction models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0841, "human_text": "  Theoretical analysis of interplay between the condensates $<\\bar{q}q>$ and $<qq>$ in vacuum is generally made by relativistic effective potentials in the mean field approximation in 2D, 3D and 4D models with two flavor and $N_c$ color massless fermions. It is found that in ground states of these models, interplay between the two condensates mainly depend on the ratio $G_S/H_S$ for 2D and 4D case or $G_S/H_P$ for 3D case, where $G_S$, $H_S$ and $H_P$ are respectively the coupling constants in a scalar $(\\bar{q}q)$, a scalar $(qq)$ and a pseudoscalar $(qq)$ channel. In ground states of all the models, only pure $<\\bar{q}q>$ condensates could exist if $G_S/H_S$ or $G_S/H_P$ is bigger than the critical value $2/N_c$, the ratio of the color numbers of the fermions entering into the condensates $<qq>$ and $<\\bar{q}q>$. As $G_S/H_S$ or $G_S/H_P$ decreases to the region below $2/N_c$, differences of the models will manifest themselves. Depending on different models, and also on $N_c$ in 3D model, one will have or have no the coexistence phase of the two condensates, besides the pure $<qq>$ condensate phase. The $G_S-H_S$ (or $G_S-H_P$) phase diagrams in these models are given. The results also implicate a real constraint on two-flavor QCD-analogous NJL model. ", "machine_text": "  We study Difermion condensates in vacuum in 2-4D four-fermion interaction models. We consider an effective two- Fermion model in a four-dimensional space-time in the presence of a non-Abelian symplectic group, which provides a break of the Lorentz invariance. In a four-dimensional space-time, this model has a one-dimensional fermion condensate with a non-Abelian structure. We also consider the evolution of this condensate in a space-time with a three-dimensional axial symmetry. The symplectic group is related to the three-dimensional geometry in the following way: the condensate is either symmetric or antisymmetric under the three-dimensional exchange of the fermions. In a space-time with a four-dimensional rotational symmetry, the fermions are related to the four-dimensional Lorentz invariance. We show that this relation is broken when the condensate becomes symmetric under the three-dimensional exchange of the fermions. This happens in a space-time with a three-dimensional axial symmetry. We also discuss the possibility of the creation of a new quark color by the interaction of the fermions with a D-brane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hitting probabilities for systems of non-linear stochastic heat\n  equations with multiplicative noise. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1312, "human_text": "  We consider a system of d non-linear stochastic heat equations in spatial dimension 1 driven by d-dimensional space-time white noise. The non-linearities appear both as additive drift terms and as multipliers of the noise. Using techniques of Malliavin calculus, we establish upper and lower bounds on the one-point density of the solution u(t,x), and upper bounds of Gaussian-type on the two-point density of (u(s,y),u(t,x)). In particular, this estimate quantifies how this density degenerates as (s,y) converges to (t,x). From these results, we deduce upper and lower bounds on hitting probabilities of the process {u(t,x)}_{t \\in \\mathbb{R}_+, x \\in [0,1]}, in terms of respectively Hausdorff measure and Newtonian capacity. These estimates make it possible to show that points are polar when d >6 and are not polar when d<6. We also show that the Hausdorff dimension of the range of the process is 6 when d>6, and give analogous results for the processes t \\mapsto u(t,x) and x \\mapsto u(t,x). Finally, we obtain the values of the Hausdorff dimensions of the level sets of these processes. ", "machine_text": "  We consider a system of stochastic heat equations with multiplicative noise. The solution of the system is a random process, whose probability distribution is calculated. This distribution has a strong dependency on the initial conditions, in a way very similar to the one displayed by the solutions of the Cauchy problem for a system of nonlinear ordinary differential equations. For a large class of initial conditions, this distribution has a heavy tail, with a finite number of local maxima. The probability that the solution stays in a small neighborhood of a given value decreases quickly as this value is approached from either side. In particular, the probability that the solution hits a given value from above or below is very small. For a particular choice of the initial conditions, the distribution of the solution is a mixture of two distributions, one with a large number of local maxima, and the other with a large number of local minima. The probabilities that the solution passes from one type of solution to the other are very small.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-IR Spectra of Red Supergiants and Giants. I- Models with Solar and\n  with Mixing-Induced Surface Abundance Ratios. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.212, "human_text": "  We provide a grid of PHOENIX spectra of red giant and supergiant stars, that extend through optical and near-IR wavelengths. For the first time, models are also provided with modified surface abundances of C, N and O, as a step towards accounting for the changes known to occur due to convective dredge-up (and to be enhanced in the case of rotation). The aims are (i) to assess how well current models reproduce observed spectra, (ii) to quantify the effects of the abundance changes on the spectra, and (iii) to determine how these changes affect estimates of fundamental stellar parameters.   Observed giant star spectra can be fitted very well at solar metallicity down to about 3400K. Modified surface abundances are preferred in only a minority of cases for luminosity class II, possibly indicating mixing in excess of standard first dredge-up.   Supergiant stars show a larger variety of near-IR spectra, and good fits are currently obtained for about one third of the observations only. Modified surface abundances help reproducing strong CN bands, but do not suffice to resolve all the difficulties. The effect of the abundance changes on the estimated Teff depends on the wavelength range of observation and can amount several 100K. Reasons for the remaining discrepancies are discussed. ", "machine_text": " We present a method for the determination of mixing-induced surface abundance ratios in cool supergiants and giants on the basis of near-infrared (NIR) spectra. The method is based on a least-squares fit to a model of the atmosphere, which includes an equation of state, a microturbulent velocity, and two surface abundance ratios. We apply the method to the analysis of NIR spectra of supergiants and giants in the solar neighborhood. The surface abundance ratios are derived from the analysis of several spectral regions, in which sensitive molecular bands occur. We determine the relative molecular abundance and the mixing-induced surface abundance ratios. The relative molecular abundances are consistent with the solar abundance, except for giants with an evolutionary state close to the red giant branch-point, which show a significant enrichment in C and N. The mixing-induced surface abundance ratios are consistent with a variety of possible interior structures. We discuss our results in the framework of current theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Simulation study of the two-dimensional Burridge-Knopoff model of\n  earthquakes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1871, "human_text": "  Spatiotemporal correlations of the two-dimensional spring-block (Burridge-Knopoff) model of earthquakes are extensively studied by means of numerical computer simulations. The model is found to exhibit either ``subcritical'' or ``supercritical'' behavior, depending on the values of the model parameters. Transition between these regimes is either continuous or discontinuous. Seismic events in the ``subcritical'' regime and those in the ``supercritical'' regime at larger magnitudes exhibit universal scaling properties. In the ``supercritical'' regime, eminent spatiotemporal correlations, {\\it e.g.}, remarkable growth of seismic activity preceding the mainshock, arise in earthquake occurrence, whereas such spatiotemporal correlations are significantly suppressed in the ``subcritical'' regime. Seismic activity is generically suppressed just before the mainshock in a close vicinity of the epicenter of the upcoming event while it remains to be active in the surroundings (the Mogi doughnut). It is also observed that, before and after the mainshock, the apparent $B$-value of the magnitude distribution decreases or increases in the ``supercritical'' or ``subcritical'' regimes, respectively. Such distinct precursory phenomena may open a way to the prediction of the upcoming large event. ", "machine_text": "  We study the two-dimensional Burridge-Knopoff model of earthquakes by numerical simulation. The model consists of a background medium in which quakes nucleate and grow in an arcade-like pattern. We find that the dynamic structure of the system is characterized by a large number of branches of different length, which are all connected at their tips. These branches are capable of initiating quakes of various sizes, and the probability distribution of the sizes is given by the Gumbel distribution. In this way, the model is able to generate quakes of all sizes in a manner that is consistent with the observed size distribution of earthquakes. We also find that the dynamic behavior of the system is characterized by an exponential increase in the number of branches as the system evolves, and that the distribution of the number of branches at any time is given by a power law. The finding that the number of branches grows exponentially is consistent with the observation that the number of earthquakes does not change monotonically but rather shows sharp increases and decreases. We also discuss the effect of various model parameters on the dynamic behavior of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Systematic Study of Departures from Chemical Equilibrium in the\n  Atmospheres of Substellar Mass Objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3922, "human_text": "  We present a systematic study of the spectral consequences of departures from chemical equilibrium in the atmospheres of L and T dwarfs, and for even cooler dwarfs. The temperature/pressure profiles of the non-equilibrium models are fully consistent with the non-equilibrium chemistry. Our grid of non-equilibrium models includes spectra for effective temperatures from 200 K to 1800 K, three surface gravities, four possible values of the coefficient of eddy diffusion in the radiative zone, and three different CO/CH$_4$ chemical reaction prescriptions. We find that the non-equilibrium overabundance of CO translates into flux suppressions in the M ($\\sim4-$5 $\\mu$m) band of at most $\\sim$40% between effective temperatures of 600 and 1800 K. The effect is largest around $T_{\\rm eff} \\approx 1100$ K. The underabundance of ammonia due to non-equilibrium chemistry translates into flux enhancements of no more than $\\sim$20% for the $T_{\\rm eff}$ range from 300 to 1800 K, with the largest effects at the lowest values of $T_{\\rm eff}$. The magnitude of the departure from chemical equilibrium increases with decreasing gravity, with increasing eddy diffusion coefficient, and with decreasing speed of the CO/CH$_4$ reaction. Though these effects are modest, they lead to better fits with the measured T dwarf spectra. Furthermore, the suppression in the M band due to non-equilibrium enhancements in the CO abundance disappears below $\\sim$500 K, and is only partial above $\\sim$500 K, preserving the M band flux as a useful diagnostic of cool atmospheres and maintaining its importance for searches for brown dwarfs cooler than T dwarfs. ", "machine_text": "  We present a systematic study of the departure from chemical equilibrium in the atmospheres of substellar mass objects. The main motivation for this work is the fact that the atmospheres of these objects are known to be chemically non-equilibrium, and the large number of molecular species that have been detected in the atmosphere of the solar twin planet, HD 209458 b, implies that this chemical non-equilibrium may be significant. We focus our study on giant exoplanets and brown dwarfs with known atmospheres, and explore how the chemical composition of these atmospheres depart from chemical equilibrium. We find that the most chemically non-equilibrium atmosphere is that of the brown dwarf, Gliese 667 Cc, which contains several species in excess of what would be expected from equilibrium chemistry, including carbon monoxide and acetone. We also find that giant exoplanet atmospheres are, on average, more chemically equilibrated than brown dwarf atmospheres, and that the chemical equilibrium is strongly dependent on the metallicity of the object. Our results suggest that chemical equilibrium is not well described by the mean molecular weight approach used in this work, and that a more sophisticated approach is needed to properly describe chemical equilibrium in these atmospheres.  We thank the following people for helpful discussions: C. Bezard, P.E. Bergren, A. Bersten, J.B. League, M.D. 10.1223/\u200b0895685X\u205796, R.W. Darmody, C. Derse, R.F. Howard, K.M. Marteau, R.W. O' 10241/\u200b99\u205712, B.N.S. Pirronello, J.E. Raymond, J.M. Strategies, P.J. Stephenson, R. St\u00fcnitz, M. PAssertion, A.M.S. Smith, and M. Dummel. This work was supported by NASA grant NNG06GH35G and the Australian Research Council through the Centres of Excellence scheme (projects number CE1100010015 and CE120009100). Some of this work was done while C.B. was on sabbatical at the University of Texas at Austin and the University of Colorado, Boulder.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Out-of-equilibrium relaxation of the Edwards-Wilkinson elastic line. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3348, "human_text": "  We study the non-equilibrium relaxation of an elastic line described by the Edwards-Wilkinson equation. Although this model is the simplest representation of interface dynamics, we highlight that many (not though all) important aspects of the non-equilibrium relaxation of elastic manifolds are already present in such quadratic and clean systems. We analyze in detail the aging behaviour of several two-times averaged and fluctuating observables taking into account finite-size effects and the crossover to the stationary and equilibrium regimes. We start by investigating the structure factor and extracting from its decay a growing correlation length. We present the full two-times and size dependence of the interface roughness and we generalize the Family-Vicsek scaling form to non-equilibrium situations. We compute the incoherent cattering function and we compare it to the one measured in other glassy systems. We analyse the response functions, the violation of the fluctuation-dissipation theorem in the aging regime, and its crossover to the equilibrium relation in the stationary regime. Finally, we study the out-of-equilibrium fluctuations of the previously studied two-times functions and we characterize the scaling properties of their probability distribution functions. Our results allow us to obtain new insights into other glassy problems such as the aging behavior in colloidal glasses and vortex glasses. ", "machine_text": "  We consider a model of a finite chain of rigid disks connected by elastic cords, which is placed on a flat surface and subjected to an arbitrarily time-dependent strain. The equilibration of this system is investigated by a combination of analytical and numerical techniques, which allows us to evaluate the out-of-equilibrium relaxation rates for the shape and the elastic line. Our main result is an exact formula for the relaxation rate of the elastic line, which is shown to agree with previous approximate results obtained from a statistical mechanics approach. In addition, we also obtain an approximate formula for the relaxation rate of the shape. The parameters of our model can be related to the characteristics of the experimental system and the imposed strain in a straightforward manner, which allows us to study the effect of the relevant parameters on the relaxation rate. Our results show that the relaxation rate increases with the number of disks and decreases with the cord stiffness and the spatial correlation of the strain. We also find that the relaxation rate has a minimum, which depends on the cord length and the strain correlation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spatially resolved kinematics and stellar populations of brightest\n  cluster and group galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3097, "human_text": "  We present an examination of the kinematics and stellar populations of a sample of 3 Brightest Group Galaxies (BGGs) and 3 Brightest Cluster Galaxies (BCGs) in X-ray groups and clusters. We have obtained high signal-to-noise Gemini/GMOS (Gemini South Multi-Object Spectrograph) long-slit spectra of these galaxies and use Lick indices to determine ages, metallicities and alpha-element abundance ratios out to at least their effective radii. We find that the BGGs and BCGs have very uniform masses, central ages and central metallicities. Examining the radial dependence of their stellar populations, we find no significant velocity dispersion, age, or alpha-enhancement gradients. However, we find a wide range of metallicity gradients, suggesting a variety of formation mechanisms. The range of metallicity gradients observed is surprising given the homogeneous environment these galaxies probe and their uniform central stellar populations. However, our results are inconsistent with any single model of galaxy formation and emphasize the need for more theoretical understanding of both the origins of metallicity gradients and galaxy formation itself. We postulate two possible physical causes for the different formation mechanisms. ", "machine_text": "  We present spatially resolved kinematics and stellar population properties of the brightest cluster and group galaxies (BCGs), based on a sample of 24 galaxies in 19 groups and clusters selected from the SDSS, and three galaxies in the Leo Group from VLA/CVF data. We find that the kinematics and stellar populations of the BCGs are well described by two parameters: the cluster/groupcentric distance and the galaxycentric distance within the group/cluster. The kinematics and stellar population properties of a given galaxy vary smoothly and continuously with these two distances, and change abruptly at the boundary of the group/cluster. We find no evidence of kinematic or stellar population differentiation within a group/cluster, except possibly in the Leo Group, although the sample is small. We find a correlation between the kinematic properties and stellar population properties, indicating that both are driven by the same physical mechanism. We show that the observed correlation can be explained by a simple model in which the galaxies are described by a set of parameters that vary smoothly and continuously with the cluster/groupcentric and galaxycentric distances. We use the model to predict the kinematic and stellar population properties of a galaxy in a face-on group/cluster, and find that the predicted properties agree well with observations, supporting the model. We discuss the implications of our results for the role of the group/cluster environment in shaping the kinematic and stellar population properties of galaxies, and for the use of the group/cluster environment as a probe of galactic structure and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Diagrammatic Category for the Representation Theory of U_q(sl_n). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1503, "human_text": "  This thesis provides a partial answer to a question posed by Greg Kuperberg in q-alg/9712003 and again by Justin Roberts as problem 12.18 in \"Problems on invariants of knots and 3-manifolds\", math.GT/0406190, essentially: \"Can one describe the category of representations of the quantum group U_q(sl_n) (thought of as a spherical category) via generators and relations?\"   For each n \\geq 0, I define a certain tensor category of trivalent graphs, modulo isotopy, and construct a functor from this category onto (a full subcategory of) the category of representations of the quantum group U_q(sl_n). One would like to describe completely the kernel of this functor, by providing generators. The resulting quotient of the diagrammatic category would then be a category equivalent to the representation category of U_q(sl_n).   I make significant progress towards this, describing certain generators of the kernel, and some obstructions to further elements. It remains a conjecture that these relations generate the kernel. My results extend those of q-alg/9712003, MR1659228, math.QA/0310143 and math.GT/0506403.   The argument is essentially by constructing a diagrammatic version of the forgetful functor coming from the inclusion of U_q(sl_{n-1}) in U_q(sl_n}. We know this functor is faithful, so a diagram is in the kernel for n exactly if its image under the diagrammatic forgetful functor is in the kernel for n-1. This allows us to perform inductive calculations, both establishing families of elements of the kernel, and finding obstructions. ", "machine_text": "  We give a diagrammatic category for the representation theory of U_q(sl_n). We show that certain quotient categories of this category are \"acting objects\" in a suitable category of categories.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for Single-Top Production at CDF. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2954, "human_text": "  This article reports on recent searches for single-top-quark production by the CDF collaboration at the Tevatron using a data set that corresponds to an integrated luminosity of 955 pb^-1. Three different analyses techniques are employed, one using likelihood discriminants, one neural networks and one matrix elements. The sensitivity to single-top production at the rate predicted by the standard model ranges from 2.1 to 2.6 sigma. While the first two analyses observe a deficit of single-top like events compared to the expectation, the matrix element method observes an excess corresponding to a background fluctuation of 2.3 sigma. The null results of the likelihood and neural network analyses translate in upper limits on the cross section of 2.6\\ pb for the t-channel production mode and 3.7 pb for the s-channel mode at the 95% C.L. The matrix element result corresponds to a measurement of 2.7^+1.5_-1.3 pb for the combined t- and s-channel single-top cross section. In addition, CDF has searched for non-standard model production of single-top-quarks via the s-channel exchange of a heavy W^\\prime boson. No signal of this process is found resulting in lower mass limits of 760 GeV/c^2 in case the mass of the right-handed neutrino is smaller than the mass of the right-handed W^\\prime or 790 GeV/c^2 in the opposite case. ", "machine_text": "  We present here the results of a search for single-top production in p-pbar collisions at \\sqrt{s}=1.96 TeV, based on a sample of beam-dump collisions collected with the CDF detector. We use a signal model with hadronization and reconstruction parameters obtained from a previous search in \\sqrt{s}=1.96 TeV collisions involving a lepton pair and in \\sqrt{s}=0.96 TeV collisions with only one lepton. We use the mass of the lightest neutral hadron as a marker for the produced top quark. The search strategy is based on the analysis of events with one or two leptons, and on the distribution of the hadron masses in the events with two leptons. We observe 2 events with a hadron mass greater than the expected background, and 1 event with a hadron mass in the expected background range. We observe no significant excess over the expected background. We set cross section limits in a range of center-of-mass energy assuming the standard model production mechanism. The analysis presented here is the first search for single-top production in hadron collisions at \\sqrt{s}=1.96 TeV, and the first analysis of top quark production in hadron collisions to use the full CDF data set.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Heat Capacity of PbS: Isotope Effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1804, "human_text": "  In recent years, the availability of highly pure stable isotopes has made possible the investigation of the dependence of the physical properties of crystals, in particular semiconductors, on their isotopic composition. Following the investigation of the specific heat ($C_p$, $C_v$) of monatomic crystals such as diamond, silicon, and germanium, similar investigations have been undertaken for the tetrahedral diatomic systems ZnO and GaN (wurtzite structure), for which the effect of the mass of the cation differs from that of the anion. In this article we present measurements for a semiconductor with rock salt structure, namely lead sulfide. Because of the large difference in the atomic mass of both constituents ($M_{\\rm Pb}$= 207.21 and ($M_{\\rm S}$=32.06 a.m.u., for the natural isotopic abundance) the effects of varying the cation and that of the anion mass are very different for this canonical semiconductor. We compare the measured temperature dependence of $C_p \\approx C_v$, and the corresponding derivatives with respect to ($M_{\\rm Pb}$ and $M_{\\rm S}$), with \\textit{\\textit{ab initio}} calculations based on the lattice dynamics obtained from the local density approximation (LDA) electronic band structure. Quantitative deviations between theory and experiment are attributed to the absence of spin-orbit interaction in the ABINIT program used for the electronic band structure calculations. ", "machine_text": "  We have measured the heat capacity of PbS as a function of temperature for several atoms. The isotope effect on the heat capacity has been determined for the stable isotopes with mass numbers 204, 206, and 208. The heat capacity of PbS is found to be extremely well described by a model in which the electronic contribution to the heat capacity is independent of temperature. The excess heat capacity has a positive temperature coefficient, suggesting that it is due to a contribution from the lattice. The agreement between the model and the data is good for temperatures below T \u2248 100 K, but poor for higher temperatures. The discrepancy is greatest for the isotope with the largest nuclear mass, 208Pb. We have also measured the magnetic specific heat of PbS, but the results are not definitive, as magnetic fields were not sufficiently stable. The low temperature heat capacity of PbS, in spite of its poor agreement with the model, is consistent with the heat capacity being due to lattice vibrations. The high temperature behavior is consistent with a model in which the electronic contribution to the heat capacity is independent of temperature, but the lattice contribution has a positive temperature coefficient. We discuss the results in the framework of a simple model in which the ions move in a square lattice, and the electronic states are described by a tight binding model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Witnessing the formation of a galaxy cluster at z=0.485: optical and\n  X-ray properties of RX J1117.4+0743 ([VMF 98] 097). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2459, "human_text": "  We present a multiwavelength study of the poor cluster RX J1117.4+0743 ([VMF 98] 097) at z=0.485, based on GMOS/Gemini South g', r' photometry and spectroscopy, and XMM-Newton observations. We examine its nature and surroundings by analyzing the projected galaxy distribution, the galaxy velocity distribution, the weak-lensing mass reconstruction, and the X-ray spectroscopy and imaging. The cluster shows a complex morphology. It is composed by at least two structures along the line-of-sight, with velocity dispersions of 592+-82 km s^-1 and 391+-85 km s^-1 respectively. Other structures are also detected in X-ray, in the galaxy projected number density map, and by weak-lensing. One of these clumps, could be gravitationally bound and associated to the main cluster. The derived temperature and bolometric X-ray luminosity reveal that [VMF 98] 097 behave like a normal cluster, in agreement with Lx-Tx correlation found for both local (z=0) and moderate redshift (z~0.4) clusters. We find that the mass determination inferred from weak-lensing is in average 3 to 4.8 times higher (depending on the model assumed) than the X-ray mass. We have two possible explanations for this discrepancy: i) the cluster is in non-equilibrium, then the deviation of the X-ray estimated mass from the true value can be as high as a factor of two; ii) the intervening mass along the line-of-sight of the cluster is producing an over-estimation of the weak-lensing mass. Based on the analysis presented, we conclude that [VMF 98] 097 is a perturbed cluster with at least two substructures in velocity space and with other nearby structures at projected distances of about 1 h^-1 Mpc. This cluster is an example of a poor cluster caught in the process of accreting sub-structures to become a rich cluster. ", "machine_text": "  We present here results of a multiwavelength study of the galaxy cluster RX J1117.4+0743 at z=0.485, in an effort to determine the role of cluster accretion in the formation of massive clusters. We find that this cluster, which is thought to be in the process of accreting a large group of galaxies, has many of the same properties as clusters that are thought to have formed through the accretion of many small groups. These properties include a large fraction of cool, blue galaxies, and a temperature-declining gas profile. We present a detailed study of the cluster's galaxies in the optical and X-ray, and show that the cool, blue galaxies are likely to be a relatively large group that has already been accreted, and that the hot gas in the cluster has not yet been strongly affected by this group's infall. We discuss the importance of this study in the context of the evolution of massive clusters, and suggest that the simplest models of cluster formation that are based on the accretion of small groups may need to be modified.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modeling Repulsive Gravity with Creation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0544, "human_text": "  There is a growing interest in the cosmologists for theories with negative energy scalar fields and creation, in order to model a repulsive gravity. The classical steady state cosmology proposed by Bondi, Gold and Hoyle in 1948, was the first such theory which used a negative kinetic energy creation field to invoke creation of matter. We emphasize that creation plays very crucial role in cosmology and provides a natural explanation to the various explosive phenomena occurring in local (z<0.1) and extra galactic universe. We exemplify this point of view by considering the resurrected version of this theory - the quasi-steady state theory, which tries to relate creation events directly to the large scale dynamics of the universe and supplies more natural explanations of the observed phenomena. Although the theory predicts a decelerating universe at the present era, it explains successfully the recent SNe Ia observations (which require an accelerating universe in the standard cosmology), as we show in this paper by performing a Bayesian analysis of the data. ", "machine_text": "  Modeling Repulsive Gravity with Creation  We propose a model of repulsive gravity in which the gravitational force between two objects is directly proportional to the creation of the objects. We show that this model can be obtained from a modification of the Lovelock mechanism, and that it has the same dynamics as the standard model of repulsive gravity, with the exception that the energy of the system is not conserved. This model has several interesting features, including a new type of creationary black hole, and a new physical meaning for the cosmological constant, and the repulsive gravity between objects can be seen as a signature of the creationary potential between them.  We begin by motivating the model. We show that a modification of the Lovelock mechanism, which relates the potential of a system to the evolution of the system, can lead to a model of repulsive gravity. We then describe the model, and show that it has the same dynamics as the standard model of repulsive gravity, with the exception that the energy of the system is not conserved. We then analyze the model, and show that it can be used to describe several physical phenomena, including a new type of creationary black hole, and a new physical meaning for the cosmological constant, and the repulsive gravity between objects can be seen as a signature of the creationary potential between them. Finally, we discuss the implications of our results for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Entropy signature of the running cosmological constant. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0174, "human_text": "  Renormalization group (RG) improved cosmologies based upon a RG trajectory of Quantum Einstein Gravity (QEG) with realistic parameter values are investigated using a system of cosmological evolution equations which allows for an unrestricted energy exchange between the vacuum and the matter sector. It is demonstrated that the scale dependence of the gravitational parameters, the cosmological constant in particular, leads to an entropy production in the matter system. The picture emerges that the Universe started out from a state of vanishing entropy, and that the radiation entropy observed today is essentially due to the coarse graining (RG flow) in the quantum gravity sector which is related to the expansion of the Universe. Furthermore, the RG improved field equations are shown to possess solutions with an epoch of power law inflation immediately after the initial singularity. The inflation is driven by the cosmological constant and ends automatically once the RG running has reduced the vacuum energy to the level of the matter energy density. ", "machine_text": " We show that the running cosmological constant, as obtained from the analysis of the cosmic microwave background radiation, has an entropy signature that is consistent with the assumption that the cosmological constant is a pure quantum state. We consider a general scheme for quantizing the cosmological constant that is invariant under general coordinate transformations and does not require the introduction of a cosmological constant term in the action function. The resulting quantum state is shown to have a particular entropy signature that can be tested against the entropy signature of the running cosmological constant. The entropy signature of the running cosmological constant as extracted from the analysis of the cosmic microwave background radiation is consistent with the cosmological constant being a pure quantum state. We show that the bulk behavior of the entropy signature is a special case of the 'folded spectrum' entropy signature associated with a particular type of general coordinate transformation. The special case of the folded spectrum entropy signature that we consider is shown to be consistent with the assumption that the cosmological constant is a pure quantum state. We discuss a simple physical model that can produce a folded spectrum entropy signature and show that this model is consistent with the assumption that the cosmological constant is a pure quantum state. We also show that the cosine-symmetry of the spatial variations of the cosmological constant is consistent with the assumption that the cosmological constant is a pure quantum state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An experimental test of non-local realism. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2529, "human_text": "  Most working scientists hold fast to the concept of 'realism' - a viewpoint according to which an external reality exists independent of observation. But quantum physics has shattered some of our cornerstone beliefs. According to Bell's theorem, any theory that is based on the joint assumption of realism and locality (meaning that local events cannot be affected by actions in space-like separated regions) is at variance with certain quantum predictions. Experiments with entangled pairs of particles have amply confirmed these quantum predictions, thus rendering local realistic theories untenable. Maintaining realism as a fundamental concept would therefore necessitate the introduction of 'spooky' actions that defy locality. Here we show by both theory and experiment that a broad and rather reasonable class of such non-local realistic theories is incompatible with experimentally observable quantum correlations. In the experiment, we measure previously untested correlations between two entangled photons, and show that these correlations violate an inequality proposed by Leggett for non-local realistic theories. Our result suggests that giving up the concept of locality is not sufficient to be consistent with quantum experiments, unless certain intuitive features of realism are abandoned. ", "machine_text": " We present an experimental test of non-local realism, based on the idea that if a quantum system is prepared in a state in which the values of certain properties are non-commuting, then a measurement of one of these properties will have an impact on the value of the other property, even when this second property is measured at a distance from the first one. To this end, we prepare an entangled state of two spatially separated qutrits, and perform a joint measurement of their respective amplitudes in a particular basis. We show that the outcome of this measurement has an immediate impact on the value of the quantum state of the other qutrit, in spite of the fact that there is no communication between the two qutrits, nor between the two measurement apparatuses. Our result implies that, even when a quantum system is prepared in a state in which non-local commutativity is guaranteed by the laws of quantum mechanics, this state nevertheless has a well-defined value for the non-commuting properties, and that this value is not affected by a distant measurement of one of these properties. We also analyze a possible experimental realization of this scenario, using current technology, and find that such a realization is within the reach of current experimental capabilities.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The discrete dipole approximation for simulation of light scattering by\n  particles much larger than the wavelength. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0037, "human_text": "  In this manuscript we investigate the capabilities of the Discrete Dipole Approximation (DDA) to simulate scattering from particles that are much larger than the wavelength of the incident light, and describe an optimized publicly available DDA computer program that processes the large number of dipoles required for such simulations. Numerical simulations of light scattering by spheres with size parameters x up to 160 and 40 for refractive index m=1.05 and 2 respectively are presented and compared with exact results of the Mie theory. Errors of both integral and angle-resolved scattering quantities generally increase with m and show no systematic dependence on x. Computational times increase steeply with both x and m, reaching values of more than 2 weeks on a cluster of 64 processors. The main distinctive feature of the computer program is the ability to parallelize a single DDA simulation over a cluster of computers, which allows it to simulate light scattering by very large particles, like the ones that are considered in this manuscript. Current limitations and possible ways for improvement are discussed. ", "machine_text": " We propose a simple and general formalism for simulation of light scattering by particles much larger than the wavelength. Our approach is based on the discrete dipole approximation, which is valid when the wavelength is much larger than the size of the scatterer. In this approximation the light scattered by a small particle is approximately described by a sum of elementary dipoles, each of which is aligned along the direction of the electric field of the incident light. We show that the strength of each dipole is proportional to the cube of the distance between the particle and the incident wave-front, and therefore the total scattered light is proportional to the product of the total number of elementary dipoles and the inverse square of the wavelength. Our approach is general and can be applied to any particle that can be described by a set of dipoles, and therefore can be used for simulation of light scattering by most macromolecules and nanoparticles. We also derive an analytical expression for the dipole approximation in the limit of large particles, and use this expression to derive a simple formula for the reduction of the scattered light as the particle size is increased. Our formula shows good agreement with numerical results for large particles, and therefore can be used for an approximate simulation and characterization of light scattering by large particles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Approche variationnelle pour le calcul bay\\'esien dans les probl\\`emes\n  inverses en imagerie. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1914, "human_text": "  In a non supervised Bayesian estimation approach for inverse problems in imaging systems, one tries to estimate jointly the unknown image pixels $\\fb$ and the hyperparameters $\\thetab$. This is, in general, done through the joint posterior law $p(\\fb,\\thetab|\\gb)$. The expression of this joint law is often very complex and its exploration through sampling and computation of the point estimators such as MAP and posterior means need either optimization of non convex criteria or int\\'egration of non Gaussian and multi variate probability laws. In any of these cases, we need to do approximations. We had explored before the possibilities of Laplace approximation and sampling by MCMC. In this paper, we explore the possibility of approximating this joint law by a separable one in $\\fb$ and in $\\thetab$. This gives the possibility of developing iterative algorithms with more reasonable computational cost, in particular, if the approximating laws are choosed in the exponential conjugate families. The main objective of this paper is to give details of different algorithms we obtain with different choices of these families. ", "machine_text": "  Abstract  In the field of medical imaging, inverse problems arise when one wants to interpret the image data in order to answer a clinical question. For example, in X-ray tomography, the goal is to determine the internal 3D structure of an object from its 2D radiographic projection. Most of the tomographic algorithms assume that the X-ray intensity measured at each voxel of the image is proportional to the volume of the material in that voxel. In practice, however, the measurement is affected by the surrounding material, giving rise to artifacts. We propose a variational approach to solve this inverse problem by incorporating prior knowledge about the possible structure of the material. In particular, we assume that the X-ray attenuation coefficient is a linear combination of basis functions, where the basis functions are related to the structure of the material. By minimizing the difference between the measured data and the projection of the solution, we recover the coefficients of the basis functions and the internal structure of the material. Our approach is general and can be applied to various tomographic algorithms, such as filtered back projection or likelihood-based methods. We illustrate our approach on simulated data, and we apply it to clinical data sets to demonstrate its potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nontrivial Geometries: Bounds on the Curvature of the Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0332, "human_text": "  Probing the geometry of the universe is one of the most important endevours in cosmology. Current observational data from the Cosmic Microwave Background anisotropy (CMB), galaxy surveys and type Ia supernovae (SNe Ia) strongly constrain the curvature of the universe to be close to zero for a universe dominated by a cosmological constant or dark energy with a constant equation of state. Here we investigate the role of cosmic priors on deriving these tight bounds on geometry, by considering a landscape motivated scenario with an oscillating curvature term. We perform a likelihood analysis of current data under such a model of non-trivial geometry and find that the uncertainties on curvature, and correspondingly on parameters of the matter and dark energy sectors, are larger. Future dark energy experiments together with CMB data from experiments like Planck could dramatically improve our ability to constrain cosmic curvature under such models enabling us to probe possible imprints of quantum gravity. ", "machine_text": " We investigate the possibility of a nontrivial geometry of the universe, and present bounds on the curvature and topology of spacetime that are implied by the assumption that the universe is spatially homogenous and isotropic. We show that the assumption of spatial homogeneity and isotropy allows one to immediately obtain a bound on the largest possible radius of a spherically symmetric space-time, and that this bound is not compatible with the assumption of a nontrivial topology. We then show that this bound can be tightened by using the fact that a nontrivial geometry would imply the existence of a privileged reference frame. We also show that the bound is tight for any spatially inhomogeneous and anisotropic universe that can be described by a spherically symmetric space-time with a radius that is smaller than the bound. We then present a physical argument that the bound is tight for a large class of possible inhomogeneous and anisotropic universes. The argument is based on the idea that if the universe has a nontrivial geometry, then this should be immediately visible in the form of preferred directions and a non-trivial spectrum of the cosmic microwave background radiation. We show that this argument implies a bound on the length of the longest diameter of the universe, and that this bound is tight for a large class of possible geometries. We finally present a general procedure for obtaining tight bounds on the curvature and topology of the universe, based on the assumption that the universe is locally similar to a spherically symmetric space-time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical 3-Space: A Review. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4146, "human_text": "  For some 100 years physics has modelled space and time via the spacetime concept, with space being merely an observer dependent perspective effect of that spacetime - space itself had no observer independent existence - it had no ontological status, and it certainly had no dynamical description. In recent years this has all changed. In 2002 it was discovered that a dynamical 3-space had been detected many times, including the Michelson-Morley 1887 light-speed anisotropy experiment. Here we review the dynamics of this 3-space, tracing its evolution from that of an emergent phenomena in the information-theoretic Process Physics to the phenomenological description in terms of a velocity field describing the relative internal motion of the structured 3-space. The new physics of the dynamical 3-space is extensively tested against experimental and astronomical observations, including the necessary generalisation of the Maxwell, Schrodinger and Dirac equations, leading to a derivation and explanation of gravity as a refraction effect of quantum matter waves. The flat and curved spacetime formalisms are derived from the new physics, so explaining their apparent many successes. ", "machine_text": "  Dynamical 3-Space: A Review  We introduce the notion of a dynamical 3-space, which is an extension of the concept of a 3-space to the setting of dynamical systems. We review the theory of dynamical 3-spaces and discuss some of their applications, such as to the representation theory of Lie groups and to the analysis of oscillatory and chaotic dynamical systems.  The theory of 3-spaces has its roots in the representation theory of finite dimensional Lie algebras. For any Lie algebra $\\mathfrak{g}$, there is a unique representation $\\pi: \\mathfrak{g} \\to \\mathfrak{B}^{n}$, where $\\mathfrak{B}$ is the Lie algebra of trace class operators on $\\mathfrak{g}$ and $n$ is the dimension of $\\mathfrak{B}$. This representation is given by the $n$-by-$n$ matrix representation of $\\mathfrak{g}$ on the space of square-integrable complex valued functions $\\mathfrak{B}^{n}$.  For a generalization of the notion of a 3-space to the setting of dynamical systems, one can define the notion of a dynamical 3-space as a space of functions on a system which are invariant under a finite set of affine transformations of the phase space of the system. The space is typically taken to be the space of square-integrable functions on the phase space, although this is not necessary.  We review the theory of dynamical 3-spaces, including the basic results on the structure of such spaces and the theory of 3-annihilators. We also discuss some of the applications of dynamical 3-spaces, such as to the representation theory of Lie groups and to the analysis of oscillatory and chaotic dynamical systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A\n  tidally-evolved binary Centaur. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1523, "human_text": "  Hubble Space Telescope observations of Uranus- and Neptune-crossing object (65489) Ceto/Phorcys (provisionally designated 2003 FX128) reveal it to be a close binary system. The mutual orbit has a period of 9.554 +/- 0.011 days and a semimajor axis of 1840 +/- 48 km. These values enable computation of a system mass of (5.41 +/- 0.42) 10^18 kg. Spitzer Space Telescope observations of thermal emission at 24 and 70 microns are combined with visible photometry to constrain the system's effective radius (109 +10/-11 km) and geometric albedo (0.084 +0.021/-0.014). We estimate the average bulk density to be 1.37 +0.66/-0.32 g cm^-3, consistent with ice plus rocky and/or carbonaceous materials. This density contrasts with lower densities recently measured with the same technique for three other comparably-sized outer Solar System binaries (617) Patroclus, (26308) 1998 SM165, and (47171) 1999 TC36, and is closer to the density of the saturnian irregular satellite Phoebe. The mutual orbit of Ceto and Phorcys is nearly circular, with an eccentricity <= 0.015. This observation is consistent with calculations suggesting that the system should tidally evolve on a timescale shorter than the age of the solar system. ", "machine_text": "  The orbit, mass, size, albedo, and density of (65489) Ceto/Phorcys: A tidally-evolved binary Centaur  We present photometric observations of the tidally-evolved binary Centaur (65489) Ceto/Phorcys. Our observations include high-precision photometry from the Canada-France-Hawaii Telescope, and medium-precision photometry from the Fine Guidance Sensor onboard the Hubble Space Telescope. Together these data are used to derive the orbital elements and physical characteristics of the Centaur. We find that Ceto and Phorcys have a relatively circular orbit with many, narrow, eccentric, and closely-spaced orbits superimposed on this baseline. The semimajor axis of the orbit is 133.8 +0.9/-0.9 km, with the period given by the spheroidal orbit being 70.685 +0.016/-0.016 years. The orbital elements are in reasonable agreement with those derived from astrometric observations, with a small but non-zero inclination to the plane of the sky. The true orbit is probably closer to circular than the spheroidal orbit, indicating that this system is very slowly evolving. We estimate the masses of Ceto and Phorcys to be 3.00 +0.09/-0.09 and 2.98 +0.09/-0.09 kg, respectively. The albedos are estimated to be 0.037 +0.007/-0.007 and 0.032 +0.007/-0.007, for Ceto and Phorcys, respectively. The size parameters are 14.1 +0.5/-0.5 and 12.7 +0.5/-0.5, for Ceto and Phorcys, respectively. The density parameters are 1.86 +0.2/-0.2 and 1.86 +0.2/-0.2, for Ceto and Phorcys, respectively. The estimated densities are consistent with the presumption that these objects are mainly icy, with a small rocky core. We conclude that this is a member of the so-called NV3 group of co-orbital, mutually-interacting, tidally-evolved binaries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing General Metric Theories of Gravity with Bursting Neutron Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2426, "human_text": "  I show that several observable properties of bursting neutron stars in metric theories of gravity can be calculated using only conservation laws, Killing symmetries, and the Einstein equivalence principle, without requiring the validity of the general relativistic field equations. I calculate, in particular, the gravitational redshift of a surface atomic line, the touchdown luminosity of a radius-expansion burst, which is believed to be equal to the Eddington critical luminosity, and the apparent surface area of a neutron star as measured during the cooling tails of bursts. I show that, for a general metric theory of gravity, the apparent surface area of a neutron star depends on the coordinate radius of the stellar surface and on its gravitational redshift in the exact same way as in general relativity. On the other hand, the Eddington critical luminosity depends also on an additional parameter that measures the degree to which the general relativistic field equations are satisfied. These results can be used in conjunction with current and future high-energy observations of bursting neutron stars to test general relativity in the strong-field regime. ", "machine_text": " We present a new method for testing theories of gravity with astronomical observations of collapsing neutron stars. Our method is based on measuring the frequency and duration of gravitational waves (GWs) generated during the plunge and subsequent oscillations of a neutron star (NS) into a black hole (BH). We show that these gravitational waves can be used to constrain the parameter space of general metric theories of gravity (GMGTs), including theories that feature a non-minimally coupled scalar field, a generalization of the Einstein-Maxwell-Chern theory, or an extra, possibly nonlinear, metric degree of freedom. We consider various GMGTs and evaluate the effectiveness of our method by comparing the predictions of these theories to the latest observations of the GW source GW150914. We show that our method is sensitive to the basic structure of GMGTs, and can distinguish between theories that feature a minimally coupled scalar field and theories that do not. We also show that our method can place significant constraints on the initial condition of the NS-BH pair, including the mass of the NS and the three other parameters that define its initial orbit, and can rule out some GMGTs with relatively mild non-minimality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing Inward Motions in Starless Cores Using The HCN J = 1-0 Hyperfine\n  Transitions : A Pointing Survey Toward Central Regions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.293, "human_text": "  We have carried out a survey toward the central regions of 85 starless cores in HCN J = 1-0 to study inward motions in the cores. Sixty-four cores were detected with HCN lines. The infall asymmetry in the HCN spectra is found to be more prevalent, and more prominent than in any other previously used infall tracers such as CS J = 2-1, DCO+ J = 2-1, and N2H+ J = 1-0. We found close relation between the intensities of the HCN and N2H+ lines. This implies that the HCN is not much depleted in the central regions of the cores. In some cores, the HCN spectra show different sign of asymmetry from other molecular lines. A few cores show various signs of asymmetry in individual HCN hyperfine lines. The distribution of the velocity shift dV of the HCN profiles with respect to the systemic velocity of the optically thin tracer is found to be more shifted toward bluer side than those of other infall tracers, indicating that the HCN traces inward motions more frequently. The dV distribution of each HCN hyperfine line for all sources is similar. Moreover the dV values obtained from different HCN hyperfine lines for each source are nearly similar. These may mean that most of starless cores are in similar kinematic states across the layers of the cores. We identify 17 infall candidates using all available indicators such as the velocity shift dV and the blue to red peak intensity ratio of double peaked profiles for HCN J = 1-0, CS J = 2-1, J = 3-2, DCO+ J = 2-1, and N2H+ J = 1-0. Four of them, L63, L492, L694-2, and L1197 are found to show higher blue to red ratio in the HCN hyperfine line along the lower opacity, suggesting that infall speed becomes higher toward the center. ", "machine_text": " We present a pointing survey toward the central regions of starless cores in order to probe inward motions using the HCN J = 1-0 hyperfine transition. We use a simple model in which the distribution of HCN is treated as a isothermal, homogenous, and stationary gas in order to derive an expression for the observed distribution of HCN J = 1-0 intensity as a function of radius. We show that this expression can be used to infer the radial distribution of the column density, N(r), and the radial motion, v(r), provided that N(r) and v(r) are known at the inner and outer edges of the core. We present observations toward 46 starless cores in the Taurus-Auriga region. We find that the column density generally increases toward the core centers, consistent with gravitational collapse, except in 6 cases in which the column density is constant. We infer the radial distribution of v(r) in the same 46 cores and find that v(r) is constant in 20 cores, decreases in 8 cores, and increases in 6 cores. We conclude that a large fraction (70%) of the cores show no evidence of inward motions, consistent with the simple assumption of isothermal, homogenous, and stationary gas distribution. We discuss possible physical mechanisms that may produce the non-monotonic distributions of v(r) and N(r) found in some cores.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Enhanced Kondo Effect in an Electron System Dynamically Coupled with\n  Local Optical Phonon. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3874, "human_text": "  We discuss Kondo behavior of a conduction electron system coupled with local optical phonon by analyzing the Anderson-Holstein model with the use of a numerical renormalization group (NRG) method. There appear three typical regions due to the balance between Coulomb interaction $U_{\\rm ee}$ and phonon-mediated attraction $U_{\\rm ph}$. For $U_{\\rm ee}>U_{\\rm ph}$, we observe the standard Kondo effect concerning spin degree of freedom. Since the Coulomb interaction is effectively reduced as $U_{\\rm ee}-U_{\\rm ph}$, the Kondo temperature $T_{\\rm K}$ is increased when $U_{\\rm ph}$ is increased. On the other hand, for $U_{\\rm ee}<U_{\\rm ph}$, there occurs the Kondo effect concerning charge degree of freedom, since vacant and double occupied states play roles of pseudo-spins. Note that in this case, $T_{\\rm K}$ is decreased with the increase of $U_{\\rm ph}$. Namely, $T_{\\rm K}$ should be maximized for $U_{\\rm ee} \\approx U_{\\rm ph}$. Then, we analyze in detail the Kondo behavior at $U_{\\rm ee}=U_{\\rm ph}$, which is found to be explained by the polaron Anderson model with reduced hybridization of polaron and residual repulsive interaction among polarons. By comparing the NRG results of the polaron Anderson model with those of the original Anderson-Holstein model, we clarify the Kondo behavior in the competing region of $U_{\\rm ee} \\approx U_{\\rm ph}$. ", "machine_text": "  We have investigated a quantum system comprising of a single electron and a single photon, which is dynamically coupled to a thermal reservoir and a local optical phonon. The system is modeled by the effective two-dimensional (2D) nonlinear Schr\u00f6dinger equation with a dissipative term that includes both the finite resistivity and the scattering by the optical phonon. We found a clear signature of the enhanced Kondo effect in the steady state of the system, which has a distinct dependence on the strength of the coupling to the phonon. We explain this effect by the enhanced stability of the single-particle basis renormalization, which in turn depends on the phonon-induced symmetry breaking. We also found a strong enhancement of the temperature dependence of the zero-frequency limit, which can be understood by the presence of an additional term in the dissipative kernel, which is related to the electron-phonon coupling. Our results may be useful in the study of various exotic phenomena related to the interplay between different degrees of freedom in a multi-particle system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Revisiting the Issues On Netflow Sample and Export Performance. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.073, "human_text": "  The high volume of packets and packet rates of traffic on some router links makes it exceedingly difficult for routers to examine every packet in order to keep detailed statistics about the traffic which is traversing the router. Sampling is commonly applied on routers in order to limit the load incurred by the collection of information that the router has to undertake when evaluating flow information for monitoring purposes. The sampling process in nearly all cases is a deterministic process of choosing 1 in every N packets on a per-interface basis, and then forming the flow statistics based on the collected sampled statistics. Even though this sampling may not be significant for some statistics, such as packet rate, others can be severely distorted. However, it is important to consider the sampling techniques and their relative accuracy when applied to different traffic patterns. The main disadvantage of sampling is the loss of accuracy in the collected trace when compared to the original traffic stream. To date there has not been a detailed analysis of the impact of sampling at a router in various traffic profiles and flow criteria. In this paper, we assess the performance of the sampling process as used in NetFlow in detail, and we discuss some techniques for the compensation of loss of monitoring detail. ", "machine_text": "  We revisit the issues of the sampling and export performance of NetFlow. We improve the characterization of the sampling process and provide a formalism to assess the bias induced by the sampling process. We derive a simple expression to compute the sampling rate, which is not uniform for all flows. We show that an optimal sampling rate exists and is inversely proportional to the product of the flow duration and the number of bytes. We analyze the impact of the sampling rate and the size of the export packets on the export performance. We derive a simple expression for the export bandwidth and show that the optimal export bandwidth is directly proportional to the sampling rate. We implement and evaluate these concepts using real traces. We provide a methodology to assess the accuracy of sampled flow measurements. Our results show that sampling can have a tremendous impact on the exported flow statistics, and that, in general, flow measurements are not accurate. We discuss the implications of our results for the operational practice and we propose a simple method to improve the quality of the sampled flow measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Controlled collisions of a single atom and ion guided by movable\n  trapping potentials. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1037, "human_text": "  We consider a system composed of a trapped atom and a trapped ion. The ion charge induces in the atom an electric dipole moment, which attracts it with an r^{-4} dependence at large distances. In the regime considered here, the characteristic range of the atom-ion interaction is comparable or larger than the characteristic size of the trapping potential, which excludes the application of the contact pseudopotential. The short-range part of the interaction is described in the framework of quantum-defect theory, by introducing some short-range parameters, which can be related to the s-wave scattering length. When the separation between traps is changed we observe trap-induced shape resonances between molecular bound states and vibrational states of the external trapping potential. Our analysis is extended to quasi-one-dimensional geometries, when the scattering exhibit confinement-induced resonances, similar to the ones studied before for short-range interactions. For quasi-one-dimensional systems we investigate the effects of coupling between the center of mass and relative motion, which occurs for different trapping frequencies of atom and ion traps. Finally, we show how the two types of resonances can be employed for quantum state control and spectroscopy of atom-ion molecules. ", "machine_text": "  We study controlled collisions of a single atom and ion guided by movable trapping potentials. We consider a scenario where a single atom is surrounded by a trapping potential in three dimensions and an ion of known energy is made to collide with the atom in a way such that the resulting atom-ion system is also surrounded by a trapping potential. We investigate the motion of the system for different initial conditions and in the presence of different types of trapping potentials. We also study the different ways in which an atom and ion can be combined to form a molecule. Our main results are: (i) We show that the system will always collide with the trapping potential in a way such that the total kinetic energy of the system remains constant. (ii) We show that the system can be made to perform a complete rotation about an axis perpendicular to the plane of the orbit even in the presence of a harmonic potential. (iii) We show that a large number of different molecular states can be obtained by suitable choice of the initial conditions and the type of potential.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of electron-electron interaction on the phonon-mediated spin\n  relaxation in quantum dots. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0868, "human_text": "  We estimate the spin relaxation rate due to spin-orbit coupling and acoustic phonon scattering in weakly-confined quantum dots with up to five interacting electrons. The Full Configuration Interaction approach is used to account for the inter-electron repulsion, and Rashba and Dresselhaus spin-orbit couplings are exactly diagonalized. We show that electron-electron interaction strongly affects spin-orbit admixture in the sample. Consequently, relaxation rates strongly depend on the number of carriers confined in the dot. We identify the mechanisms which may lead to improved spin stability in few electron (>2) quantum dots as compared to the usual one and two electron devices. Finally, we discuss recent experiments on triplet-singlet transitions in GaAs dots subject to external magnetic fields. Our simulations are in good agreement with the experimental findings, and support the interpretation of the observed spin relaxation as being due to spin-orbit coupling assisted by acoustic phonon emission. ", "machine_text": " We investigate electron-electron interaction effects on the phonon-mediated spin relaxation in quantum dots by means of analytical and numerical techniques. We consider a spherical quantum dot with a spherically symmetric potential and no internal electric field. We find that the spin-phonon interaction in this system is extremely long-range in character. We show that this is due to a very large value of the acoustic impedance Z, which is directly related to the ratio of the angular momentum to the inverse temperature. Therefore, the relaxation is very fast and the dynamic behavior of the system is completely different from that of the elementary particles, such as electrons and phonons. We show that the dynamic behavior of the system can be well described by a single parameter Y, which is related to the damping ratio of the dynamic evolution. We find that Y is always greater than one, which means that the system always relaxes to a state with less disorder. The results obtained are consistent with the fact that electron-electron interaction reduces the entanglement of the system. We also derive a simple expression for the spin relaxation time in this system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Study in Depth of f0(1370). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1341, "human_text": "  Claims have been made that f0(1370) does not exist. The five primary sets of data requiring its existence are refitted. Major dispersive effects due to the opening of the 4pi threshold are included for the first time; the sigma -> 4pi amplitude plays a strong role. Crystal Barrel data on pbar-p -> 3pizero at rest require f0(1370) signals of at least 32 and 33 standard deviations in 1S0 and 3P1 annihilation respectively. Furthermore, they agree within 5 MeV for mass and width. Data on pbar-p -> eta-eta-pizero agree and require at least a 19 standard deviation contribution. This alone is sufficient to demonstrate the existence of f0(1370). BES II data for J/Psi -> phi-pi-pi contain a visible f0(1370) signal > 8 standard devations. In all cases, a resonant phase variation is required. The possibility of a second pole in the sigma amplitude due to the opening of the 4pi channel is excluded. Cern-Munich data for pi-pi elastic scattering are fitted well with the inclusion of some mixing between sigma, f0(1370) and f0(1500). The pi-pi widths for f2(1565), rho3(1690), rho3(1990) and f4(2040) are determined. ", "machine_text": " We present a study in depth of the radial mode f0(1370), which has been observed in the Sun's atmosphere in the form of small-scale structures. These structures are visible as bright points in the solar photosphere, in photospheric areas of enhanced temperature and low magnetic activity. We find that the amplitude of f0(1370) increases linearly with depth in the photosphere, then remains almost constant in the transition region, and finally decreases exponentially in the corona. The frequency of f0(1370) in the photosphere is slightly higher than that in the corona. Our results indicate that the source of f0(1370) is probably close to the solar surface, in a layer several thousand kilometers thick, and that the energy is carried to the corona by the emerging magnetic field. We propose that f0(1370) is related to the internal dynamics of the Sun and could be excited by different physical processes in different regions. Our findings are consistent with a picture in which the amplitude of f0(1370) is controlled by the competition between the upward and downward propagating components of the wave, which is related to the temperature, density, and magnetic field distribution in the solar atmosphere.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Super stellar clusters with a bimodal hydrodynamic solution: an\n  Approximate Analytic Approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1889, "human_text": "  We look for a simple analytic model to distinguish between stellar clusters undergoing a bimodal hydrodynamic solution from those able to drive only a stationary wind. Clusters in the bimodal regime undergo strong radiative cooling within their densest inner regions, which results in the accumulation of the matter injected by supernovae and stellar winds and eventually in the formation of further stellar generations, while their outer regions sustain a stationary wind. The analytic formulae are derived from the basic hydrodynamic equations. Our main assumption, that the density at the star cluster surface scales almost linearly with that at the stagnation radius, is based on results from semi-analytic and full numerical calculations. The analytic formulation allows for the determination of the threshold mechanical luminosity that separates clusters evolving in either of the two solutions. It is possible to fix the stagnation radius by simple analytic expressions and thus to determine the fractions of the deposited matter that clusters evolving in the bimodal regime blow out as a wind or recycle into further stellar generations. ", "machine_text": "  We consider the problem of describing the dynamical evolution of stellar clusters in galaxies. We derive a new approximate analytic solution to the coupled hydrodynamic and kinetic equations for a spherically symmetric cluster within a potential field, which includes a correction due to the kinetic energy of the cluster particles. The solution is bimodal, with two different concentrations of the cluster particles, which can be related to the core and the outer regions of the cluster. We find that the relaxation time of the cluster is inversely proportional to the square of the ratio of the kinetic energy to the potential energy. We discuss the physical meaning of the solution, and show that the relaxation time is inversely proportional to the square of the cluster mass. We compare the result with the case of an N-body cluster, and discuss the differences. We also analyze the case of a cluster in a driven potential field, and show that the result can be understood in terms of the optimal distribution of the cluster particles in the potential field. Finally, we discuss some applications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Multiphilic Descriptor for Chemical Reactivity and Selectivity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0334, "human_text": "  In line with the local philicity concept proposed by Chattaraj et al. (Chattaraj, P. K.; Maiti, B.; Sarkar, U. J. Phys. Chem. A. 2003, 107, 4973) and a dual descriptor derived by Toro-Labbe and coworkers (Morell, C.; Grand, A.; Toro-Labbe, A. J. Phys. Chem. A. 2005, 109, 205), we propose a multiphilic descriptor. It is defined as the difference between nucleophilic (Wk+) and electrophilic (Wk-) condensed philicity functions. This descriptor is capable of simultaneously explaining the nucleophilicity and electrophilicity of the given atomic sites in the molecule. Variation of these quantities along the path of a soft reaction is also analyzed. Predictive ability of this descriptor has been successfully tested on the selected systems and reactions. Corresponding force profiles are also analyzed in some representative cases. Also, to study the intra- and intermolecular reactivities another related descriptor namely, the nucleophilicity excess (DelW-+) for a nucleophile, over the electrophilicity in it has been defined and tested on all-metal aromatic compounds. ", "machine_text": " A Multiphilic Descriptor for Chemical Reactivity and Selectivity The ability to predict the products of a chemical reaction is a long-standing problem in chemistry, and is a major challenge for organic chemistry in particular. We have developed a new approach to the prediction of organic reaction products, which is based on the idea of a multiphilic descriptor. This descriptor uses a combination of various hydrophobic and hydrophilic properties to characterize the reactants, and is shown to be highly predictive for a wide range of organic reaction types. The approach is tested on a set of 76 different reaction types, and the results are compared to those obtained using other popular descriptor types. The multiphilic descriptor is shown to be the most predictive, with a prediction success rate of 80%. The method is also compared to other recent methods for reaction prediction, and is shown to be competitive with the best of these methods. The practical utility of the multiphilic descriptor is illustrated by its use in the development of a model for the prediction of product selectivity in the Apple Baylis-Hillman reaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Census of Baryons in Galaxy Clusters and Groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1726, "human_text": "  We determine the contribution of stars in galaxies, intracluster stars, and the intracluster medium to the total baryon budget in nearby galaxy clusters and groups. We find that the baryon mass fraction (f_b) within r500 is constant for systems with M500 between 6e13 and 1e15 Msun. Although f_b is lower than the WMAP value, the shortfall is on the order of both the observational systematic uncertainties and the depletion of baryons within r500 that is predicted by simulations. The data therefore provide no compelling evidence for undetected baryonic components, particularly any that vary in importance with cluster mass. A unique feature of the current analysis is direct inclusion of the contribution of intracluster light (ICL) in the baryon budget. The increase in X-ray gas mass fraction with increasing total mass is entirely accounted for by a decrease in the total stellar mass fraction, supporting the argument that the behavior of both the stellar and X-ray gas components is dominated by a decrease in star formation efficiency in more massive environments. Within just the stellar component, the fraction of the total stellar luminosity in the BCG and ICL decreases as velocity dispersion increases, suggesting that the BCG+ICL component, and in particular the dominant ICL component, grows less efficiently in higher mass environments. The degree to which this behavior arises from our sample selection, which favored systems with central, giant elliptical galaxies, remains unclear. A more robust result is the identification of low mass groups with large BCG+ICL components, demonstrating that the creation of intracluster stars does not require a massive cluster environment. Within r500 and r200, the BCG+ICL contributes on average 40% and 33% of the total stellar light, respectively. ", "machine_text": "  We present a census of baryons in groups and clusters of galaxies, based on a combination of galaxy redshift surveys and X-ray observations of clusters. We find that the total baryonic content of groups and clusters is 1.8 times that of the local galaxy group, with the groups containing slightly more baryons than the clusters. This result is consistent with the clusters containing relatively massive galaxies in the core, and the groups containing many more low mass galaxies in the outskirts. We find that the groups and clusters contain large amounts of gas, with the gas fraction dropping quickly from the clusters to the groups. This suggests that the gas in the clusters has recently been accreted, and has not yet had time to cool and condense into stars. The clusters and groups also contain large amounts of hot dust, indicating the presence of an active star formation. We find that the groups and clusters contain large amounts of carbon, indicating that the gas in the clusters has not yet cooled and condensed into stars. We discuss the implications of our results for the formation of groups and clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nanomechanics of single keratin fibres: A Raman study of the alpha helix\n  -> beta sheet transition and water effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0776, "human_text": "  The use of micro-Raman spectroscopy, through chemical bond nano-scale probes, allows the changes in conformations (alpha helix -> beta sheet), chain orientation, disconnection of disulfide bonds (-20%) and the increase of intra and inter-chain distances during the strain to be distinguished. The combination of micro-Raman spectroscopy and a allows a quantitative measure of the extension of chemical bonds in the peptidic chain during loading. The nano-structural transformations of keratin during the strain of human hair in a dry environment (40-60 % relative humidity) and saturated with water have been studied. The water permits the sliding of the chains and decreases the bond energy hair. Spectral analyses and 2D correlation are two coherent and independent methods to follow change the Raman probes which are sensitive to structural . The between nano-mechanical (Raman) and micro-mechanical (strain/stress) analyses confirms the validity of the experimental results, tools and principles used, as well as the agreement with the structural model of keratin fibres described by Chapman & Hearle. ", "machine_text": " We present a study of the nanomechanics of single keratin fibres using Raman spectroscopy. The motivation for this work is a desire to understand the mechanical properties of keratin fibres at the molecular level in order to gain fundamental knowledge that may be relevant to the design of new hair care products. We have investigated the effect of water on the alpha helix -> beta sheet transition temperature of the keratin polypeptide using high resolution Raman spectroscopy. We have also characterised the distribution of the different types of bonds present in the keratin fibre. The results of this work show that the water soluble fraction of the keratin fibre consists almost entirely of alpha helical structure, while the water insoluble fraction is largely beta sheet structure. The results also show that the transition temperature for the alpha helix -> beta sheet transition is significantly affected by the presence of water, with the transition temperature being raised by the presence of water. The practical application of this work is that it may be possible to design hair care products that can stabilise the alpha helix structure of the keratin polypeptide, and thus give better curl retention to the hair.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy-Efficient Resource Allocation in Wireless Networks: An Overview\n  of Game-Theoretic Approaches. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1787, "human_text": "  An overview of game-theoretic approaches to energy-efficient resource allocation in wireless networks is presented. Focusing on multiple-access networks, it is demonstrated that game theory can be used as an effective tool to study resource allocation in wireless networks with quality-of-service (QoS) constraints. A family of non-cooperative (distributed) games is presented in which each user seeks to choose a strategy that maximizes its own utility while satisfying its QoS requirements. The utility function considered here measures the number of reliable bits that are transmitted per joule of energy consumed and, hence, is particulary suitable for energy-constrained networks. The actions available to each user in trying to maximize its own utility are at least the choice of the transmit power and, depending on the situation, the user may also be able to choose its transmission rate, modulation, packet size, multiuser receiver, multi-antenna processing algorithm, or carrier allocation strategy. The best-response strategy and Nash equilibrium for each game is presented. Using this game-theoretic framework, the effects of power control, rate control, modulation, temporal and spatial signal processing, carrier allocation strategy and delay QoS constraints on energy efficiency and network capacity are quantified. ", "machine_text": " We survey recent game-theoretic approaches to energy-efficient resource allocation in wireless networks. In particular, we focus on the problem of jointly optimizing the energy consumption and the Quality-of-Service (QoS) requirements of a set of users, each having resource requests of different types and QoS requirements, and each being associated with a battery of finite capacity. We first motivate our survey by reviewing the challenges that the energy-constrained operation of wireless networks raises. We then present a game-theoretic formulation of the joint energy-efficient QoS provisioning problem and survey several game-theoretic solution concepts that have been proposed to solve this problem, including game theory, stochastic game theory, and mechanism design. We review both the classical approaches that consider the energy consumption of the users as a resource to be managed and the recent approaches that consider the total energy consumption of the network as a resource to be managed. We discuss the trade-off between the selfish and the socially-optimal behavior of the users, and we survey how this trade-off can be captured via the incentives offered to the users in the different game-theoretic solution concepts. We then survey the existing game-theoretic solution concepts in terms of their flexibility, which is captured by the number of parameters that their design requires, and their efficiency, which is captured by the performance that one can achieve with a given number of parameters. We finally discuss the practical relevance of the surveyed results and the open problems that remain in this field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modeling transcription factor binding events to DNA using a random\n  walker/jumper representation on a 1D/2D lattice with different affinity sites. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2454, "human_text": "  Surviving in a diverse environment requires corresponding organism responses. At the cellular level, such adjustment relies on the transcription factors (TFs) which must rapidly find their target sequences amidst a vast amount of non-relevant sequences on DNA molecules. Whether these transcription factors locate their target sites through a 1D or 3D pathway is still a matter of speculation. It has been suggested that the optimum search time is when the protein equally shares its search time between 1D and 3D diffusions. In this paper, we study the above problem using a Monte Carlo simulation by considering a very simple physical model. A 1D strip, representing a DNA, with a number of low affinity sites, corresponding to non-target sites, and high affinity sites, corresponding to target sites, is considered and later extended to a 2D strip. We study the 1D and 3D exploration pathways, and combinations of the two modes by considering three different types of molecules: a walker that randomly walks along the strip with no dissociation; a jumper that represents dissociation and then re-association of a TF with the strip at later time at a distant site; and a hopper that is similar to the jumper but it dissociates and then re-associates at a faster rate than the jumper. We analyze the final probability distribution of molecules for each case and find that TFs can locate their targets fast enough even if they spend 15% of their search time diffusing freely in the solution. This indeed agrees with recent experimental results obtained by Elf et al. 2007 and is in contrast with theoretical expectation. ", "machine_text": " We present a stochastic algorithm to model transcription factor binding events to DNA using a random walker/jumper representation on a 1D/2D lattice with different affinity sites. The algorithm is based on a stochastic solution of the master equation that describes the dynamics of the corresponding random walker/jumper system. We analyze the solution of the master equation in the limit of large number of sites and large number of bound walkers/jumpers. In this regime the solution is shown to converge to a limiting distribution that depends only on the number of sites and the walkers/jumpers, and not on their individual positions. The limiting distribution is shown to be consistent with the well-known model of random monomer binding to a lattice with equal affinity sites. We also analyze the solution of the master equation in the case of non-equal affinity sites and show that the limiting distribution in this case is consistent with a model of non-uniform random monomer binding to a lattice. The results of this work have important practical applications in modeling the evolution of gene expression and the development of cellular phenotypes. In addition, the theoretical results obtained in this work have implications for the theory of random walks on lattices with non-equal affinity sites, and in general for the theory of statistical mechanics systems with non-equal occupancy of the sites.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Study of Direct Photon plus Jet production in CMS Experiment at\n  \\sqrt{s}=14 TeV. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.274, "human_text": "  We present simulation results of $\\gamma$ + Jet analysis using CMS (Compact Muon Solenoid) Object-Oriented software at the Large Hadron Collider (LHC) center of mass energy $\\sqrt{s}$=14 TeV. The study of direct photon production helps in validating the perturbative Quantum Chromodynamics (pQCD) and providing information on the gluon distribution in the nucleons. Direct photon processes also constitute a major background to several other Standard Model (SM) processes and signals of new physics. Thus these processes need to be understood precisely in the new energy regime. In this work, we have done a detailed study of the GEANT4 simulated $\\gamma$ + jet events generated with Pythia, and the related background processes. Isolation cuts have been optimized for direct photon which improves the signal over background ratio by $\\sim25%$ as compared to previous studies done in CMS. The inclusion of a large $\\Delta\\phi$ cut between the photon and the leading jet at $40^0$ in the analysis leads to a further increase of $\\sim15%$ in S/B, thus giving an overall gain of $\\sim42%$ in S/B ratio. ", "machine_text": "  We present the first measurement of the direct photon plus jet production cross section in hadron collisions at \\sqrt{s}=14 TeV performed with the CMS detector at the LHC. The analysis is based on the data collected in 2016 by the CMS collaboration, corresponding to an integrated luminosity of 35.8 fb-1 of collision events containing hadron jets. The cross section is measured for events with two jets and a photon produced in the same hadron collision, in the mass region around 1 TeV. The analysis uses the minimum-bias trigger, selecting events with two jets of hadron-Hadron calorimeter (HCAL) energy above 2.5 GeV, and a photon of energy above 1 GeV produced in the same event. We observe a cross section in good agreement with next-to-leading order theory, corrected for non-perturbative effects, such as jet quenching and jet merging. We also measure the differential cross section as a function of the hadron jet momentum, and find a good agreement with theory, which includes non-perturbative contributions. The measurement is in agreement with theoretical predictions based on the perturbative theory, with a statistical uncertainty of \\sim 3\\% and a systematic uncertainty of \\sim 7%. The results are used to constrain the non-perturbative corrections to the theory and to test the reliability of the perturbative approach to describe the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The First Survey of X-ray Flares from Gamma Ray Bursts Observed by\n  Swift: Spectral Properties and Energetics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1564, "human_text": "  Observations of gamma ray bursts (GRBs) with Swift produced the initially surprising result that many bursts have large X-ray flares superimposed on the underlying afterglow. The flares were sometimes intense, had rapid rise and decay phases, and occurred late relative to the ``prompt'' phase. Some remarkable flares are observed with fluence comparable to the prompt GRB fluence. Many GRBs have several flares, which are sometimes overlapping. Short, intense, repetitive, and late flaring can be most easily understood within the context of the standard fireball model with the internal engine that powers the prompt GRB emission in an active state at late times. However, other models for flares have been proposed. Flare origin can be investigated by comparing the flare spectra to that of the afterglow and the initial prompt emission. In this work, we have analyzed all significant X-ray flares from the first 110 GRBs observed by Swift. From this sample 33 GRBs were found to have significant X-ray flares, with 77 flares that were detected above the 3$\\sigma$ level. In addition to temporal analysis presented in a companion paper, a variety of spectral models have been fit to each flare. In some cases, we find that the spectral fits favor a Band function model, which is more akin to the prompt emission than to that of an afterglow. We find that the average fluence of the flares is 2.4e-7 erg/cm^2/s in the 0.2-10 keV energy band, which is approximately a factor of ten below the average prompt GRB fluence. These results, when combined with those presented in the companion paper on temporal properties of flares, supports the hypothesis that most X-ray flares are late-time activity of the internal engine that spawned the initial GRB; not an afterglow related effect. ", "machine_text": " We present the first survey of X-ray flares from gamma-ray bursts (GRBs) observed by the Swift satellite. The survey consists of 42 X-ray flares from 33 bursts, observed during the period August 2005 to February 2007. We find that the X-ray flux rises faster and is, on average, two times higher during the prompt emission than during the afterglow. The observed phenomenology is consistent with a radioactive decay model in which the parent radionuclide decays with a half-life of  \u223c 2 ms to a stable end-product. For most of the bursts with observed X-ray flares, the total radiated energy in X-rays is  \u223c 5 kJ, which is  \u223c 1% of the total burst energy. We show that the observed X-ray phenomenology can be explained by a simple model in which the X-ray emission arises from a single region, located at the boundary between the radiative and kinetic energy deposition regions. Our model predicts that the X-ray flare should rise with a given burst's total energy deposition and decay with the corresponding kinetic energy deposition. We discuss the implications of our results for the energy budget of GRBs and for the nature of the energy deposition and radiative processes in the bursts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Astrometry with \"Carte du Ciel\" plates, San Fernando zone. I.\n  Digitization and measurement using a flatbed scanner. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.19, "human_text": "  We present an original method of digitizing and astrometrically reducing \"Carte du Ciel\" plate material using an inexpensive flatbed scanner, to demonstrate that for this material there is an alternative to more specialized measuring machines that are very few in number and thus not readily available. The sample of plates chosen to develop this method are original \"Carte du Ciel\" plates of the San Fernando zone, photographic material with a mean epoch 1903.6, and a limiting photographic magnitude ~14.5, covering the declination range of -10 < dec < -2. Digitization has been made using a commercial flatbed scanner, demonstrating the internal precision that can be attained with such a device. A variety of post-scan corrections are shown to be necessary. In particular, the large distortion introduced by the non-uniform action of the scanner is modelled using multiple scans of each plate. We also tackle the specific problems associated with the triple-exposure images on some plates and the grid lines present on all. The final measures are reduced to celestial coordinates using the Tycho-2 Catalogue. The internal precision obtained over a single plate, 3microns ~ 0.18\" in each axis, is comparable to what is realized with similar plate material using slower, less affordable, and less widely available conventional measuring machines, such as a PDS microdensitometer. The accuracy attained over large multi-plate areas, employing an overlapping plate technique, is estimated at 0.2\". ", "machine_text": " We present a new method to measure the positions of stars using the digital scans of old \"Carte du Ciel\" plates. We focus on a zone of the sky around San Fernando where the plates are of good quality and where the astrometry is relatively simple. We describe the reduction procedure, the necessary calibrations, and the final accuracy of the positions, which is about 2-3 arcsec for stars brighter than mag 6. We find a general agreement with the positions from the GALAHKDP and 2MASS redshifts, with a scatter of about 3 arcsec in Galactic coordinates. We also compare the proper motions from our measurements with those from the Hipparcos catalogue. We find a large scatter in the proper motions, which we attribute to the uncertainty in the knowledge of the plate dates. We discuss the systematic effect of the scanning process on the measured positions. Finally, we present a new method to measure the plate scale using only the stars on the plate, which allows to avoid the use of artificial landmarks, as well as a method to measure the attitude of the plate using only the positions of stars with known proper motion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: INTEGRAL high energy monitoring of the X-ray burster KS 1741-293. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0832, "human_text": "  KS 1741-293, discovered in 1989 by the X-ray camera TTM in the Kvant module of the Mir space station and identified as an X-ray burster, has not been detected in the hard X band until the advent of the INTEGRAL observatory. Moreover this source has been recently object of scientific discussion, being also associated to a nearby extended radio source that in principle could be the supernova remnant produced by the accretion induced collapse in the binary system. Our long term monitoring with INTEGRAL, covering the period from February 2003 to May 2005, confirms that KS 1741-293 is transient in soft and hard X band. When the source is active, from a simultaneous JEM-X and IBIS data analysis, we provide a wide band spectrum from 5 to 100 keV, that can be fit by a two component model, a multiple blackbody for the soft emission and a Comptonized or a cut-off power law model for the hard component. Finally, by the detection of two X-ray bursters with JEM-X, we confirm the bursting nature of KS 1741-293, including this source in the class of the hard tailed X-ray bursters. ", "machine_text": " We present here results of a monitoring campaign, carried out with INTEGRAL, of the hard X-ray transient KS 1741-293. The source was observed during a monitoring campaign in February-March 2002, with the INTEGRAL instruments OCK and SPI. We find that the accretion phase lasts at most 2-3 hours, with a few outbursts per year. The observed phenomenology is consistent with a smoothly increasing flux triggered at the periastron passage in a wide eccentric orbit with many short-lived (a few hours) accretion pulses and a final flaring phase of a few minutes when the gas is directly transferred to the white dwarf. The observed phenomenology is consistent with a continuous accretion process in which the gas is first accumulated in a large orbit and then gradually transferred to the white dwarf. The accretion process is likely to be a direct accretion onto the white dwarf. We discuss a possible explanation for the observed phenomenology in terms of a model in which the accretion process is controlled by the instability of a cavity around the white dwarf. We show that the main parameters of the system can be derived from the observed phenomenology. In particular we find that the white dwarf has a relatively long spin period (41-67 min) and that the accretion rate is at most 1.4 10^33 erg s^-1. We discuss a simple model in which the accretion process is treated as a viscous disc around the white dwarf. We show that such a model is consistent with the observed phenomenology and that it predicts a critical accretion rate of log(R_(acc)/R_WD) = -1.1, where R_acc is the accretion rate and R_WD is the radius of the white dwarf.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Decoherence of a driven multilevel quantum system interacting with a\n  multi-bath reservoir. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0995, "human_text": "  A general theory is presented for the treatment of decoherence of a multilevel quantum system (with many degrees of freedom) interacting with multi-bath reservoir and driven by ac fields. In this approach, the system is described by a reduced density operator and the multi-bath reservoir is characterized by a number of spectral densities. The reduced density operator is governed by the master equation in which the effect of ac driving fields and the leakage to non-computational states are included. The theory is applied to the study of decoherence of a two-dimensional (2D) SQUID flux qubit coupled to control and readout circuits. The predicted results are in very good agreement with available experimental results in the absence of driving fields and with the analytic results of a dissipative two-level system in the presence of weak driving fields. The relaxation and decoherence times versus the parameters and temperature of the control and readout circuits are also explored in details to facilitate the optimization of the 2D SQUID qubit. ", "machine_text": "  We investigate the problem of a driven multilevel quantum system interacting with a multi-bath reservoir. We analyze the effects of the driving on the dynamics of the system-reservoir interaction, in particular on the achievable degree of coherence of the driven system. In our analysis we take into account the fact that the dynamics of the system-reservoir interaction is typically very fast, while the driving is done on a longer time-scale. Our main results can be summarized as follows. If the driving is sufficiently fast in comparison to the dynamics of the system-reservoir interaction, then the driven system can achieve a high degree of coherence. If the driving is too slow, however, the coherence will be largely destroyed by the fast dynamics of the system-reservoir interaction. We also find that in order to achieve a high degree of coherence the driving field must be optimized in a way that depends on the details of the system-reservoir interaction. Our results are illustrated with a simple example.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electrostatic Interactions of Asymmetrically Charged Membranes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0893, "human_text": "  We predict the nature (attractive or repulsive) and range (exponentially screened or long-range power law) of the electrostatic interactions of oppositely charged and planar plates as a function of the salt concentration and surface charge densities (whose absolute magnitudes are not necessarily equal). An analytical expression for the crossover between attractive and repulsive pressure is obtained as a function of the salt concentration. This condition reduces to the high-salt limit of Parsegian and Gingell where the interaction is exponentially screened and to the zero salt limit of Lau and Pincus in which the important length scales are the inter-plate separation and the Gouy-Chapman length. In the regime of low salt and high surface charges we predict - for any ratio of the charges on the surfaces - that the attractive pressure is long-ranged as a function of the spacing. The attractive pressure is related to the decrease in counter-ion concentration as the inter-plate distance is decreased. Our theory predicts several scaling regimes with different scaling expressions for the pressure as function of salinity and surface charge densities. The pressure predictions can be related to surface force experiments of oppositely charged surfaces that are prepared by coating one of the mica surfaces with an oppositely charged polyelectrolyte. ", "machine_text": "  We present a theory of the electrostatic interactions of asymmetrically charged membranes. The theory is based on a simple, first-principles, microscopic model of the membrane, which we solve numerically. We show that the membrane potential is a linear combination of the potentials of the different charged components of the membrane, and that the resulting potential is very well described by a model in which the membrane is represented by a single point charge, located at the center of mass of the membrane. This theory is very general, and can be applied to any system in which the relevant electrostatic interactions are weak, regardless of the detailed structure of the system. As an example application, we consider the role of the electrostatic interactions in the formation of liposomes from lipid molecules. We find that the electrostatic interactions are significant for systems in which the lipids are charged, and that they can either stabilize the resulting liposome, or make it less stable. We also consider the role of the electrostatic interactions in the transport of small charged molecules through a membrane. We find that the dependence of the transport on the molecular charge is in general rather complex, and depends on the detailed structure of the membrane.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Trigonometric parallaxes of high velocity halo white dwarf candidates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0355, "human_text": "  The status of 38 halo white dwarf candidates identified by Oppenheimer et al. (2001) has been intensively discussed by various authors. In analyses undertaken to date, trigonometric parallaxes are crucial missing data. Distance measurements are mandatory to kinematically segregate halo object from disk objects and hence enable a more reliable estimate of the local density of halo dark matter residing in such objects.   We present trigonometric parallax measurements for 15 candidate halo white dwarfs (WDs) selected from the Oppenheimer et al. (2001) list. We observed the stars using the ESO 1.56-m Danish Telescope and ESO 2.2-m telescope from August 2001 to July 2004. Parallaxes with accuracies of 1--2 mas were determined yielding relative errors on distances of $\\sim5$% for 6 objects, $\\sim12$% for 3 objects, and $\\sim20$% for two more objects. Four stars appear to be too distant (probably farther than 100 pc) to have measurable parallaxes in our observations. Distances, absolute magnitudes and revised space velocities were derived for the 15 halo WDs from the Oppenheimer et al. (2001) list. Halo membership is confirmed unambiguously for 6 objects while 5 objects may be thick disk members and 4 objects are too distant to draw any conclusion based solely on kinematics. Comparing our trigonometric parallaxes with photometric parallaxes used in previous work reveals an overestimation of distance as derived from photometric techniques. This new data set can be used to revise the halo white dwarf space density, and that analysis will be presented in a subsequent publication. ", "machine_text": "  We present trigonometric parallax measurements for 26 high-velocity halo white dwarf candidates from the first year data set of the ZTF survey. We find that the largest parallax is 6.36 \u00b1 0.13 arcsec for the white dwarf with the highest velocity, indicating an accuracy of  \u223c 1% in the determination of the distance to the high-velocity halo. We find a correlation between the projected velocity and the cosine of the parallax, but it is not a tight correlation and there are several outliers. We find no evidence of large-scale structure in the high-velocity halo. We derive a density distribution for the high-velocity halo, and find it to be consistent with a King- Defineson distribution with a power law index of 1.70 \u00b1 0.01 and a scale length of 2.2 kpc. We find a total of five subclumps in the high-velocity halo, with the largest subclump having a velocity difference of  \u223c 6 kps from the rest of the halo. The subclumps have a higher density than the rest of the halo, but do not exhibit a different density distribution. We also present a search for double white dwarfs using the ZTF data set, and find no evidence of such a system in the high-velocity halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3643, "human_text": "  We apply a previously developed Gibbs sampling framework to the foreground corrected 3-yr WMAP polarization data and compute the power spectrum and residual foreground template amplitude posterior distributions. We first analyze the co-added Q- and V-band data, and compare our results to the likelihood code published by the WMAP team. We find good agreement, and thus verify the numerics and data processing steps of both approaches. However, we also analyze the Q- and V-bands separately, allowing for non-zero EB cross-correlations and including two individual foreground template amplitudes tracing synchrotron and dust emission. In these analyses, we find tentative evidence of systematics: The foreground tracers correlate with each of the Q- and V-band sky maps individually, although not with the co-added QV map; there is a noticeable negative EB cross-correlation at l <~ 16 in the V-band map; and finally, when relaxing the constraints on EB and BB, noticeable differences are observed between the marginalized band powers in the Q- and V-bands. Further studies of these features are imperative, given the importance of the low-l EE spectrum on the optical depth of reionization tau and the spectral index of scalar perturbations n_s. ", "machine_text": "  We present a Bayesian analysis of the low-resolution polarized 3-year WMAP sky maps. We use a Gaussian process (GP) prior on the power spectrum, with the auto- and cross-power spectrum degrees of freedom as the only parameters. The posteriors on these parameters are computed using a Markov chain Monte Carlo (MCMC) method, based on the Slice Sampler, that allows for efficient sampling from the posterior distribution. We show that the resulting posteriors are close to the ones obtained using the more extensive Markov chain Monte Carlo analysis presented in the WMAP paper. This is confirmed by a formal Kullback-Leibler (KL) divergence calculation. The method also allows for an efficient computation of the likelihood function, which in this case is the ratio of the full-sky power to the power in a set of a priori defined large-scale structures. We use this likelihood function as a proxy for the secondary analysis described in the WMAP paper, which seeks to measure the B-mode in the power spectrum due to large-scale anisotropic structures in the sky. Our results are consistent with the secondary analysis of the WMAP paper, and thus in agreement with the conclusion that the large-scale anisotropic component in the power spectrum is likely to be generated by the cosmic microwave background itself, rather than by the galaxy distribution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spitzer spectral line mapping of supernova remnants: I. Basic data and\n  principal component analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2179, "human_text": "  We report the results of spectroscopic mapping observations carried out toward small (1 x 1 arcmin) regions within the supernova remnants W44, W28, IC443, and 3C391 using the Infrared Spectrograph of the Spitzer Space Telescope. These observations, covering the 5.2 - 37 micron spectral region, have led to the detection of a total of 15 fine structure transitions of Ne+, Ne++, Si+, P+, S, S++, Cl+, Fe+, and Fe++; the S(0) - S(7) pure rotational lines of molecular hydrogen; and the R(3) and R(4) transitions of hydrogen deuteride. In addition to these 25 spectral lines, the 6.2, 7.7, 8.6, 11.3 and 12.6 micron PAH emission bands were also observed. Most of the detected line transitions have proven strong enough to map in several sources, providing a comprehensive picture of the relative distribution of the various line emissions observable in the Spitzer/IRS bandpass. A principal component analysis of the spectral line maps reveals that the observed emission lines fall into five distinct groups, each of which may exhibit a distinct spatial distribution: (1) lines of S and H2 (J > 2); (2) the H2 S(0) line; (3) lines of ions with appearance potentials less than 13.6 eV; (4) lines of ions with appearance potentials greater than 13.6 eV, not including S++; (5) lines of S++. Lines of group (1) likely originate in molecular material subject to a slow, nondissociative shock that is driven by the overpressure within the supernova remnant, and lines in groups (3) - (5) are associated primarily with dissociative shock fronts with a range of (larger) shock velocities. The H2 S(0) line shows a low-density diffuse emission component, and - in some sources - a shock-excited component. ", "machine_text": "  We present a catalog of 1251 Spitzer line luminosities of specially selected supernova (SN) remnants in the Local Volume. These data are combined with 42 selected SN remnants in a separate catalog with published Spitzer line luminosities, for a total of 1393 SN remnants. We use principal component analysis (PCA) to explore the linearly dependent structure in the Spitzer line luminosity data. We find a clear correlation of the SN remnant Luminosity (L_Spitzer) with the 3.5 kpc ish radius, R_(3.5), but not with the 6 kpc ish radius, R_(6). The Spitzer line luminosity is not correlated with the age of the remnant, except possibly for the oldest remnants ( >> 5 kyr). The size and the age of a SN remnant are correlated, in that larger remnants are generally older. The Spitzer line luminosity is linearly dependent on the metallicity (Z_Fe) of the SN remnant, but not on the distance to the SN remnant. This is consistent with the known correlation of the Spitzer line luminosity with the age of the remnant, since the metallicity of the remnant is roughly constant with age. We discuss these results in the context of models for SN remnant evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Uniqueness of polynomial canonical representations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2345, "human_text": "  Let P(z) and Q(y) be polynomials of the same degree k>=1 in the complex variables z and y, respectively. In this extended abstract we study the non-linear functional equation P(z)=Q(y(z)), where y(z) is restricted to be analytic in a neighborhood of z=0. We provide sufficient conditions to ensure that all the roots of Q(y) are contained within the range of y(z) as well as to have y(z)=z as the unique analytic solution of the non-linear equation. Our results are motivated from uniqueness considerations of polynomial canonical representations of the phase or amplitude terms of oscillatory integrals encountered in the asymptotic analysis of the coefficients of mixed powers and multivariable generating functions via saddle-point methods. Uniqueness shall prove important for developing algorithms to determine the Taylor coefficients of the terms appearing in these representations. The uniqueness of Levinson's polynomial canonical representations of analytic functions in several variables follows as a corollary of our one-complex variables results. ", "machine_text": "  We show that polynomial canonical representations of non-trivial Lie algebras over fields of characteristic zero are unique in a certain sense. The motivation for this research is the problem of canonical implementations of polynomial representations of Lie algebras. We give an example of a Lie algebra A, with characteristic zero, for which the canonical representation is not induced by a representation of the universal covering group. We show that the problem of canonical implementations of polynomial representations is in general not trivial and that it has to be solved for each Lie algebra separately. We provide a methodology for solving this problem which is based on the description of the polynomial representation in terms of certain generating functions and on the classification of representations of finite groups. This methodology allows us in particular to give a description of the canonical representation of any complex Lie algebra in terms of symmetric and antisymmetric functions. As an application we give a description of the canonical representation of the Lie algebra of a semi-simple Lie group in terms of symmetric and antisymmetric functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Off-center HII regions in power-law density distributions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0711, "human_text": "  The expansion of ionization fronts in uniform and spherically symmetric power-law density distributions is a well-studied topic. However, in many situations, such as a star formed at the edge of a molecular cloud core, an offset power-law density distribution would be more appropriate. In this paper a few of the main issues of the formation and expansion of HII regions in such media are outlined and results are presented for the particular cases where the underlying power laws are 1/r^2 and 1/r^3. A simple criterion is developed for determining whether the initial photoionized region will be unbounded, which depends on the power-law exponent and the ratio of the equivalent Stroemgren radius produced by the star in a uniform medium to the stellar offset distance. In the expansion stage, the ionized volumes will eventually become unbounded unless pressure balance with the external medium is reached before the ionization front velocity becomes supersonic with respect to the ionized gas. ", "machine_text": "  We present a study of off-center HII regions in power-law density distributions. The study consists of a comparison of the observed distribution of off-center HII regions in a sample of 19 galaxies with power-law density distributions, obtained from the integral field spectrograph SINFONI on the E-ELT, with the predictions of a simple model in which the formation of HII regions is related to the evolution of the over-density with radius. We find that the model is consistent with the observations and that the distribution of off-center HII regions in these galaxies is well described by a power law with a characteristic radius of 1-2 kpc and a power law index of 1.5-2. This suggests that the formation of off-center HII regions is a universal feature in power-law density distributions and that the simple model we use is valid for galaxies with power-law density distributions of different morphological types. We discuss the physical mechanism that can explain the origin of these off-center HII regions in terms of the competition between the accretion of matter and the conservation of angular momentum. We also show that the model predicts that the number of off-center HII regions is inversely proportional to the square of the central surface density. We discuss the implications of our results for the physical properties of galaxies with power-law density distributions and for the role of the cold gas phase in galaxy evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
