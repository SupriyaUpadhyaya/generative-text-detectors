{"prompt": "Generate an abstract for work with title: Ultimate Fate of our Universe from Quantum Mechanics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2166, "human_text": "  It is conjectured that time intervals of any kind are proportional to the age of the Universe taken at the time we are considering the interval. If this is the case then the speed of light, in fact any speed, must decrease inversely proportional to this age. The immediate consequence is that energy is not conserved: the hypothesis that time is a homogeneous property implies conservation of energy (the theorem of Noether). Nonconservation of energy follows from the condition that any time interval is proportional to the cosmological time, and therefore time can not be homogeneous. From the uncertainty principle, taking the constant of Planck as a real constant, time independent, it follows that any energy in the Universe decreases linearly with time. We then prove that Schroedinger equation does not change, except for the potential energy term. The future of the Universe gives for the wave functions a long sinusoidal spatial solution, so that everything becomes unlocalized. The relativistic absolute interval remains the same, even with a changing speed of light, and the Universe turns out to be nonexpanding. A Mass-Boom effect is confirmed. ", "machine_text": "  Ultimate Fate of our Universe from Quantum Mechanics  We have developed a new approach to the problem of the ultimate fate of our universe from quantum mechanics principles. Our approach is based on the idea that the fate of our universe is related to the properties of the ground state of the universe, which is the state with the minimum energy. We have shown that the ground state of the universe can be either a state of high potential or a state of low potential. The state of high potential is a state in which the potential energy is high and the kinetic energy is low. The state of low potential is a state in which the potential energy is low and the kinetic energy is high. We have shown that the state of high potential is unstable and will eventually decay into the state of low potential. The state of low potential is stable and will eventually become the ground state of the universe. We have also shown that the transition from the state of high potential to the state of low potential can be described using the principles of quantum mechanics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical Computation on Coefficients of Electroweak Chiral Lagrangian   from One-doublet and Topcolor-assisted Technicolor Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0115, "human_text": "  Based on previous studies deriving the chiral Lagrangian for pseudo scalar mesons from the first principle of QCD, we derive the electroweak chiral Lagrangian and build up a formulation for computing its coefficients from one-doublet technicolor model and a schematic topcolor-assisted technicolor model. We find that the coefficients of the electroweak chiral Lagrangian for the topcolor-assisted technicolor model are divided into three parts: direct TC2 interaction part, TC1 and TC2 induced effective Z' particle contribution part, and ordinary quarks contribution part. The first two parts are computed in this paper and we show that the direct TC2 interaction part is the same as that in the one-doublet technicolor model, while effective Z' contributions are at least proportional to the p^2 order parameter \\beta_1 in the electroweak chiral Lagrangian and typical features of topcolor-assisted technicolor model are that it only allows positive T and U parameters and the T parameter varies in the range 0\\sim 1/(25\\alpha), the upper bound of T parameter will decrease as long as Z' mass become large. The S parameter can be either positive or negative depending on whether the Z' mass is large or small. The Z' mass is also bounded above and the upper bound depend on value of T parameter. We obtain the values for all the coefficients of the electroweak chiral Lagrangian up to order of p^4. ", "machine_text": " We study the dynamics of computation on coefficients of Electroweak Chiral Lagrangian from One-doublet and Topcolor-assisted Technicolor Models. The motivation for the research is to better understand the computation on coefficients of Electroweak Chiral Lagrangian from Topcolor-assisted Technicolor Models. The key ideas and methodology are to use the correlation functions of the Standard Model and Topcolor-assisted Technicolor Models to compute the coefficients of Electroweak Chiral Lagrangian from Topcolor-assisted Technicolor Models. The results obtained are that the dynamics of computation on coefficients of Electroweak Chiral Lagrangian from Topcolor-assisted Technicolor Models is more complicated than the computation on coefficients of Electroweak Chiral Lagrangian from the Standard Model. The problem this work attempts to solve is to better understand the computation on coefficients of Electroweak Chiral Lagrangian from Topcolor-assisted Technicolor Models. The practical application of this work is to better understand the theory of Topcolor-assisted Technicolor Models. The theoretical application of this work is to provide a method to compute the coefficients of Electroweak Chiral Lagrangian from Topcolor-assisted Technicolor Models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Temperature-driven transition from the Wigner Crystal to the   Bond-Charge-Density Wave in the Quasi-One-Dimensional Quarter-Filled band. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1656, "human_text": "  It is known that within the interacting electron model Hamiltonian for the one-dimensional 1/4-filled band, the singlet ground state is a Wigner crystal only if the nearest neighbor electron-electron repulsion is larger than a critical value. We show that this critical nearest neighbor Coulomb interaction is different for each spin subspace, with the critical value decreasing with increasing spin. As a consequence, with the lowering of temperature, there can occur a transition from a Wigner crystal charge-ordered state to a spin-Peierls state that is a Bond-Charge-Density Wave with charge occupancies different from the Wigner crystal. This transition is possible because spin excitations from the spin-Peierls state in the 1/4-filled band are necessarily accompanied by changes in site charge densities. We apply our theory to the 1/4-filled band quasi-one-dimensional organic charge-transfer solids in general and to 2:1 tetramethyltetrathiafulvalene (TMTTF) and tetramethyltetraselenafulvalene (TMTSF) cationic salts in particular. We believe that many recent experiments strongly indicate the Wigner crystal to Bond-Charge-Density Wave transition in several members of the TMTTF family. We explain the occurrence of two different antiferromagnetic phases but a single spin-Peierls state in the generic phase diagram for the 2:1 cationic solids. The antiferromagnetic phases can have either the Wigner crystal or the Bond-Charge-Spin-Density Wave charge occupancies. The spin-Peierls state is always a Bond-Charge-Density Wave. ", "machine_text": "  We study a temperature-driven transition from the Wigner Crystal to the Bond-Charge-Density Wave in the quasi-one-dimensional quarter-filled band. We use the nonequilibrium Green's function technique within the framework of the effective two-dimensional Ising model with a random bond-angle distribution. Our approach is exact and takes into account the finite size of the system. The parameters of the random bond-angle distribution are such that the system is in the thermodynamic equilibrium at zero temperature, and the nonequilibrium ground state has a Wigner crystal structure. We determine the temperature dependence of the real-space structure, the spectral function, and the linear-response function. We find that the transition to the Bond-Charge-Density Wave is continuous and occurs at a finite temperature, T^{*}, which depends on the parameters of the random bond-angle distribution. Our result for T^{*} is consistent with the theory of the random-bond Ising model with a finite number of bonds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Molecular line intensities as measures of cloud masses - II. Conversion   factors for specific galaxy types. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2603, "human_text": "  We present theoretically-established values of the CO-to-H2 and C-to-H2 conversion factors that may be used to estimate the gas masses of external galaxies. We consider four distinct galaxy types, represented by M51, NGC 6946, M82 and SMC N27. The physical parameters that best represent the conditions within the molecular clouds in each of the galaxy types are estimated using a chi^2 analysis of several observed atomic fine structure and CO rotational lines. This analysis is explored over a wide range of density, radiation field, extinction, and other relevant parameters. Using these estimated physical conditions in methods that we have previously established, CO-to-H2 conversion factors are then computed for CO transitions up to J=9-8. For the conventional CO(1-0) transition, the computed conversion factor varies significantly below and above the canonical value for the Milky Way in the four galaxy types considered. Since atomic carbon emission is now frequently used as a probe of external galaxies, we also present, for the first time, the C-to-H2 conversion factor for this emission in the four galaxy types considered. ", "machine_text": " We present the results of a numerical study of the dependence of molecular line intensities in galaxies on the properties of the clouds in which the molecules are formed. We use a simple chemical model to compute the relative abundance of different molecular species in the clouds, and we employ a one-dimensional hydrodynamical code to solve the hydrodynamics of cloud formation and evolution. We vary physical parameters to explore the parameter space, and we compute the molecular line intensities as a function of the mass of the clouds. We find that the molecular line intensity of a given molecular species is proportional to the cloud mass, but the proportionality constant depends on the species and on the physical parameters. We derive general conversion factors for specific galaxy types that can be used to convert molecular line intensities into cloud masses. Our results suggest that the mass of a molecular cloud can be estimated with reasonable accuracy by measuring the molecular line intensity of a few bright galaxies in a galaxy cluster, provided that the galaxies are of a type for which we have derived a conversion factor.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetic Sensitivity of the Ba II D1 and D2 Lines of the Fraunhofer   Spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3979, "human_text": "  The physical interpretation of the spectral line polarization produced by the joint action of the Hanle and Zeeman effects offers a unique opportunity to obtain empirical information about hidden aspects of solar and stellar magnetism. To this end, it is important to achieve a complete understanding of the sensitivity of the emergent spectral line polarization to the presence of a magnetic field. Here we present a detailed theoretical investigation on the role of resonance scattering and magnetic fields on the polarization signals of the Ba II D1 and D2 lines of the Fraunhofer spectrum, respectively at 4934 \\AA\\ and 4554 \\AA. We adopt a three-level model of Ba II, and we take into account the hyperfine structure that is shown by the $^{135}$Ba and $^{137}$Ba isotopes. Despite of their relatively small abundance (18%), the contribution coming from these two isotopes is indeed fundamental for the interpretation of the polarization signals observed in these lines. We consider an optically thin slab model, through which we can investigate in a rigorous way the essential physical mechanisms involved (resonance polarization, Zeeman, Paschen-Back and Hanle effects), avoiding complications due to radiative transfer effects. We assume the slab to be illuminated from below by the photospheric solar continuum radiation field, and we investigate the radiation scattered at 90 degrees, both in the absence and in the presence of magnetic fields, deterministic and microturbulent. We show in particular the existence of a differential magnetic sensitivity of the three-peak Q/I profile that is observed in the D2 line in quiet regions close to the solar limb, which is of great interest for magnetic field diagnostics. ", "machine_text": " The Magnetic Sensitivity of the Ba II D1 and D2 Lines of the Fraunhofer Spectrum  We have investigated the magnetic sensitivity of the Ba II D1 and D2 lines in the Fraunhofer spectrum of a totally absorbing barium vapor lamp. The ratio of the intensities of the D1 and D2 lines in the Fraunhofer spectrum is found to be proportional to the magnetic field along the line of sight. We have determined the coefficient of proportionality to be 1.213 (2), which agrees with the value given by est Divinity. Our result is in qualitative agreement with the results of a previous investigation, in which the author had found the ratio to be proportional to the magnetic field, but the coefficient of proportionality found by us differs from that given in the earlier investigation. We have also investigated the effect of the total pressure of the barium vapor on the magnetic sensitivity of the Ba II D1 and D2 lines in the Fraunhofer spectrum. The ratio of the intensities of the D1 and D2 lines in the Fraunhofer spectrum is found to be independent of the total pressure of the barium vapor.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Energy-Efficient Resource Allocation in Wireless Networks with   Quality-of-Service Constraints. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.388, "human_text": "  A game-theoretic model is proposed to study the cross-layer problem of joint power and rate control with quality of service (QoS) constraints in multiple-access networks. In the proposed game, each user seeks to choose its transmit power and rate in a distributed manner in order to maximize its own utility while satisfying its QoS requirements. The user's QoS constraints are specified in terms of the average source rate and an upper bound on the average delay where the delay includes both transmission and queuing delays. The utility function considered here measures energy efficiency and is particularly suitable for wireless networks with energy constraints. The Nash equilibrium solution for the proposed non-cooperative game is derived and a closed-form expression for the utility achieved at equilibrium is obtained. It is shown that the QoS requirements of a user translate into a \"size\" for the user which is an indication of the amount of network resources consumed by the user. Using this competitive multiuser framework, the tradeoffs among throughput, delay, network capacity and energy efficiency are studied. In addition, analytical expressions are given for users' delay profiles and the delay performance of the users at Nash equilibrium is quantified. ", "machine_text": "  We propose a novel energy-efficient resource allocation strategy for wireless networks with Quality-of-Service (QoS) constraints. Our strategy is based on the idea of joint optimization of resource allocation and wireless network coding. We consider a scenario where a base station (BS) wants to maximize the number of successful transmissions to wireless terminals (or equivalently, the sum utility of the terminals) while minimizing the energy consumption. We propose a general framework for joint optimization of resource allocation and network coding that is applicable to a broad range of wireless network architectures and many types of QoS constraints. In our framework, the BS formulates the joint optimization problem as a bilevel program and then solve it using a generalized Benders decomposition algorithm. We analyze the proposed framework via simulations and show that it achieves significant improvements in terms of energy efficiency and QoS satisfaction, as compared to existing resource allocation strategies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Domain wall switching: optimizing the energy landscape. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0913, "human_text": "  It has recently been suggested that exchange spring media offer a way to increase media density without causing thermal instability (superparamagnetism), by using a hard and a soft layer coupled by exchange. Victora has suggested a figure of merit xi = 2 E_b/mu_0 m_s H_sw, the ratio of the energy barrier to that of a Stoner-Wohlfarth system with the same switching field, which is 1 for a Stoner-Wohlfarth (coherently switching) particle and 2 for an optimal two-layer composite medium. A number of theoretical approaches have been used for this problem (e.g., various numbers of coupled Stoner-Wohlfarth layers and continuum micromagnetics). In this paper we show that many of these approaches can be regarded as special cases or approximations to a variational formulation of the problem, in which the energy is minimized for fixed magnetization. The results can be easily visualized in terms of a plot of the energy as a function of magnetic moment m_z, in which both the switching field [the maximum slope of E(m_z)] and the stability (determined by the energy barrier E_b) are geometrically visible. In this formulation we can prove a rigorous limit on the figure of merit xi, which can be no higher than 4. We also show that a quadratic anistropy suggested by Suess et al comes very close to this limit. ", "machine_text": "  Domain wall switching: optimizing the energy landscape  We consider a model of domain wall (DW) switching in nanowires with a transverse magnetic anisotropy and a negative exchange energy. We find that the dynamics of domain wall switching can be optimized by introducing a perpendicular anisotropy, resulting in a significant reduction of the total energy. The energy landscape can be further optimized by using a dipolar field. We also show that the optimal energy landscape is very sensitive to the sign of the anisotropy. Our findings are consistent with recent experiments on magnetic nanowires.  We consider a one-dimensional model of domain wall (DW) switching in nanowires with a transverse magnetic anisotropy and a negative exchange energy, in the presence of a perpendicular magnetic field. We find that the dynamics of domain wall switching can be optimized by introducing a perpendicular anisotropy, resulting in a significant reduction of the total energy. The energy landscape can be further optimized by using a dipolar field. We also show that the optimal energy landscape is very sensitive to the sign of the anisotropy. Our findings are consistent with recent experiments on magnetic nanowires.  We consider a model of domain wall (DW) switching in nanowires with a transverse magnetic anisotropy and a negative exchange energy, in the presence of a perpendicular magnetic field. We find that the dynamics of domain wall switching can be optimized by introducing a perpendicular anisotropy, resulting in a significant reduction of the total energy. The energy landscape can be further optimized by using a dipolar field. We also show that the optimal energy landscape is very sensitive to the sign of the anisotropy. Our findings are consistent with recent experiments on magnetic nanowires.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolutionary Optimisation Methods for Template Based Image Registration. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1674, "human_text": "  This paper investigates the use of evolutionary optimisation techniques to register a template with a scene image. An error function is created to measure the correspondence of the template to the image. The problem presented here is to optimise the horizontal, vertical and scaling parameters that register the template with the scene. The Genetic Algorithm, Simulated Annealing and Particle Swarm Optimisations are compared to a Nelder-Mead Simplex optimisation with starting points chosen in a pre-processing stage. The paper investigates the precision and accuracy of each method and shows that all four methods perform favourably for image registration. SA is the most precise, GA is the most accurate. PSO is a good mix of both and the Simplex method returns local minima the most. A pre-processing stage should be investigated for the evolutionary methods in order to improve performance. Discrete versions of the optimisation methods should be investigated to further improve computational performance. ", "machine_text": "  Abstract  Registration is the process of finding the correspondence between two or more images. Template-based registration is an active area of research. In this paper we review the use of Evolutionary Optimisation (EO) methods for template-based registration. Template-based registration is a challenge forEO methods due to the difficulty in accurately evaluating the similarity between two templates. We presentEO methods that are capable of dealing with template-based registration. We discuss the similarities and differences between template-based registration and the more standard intensity-based registration. We present a number of novelEO methods for template-based registration and show how these methods can be used to register Templates. We compare the performance of theEO methods with the more standard mutual information-based registration. We show that theEO methods are competitive in terms of registration accuracy and are superior in terms of computation time. We also present a newEO method for template-based registration, which is based on the use of a Markov Random Field. This method is shown to be highly competitive in terms of both accuracy and computation time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Risk Assessment Algorithms Based On Recursive Neural Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0602, "human_text": "  The assessment of highly-risky situations at road intersections have been recently revealed as an important research topic within the context of the automotive industry. In this paper we shall introduce a novel approach to compute risk functions by using a combination of a highly non-linear processing model in conjunction with a powerful information encoding procedure. Specifically, the elements of information either static or dynamic that appear in a road intersection scene are encoded by using directed positional acyclic labeled graphs. The risk assessment problem is then reformulated in terms of an inductive learning task carried out by a recursive neural network. Recursive neural networks are connectionist models capable of solving supervised and non-supervised learning problems represented by directed ordered acyclic graphs. The potential of this novel approach is demonstrated through well predefined scenarios. The major difference of our approach compared to others is expressed by the fact of learning the structure of the risk. Furthermore, the combination of a rich information encoding procedure with a generalized model of dynamical recurrent networks permit us, as we shall demonstrate, a sophisticated processing of information that we believe as being a first step for building future advanced intersection safety systems ", "machine_text": "  Recursive neural networks (RNNs) have recently become a popular tool for time series prediction, both for practical applications and as a benchmark for more exotic methods. We show that, in addition to prediction, RNNs are suitable for a variety of related tasks, such as risk assessment. In fact, the popular long short-term memory (LSTM) network is well-suited for risk assessment, provided that the network is appropriately initialized and that the prediction is conditioned on a finite set of explanatory variables. To highlight the versatility of the approach, we consider a variety of risk assessment tasks, such as quantile regression, value-at-risk estimation, and unconditional risk assessment. We show that a single model can be used to perform all of these tasks, and that the model is flexible enough to be applied to a variety of datasets. We also present a new risk assessment task, which we call informed risk assessment, and show that the RNN-based approach is capable of solving it.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Visible spectroscopic and photometric survey of Jupiter Trojans: final   results on dynamical families. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.035, "human_text": "  We present the results of a visible spectroscopic and photometric survey of Jupiter Trojans belonging to different dynamical families carried out at the ESO-NTT telescope. We obtained data on 47 objects, 23 belonging to the L5 swarm and 24 to the L4 one. These data together with those already published by Fornasier et al. (2004a) and Dotto et al. (2006), constitute a total sample of visible spectra for 80 objects. The survey allows us to investigate six families (Aneas, Anchises, Misenus, Phereclos, Sarpedon, Panthoos) in the L5 cloud and four L4 families (Eurybates, Menelaus, 1986 WD and 1986 TS6). The sample that we measured is dominated by D--type asteroids, with the exception of the Eurybates family in the L4 swarm, where there is a dominance of C- and P-type asteroids. All the spectra that we obtained are featureless with the exception of some Eurybates members, where a drop--off of the reflectance is detected shortward of 5200 A. Similar features are seen in main belt C-type asteroids and commonly attributed to the intervalence charge transfer transition in oxidized iron. Our sample comprises fainter and smaller Trojans as compared to the literature's data and allows us to investigate the properties of objects with estimated diameter smaller than 40--50 km. The analysis of the spectral slopes and colors versus the estimated diameters shows that the blue and red objects have indistinguishable size distribution. We perform a statistical investigation of the Trojans's spectra property distributions as a function of their orbital and physical parameters, and in comparison with other classes of minor bodies in the outer Solar System. Trojans at lower inclination appear significantly bluer than those at higher inclination, but this effect is strongly driven by the Eurybates family. ", "machine_text": "  We present final results of a visible spectroscopic and photometric survey of Jupiter Trojans in dynamical families. We use the ground-based data and the HST data to select the objects in a wider region of the sky to be observed by the Cassini UVIS. Our sample is composed of 52 Trojans, evenly divided between the L4 and L5 points. For the first time, the non-inertial proper motions of the Trojans in these families are determined. The distribution of the non-inertial proper motions of the members of the four families we are able to identify in our sample (Fkl, W, H, and P) is compatible with a purevsingular model with two parameters. The best-fit model with two free parameters describes the data with a reduced \u03c72 of 0.62 and gives a ratio of mean non-inertial proper motion to orbital proper motion of 0.39 \u00b1 0.18. The best-fit model can be used to derive a lower limit for the lifetime of the families of 11.9 Gyr. A large number of objects in our sample, 28, have a non-inertial proper motion larger than this limit, indicating that they must have been born elsewhere. Our results therefore confirm the picture that has emerged from the analysis of the individual objects observed with the Cassini UVIS: the Jupiter Trojans in dynamical families are not, for the most part, the debris left behind by the collisional evolution of a planetesimal belt, but rather the members of an enormous population of small solar system bodies that has migrated in from elsewhere. The four families we have identified probably represent the four largest groups of Trojans that share a common dynamical history. The other Trojans, whose numbers are increasing as our observations improve, apparently come from a wide variety of dynamical backgrounds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmology from String Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0928, "human_text": "  We explore the cosmological content of Salam-Sezgin six dimensional supergravity, and find a solution to the field equations in qualitative agreement with observation of distant supernovae, primordial nucleosynthesis abundances, and recent measurements of the cosmic microwave background. The carrier of the acceleration in the present de Sitter epoch is a quintessence field slowly rolling down its exponential potential. Intrinsic to this model is a second modulus which is automatically stabilized and acts as a source of cold dark matter with a mass proportional to an exponential function of the quintessence field (hence realizing VAMP models within a String context). However, any attempt to saturate the present cold dark matter component in this manner leads to unacceptable deviations from cosmological data -- a numerical study reveals that this source can account for up to about 7% of the total cold dark matter budget. We also show that (1) the model will support a de Sitter energy in agreement with observation at the expense of a miniscule breaking of supersymmetry in the compact space; (2) variations in the fine structure constant are controlled by the stabilized modulus and are negligible; (3) ``fifth''forces are carried by the stabilized modulus and are short range; (4) the long time behavior of the model in four dimensions is that of a Robertson-Walker universe with a constant expansion rate (w = -1/3). Finally, we present a String theory background by lifting our six dimensional cosmological solution to ten dimensions. ", "machine_text": "  We propose a model of the early universe based on string theory. In our model the formation of the early universe is described by the formation of various 2-D membranes, in a process which is analogous to the formation of the 1-D string theory universe. Our model has several new features, which are absent in the usual version of string theory cosmology. First, our model has a non-trivial topology, which describes the universe as a three-dimensional space-time with non-trivial topology. Second, the model describes the early universe as a set of 2-D membranes, which collide and fuse with each other. The resulting space-time has a very complicated structure, with many \"branes\" (membranes) which are \"stacked\" on top of each other. Third, the model describes the early universe as a dynamic process, in which the branes evolve and change their properties. In particular, the model describes the early universe as a process of \"stringy inflation\", in which the size of the universe increases dramatically, due to the dynamics of the string theory. Finally, our model has some physical consequences, which are not present in the usual string theory cosmology. In particular, our model predicts the existence of \"antimatter branes\", which are invisible to ordinary matter, but which can be detected by a \" Dirac detector\".", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quasi Ordinary Singularities, Essential Divisors and Poincare Series. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0603, "human_text": "  We define Poincar\\'e series associated to a toric or analytically irreducible quasi-ordinary hypersurface singularity, (S,0), by a finite sequence of monomial valuations, such that at least one of them is centered at the origin 0. This involves the definition of a multi-graded ring associated to the analytic algebra of the singularity by the sequence of valuations. We prove that the Poincar\\'e series is a rational function with integer coefficients, which can be defined also as an integral with respect of the Euler characteristic, over the projectivization of the analytic algebra of the singularity, of a function defined by the valuations. In particular, the Poincar\\'e series associated to the set of divisorial valuations associated to the essential divisors, considered both over the singular locus and over the point 0, is an analytic invariant of the singularity. In the quasi-ordinary hypersurface case we prove that this Poincar\\'e series determines and it is determined by the normalized sequence of characteristic monomials. These monomials in the analytic case define a complete invariant of the embedded topological type of the hypersurface singularity. ", "machine_text": "  We give a survey of the theory of quasi-ordinary singularities of transversally intersecting vector fields on a smooth projective surface, develop some new examples and discuss some of the open problems.  Let $M$ be a smooth projective manifold and let $X$ and $Y$ be transversally intersecting vector fields on $M$. An example of $M$ with such a pair of vector fields is the Grassmannian $Gr(2,{{\\mathbb C}}^3)$ with the standard symmetric and antisymmetric two-forms on ${\\mathbb C}^3$. If ${{\\mathcal O}}$ is the tautological one-form on $M$, then the vector fields $X={\\mathcal O}^{-1}\\otimes {\\mathcal O}^{-1}$ and $Y={\\mathcal O}^{-1}\\otimes {\\mathcal O}^{2}$ on $Gr(2,{{\\mathbb C}}^3)$ generate the singularity category ${{\\mathcal D}}^{{\\mathrm{ab}}}_{{{\\mathbb C}}^3}$. Our main result is that, in general, this category is not ${{\\mathcal D}}^{{\\mathrm{ab}}}_{M}$. In particular, if ${{\\mathcal D}}^{{\\mathrm{ab}}}_{{{\\mathbb C}}^3}$ is represented by a quasicanonical singularity on $M$, then ${{\\mathcal D}}^{{\\mathrm{ab}}}_{{{\\mathbb C}}^3}$ is not quasi-ordinary on $M$. We show that this phenomenon can be understood by considering the essential divisors of the involved vector fields. As an application, we show that the Poincare series of the singularity category ${{\\mathcal D}}^{{\\mathrm{ab}}}_{{{\\mathbb C}}^3}$ is not finite.  We also show that the singularity category ${{\\mathcal D}}^{{\\mathrm{ab}}}_{M}$ is not necessarily a tensor category in the sense of|||||., if $M$ is not a K3-type manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kalman--Yakubovich--Popov inequality for passive discrete   time-invariant systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0653, "human_text": "  We consider the Kalman - Yakubovich - Popov (KYP) inequality \\[ \\begin{pmatrix} X-A^* XA-C^*C & -A^*X B- C^*D\\cr -B^*X A-D^* C & I- B^*X B-D^*D \\end{pmatrix} \\ge 0 \\] for contractive operator matrices $ \\begin{pmatrix} A&B\\cr C &D \\end{pmatrix}:\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{M} \\end{pmatrix}\\to\\begin{pmatrix}\\mathfrak{H}\\cr\\mathfrak{N} \\end{pmatrix}, $ where $\\mathfrak{H},$ $\\mathfrak{M}$, and $\\mathfrak{N}$ are separable Hilbert spaces. We restrict ourselves to the solutions $X$ from the operator interval $[0, I_\\mathfrak{H}]$. Several equivalent forms of KYP are obtained. Using the parametrization of the blocks of contractive operator matrices, the Kre\\u{\\i}n shorted operator, and the M\\\"obius representation of the Schur class operator-valued function we find several equivalent forms of the KYP inequality. Properties of solutions are established and it is proved that the minimal solution of the KYP inequality satisfies the corresponding algebraic Riccati equation and can be obtained by the iterative procedure with the special choice of the initial point. In terms of the Kre\\u{\\i}n shorted operators a necessary condition and some sufficient conditions for uniqueness of the solution are established. ", "machine_text": "  We consider the problem of characterizing the behavior of a discrete time-invariant system with passive inputs. Let $\\dot{\\bf x}=\\bf A x$ be such a system, where $\\dot{\\bf x}$ denotes the time derivative of $\\bf x$ and $\\bf A$ denotes the linear map from $\\mathbb R^n$ to $\\mathbb R^n$ associated with the system. We assume that $\\dot{\\bf x}=\\bf A x$ has a solution $\\dot{\\bf x}=\\bf x$ and that the solution $\\dot{\\bf x}=\\bf x$ is unique. The well-known Kalman--Yakubovich--Popov inequality relates the norm of $\\dot{\\bf x}-\\dot{\\bf x}^\\ast$ to the norm of $\\bf A$ and the energy $\\dot{\\bf x}^\\ast\\dot{\\bf x}$. We show that under suitable assumptions on $\\dot{\\bf x}$ and $\\dot{\\bf x}^\\ast$ the inequality can be refined to relate the norm of $\\dot{\\bf x}-\\dot{\\bf x}^\\ast$ to the norm of $\\dot{\\bf x}^\\ast\\dot{\\bf x}$, or in other words, to the inner product of $\\dot{\\bf x}^\\ast$ with $\\dot{\\bf x}$. We show that the assumptions on $\\dot{\\bf x}$ and $\\dot{\\bf x}^\\ast$ can be weakened if we consider a class of matrices $\\mathcal M$ that includes all the Toeplitz matrices. Finally, we consider a special case of the problem where the dimension of the input space $\\mathcal I$ is one.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Five Intermediate-Period Planets from the N2K Sample. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1191, "human_text": "  We report the detection of five Jovian mass planets orbiting high metallicity stars. Four of these stars were first observed as part of the N2K program and exhibited low RMS velocity scatter after three consecutive observations. However, follow-up observations over the last three years now reveal the presence of longer period planets with orbital periods ranging from 21 days to a few years. HD 11506 is a G0V star with a planet of \\msini = 4.74 \\mjup in a 3.85 year orbit. HD 17156 is a G0V star with a 3.12 \\mjup planet in a 21.2 day orbit. The eccentricity of this orbit is 0.67, one of the highest known for a planet with a relatively short period. The orbital period for this planet places it in a region of parameter space where relatively few planets have been detected. HD 125612 is a G3V star with a planet of \\msini = 3.5 \\mjup in a 1.4 year orbit. HD 170469 is a G5IV star with a planet of \\msini = 0.67 \\mjup in a 3.13 year orbit. HD 231701 is an F8V star with planet of 1.08 \\mjup in a 142 day orbit. All of these stars have supersolar metallicity. Three of the five stars were observed photometrically but showed no evidence of brightness variability. A transit search conducted for HD 17156 was negative but covered only 25% of the search space and so is not conclusive. ", "machine_text": "  Five Intermediate-Period Planets from the N2K Sample  We present photometric detections of five new planets in the N2K sample. These planets have orbital periods between 4.7 and 5.4 days, which corresponds to semi-major axes between 0.12 and 0.10 AU. These planets have minimum masses of 18.56, 14.66, 13.25, 11.88, and 9.83 MJup. These five planets were detected using a combination ofEVE/Visible andIRTF data. We find that the detectability of these planets is helped by the fact that the host stars are slightly evolved intermediate-period K stars. We present an analysis of the detectability of such planets using a combination of archive and new data fromIRTF. We find that the sensitivity is dependent on both the host star's mass and its evolutionary state. We conclude that while planets of this size can be detected around solar-mass stars, the sensitivity is much better for slightly evolved intermediate-period stars. We discuss this detection technique in the context of theknown population of close-in giant planets, and in terms of planet formation theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Critical Current of Type-II Superconductors in a Broken Bose Glass State. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1536, "human_text": "  The tilt modulus of a defective Abrikosov vortex lattice pinned by material line defects is computed using the boson analogy. It tends to infinity at long wavelength, which yields a Bose glass state that is robust to the addition of weak point-pinning centers, and which implies a restoring force per vortex line for rigid translations about mechanical equilibrium that is independent of magnetic field. It also indicates that the Bose glass state breaks into pieces along the direction of the correlated pinning centers if the latter have finite length. The critical current is predicted to crossover from two dimensional to three dimensional behavior as a function of sample thickness along the correlated pinning centers in such case. That crossover notably can occur at a film thickness that is much larger than that expected from point pins of comparable strength. The above is compared to the dependence on thickness shown by the critical current in certain films of high-temperature superconductors currently being developed for wire technology. ", "machine_text": "  Critical Current of Type-II Superconductors in a Broken Bose Glass State  We have investigated the critical current density of type-II superconductors in a broken Bose glass state. A model of the critical current density in the presence of a linearly increasing longitudinal resistivity along the superconductor is suggested. The model is consistent with the critical current density data for the cuprate superconductor Bi-2212 and the organic superconductor (TTF) molecules in a disordered glass state. Our results suggest that the entanglement of the superconducting order with the disorder-induced singlet excitations is a possible mechanism for the enhancement of the critical current density in a type-II superconductor in a broken glass state.  The critical current density of a type-II superconductor has been found to increase significantly in a broken glass state. This enhancement has been explained in terms of the breaking of the rotational and translational symmetry of the superconductor in the presence of a strong spin-glass state. We have investigated this possibility for the cuprate superconductor Bi-2212 and the organic superconductor (TTF) molecules in a disordered glass state. Our results show that the enhancement of the critical current density in a type-II superconductor in a broken glass state is due to the entanglement of the superconducting order with the disorder-induced singlet excitations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Natural Priors, CMSSM Fits and LHC Weather Forecasts. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0487, "human_text": "  Previous LHC forecasts for the constrained minimal supersymmetric standard model (CMSSM), based on current astrophysical and laboratory measurements, have used priors that are flat in the parameter tan beta, while being constrained to postdict the central experimental value of MZ. We construct a different, new and more natural prior with a measure in mu and B (the more fundamental MSSM parameters from which tan beta and MZ are actually derived). We find that as a consequence this choice leads to a well defined fine-tuning measure in the parameter space. We investigate the effect of such on global CMSSM fits to indirect constraints, providing posterior probability distributions for Large Hadron Collider (LHC) sparticle production cross sections. The change in priors has a significant effect, strongly suppressing the pseudoscalar Higgs boson dark matter annihilation region, and diminishing the probable values of sparticle masses. We also show how to interpret fit information from a Markov Chain Monte Carlo in a frequentist fashion; namely by using the profile likelihood. Bayesian and frequentist interpretations of CMSSM fits are compared and contrasted. ", "machine_text": " We present a new method for fitting resonant states to electroweak Precision tests of the Standard Model (SM) at the Large Hadron Collider (LHC) are sensitive to the structure of states in the Very Small Black Hole (VSBH) regime. We show that a suitable choice of a natural prior for the mass of a VSBH, which depends on the mass of the lightest vector boson ( lighter than the one expected from the Higgs sector), can greatly improve the fit to the electroweak data. The method is similar to the one recently proposed by Abulencia, crossing the Higgs sector with the goal of VSBHs, and relies on the use of a proper natural prior for the mass of the new states. The main difference is that we work in the VSBH regime, and use the VSBH mass scale as the pivot point in the Prior. We find that a prior which is a power law with a positive power is particularly suitable. This is a generic result which can be applied to other resonances. We also show that if the SM is extended with a minimal supersymmetry (MSSM) the power law prior can be used to get an improved fit to the MSSM data. Finally, we present a forecast for the LHC weather in the coming years, derived using a combination of the optimal fit to the electroweak data and the MSSM mass constraints.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cooling and heating by adiabatic magnetization in the   Ni$_{50}$Mn$_{34}$In$_{16}$ magnetic shape memory alloy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1241, "human_text": "  We report on measurements of the adiabatic temperature change in the inverse magnetocaloric Ni$_{50}$Mn$_{34}$In$_{16}$ alloy. It is shown that this alloy heats up with the application of a magnetic field around the Curie point due to the conventional magnetocaloric effect. In contrast, the inverse magnetocaloric effect associated with the martensitic transition results in the unusual decrease of temperature by adiabatic magnetization. We also provide magnetization and specific heat data which enable to compare the measured temperature changes to the values indirectly computed from thermodynamic relationships. Good agreement is obtained for the conventional effect at the second-order paramagnetic-ferromagnetic phase transition. However, at the first order structural transition the measured values at high fields are lower than the computed ones. Irreversible thermodynamics arguments are given to show that such a discrepancy is due to the irreversibility of the first-order martensitic transition. ", "machine_text": " We have performed systematic measurements of the thermal and thermomechanical response of single crystals of the Ni50Mn34In16 magnetic shape memory alloy in a magnetic field applied along the easy axis of magnetization, at temperatures near and below the martensitic transition temperature, in the mixed-phase region. We found that the thermal and thermomechanical properties of the martensite phase, such as the specific heat and the elastic constants, are enhanced by magnetic field applied along the easy axis of magnetization. The change in the specific heat is found to be due to the adiabatic magnetization. We also found that the thermal expansion coefficient along the easy axis of magnetization is reduced due to the formation of the martensite phase, and the reduction increases with the increase of the magnetic field. We explain the enhancement of the thermomechanical properties of the martensite phase by the increase of the internal magnetic field in the martensite phase by the adiabatic magnetization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fabrication of half metallicity in a ferromagnetic metal. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0321, "human_text": "  We investigate the growth of half metallic phase in a ferromagnetic material using state-of-the-art full potential linearized augmented plane wave method. To address the issue, we have substituted Ti at the Ru-sites in SrRuO3, where SrRuO3 is a ferromagnetic material. Calculated results establish Ti4+ valence states (similar to SrTiO3), which was predicted experimentally. Thus, Ti substitution dilutes the Ru-O-Ru connectivity, which is manifested in the calculated results in the form of significant band narrowing leading to finite gap between t2g and eg bands. At 75% substitution, a large gap (> 2 eV) appears at the Fermi level, e_F in the up spin density of states, while the down spin states contributes at e_F characterizing the system a half-metallic ferromagnet. The t2g - eg gap can be tailored judiciously by tuning Ti concentrations to minimize thermal effects, which is often the major bottleneck to achieve high spin polarization at elevated temperatures in other materials. This study, thus, provides a novel but simple way to fabricate half-metallicity in ferromagnetic materials, which are potential candidates for spin-based technology. ", "machine_text": " We report a simple and general approach to introduce half metallicity in a ferromagnetic metal, using thermal treatment of a conventional metallic alloy. We show that this method creates a unique nanostructure, in which the magnetic metal is encapsulated by a non-magnetic shell, leading to a large enhancement of the magnetic coercivity. Our results provide a new route for the fabrication of half metallistic nanostructures, which could be useful in spintronic applications.  Magnetism and metallic conductivity are two fundamental properties of materials that are often mutually exclusive. Although a few magnetic metals, such as nickel and cobalt, do exist, their magnetic properties are rather poor. The ability to combine high magnetic permeability and metallic conductivity in a single material would be extremely useful for spintronic applications, such as magnetic memories, sensors, and oscillators. A natural way to combine these properties is to create a half metallicity in a ferromagnetic metal. In such a material, the magnetic properties are derived from the metal, while the non-magnetic properties are derived from the insulating shell. Ideally, such a half metallicity would have a high metallic conductivity and a high magnetic permeability, in addition to other useful properties, such as superconductivity.  We report a simple and general approach to create half metallicity in a ferromagnetic metal, using thermal treatment of a conventional metallic alloy. We show that this method creates a unique nanostructure, in which the magnetic metal is encapsulated by a non-magnetic shell. This nanostructure has a large enhancement of the magnetic coercivity, in comparison with the original magnetic metal. Our results provide a new route for the fabrication of half metallistic nanostructures, which could be useful in spintronic applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Continuous Magnetophoretic Separation of Blood Cells from Plasma at the   Microscale. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1831, "human_text": "  We present a method for the direct and continuous separation of red and white blood cells from plasma at the microscale. The method is implemented in a microfluidic system with magnetic functionality. The fluidic structure within the microsystem consists of an inlet and a single microfluidic channel with multiple outlets. The magnetic functionality is provided by an array of integrated soft-magnetic elements that are embedded transverse and adjacent to the microchannel. The elements are magnetized using an external field, and once magnetized they produce a magnetic force on blood cells as they flow through the microchannel. In whole blood, white blood cells (WBCs) behave as diamagnetic microparticles, while red blood cells (RBCs) exhibit diamagnetic or paramagnetic behavior depending on the oxygenation of their hemoglobin. We study the motion of blood cells through the microchannel using a mathematical model that takes into account the magnetic, fluidic and gravitational forces on the cells. We use the model to study blood cell separation, and our analysis indicates that the microsystem is capable of separating WBC-rich plasma, deoxygenated RBC-rich plasma and cell-depleted plasma into respective outlets. ", "machine_text": "  We report a continuous and magnetically driven separation of blood cells from plasma at the microscale. A microfluidic chip was designed to carry out the continuous and simultaneous separation of blood cells from plasma using magnetophoresis. Our motivation is to develop a portable and integrated system for rapid separation of blood cells from plasma at the point-of-care. The ability to separate blood cells from plasma is important for many diagnostic applications, such as determining the concentration of blood analytes, studying the formation of blood clots, and quantifying the activation of cells. We use a combination of permanent magnets and electromagnets to create a magnetic field gradient in a microchannel. This magnetic field gradient is used to separate the blood cells from the plasma based on the difference in the magnetic properties of the two constituents. Our approach uses a low magnetic field strength to avoid any damage to the blood cells. This work describes the design and the operation of the microfluidic chip, as well as the laboratory-scale characterization of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The AMIGA sample of isolated galaxies. IV. A catalogue of neighbours   around isolated galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0479, "human_text": "  Studies of the effects of environment on galaxy properties and evolution require well defined control samples. Such isolated galaxy samples have up to now been small or poorly defined. The AMIGA project (Analysis of the interstellar Medium of Isolated GAlaxies) represents an attempt to define a statistically useful sample of the most isolated galaxies in the local (z < 0.05) Universe. A suitable large sample for the AMIGA project already exists, the Catalogue of Isolated Galaxies (CIG, Karachentseva 1973; 1050 galaxies), and we use this sample as a starting point to refine and perform a better quantification of its isolation properties. Digitised POSS-I E images were analysed out to a minimum projected radius R > 0.5 Mpc around 950 CIG galaxies (those within Vr = 1500 km s-1 were excluded). We identified all galaxy candidates in each field brighter than B = 17.5 with a high degree of confidence using the LMORPHO software. We generated a catalogue of approximately 54 000 potential neighbours (redshifts exist for 30% of this sample). Six hundred sixty-six galaxies pass and two hundred eighty-four fail the original CIG isolation criterion. The available redshift data confirm that our catalogue involves a largely background population rather than physically associated neighbours. We find that the exclusion of neighbours within a factor of four in size around each CIG galaxy, employed in the original isolation criterion, corresponds to Delta Vr ~ 18000 km s-1 indicating that it was a conservative limit. Galaxies in the CIG have been found to show different degrees of isolation. We conclude that a quantitative measure of this is mandatory. It will be the subject of future work based on the catalogue of neighbours obtained here. ", "machine_text": "  We present a catalogue of 1,145 galaxies selected by their neighbours from a sample of 864 isolated galaxies in the Local Volume, drawn from the AMIGA survey. The sample is used to investigate the properties of galaxies which are members of poor groups and the effects of group membership on galaxy evolution. The catalogue is the fourth in a series of papers based on the AMIGA survey. A total of 55 groups are found containing two or more of our sample galaxies; 37 of these groups are poor. We find that poor group members are, on average, significantly less massive than galaxies in rich groups. In addition, they are more likely to be morphologically late-type galaxies and to be found in smaller groups. We find that the global group property of feedback influences the properties of group members in poor groups more than in rich groups, suggesting that feedback is more efficient in poor groups. We also find that the group member which is most influenced by its group environment is a morphologically early-type galaxy, suggesting that these galaxies are most susceptible to the group environment. Our results are consistent with a model in which group membership has a significant effect on galaxy evolution and in which poor groups are efficient star-formation feedback amplifiers.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stochastic interacting particle systems out of equilibrium. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1247, "human_text": "  This paper provides an introduction to some stochastic models of lattice gases out of equilibrium and a discussion of results of various kinds obtained in recent years. Although these models are different in their microscopic features, a unified picture is emerging at the macroscopic level, applicable, in our view, to real phenomena where diffusion is the dominating physical mechanism. We rely mainly on an approach developed by the authors based on the study of dynamical large fluctuations in stationary states of open systems. The outcome of this approach is a theory connecting the non equilibrium thermodynamics to the transport coefficients via a variational principle. This leads ultimately to a functional derivative equation of Hamilton-Jacobi type for the non equilibrium free energy in which local thermodynamic variables are the independent arguments. In the first part of the paper we give a detailed introduction to the microscopic dynamics considered, while the second part, devoted to the macroscopic properties, illustrates many consequences of the Hamilton-Jacobi equation. In both parts several novelties are included. ", "machine_text": "  We consider stochastic interacting particle systems out of equilibrium. We review the general theory of such systems and present some new results on an important special class of such systems, namely, the stochastic particle systems with elastic interactions and internal degree of freedom. The main motivation for this work is to study the Statistical Mechanics of these systems in the absence of an external driving, in other words, to study the statistical equilibrium of these systems. We show that these systems have very rich statistical equilibrium behavior which can be very different from the equilibrium behavior of the corresponding equilibrium system. In particular, we show the existence of a new type of phase transition which is absent in the equilibrium case. As an application, we consider the statistical equilibrium of a new model of active particles which interact via elastic collisions and have an internal degree of freedom. We show that this system has a rich phase diagram which includes a new type of phase transition, namely, a phase transition between a disordered state and a state with long range order. We also consider the statistical dynamics of these systems and show that the dynamics is very different from the dynamics of the corresponding equilibrium system. We show that the dynamical critical behavior is in general very different from the statistical critical behavior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nobeyama CO Atlas of Nearby Spiral Galaxies: Distribution of Molecular   Gas in Barred and Non-barred Spiral Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2678, "human_text": "  The data from a CO(1 - 0) mapping survey of 40 nearby spiral galaxies performed with the Nobeyama 45-m telescope are presented. The criteria of the sample selection were (1) RC3 morphological type in the range Sa to Scd, (2) distance less than 25 Mpc, (3) inclination angle less than 79deg (RC3), (4) flux at 100 um higher than ~ 10 Jy, (5) spiral structure is not destroyed by interaction. The maps of CO cover most of the optical disk of the galaxies. We investigated the influence of bar on the distribution of molecular gas in spiral galaxies using these data. We confirmed that the degree of central concentration is higher in barred spirals than in non-barred spirals as shown by the previous works. Furthermore, we present an observational evidence that bars are efficient in driving molecular gas that lies within the bar length toward the center, while the role in bringing gas in from the outer parts of the disks is small. The transported gas accounts for about half of molecular gas within the central region in barred spiral galaxies. We found a correlation between the degree of central concentration and bar strength. Galaxies with stronger bars tend to have higher central concentration. The correlation implies that stronger bars accumulate molecular gas toward the center more efficiently. These results are consistent with long-lived bars. ", "machine_text": "  We present a census of molecular gas in galaxies in the vicinity of the Nobeyama CO Ring, a dense ring of carbon monoxide (CO) emitting galaxies at a distance of 4-5 Mpc from the galactic plane. We used the infra-red CO J=1-0 line to search for molecular gas in galaxies in this area, and found that the number density of molecular galaxies is 1.5+1.3(-1.6) times higher than the number density of star-forming galaxies in the same area, but there is no significant correlation between molecular gas and star-forming gas. We found 13 galaxies with molecular gas (with a total molecular gas mass of 1.4 kpc^2) in a field of 1.3 deg^2, and four of these galaxies are classified as barred spiral galaxies. The total molecular gas mass in the barred spiral galaxies is 0.4 kpc^2, which is equivalent to 30% of the total gas mass in the field. The gas distribution in the barred spiral galaxies is different from that in the non-barred spiral galaxies, and the gas in the barred spiral galaxies is more efficiently converted into stars. We found four main gas distributions in the barred spiral galaxies, and all of them are compatible with the assumption that the gas is released from the bar. We also found a possible link between the location of the gas and the position of the bar, which may provide information on the formation of the bar.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray Flares in Orion Low Mass Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.15, "human_text": "  Context. X-ray flares are common phenomena in pre-main sequence stars. Their analysis gives insights into the physics at work in young stellar coronae. The Orion Nebula Cluster offers a unique opportunity to study large samples of young low mass stars. This work is part of the Chandra Orion Ultradeep project (COUP), an ~10 day long X-ray observation of the Orion Nebula Cluster (ONC). Aims. Our main goal is to statistically characterize the flare-like variability of 165 low mass (0.1-0.3 M_sun) ONC members in order to test and constrain the physical scenario in which flares explain all the observed emission. Methods. We adopt a maximum likelihood piece-wise representation of the observed X-ray light curves and detect flares by taking into account both the amplitude and time derivative of the count-rate. We then derive the frequency and energy distribution of the flares. Results. The high energy tail of the energy distribution of flares is well described by a power-law with index 2.2. We test the hypothesis that light curves are built entirely by overlapping flares with a single power law energy distribution. We constrain the parameters of this simple model for every single light curve. The analysis of synthetic light curves obtained from the model indicates a good agreement with the observed data. Comparing low mass stars with stars in the mass interval (0.9-1.2M_sun), we establish that, at ~1 Myr, low mass and solar mass stars of similar X-ray luminosity have very similar flare frequencies. Conclusions. Our observational results are consistent with the following model/scenario: the light curves are entirely built by over- lapping flares with a power-law intensity distribution; the intense flares are individually detected, while the weak ones merge and form a pseudo-quiescent level, which we indicate as the characteristic level. ", "machine_text": "  We present here a systematic study of X-ray flares in low-mass stars of the Orion Nebula Cluster. We find that the occurrence of X-ray flares in these stars is not uniform, but rather, is correlated with several parameters such as spectral type, orbital period, and the presence or absence of a surrounding disk. We have found a correlation between the occurrence of X-ray flares and the magnetic activity level of these stars, as indicated by the strength of the Ca II H line. The flares occur most frequently (with a probability of about 80%) in low-mass stars (M0-M2 spectral type) with a high level of magnetic activity (Ca II H > 3.5 km/s). The frequency of X-ray flares in G and K stars is much smaller, with only a few events detected during our monitoring campaign. We have found no evidence for a correlation between the occurrence of X-ray flares and the presence of a surrounding disk. However, a trend is observed in the distribution of X-ray flare occurrence in the different orbital periods, with the flares being more frequent in short-period ( \u2272 100 days) stars. We find that the X-ray flares in low-mass stars follow the same physical mechanism as in solar flares, where a reconnection process in the corona triggers a eruption of the solar plasma in the upper atmosphere, creating a radiation flare. Our observations suggest that magnetic activity is an important physical mechanism that plays a key role in the evolution of low-mass stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Using Image Attributes for Human Identification Protocols. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2295, "human_text": "  A secure human identification protocol aims at authenticating human users to a remote server when even the users' inputs are not hidden from an adversary. Recently, the authors proposed a human identification protocol in the RSA Conference 2007, which is loosely based on the ability of humans to efficiently process an image. The advantage being that an automated adversary is not effective in attacking the protocol without human assistance. This paper extends that work by trying to solve some of the open problems. First, we analyze the complexity of defeating the proposed protocols by quantifying the workload of a human adversary. Secondly, we propose a new construction based on textual CAPTCHAs (Reverse Turing Tests) in order to make the generation of automated challenges easier. We also present a brief experiment involving real human users to find out the number of possible attributes in a given image and give some guidelines for the selection of challenge questions based on the results. Finally, we analyze the previously proposed protocol in detail for the relationship between the secrets. Our results show that we can construct human identification protocols based on image evaluation with reasonably ``quantified'' security guarantees based on our model. ", "machine_text": "  Abstract  In this work, we propose a novel strategy for human identification protocols based on the use of image attributes. Our approach is based on the generation of different signatures for each individual, where each signature is formed by a set of attributes that are extracted from a set of reference images. The proposed protocol is based on three main steps. The first one is the registration of the users, where a set of images of each user is obtained and stored. The second step is the definition of the attributes that will be used for the generation of the signatures. In this step, the set of images of each user is analyzed, in order to extract the most relevant features that can be used for the generation of the signatures. The third step is the generation of the signatures and the training of the classifier. The obtained signatures are used to train a classifier that is capable of distinguishing between the signatures of the different users. The obtained signatures can be considered as a kind of footprint of the user, which can be used for the identification process. The proposed protocol has been tested with a database of images of different individuals, and the obtained results show that our protocol is capable of identifying the users with a high degree of reliability, even when the images used for the identification are not the ones that were used for the generation of the signatures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Circulating Hydrogen Ultra-High Purification System for the MuCap   Experiment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1473, "human_text": "  The MuCap experiment is a high-precision measurement of the rate for the basic electroweak process of muon capture, mu- + p -> n + nu . The experimental approach is based on an active target consisting of a time projection chamber (TPC) operating with pure hydrogen gas. The hydrogen has to be kept extremely pure and at a stable pressure. A Circulating Hydrogen Ultrahigh Purification System was designed at the Petersburg Nuclear Physics Institute (PNPI) to continuously clean the hydrogen from impurities. The system is based on an adsorption cryopump to stimulate the hydrogen flow and on a cold adsorbent for the hydrogen cleaning. It was installed at the Paul Scherrer Institute (PSI) in 2004 and performed reliably during three experiment runs. During several months long operating periods the system maintained the hydrogen purity in the detector on the level of 20 ppb for moisture, which is the main contaminant, and of better than 7 ppb and 5 ppb for nitrogen and oxygen, respectively. The pressure inside the TPC was stabilized to within 0.024% of 10 bar at a hydrogen flow rate of 3 standard liters per minute. ", "machine_text": "  A Circulating Hydrogen Ultra-High Purification System for the MuCap Experiment   Hydrogen is an important element that has a very wide range of applications in our daily life, such as in the pharmaceutical, chemical, and energy industries. In addition, hydrogen is one of the most promising clean energy sources. In this experiment, we designed, constructed, and tested a circulating hydrogen ultra-high purification system for the MuCap experiment. The system consists of three major parts: a compressor, a hydrogen sorption pump, and a pressure swing adsorption (PSA) unit. The compressor is used to circulate the hydrogen gas and to control the pressure of the system. The hydrogen sorption pump is used to sorb and transport the hydrogen gas. The PSA unit is used to separate the hydrogen gas from the other gases and to obtain high-purity hydrogen. The purpose of this experiment is to test the performance of the PSA unit and to obtain high-purity hydrogen for the MuCap experiment.  This paper presents the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research in a formal academic and scientific writing voice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Can a charged dust ball be sent through the Reissner--Nordstr\\\"{o}m   wormhole?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4066, "human_text": "  In a previous paper we formulated a set of necessary conditions for the spherically symmetric weakly charged dust to avoid Big Bang/Big Crunch, shell crossing and permanent central singularities. However, we did not discuss the properties of the energy density, some of which are surprising and seem not to have been known up to now. A singularity of infinite energy density does exist -- it is a point singularity situated on the world line of the center of symmetry. The condition that no mass shell collapses to $R = 0$ if it had $R > 0$ initially thus turns out to be still insufficient for avoiding a singularity. Moreover, at the singularity the energy density $\\epsilon$ is direction-dependent: $\\epsilon \\to - \\infty$ when we approach the singular point along a $t =$ const hypersurface and $\\epsilon \\to + \\infty$ when we approach that point along the center of symmetry. The appearance of negative-energy-density regions turns out to be inevitable. We discuss various aspects of this property of our configuration. We also show that a permanently pulsating configuration, with the period of pulsation independent of mass, is possible only if there exists a permanent central singularity. ", "machine_text": " We study the possibility of sending a charged dust ball through the Reissner--Nordstr\\\"{o}m wormhole. Our main result is that, in contrast to the situation for a point-like charged particle, a charged dust ball can in general not be sent through the wormhole. The main reasons for this are the following: (1) If the electric field in the wormhole is not zero, the dust ball will be attracted to one of the sides of the wormhole and can in general not be sent through the wormhole. (2) If the electric field in the wormhole is zero, we must have that the electric field in the external space is also zero. Therefore, it is in general not possible to send a positively charged dust ball through the wormhole, as the positive charge will attract the dust ball to the wormhole. (3) In the special case where the dust ball is made up of only two point-like charges, the dust ball can in general not be sent through the wormhole, as the two charges will be attracted to each other and will in general not be able to pass each other in the wormhole.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Binary Quantum Search. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0777, "human_text": "  Database search has wide applications and is used as a subroutine in many important algorithms. We shall consider a database with one target item. Quantum algorithm finds the target item in a database faster than any classical algorithm. It frequently occurs in practice that only a portion of information about the target item is interesting, or we need to find a group of items sharing some common feature as the target item. This problem is in general formulated as search for a part of the database [a block] containing the target item, instead of the item itself. This is partial search. Partial search trades accuracy for speed, i.e. it works faster than a full search. Partial search algorithm was discovered by Grover and Radhakrishnan. We shall consider optimized version of the algorithm and call it GRK. It can be applied successively [in a sequence]. First the database is partitioned into blocks and we use GRK to find the target block. Then this target block is partitioned into sub-blocks and we use GRK again to find the target sub-block. [We can call it binary quantum search.] Another possibility is to partition the database into sub-blocks directly and use GRK to find the target sub-block in one time. In this paper we prove that the latter is faster [makes less queries to the oracle]. ", "machine_text": "  Binary Quantum Search We introduce and study a new quantum search algorithm for finding the left-most or right-most element of a superposition of 0s and 1s that matches a given search key. The algorithm is based on a binary search in the overlap between the search key and the transformed search superposition. For a successful search, the number of qubits in the search superposition that are simultaneously in the right state (here, the state that matches the search key) must be higher than the number of qubits in the overlap. The algorithm can be designed to be quantum-safe, in the sense that it does not reveal the search key by its input-output behavior. We analyze the algorithm and find the necessary and sufficient conditions for a successful search. The analysis is based on the use of the randomness assumption and a generalization of the notion of a characteristic function for probabilistic systems. In particular, we show that for a successful search the algorithm requires that the search key has a low Hamming distance from the all-0s state, and that the input probability distribution is such that the randomness assumption can be justified. As an application, we show that the algorithm can be used to design a quantum-safe hash function that is efficient on a quantum computer. We also analyze the competitive ratio of the algorithm as a function of the number of qubits in the search superposition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Perspectives for the detection and measurement of Supersymmetry in the   focus point region of mSUGRA models with the ATLAS detector at LHC. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2515, "human_text": "  This paper discusses the ATLAS potential to study Supersymmetry for the \"Focus-Point\" region of the parameter space of mSUGRA models. The potential to discovery a deviation from Standard Model expectations with the first few ${fb}^{-1}$ of LHC data was studied using the parametrized simulation of the ATLAS detector. Several signatures were considered, involving hard jets, large missing energy, and either $b$-tagged jets, opposite-sign isolated electron or muon pairs, or top quarks reconstructed exploiting their fully hadronic decays. With only 1 ${fb}^{-1}$ of data each of these signatures may allow to observe an excess of events over Standard Model expectation with a statistical significance exceeding 5 standard deviations. An analytical expression was derived for the shape of the distribution of the dilepton invariant mass arising from the three-body leptonic decay of the neutralinos under the hypothesis of heavy scalars, which is appropriate for the focus-point scenario. The resulting function was used to fit the distribution of the dilepton invariant mass obtained with simulated LHC data, and to extract the value of two kinematic endpoints measuring the $\\tilde \\chi^0_2 - \\tilde \\chi^0_1$ and the $\\tilde \\chi^0_3 - \\tilde \\chi^0_1$ mass differences. This information was used to constrain the MSSM parameter space compatible with the data. ", "machine_text": "  We present a detailed study of the prospects for the detection and measurement of Supersymmetry (SUSY) in the focus point region of mSUGRA models with the ATLAS detector at the LHC. We evaluate the signature of the Higgs sector in this context and compare the theoretical predictions with the expected experimental signatures. We find that the main channel for the discovery of SUSY, namely the production of a pair of SUSY particles of opposite charge with a significant mass gap, has a cross section that is too small to be detected with the LHC, unless the mass of the produced SUSY particles is several TeV. However, there are several other production mechanisms that could lead to a discovery, mainly the production of a SUSY particle together with other particles with a significant contribution to the final state, such as  quarks, jets, or missing energy. We also evaluate the ability of the LHC to measure the parameters of the SUSY sector in this scenario, and find that it could provide valuable information on the SUSY particle masses and mixings, if a SUSY signal is found.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermodynamics of an Accretion Disk Annulus with Comparable Radiation   and Gas Pressure. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0305, "human_text": "  We explore the thermodynamic and global structural properties of a local patch of an accretion disk whose parameters were chosen so that radiation pressure and gas pressure would be comparable in magnitude. Heating, radiative transport, and cooling are computed self-consistently with the structure by solving the equations of radiation MHD in the shearing-box approximation. Using a fully 3-d and energy-conserving code, we compute the structure and energy balance of this disk segment over a span of more than forty cooling times. As is also true when gas pressure dominates, the disk's upper atmosphere is magnetically-supported. However, unlike the gas-dominated case, no steady-state is reached; instead, the total (i.e., radiation plus gas) energy content fluctuates by factors of 3--4 over timescales of several tens of orbits, with no secular trend. Because the radiation pressure varies much more than the gas pressure, the ratio of radiation pressure to gas pressure varies over the approximate range 0.5--2. The volume-integrated dissipation rate generally increases with increasing total energy, but the mean trend is somewhat slower than linear, and the instantaneous dissipation rate is often a factor of two larger or smaller than the mean for that total energy level. Locally, the dissipation rate per unit volume scales approximately in proportion to the current density; the time-average dissipation rate per unit mass is proportional to m^{-1/2}, where m is the horizontally-averaged mass column density to the nearer of the top or bottom surface. As in our earlier study of a gas-dominated shearing-box, we find that energy transport is completely dominated by radiative diffusion, with Poynting flux carrying less than 1% of the energy lost from the box. ", "machine_text": " We investigate the thermodynamics of an accretion disk annulus with comparable radiation and gas pressure. In particular, we consider the effect of temperature-dependent radiative cooling and gas viscosity on the temperature and density structure of the disk. We find that the temperature-dependent radiative cooling produces a temperature gradient in the disk, with the temperature increasing towards the inner edge of the annulus. The gas viscosity acts to balance this temperature gradient, producing a density structure with higher density towards the outer edge of the annulus. We also find that the gas viscosity has a non-monotonic dependence on the temperature, with the viscosity increasing initially with increasing temperature, and then decreasing towards the maximum. The increase in viscosity with temperature produces a strong gas pressure gradient in the annulus, with the gas pressure increasing towards the inner edge of the annulus. The combined effects of radiative cooling and gas viscosity produce a complex temperature and density structure in the disk, with temperature and density both increasing towards the inner edge of the annulus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Gaussianity analysis on local morphological measures of WMAP data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2346, "human_text": "  The decomposition of a signal on the sphere with the steerable wavelet constructed from the second Gaussian derivative gives access to the orientation, signed-intensity, and elongation of the signal's local features. In the present work, the non-Gaussianity of the WMAP temperature data of the cosmic microwave background (CMB) is analyzed in terms of the first four moments of the statistically isotropic random fields associated with these local morphological measures, at wavelet scales corresponding to angular sizes between 27.5 arcminutes and 30 degrees on the celestial sphere. While no detection is made neither in the orientation analysis nor in the elongation analysis, a strong detection is made in the excess kurtosis of the signed-intensity of the WMAP data. The non-Gaussianity is observed with a significance level below 0.5% at a wavelet scale corresponding to an angular size around 10 degrees, and confirmed at neighbour scales. This supports a previous detection of an excess of kurtosis in the wavelet coefficient of the WMAP data with the axisymmetric Mexican hat wavelet (Vielva et al. 2004). Instrumental noise and foreground emissions are not likely to be at the origin of the excess of kurtosis. Large-scale modulations of the CMB related to some unknown systematics are rejected as possible origins of the detection. The observed non-Gaussianity may therefore probably be imputed to the CMB itself, thereby questioning the basic inflationary scenario upon which the present concordance cosmological model relies. Taking the CMB temperature angular power spectrum of the concordance cosmological model at face value, further analysis also suggests that this non-Gaussianity is not confined to the directions on the celestial sphere with an anomalous signed-intensity. ", "machine_text": " We study the statistical properties of local morphological measures computed on the WMAP full-sky map. In particular, we consider the statistics of the \" hearth \" defined as the pixels that are surrounded by a high-explanatory-value region. We show that the distribution of the number of pixels in each \" hearth \" has heavy tails and is not Gaussian. This non-Gaussianity is due to the fact that the large scale structure in the Universe is not completely described by the power law, but has a lot of small-scale fluctuations. We show that this non-Gaussianity is in fact a general feature of the distribution of the number of pixels in a region with a given morphological measure. We find that this non-Gaussianity is in fact scale-free. We show that the same type of non-Gaussianity can be obtained by a simple model in which the large scale structure is described by a power law with a cut-off, while the small-scale fluctuations are generated by a Gaussian random field. We show that the distribution of the number of pixels in a region with a given morphological measure has a few remarkable features: (i) it has heavy tails, (ii) it is scale-free, and (iii) it can be well described by a simple model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the freezing of variables in random constraint satisfaction problems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2147, "human_text": "  The set of solutions of random constraint satisfaction problems (zero energy groundstates of mean-field diluted spin glasses) undergoes several structural phase transitions as the amount of constraints is increased. This set first breaks down into a large number of well separated clusters. At the freezing transition, which is in general distinct from the clustering one, some variables (spins) take the same value in all solutions of a given cluster. In this paper we study the critical behavior around the freezing transition, which appears in the unfrozen phase as the divergence of the sizes of the rearrangements induced in response to the modification of a variable. The formalism is developed on generic constraint satisfaction problems and applied in particular to the random satisfiability of boolean formulas and to the coloring of random graphs. The computation is first performed in random tree ensembles, for which we underline a connection with percolation models and with the reconstruction problem of information theory. The validity of these results for the original random ensembles is then discussed in the framework of the cavity method. ", "machine_text": "  We study random constraint satisfaction problems (RCSPs) in which some of the variables have their values frozen to constants. We focus on the case where the number of frozen variables is small compared to the number of free variables. We show that the probability of random satisfaction of an RCSP with a small number of frozen variables is relatively high. This is in contrast to the case where the number of frozen variables is large, in which case the probability of random satisfaction is low. Our results imply that the random satisfaction probability of an RCSP increases as the number of frozen variables decreases. We also show that the fraction of variable assignments that satisfy the constraints of the RCSP has a sharp threshold around the fraction of frozen variables, above which the fraction of satisfying assignments converges to one and below which it converges to zero as the number of trials increases. These results are obtained using a probabilistic method based on random annealing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scanning and Sequential Decision Making for Multi-Dimensional Data -   Part II: the Noisy Case. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2854, "human_text": "  We consider the problem of sequential decision making on random fields corrupted by noise. In this scenario, the decision maker observes a noisy version of the data, yet judged with respect to the clean data. In particular, we first consider the problem of sequentially scanning and filtering noisy random fields. In this case, the sequential filter is given the freedom to choose the path over which it traverses the random field (e.g., noisy image or video sequence), thus it is natural to ask what is the best achievable performance and how sensitive this performance is to the choice of the scan. We formally define the problem of scanning and filtering, derive a bound on the best achievable performance and quantify the excess loss occurring when non-optimal scanners are used, compared to optimal scanning and filtering.   We then discuss the problem of sequential scanning and prediction of noisy random fields. This setting is a natural model for applications such as restoration and coding of noisy images. We formally define the problem of scanning and prediction of a noisy multidimensional array and relate the optimal performance to the clean scandictability defined by Merhav and Weissman. Moreover, bounds on the excess loss due to sub-optimal scans are derived, and a universal prediction algorithm is suggested.   This paper is the second part of a two-part paper. The first paper dealt with sequential decision making on noiseless data arrays, namely, when the decision maker is judged with respect to the same data array it observes. ", "machine_text": "  We consider the problem of sequentially making decisions when the underlying data is multi-dimensional and noisy. In Part I of this work, we focused on the noiseless case, and considered the fundamental trade-off between the number of scans and the amount of information gained at each scan. We showed that the rate of information gain is asymptotically proportional to the amount of data, if the scans are independent and the data is uniformly distributed. In this Part II, we consider the noisy case. We assume that the data is generated by independently flipping coins, and that each coin has some probability p of landing heads, and 1-p of landing tails. We assume that each coin flip is independent of the others, and that the probability p is the same for each flip. We show that the rate of information gain is still asymptotically proportional to the amount of data, if the noise is small enough. We also consider a more realistic model where the probability p varies randomly. In this case, the rate of information gain is shown to be upper bounded by a constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Capillary ordering and layering transitions in two-dimensional hard-rod   fluids. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1467, "human_text": "  In this article we calculate the surface phase diagram of a two-dimensional hard-rod fluid confined between two hard lines. In a first stage we study the semi-infinite system consisting of an isotropic fluid in contact with a single hard line. We have found complete wetting by the columnar phase at the wall-isotropic fluid interface. When the fluid is confined between two hard walls, capillary columnar ordering occurs via a first-order phase transition. For higher chemical potentials the system exhibits layering transitions even for very narrow slits (near the one-dimensional limit). The theoretical model used was a density-functional theory based on the Fundamental-Measure Functional applied to a fluid of hard rectangles in the restricted-orientation approximation (Zwanzig model). The results presented here can be checked experimentally in two-dimensional granular media made of rods, where vertical motions induced by an external source and excluded volume interactions between the grains allow the system to explore those stationary states which entropically maximize packing configurations. We claim that some of the surface phenomena found here can be present in two-dimensional granular-media fluids. ", "machine_text": " We study the structure and dynamics of two-dimensional (2D) hard-rod fluids under the influence of an external field, using Monte Carlo simulations. We find that the order parameter has a continuous dependence on the field, in spite of the fact that the hard-rods can only form defects, not perfect crystals. The critical field depends on the thermal energy and the interaction strength between the hard-rods, but it does not depend on the initial configuration. For a range of temperatures, the order parameter increases continuously with the field, until it reaches a maximum, and then decreases again. We also find a transition to a different type of ordered structure, in which the hard-rods form a layered structure, with a clear first-order transition line. For this new structure, the order parameter has a non-monotonic dependence on the field. We also study the influence of a local field, which can be thought of as a defects or impurities in the fluid. We find that such a field can have a significant effect on the order parameter, even if it is small, and can lead to a complete breakdown of the order. Our results suggest a general mechanism for the destruction of order in fluids, which is based on the competition between different types of defects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Influence of the lattice topography on a three-dimensional, controllable   Brownian motor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4041, "human_text": "  We study the influence of the lattice topography and the coupling between motion in different directions, for a three-dimensional Brownian motor based on cold atoms in a double optical lattice. Due to controllable relative spatial phases between the lattices, our Brownian motor can induce drifts in arbitrary directions. Since the lattices couple the different directions, the relation between the phase shifts and the directionality of the induced drift is non trivial. Here is therefore this relation investigated experimentally by systematically varying the relative spatial phase in two dimensions, while monitoring the vertically induced drift and the temperature. A relative spatial phase range of 2pi x 2pi is covered. We show that a drift, controllable both in speed and direction, can be achieved, by varying the phase both parallel and perpendicular to the direction of the measured induced drift. The experimental results are qualitatively reproduced by numerical simulations of a simplified, classical model of the system. ", "machine_text": " We study a three-dimensional, controllable Brownian motor attached to a lattice with a high-index topographical defect. We show analytically and numerically that the Brownian motor's dynamic responds to the underlying lattice defect in a strong and nonlinear manner. In particular, the statistical displacement of the motor increases in the presence of the defect, and it exhibits directed transport along the defect's longitudinal direction. We explain these phenomena by a detailed analysis of the spatial and temporal correlations of the motor's dynamic, which reveals the existence of an effective random walk dynamics in the presence of the defect. We also analyze the dependence of the transport efficiency on the system parameters, such as the strength of the anchoring interaction and the size of the motor particles. Our results suggest that high-index topographical defects can have a significant influence on the dynamic of Brownian motors, and they may be used to control the transport efficiency and direction in Brownian transport systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 658 GHz Vibrationally-Excited Water Masers with the Submillimeter Array. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2655, "human_text": "  Discovered in 1995 at the Caltech Submillimeter Observatory (CSO), the vibrationally-excited water maser line at 658 GHz (455 micron) is seen in oxygen-rich giant and supergiant stars. Because this maser can be so strong (up to thousands of Janskys), it was very helpful during the commissioning phase of the highest frequency band (620-700 GHz) of the Submillimeter Array (SMA) interferometer. From late 2002 to early 2006, brief attempts were made to search for emission from additional sources beyond the original CSO survey. These efforts have expanded the source count from 10 to 16. The maser emission appears to be quite compact spatially, as expected from theoretical considerations; thus these objects can potentially be used as atmospheric phase calibrators. Many of these objects also exhibit maser emission in the vibrationally-excited SiO maser at 215 GHz. Because both maser lines likely originate from a similar physical region, these objects can be used to test techniques of phase transfer calibration between millimeter and submillimeter bands. The 658 GHz masers will be important beacons to assess the performance of the Atacama Large Millimeter Array (ALMA) in this challenging high-frequency band. ", "machine_text": "  We present a study of the 658 GHz water vapor masers in the Arp 220 jet with the Submillimeter Array (SMA). We have observed eight sources in the 12 \u00b4 12 \u00b4 12 degree 3 sky field, four of which are new discoveries. The most compact and brightest source, SSA 22, has a maser knot almost at the peak of the cold dark matter profile, which suggests that the gas density is extremely high. The other sources are distributed along the jet, with their masers located on the side of the dark matter peak, in a region of lower gas density. The high brightness of the SSA 22 maser, and the fact that it is so close to the center of the object, suggests that the maser pumping region is small, perhaps only a few tens of pc. We discuss this in the framework of a simple model in which the maser pumping region is at the center of a jet with a view angle a. We find that for a range of plausible values of a, the population in the maser pumping region is small, and thus the maser power is high. For very small values of a the population can be large and the maser power is low. We discuss the implications of this model for the understanding of the maser pumping mechanism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Suppressed radio emission in supercluster galaxies: enhanced ram   pressure in merging clusters?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3431, "human_text": "  The environmental influence on the 1.4 GHz continuum radio emission of galaxies is analyzed in a 600 deg2 region of the local Universe containing the Shapley Supercluster (SSC). Galaxies in the FLASH and 6dFGS redshift surveys are cross-identified with NVSS radio sources, selected in a subsample doubly complete in volume and luminosity. Environmental effects are studied through a smoothed density field (normalized with random catalogs with the same survey edges and redshift selection function) and the distance to the nearest cluster (R/r200, where r200 is the virial radius, whose relation to the aperture velocity dispersion is quantified). The fraction of high radio loudness (R_K=L_radio/L_K) galaxies in the 10 Mpc Abell 3558 cluster complex at the core of the SSC (SSC-CR) is half as large than elsewhere. In the SSC-CR, R_K is anti-correlated with the density of the large-scale environment and correlated with R/r200: central brightest cluster galaxies (BCGs) in the SSC-CR are 10x less radio-loud than BCGs elsewhere, with signs of suppressed radio loudness in the SSC-CR also present beyond the BCGs, out to at least 0.3 r200. This correlation is nearly as strong as the tight correlation of L_K with R/r200 (K-luminosity segregation), inside the SSC-CR. The suppression of radio loudness in SSC-CR BCGs can be attributed to cluster-cluster mergers that destroy the cool core and thus the supply of gas to the central AGN. We analytically demonstrate that the low radio loudness of non-BCG galaxies within SSC-CR clusters cannot be explained by direct major galaxy mergers or rapid galaxy flyby collisions, but by the loss of gas supply through the enhanced ram pressure felt when these galaxies cross the shock front between the 2 merging clusters and are later subjected to the stronger wind from the 2nd cluster. ", "machine_text": " We present radio continuum observations of galaxies in nine superclusters in the Southern Hemisphere. The radio galaxies show a large range of radio power, but no correlation with optical or IR properties. We find that the radio source galaxies in superclusters have on average higher radio power than galaxies in control samples of clusters and voids, but the difference is only significant at >1 kpc. We show this to be consistent with the superclusters containing more powerful radio galaxies, even at high redshift, and that this is likely due to the galaxies being in mergers. We conclude that the main process in generating radio galaxies in superclusters is the same as in clusters, except that in the case of superclusters the dominant effect is at larger scales and over larger volumes, and hence is less efficient in converting cluster kinetic energy into radio power. We discuss this in terms of the mean free path of the plasma, which is much shorter in clusters than in superclusters. We also find that the host galaxies of the most powerful radio galaxies in the superclusters are themselves optically and IR-quiet, and thus are likely to be dominated by merging phenomena.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What Gamma-Ray Bursts Explode Into. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0461, "human_text": "  The association of long gamma-ray bursts (GRBs) with Type Ib/c supernovae implies that they explode into the winds of their Wolf-Rayet progenitor stars. Although the evolution of some GRB afterglows is consistent with expansion into a free wind, there is also good evidence for expansion into a constant density medium. The evidence includes the evolution of X-ray afterglows (when X-rays are below the cooling frequency), the evolution of the pre-jet break optical and X-ray afterglow, and the sharp turn-on observed for some afterglows. Recent observations of short bursts, which are expected to be interacting with a constant density medium, provide a check on the standard afterglow model. Although radio observations do not support the constant density model for long bursts in some cases, the evidence for constant density interaction is strong. The most plausible way to produce such a medium around a massive star is to shock the progenitor wind. This requires a smaller termination shock than would be expected, possibly due to a high pressure surroundings, a high progenitor velocity, or the particular evolution leading to a GRB. However, the need for the termination shock near the deceleration radius cannot be plausibly accomodated and may indicate that some long bursts have compact binary progenitors and explode directly into the interstellar medium. ", "machine_text": " We present here results of a statistical study of the environments of long-duration gamma-ray bursts (GRBs) based on a sample of 60 bursts with well-observed afterglows. We have derived the spectral energy distribution of the afterglows, and have analyzed the spectral, spatial, and temporal characteristics of the bursts and their afterglows. We have also estimated the host galaxy magnitudes and distances, and have derived the redshift distribution for our sample. We find that GRBs are a powerful probe of the ISM in galaxies, and can detect gas at high optical depths, far beyond the reach of optical/NIR observations. Our results suggest that the ISM in galaxies is not homogeneously distributed, but has dense pockets, which are potentially responsible for the energy budgets of individual bursts. We find a significant correlation between the burst duration and the peak fluence, and we discuss this in the framework of the radiative and kinetic energy budgets of GRBs. Our results suggest that the energy budgets of GRBs are potentially very different, depending on the details of the ISM structure in the burst's host galaxy. We also analyze the evolution of the afterglow color as a function of time, and find that the time evolution of the color can be described by a simple model, in which the color is directly proportional to the fluence. We discuss this model in the framework of the different physical processes which may be responsible for the afterglow emission.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Very High Energy $\\gamma$-ray and Near Infrared observations of   1ES2344+514 during 2004-05. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3533, "human_text": "  We have observed the BL Lac object 1ES2344+514 (z = 0.044) in Very High Energy (VHE) gamma-ray and near-infrared wavelength bands with TACTIC and MIRO telescopes respectively. The observations were made from 18th October to 9th December 2004 and 27th October 2005 to 1st January 2006. Detailed analysis of the TACTIC data indicates absence of a statistically significant gamma-ray signal both in overall data and on a nightly basis from the source direction. We estimate an upper limit of I($\\geq$1.5 TeV)$\\leq 3.84 \\times 10^{-12}$ photons cm$^{-2}$ s$^{-1}$ at a 3$\\sigma$ confidence level on the integrated $\\gamma$-ray flux. In addition, we have also compared TACTIC TeV light curves with those of the RXTE ASM (2-12keV) for the contemporary period and find that there are no statistically significant increases in the signal strengths from the source in both these energy regions. During 2004 IR observations, 1ES2344+514 shows low level (~0.06 magnitude) day-to-day variation in both, J & H bands. However, during 2005 observation epoch, the source brightens up by about 0.41 magnitude from its October 2005 level J magnitude= 12.64 to J = 12.23 on December 6, 2005. It then fades by about 0.2 magnitude during 6 to 10 December, 2005. The variation is seen in both, J & H, bands simultaneously. The light travel time arguments suggest that the emission region size is of the order of $10^{17}$ cms. ", "machine_text": "  We present Very High Energy $\\gamma$-ray and Near Infrared observations of the flaring Active Galactic Nucleus 1ES2344+514 made in 2004-05. These data sets were obtained with the Very High Energy Radiation Imaging Telescope (VHET) and the InfraRed Optical Telescope Array (IOTA), two of the instruments on board the Rossi-RXTE space mission. We find that the accretion process is dominated by a smoothly varying (but highly non-linear) flux density evolution in both the $\\gamma$-ray and Near Infrared bands. The observed $\\gamma$-ray and Near Infrared brightnesses are consistent with a smoothly varying layer of accretion material surrounding the central engine. The simple model of a flared inner boundary and a smoothly varying accretion layer provides a good description of the observed data. The $\\gamma$-ray and Near Infrared data are consistent with a torus-like accretion structure with a flared inner boundary, a radial gap and a smoothly varying outer boundary. The observed distribution of $\\gamma$-ray emission is consistent with a uniform intensity distribution within the torus-like accretion structure, except for a bright spot at the inner boundary. The torus is surrounded by a probable emission-free boundary layer, which is itself surrounded by a scattering layer. The observed Near Infrared brightness distribution is consistent with a smoothly varying layer with a triangular or trapezoidal cross section. The torus-like structure and the emission free zone are consistent with being both geometrically and optically thick. We discuss the relation between the flaring history and the structure of the accretion torus.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Trans-Planckian Issue in the Milne Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.098, "human_text": "  The ``trans-Planckian'' challenge in cosmology appears when we trace the present physical wavelengths of fluctuations backwards in time. They become smaller and smaller until crossing the Planck scale where conventional QFT is challenged, so that unknown ultraviolet physics may be traced in the observable cosmological fluctuations. Usually this issue is addressed in the inflationary context, but trans-Planckian reasoning is much broader. We examine this logic in a simple example of scalar quantum field theory in the expanding and contracting Milne universes, where wavelengths of the eigenmodes are red- or blue-shifted. Trans-Planckian modifications of QFT should result in a UV-dependent VeV of the energy momentum tensor of a scalar field in the Milne universe. On the other hand, the Milne universe is another coordinate systems of flat Minkowski space-time, and the covariant energy momentum tensor should be the same (but vacuum-dependent) in different coordinates of flat space time. We explicitly demonstrate that in conventional QFT the energy momentum tensor, choosing the adiabatic vacuum, is identical to zero in Minkowski coordinates, and remains zero in the contracting Milne universe (due to non-trivial cancellations of contributions from particles which appear in the accelerating frame and from vacuum polarization there). In contrast to this, the trans-Planckian modification of the energy momentum tensor is not motivated. We provide a similar argument for the expanding Milne universe, where the energy momentum tensor in the conformal vacuum is non-zero. Similar arguments are applicable for other cosmological models where the curvature is much lower than Planckian which leads to conflicts with trans-Planckian considerations. ", "machine_text": " We show that the trans-Planckian issue can be rescued if the Milne universe is replaced by a Taub-NUT-WBW universe with a suitable cosmological constant. In this model the Milne universe is recovered as a special case, which corresponds to the case of a zero cosmological constant. Our main tool is the possibility to deform the Taub-NUT-WBW model in a way that it remains covariant under a transformation to a new time variable, which we call fundamental time. This deformation allows us to choose the normal time variable to be realized in the future as a local time variable, that is, as a time variable that is observer dependent. We find that only for a vanishing cosmological constant this can be chosen to be the fundamental time. This is in contrast to the case with a positive cosmological constant, where we have two possible choices for a local time variable. For the case with a negative cosmological constant our results show that no choice of a local time variable can be made, which implies that in this case the theory is in principle non-relativistic.  We would like to thank Mario Scottsdale for helpful discussions. We also thank an anonymous referee for useful comments. M.H. thanks C.GRESSANO for useful discussions on the trans-Planckian issue. This research was supported in part by MCI project CONICYT AF209017.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: X-ray and Sunyaev-Zel'dovich scaling relations in galaxy clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2678, "human_text": "  [Abridged] We present an analysis of the scaling relations between X-ray properties and Sunyaev-Zel'dovich (SZ) parameters for a sample of 24 X-ray luminous galaxy clusters observed with Chandra and with measured SZ effect. These objects are in the redshift range 0.14--0.82 and have X-ray bolometric luminosity L>10^45 erg/s. We perform a spatially resolved spectral analysis and recover the density, temperature and pressure profiles of the ICM, just relying on the spherical symmetry of the cluster and the hydrostatic equilibrium hypothesis. We observe that the correlations among X-ray quantities only are in agreement with previous results obtained for samples of high-z X-ray luminous galaxy clusters. On the relations involving SZ quantities, we obtain that they correlate with the gas temperature with a logarithmic slope significantly larger than the predicted value from the self-similar model. The measured scatter indicates, however, that the central Compton parameter y_0 is a proxy of the gas temperature at the same level of other X-ray quantities like luminosity. Our results on the X-ray and SZ scaling relations show a tension between the quantities more related to the global energy of the system (e.g. gas temperature, gravitating mass) and the indicators of the structure of the ICM (e.g. gas density profile, central Compton parameter y_0), showing the most significant deviations from the values of the slope predicted from the self-similar model in the L-T, L-M_{tot}, M_{gas}-T, y_0-T relations. When the slope is fixed to the self-similar value, these relations consistently show a negative evolution suggesting a scenario in which the ICM at higher redshift has lower both X-ray luminosity and pressure in the central regions than the expectations from self-similar model. ", "machine_text": "  We present scaling relations between X-ray and Sunyaev-Zel'dovich (SZ) signals in galaxy clusters, based on a sample of clusters with known redshift, clustercentric distance, gas mass, and SZ flux. We show that the X-ray gas temperature and the SZ scale length are correlated, with the temperature scaling as the square of the scale length. The X-ray gas density and the SZ flux are also correlated, with the density scaling as the inverse square of the flux. We explain these scaling relations by a simple model in which the X-ray gas and the SZ gas are identical, with the X-ray gas at a higher temperature and lower density than the SZ gas. We show that the SZ scale length depends only on the total gas mass and the redshift, and is independent of the gas temperature and density. We use our scaling relations to predict the SZ scale length of a cluster with a given gas mass, and show that this prediction is in good agreement with the observed SZ scale length. We also show that the gas temperature and density are predicted by our scaling relations to have a wide range of values, depending on the cluster's properties.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sub-arcsecond CO(1-0) and CO(2-1) observations of the ultraluminous   infrared galaxy IRAS 10190+1322. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3583, "human_text": "  We present the results of high resolution mapping of the CO(1-0) and CO(2-1) emission of the ultraluminous infrared galaxy (ULIRG) IRAS 10190+1322, with the IRAM interferometer, down to an angular resolution of ~0.3 arcsec. This object is composed of two interacting galaxies with a projected nuclear separation of 6 kpc, and was selected to analyze the physical and dynamical properties of the molecular gas in each galaxy in order to study the conditions that lead a galaxy pair to become ultraluminous in the infrared. With the exception of Arp 220, the closest ULIRG, this is the first time that the CO emission is morphologically and kinematically resolved in the two interacting galaxies of a ULIRG system. In one of the galaxies the molecular gas is highly concentrated, distributed in a circumnuclear disk of 1.7 kpc in size. The molecular gas in the presumably less infrared luminous galaxy is distributed in a more extended disk of 7.4 kpc. The molecular gas mass accounts for ~10% of the dynamical mass in each galaxy. Both objects are rich enough in molecular gas, Mgas ~ 4 10^9 Msun, as to experience an infrared ultraluminous phase. ", "machine_text": "  We present sub-arcsecond CO(1-0) and CO(2-1) observations of the ultraluminous infrared galaxy IRAS 10190+1322. These data are the most sensitive and spatially-resolved measure of the gas distribution in the galaxy. The data show a clumpy distribution of gas with a total mass of 1.4 kpc^2. The data can be described by a model in which the gas is evenly distributed within the galaxy but has clumped into four distinct regions, two of which are associated with the strong radio sources at the ends of the galaxy and the other two of which are associated with fainter radio sources in the central region of the galaxy. We discuss several models to explain the origin of the gas clumps. We find that a model in which the clumps are collimated along magnetic field lines is as effective at fitting the data as a model in which the gas is distributed isotropically and the clumps are the result of radiative cooling, and that a model in which the gas is distributed along the longest dimension of the galaxy and the clumps are formed by gravitational instability is also consistent with the data. We discuss the implications of our findings for models of ultraluminous infrared galaxy formation and for the kinematics of gas in the galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Precision measurements of large scale structure with future type Ia   supernova surveys. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0979, "human_text": "  Type Ia supernovae are currently the best known standard candles at cosmological distances. In addition to providing a powerful probe of dark energy they are an ideal source of information about the peculiar velocity field of the local universe. Even with the very small number of supernovae presently available it has been possible to measure the dipole and quadrupole of the local velocity field out to z~0.025. With future continuous all-sky surveys like the LSST project the luminosity distances of tens of thousands of nearby supernovae will be measured accurately. This will allow for a determination of the local velocity structure of the universe as a function of redshift with unprecedented accuracy, provided the redshifts of the host galaxies are known. Using catalogues of mock surveys we estimate that future low redshift supernova surveys will be able to probe sigma-8 to a precision of roughly 5% at 95% C.L. This is comparable to the precision in future galaxy and weak lensing surveys and with a relatively modest observational effort it will provide a crucial cross-check on future measurements of the matter power spectrum. ", "machine_text": "  We present a detailed analysis of the potential of future Type Ia supernova (SN) surveys to constrain cosmological parameters with high precision, using the observed large-scale structure (LSS). We consider the case of a standard Type Ia SN survey which is not designed to extract any information from the LSS, and show that it can in fact be used to constrain the matter density with $\\Delta\\Omega_{\\rm m} / \\Omega_{\\rm m} \\sim  1.5\\%$, using $\\sim 100$ SNe. We show that a large improvement can be obtained by adding a LSS analysis to a Type Ia SN survey, and that this would allow to constrain the matter density to $\\Delta\\Omega_{\\rm m} / \\Omega_{\\rm m} \\sim 0.1\\%$. We also quantify the optimal use of a SN sample to constrain the LSS parameters $\\delta\\Omega_{\\rm m}$ and $\\delta\\sigma_8$, and show that the optimal analysis is very sensitive to the choice of the sample selection criteria. A simple criterion to select the SNe is to require that they must lie within a given redshift range, and to require that they must be within a given distance from the nearest galaxy. We show that such a simple criterion can already constrain $\\delta\\Omega_{\\rm m}$ to $\\Delta\\Omega_{\\rm m} / \\Omega_{\\rm m} \\sim 2.8\\%$, and that this can be improved to $\\Delta\\Omega_{\\rm m} / \\Omega_{\\rm m} \\sim 1.3\\%$ if SNe are additionally required to be of high photometric precision. We also show that the optimal selection of the SNe can be used to constrain $\\delta\\sigma_8$ to $\\Delta\\sigma_8 / \\sigma_8 \\sim 4.6\\%$, and that this can be improved to $\\Delta\\sigma_8 / \\sigma_8 \\sim 2.4\\%$ by additionally requiring the SNe to be of high photometric precision. We finally discuss the prospects of a dedicated LSS survey, which could potentially provide a much stronger constraint on $\\delta\\sigma_8$ than any Type Ia SN survey, by reaching $\\Delta\\sigma_8 / \\sigma_8 \\sim 1.5\\%$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetization oscillations induced by a spin-polarized current in a   point-contact geometry: mode hopping and non-linear damping effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1515, "human_text": "  In this paper we study magnetization excitations induced in a thin extended film by a spin-polarized dc-current injected through a point contact in the current-perpendicular-to-plane (CPP) geometry. Using full-scale micromagnetic simulations, we demonstrate that in addition to the oscillations of the propagating wave type, there exist also two localized oscillation modes. The first localized mode has a relatively homogeneous magnetization structure of its kernel and corresponds to the so called 'bullet' predicted analytically by Slavin and Tiberkevich (Phys. Rev. Lett., 95 (2005) 237201). Magnetization pattern of the second localized mode kernel is highly inhomogeneous, leading to a much smaller power of magnetoresistance oscillations caused by this mode. We have also studied the influence of a non-linear damping for this system and have found the following main qualitative effects: (i) the appearance of frequency jumps within the existence region of the propagating wave mode and (ii) the narrowing of the current region where the 'bullet' mode exists, until this mode completely disappears for a sufficiently strong non-linear damping. ", "machine_text": " We study the dynamics of magnetization induced by a spin-polarized current in a point-contact geometry. We find a rich variety of oscillatory modes, which can be divided into two classes. The first class contains modes with frequencies  \u2248  0  Hz, which correspond to the conventional damped oscillations of the magnetization. These modes can be obtained in a linear approximation, and their damping is described by the standard expressions for Ohmic and magnetic damping. The second class contains modes with frequencies  \u2260  0  Hz, which are conventionally absent in this geometry. These modes are caused by a non-linear damping mechanism, and their amplitudes are governed by the transient spin-torque effect. Our model also describes the mode-hopping effect, where the oscillations can be driven from one mode to another by a small perturbation. We analyze our results by considering the generic case of a thin ferromagnetic layer in a point-contact geometry, and also by considering the specific case of a magnetic tunnel junction. Our results are relevant for understanding the dynamics of magnetization in nanoscale magnetic elements, and also for the development of spin-torque oscillators and sensors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Symmetries in Differential Geometry: A Computational Approach to   Prolongations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0764, "human_text": "  The aim of this work is to develop a systematic manner to close overdetermined systems arising from conformal Killing tensors (CKT). The research performs this action for 1-tensor and 2-tensors. This research makes it possible to develop a new general method for any rank of CKT. This method can also be applied to other types of Killing equations, as well as to overdetermined systems constrained by some other conditions.   The major methodological apparatus of the research is a decomposition of the section bundles where the covariant derivatives of the CKT land via generalized gradients. This decomposition generates a tree in which each row represents a higher derivative. After using the conformal Killing equation, just a few components (branches) survive, which means that most of them can be expressed in terms of lower order terms. This results in a finite number of independent jets. Thus, any higher covariant derivative can be written in terms of these jets.   The findings of this work are significant methodologically and, more specifically, in the potential for the discovery of symmetries. First, this work has uncovered a new method that could be used to close overdetermined systems arising from conformal Killing tensors (CKT). Second, through an application of this method, this research finds higher symmetry operators of first and second degree, which are known by other means, for the Laplace operator. The findings also reveal the first order symmetry operators for the Yamabe case. Moreover, the research leads to conjectures about the second order symmetries of the Yamabe operator. ", "machine_text": "  Symmetries in Differential Geometry: A Computational Approach to Prolongations  We consider the problem of computing a geometrically faithful representation of a symmetry of a Riemannian manifold, for a general class of such symmetries, and in a way that is suitable for automated manipulation. This is a difficult problem, with many challenges that have been explored in the literature on several fronts. We review the main ideas that have been proposed to address this problem, and then we propose a simple algorithm that seems to capture all the key ingredients that have been identified so far. Our algorithm is based on a generalization of the notion of a prolongation of a curve in a Riemannian manifold. We show that our algorithm is capable of computing a geometrically faithful representation of a large class of symmetries, including the case of anisotropic metrics and of anisotropic connections, and the case of metrics with boundary conditions. The algorithm is illustrated on several examples, and some of the examples are used to highlight some simple but non-obvious geometric aspects of geometric symmetries.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantile and Probability Curves Without Crossing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3649, "human_text": "  This paper proposes a method to address the longstanding problem of lack of monotonicity in estimation of conditional and structural quantile functions, also known as the quantile crossing problem. The method consists in sorting or monotone rearranging the original estimated non-monotone curve into a monotone rearranged curve. We show that the rearranged curve is closer to the true quantile curve in finite samples than the original curve, establish a functional delta method for rearrangement-related operators, and derive functional limit theory for the entire rearranged curve and its functionals. We also establish validity of the bootstrap for estimating the limit law of the the entire rearranged curve and its functionals. Our limit results are generic in that they apply to every estimator of a monotone econometric function, provided that the estimator satisfies a functional central limit theorem and the function satisfies some smoothness conditions. Consequently, our results apply to estimation of other econometric functions with monotonicity restrictions, such as demand, production, distribution, and structural distribution functions. We illustrate the results with an application to estimation of structural quantile functions using data on Vietnam veteran status and earnings. ", "machine_text": "  We consider the problem of generating probability and quantile curves for a random variable with a discontinuous cumulative distribution, under the assumption that the underlying probability density function is constant on each interval on which the cumulative distribution is constant. The standard approach to the problem, which consists in drawing the quantile curves by accumulation of area under the probability curves, may not be applicable in this case, as the probability curves may not cross each other. We propose a method for generating the quantile and probability curves without requiring that they cross each other. The method consists in finding the minimum and maximum of the conditional expectation of the random variable, conditioned to the event that the random variable has a value larger than a given threshold. The conditional expectation can be computed analytically, and the problem then reduces to finding the minimum and maximum of two functions of one variable. We illustrate our method by generating the quantile and probability curves for the random variable with a geometric distribution, whose cumulative distribution is piecewise constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Close Pairs as Proxies for Galaxy Cluster Mergers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0518, "human_text": "  Galaxy cluster merger statistics are an important component in understanding the formation of large-scale structure. Unfortunately, it is difficult to study merger properties and evolution directly because the identification of cluster mergers in observations is problematic. We use large N-body simulations to study the statistical properties of massive halo mergers, specifically investigating the utility of close halo pairs as proxies for mergers. We examine the relationship between pairs and mergers for a wide range of merger timescales, halo masses, and redshifts (0<z<1). We also quantify the utility of pairs in measuring merger bias. While pairs at very small separations will reliably merge, these constitute a small fraction of the total merger population. Thus, pairs do not provide a reliable direct proxy to the total merger population. We do find an intriguing universality in the relation between close pairs and mergers, which in principle could allow for an estimate of the statistical merger rate from the pair fraction within a scaled separation, but including the effects of redshift space distortions strongly degrades this relation. We find similar behavior for galaxy-mass halos, making our results applicable to field galaxy mergers at high redshift. We investigate how the halo merger rate can be statistically described by the halo mass function via the merger kernel (coagulation), finding an interesting environmental dependence of merging: halos within the mass resolution of our simulations merge less efficiently in overdense environments. Specifically, halo pairs with separations less than a few Mpc/h are more likely to merge in underdense environments; at larger separations, pairs are more likely to merge in overdense environments. ", "machine_text": "  We present a method to detect close pairs in galaxy clusters using an adaptation of the separate galaxy-galaxy correlation function (GGCF) technique. We show that the number of close pairs in a cluster is related to the cluster's dynamical state, in particular to the rate of infalling matter and the presence of mergers. We use the estimated close pair number as a proxy for these dynamical phenomena. We find that the estimated close pair number is correlated with the observed radial distribution of galaxies in clusters, the intergalactic medium, and the large-scale structure of the Universe, and we demonstrate that the close pair fraction is predictive of the strength of the cluster's central galaxy. Our results suggest that the number of close pairs is largely driven by the infall of matter and the occurrence of mergers, rather than by the particular choice of the pairs' definition. We find that approximately 1-2% of clusters contain a close pair, and that the percentage is independent of the cluster's richness. We discuss the application of our method to the analysis of clusters in the Universe, and we present a new algorithm to detect close pairs in N-body simulations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Reliability on the Direction of the Incident Neutrino for the Fully   Contained Events and Partially Contained Events due to QEL in the   Super-Kamiokande. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.019, "human_text": "  In the SK analysis of the neutrino events for [Fully Contained Events] and [Partially Contained Events] on their zenith angle distribution, it is assumed that the zenith angle of the incident neutrino is the same as that of the detected charged lepton. In the present paper, we examine the validity of [the SK assumption on the direction] of the incident neutrinos. Concretely speaking, we analyze muon-like events due to QEL. For the purpose, we develop [Time Sequential Monte Carlo Simulation] to extract the conclusion on the validity of the SK assumption. In our [Time Sequential Simulation], we simulate every physical process concerned as exactly as possible without any approximation.   From the comparison between the zenith angle distributon of the emitted muons under [the SK assumption on the direction] and the corresponding one obtained under our [Time Sequential Simulation], it is concluded that the measurement of the direction of the incident neutrino for the neutrino events occurring inside the detector in the SK analysis turns out to be unreliable, which holds irrespective of the existence and/or non-existence of the neutrino oscillation. ", "machine_text": " We investigated the reliability on the direction of the incident neutrino for the fully contained events and partially contained events due to QEL in the Super-Kamiokande. We found that the reliability of the direction is higher for the fully contained events. This is because the fully contained events have the large signal inside the detector and can be reconstructed accurately. On the other hand, the partially contained events have the small signal and the direction is not reconstructed accurately. We also found that the fully contained events have the higher reliability on the direction than the partially contained events. We tried to find the origin of the QEL and found that the signals from the top and the bottom of the detector are large and have the high reliability. On the other hand, the signals from the side of the detector are small and have the low reliability. This is because the QEL from the side of the detector is not fully contained and the direction is not reconstructed accurately.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Plasma effects in a micromachined floating-gate high-electron-mobility   transistor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2082, "human_text": "  We study plasma effects in a micromachined high-electron mobility transistor (HEMT) with the microcantilever serving as the gate using the developed a model. The model accounts for mechanical motion of the microcantilever and spatio-temporal variations (plasma effects) of the two-dimensional electron gas(2DEG) system in the transistor channel. The microcantilever mechanical motion is described in the point-mass approximation. The hydrodynamic electron transport model is used to describe distributed electron plasma phenomena in the 2DEG system. Using the developed model, we calculated the response function characterizing the amplitude microcantilever oscillations and the output electric signal as functions of the signal frequency and the bias voltage for the devices with different parameters. We find the voltage dependences of the frequency of the mechanical resonance and its damping. In particular, it is demonstrated that the amplitudes of the mechanical oscillations and output electric signal exhibit pronounced maxima at the bias voltages close to the voltage of the 2DEG channel depletion followed by a steep drop with further increase in the bias voltage. ", "machine_text": " The paper presents the study of the influence of a low-frequency plasma on a micromachined floating-gate high-electron-mobility transistor. The study is performed by means of both experimental measurements and computer simulations. The experiments are based on the comparison of two identical transistors, one of which is exposed to a plasma and the other is not. The computer simulations are based on the 3-D finite element method, and they are used to determine the spatial distribution of the electric field in the transistor. The results show that the plasma has a significant influence on the electrical characteristics of the transistor. In particular, it is found that the plasma increases the electric field in the drift region, which results in an increase of the output current. This effect is more pronounced for a transistor with a larger gate-to-drain distance. The increase of the output current is explained by the increase of the surface mobility due to the lowering of the effective electron mass. The practical importance of the results is discussed in terms of the possibility of using a micromachined floating-gate high-electron-mobility transistor as a sensitive detector of electromagnetic radiation in the millimeter wavelength range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strings as sigma models and in the tensionless limit. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2346, "human_text": "  This thesis considers two different aspects of string theory, the tensionless limit of the string and supersymmetric sigma models. The tensionless limit is used to find a IIB supergravity background generated by a tensionless string. Quantization of the tensionless string in a pp-wave background is performed and the tensionless limit is found to commute with quantization. Further, the sigma model with N=(2,2) extended world-sheet supersymmetry is considered and the requirement on the target space to have a bi-Hermitean geometry is reviewed. It is shown that the equivalence between bi-Hermitean geometry and generalized Kahler follows, in this context, from the equivalence between the Lagrangian- and Hamiltonian formulation of the model. Moreover, the explicit T-duality transformation in the Hamiltonian formulation of the sigma model is constructed and shown to be a symplectomorphism. Under certain assumptions, the amount of extended supersymmetry present in the sigma model is shown to be preserved under T-duality. Further, by requiring N=(2,2) extended supersymmetry in a first order formulation of the sigma model an intriguing geometrical structure arises and in a special case generalized complex geometry is found to be contained in the new framework. ", "machine_text": "  We consider the theories of strings and membranes in the tensionless limit. For the string we show that the bulk dynamics is described by a sigma model with a non-relativistic Higgs sector, and the membrane by a duality with a string theory in the tensionless limit. The motivation for this work is the following observation: for a string in the tensionless limit the massless bosons are necessarily associated with a symmetry group, and their number is restricted by the Poincar\u00e9 polynomial. We show that this observation can be understood by considering the string as a sigma model with a non-relativistic Higgs sector. The bulk dynamics is related to the pure Yang-Mills theory with a non-relativistic Higgs sector, which in the limit of vanishing tension becomes equivalent to the Nambu-Goldstone model. The result is in agreement with the earlier suggestion by Dine and Seiberg that the string in the tensionless limit is described by a sigma model with a non-relativistic Higgs sector. As an application, we consider the massless bosons of a special kind of string in the tensionless limit, and show that their number is restricted by the Top polynomial. We also discuss the connection between our results and the lately proposed idea of an effective Nambu-Goldstone model as a description of the string in the tensionless limit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Staggered Heavy Baryon Chiral Perturbation Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.149, "human_text": "  Although taste violations significantly affect the results of staggered calculations of pseudoscalar and heavy-light mesonic quantities, those entering staggered calculations of baryonic quantities have not been quantified. Here I develop staggered chiral perturbation theory in the light-quark baryon sector by mapping the Symanzik action into heavy baryon chiral perturbation theory. For 2+1 dynamical quark flavors, the masses of flavor-symmetric nucleons are calculated to third order in partially quenched and fully dynamical staggered chiral perturbation theory. To this order the expansion includes the leading chiral logarithms, which come from loops with virtual decuplet-like states, as well as terms the order of the cubed pion mass, which come from loops with virtual octet-like states. Taste violations enter through the meson propagators in loops and tree-level terms the order of the squared lattice spacing. The pattern of taste symmetry breaking and the resulting degeneracies and mixings are discussed in detail. The resulting chiral forms are appropriate to lattice results obtained with operators already in use and could be used to study the restoration of taste symmetry in the continuum limit. I assume that the fourth root of the fermion determinant can be incorporated in staggered chiral perturbation theory using the replica method. ", "machine_text": "  We develop a staggered heavy baryon chiral perturbation theory (SCPT) within the framework of the effective two-meson theory. The staggered CPT (SCT) is applicable to the case of strong external fields. In this theory the chiral symmetry is not protected by a condensation mechanism as is the case for the conventional CPT. The basic idea of the SCT is to take into account the two different contributions to the evolution of the quark fields, corresponding to the quark and antiquark charged currents, in a staggered way. The SCT contains two additional parameters, which can be fixed from the beginning or be allowed to vary, and the evolution of the quark fields is given in terms of the two integral equations for the quark and antiquark charged currents. The SCT has a good physical basis, is consistent with the CPT, and in a certain range of the parameters it gives an improvement of the description of the strong interaction compared to the CPT. We also compare the SCT with the standard CPT in the limit of small meson masses and small external field strengths, and show that the SCT gives a slightly better description of the strong interaction in this limit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Proper Motions in the Galactic Bulge: Plaut's Window. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1975, "human_text": "  A proper motion study of a field of 20' x 20' inside Plaut's low extinction window (l,b)=(0 deg,-8 deg), has been completed. Relative proper motions and photographic BV photometry have been derived for ~21,000 stars reaching to V~20.5 mag, based on the astrometric reduction of 43 photographic plates, spanning over 21 years of epoch difference. Proper motion errors are typically 1 mas/yr and field dependent systematics are below 0.2 mas/yr. Cross-referencing with the 2MASS catalog yielded a sample of ~8,700 stars, from which predominantly disk and bulge subsamples were selected photometrically from the JH color-magnitude diagram. The two samples exhibited different proper-motion distributions, with the disk displaying the expected reflex solar motion as a function of magnitude. Galactic rotation was also detected for stars between ~2 and ~3 kpc from us. The bulge sample, represented by red giants, has an intrinsic proper motion dispersion of (sigma_l,sigma_b)=(3.39, 2.91)+/-(0.11,0.09) mas/yr, which is in good agreement with previous results, and indicates a velocity anisotropy consistent with either rotational broadening or tri-axiality. A mean distance of 6.37^{+0.87}_{-0.77} kpc has been estimated for the bulge sample, based on the observed K magnitude of the horizontal branch red clump. The metallicity [M/H] distribution was also obtained for a subsample of 60 bulge giants stars, based on calibrated photometric indices. The observed [M/H] shows a peak value at [M/H]~-0.1 with an extended metal poor tail and around 30% of the stars with supersolar metallicity. No change in proper motion dispersion was observed as a function of [M/H]. We are currently in the process of obtaining CCD UBVRI photometry for the entire proper-motion sample of ~21,000 stars. ", "machine_text": " We present new proper motion data for about one million stars in the Galactic bulge, obtained from the European Space Agency's Hipparchus mission. Proper motions in the bulge are dominated by large-scale streaming motions of the hydrogen and metal-poor old stars, with a different kinematic structure in the southern and northern halves. We show that the Galactic potential field in the bulge is well described by two superposed potentials, which explains the difference in the velocity fields in the two halves. We also present a model in which the radial velocity distribution of young stars is fit to the observed proper motions. This model indicates that the young stars in the bulge are confined to a thin layer, most probably related to the Galactic disk. We show that the radial velocity distribution of both old and young stars is consistent with a galactic fountain model in which the stars are upward-accelerated by supernova explosions in the Galactic center. Our data set also contains a significant number of high-velocity stars, which are likely to be members of the Galactic globular clusters. The proper motion of these stars is inconsistent with the assumption of a static cluster, and they must have been perturbed by the Galactic potential. We discuss the implications of our findings for the structure and dynamics of the Galactic bulge, and for Galactic evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Universality of Mixed Action Extrapolation Formulae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0035, "human_text": "  Mixed action theories with chirally symmetric valence fermions exhibit very desirable features both at the level of the lattice calculations as well as in the construction and implementation of the low energy mixed action effective field theory. In this work we show that when such a mixed action effective field theory is projected onto the valence sector, both the Lagrangian and the extrapolation formulae become universal in form through next to leading order, for all variants of discretization methods used for the sea fermions. Our conclusion relies on the chiral nature of the valence quarks. The result implies that for all sea quark methods which are in the same universality class as QCD, the numerical values of the physical coefficients in the various mixed action chiral Lagrangians will be the same up to lattice spacing dependent corrections. This allows us to construct a prescription to determine the mixed action extrapolation formulae for a large class of hadronic correlation functions computed in partially quenched chiral perturbation theory at the one-loop level. For specific examples, we apply this prescription to the nucleon twist--2 matrix elements and the nucleon--nucleon system. In addition, we determine the mixed action extrapolation formula for the neutron EDM as this provides a nice example of a theta-dependent observable; these observables are exceptions to our prescription. ", "machine_text": "  We consider the problem of constructing a converging sequence of estimates for a solution to a stochastic differential equation with jumps by means of Extrapolation Formulae (EFs) which are alternating between deterministic and stochastic differential equations. Such a sequence is called a Mixed Action Extrapolation Formula (MAEF). We show that, under suitable regularity conditions, the set of all MAEFs has a naturalubounded basis which we call the Universal MAEF Basis. This basis is obtained by starting from a general MAEF and then expressing it as a linear combination of basis elements, each of which is an EF. We show that this basis is in fact closed under differentiation, which implies that any MAEF can be expressed as a linear combination of basis elements. We also show that any system of MAEFs can be written as a linear combination of basis elements. These results are applied to give a simple description of the class of MAEFs which have a particular property, namely that of being unconditionally stable.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral Analysis of the Chandra Comet Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1648, "human_text": "  We present results of the analysis of cometary X-ray spectra with an extended version of our charge exchange emission model (Bodewits et al. 2006). We have applied this model to the sample of 8 comets thus far observed with the Chandra X-ray observatory and ACIS spectrometer in the 300-1000 eV range. The surveyed comets are C/1999 S4 (LINEAR), C/1999 T1 (McNaught-Hartley), C/2000 WM1 (LINEAR), 153P/2002 (Ikeya-Zhang), 2P/2003 (Encke), C/2001 Q4 (NEAT), 9P/2005 (Tempel 1) and 73P/2006-B (Schwassmann-Wachmann 3) and the observations include a broad variety of comets, solar wind environments and observational conditions. The interaction model is based on state selective, velocity dependent charge exchange cross sections and is used to explore how cometary X-ray emission depend on cometary, observational and solar wind characteristics. It is further demonstrated that cometary X-ray spectra mainly reflect the state of the local solar wind. The current sample of Chandra observations was fit using the constrains of the charge exchange model, and relative solar wind abundances were derived from the X-ray spectra. Our analysis showed that spectral differences can be ascribed to different solar wind states, as such identifying comets interacting with (I) fast, cold wind, (II), slow, warm wind and (III) disturbed, fast, hot winds associated with interplanetary coronal mass ejections. We furthermore predict the existence of a fourth spectral class, associated with the cool, fast high latitude wind. ", "machine_text": "  We present a spectral analysis of the Chandra observations of comets in the COBE/FIR Colebrook-Ricalton galaxies survey. The data set consists of 27, Fran\u00e7ois and 26, Hyakutake, and has a total on-source exposure time of about 2000 ks. We find that the comet light curves can be well described by a power law with a cut-off exponential, A \u221d t^(n) exp(-t/T), where t is the observed time, A is the magnitude, n is the power law index, and T is the exponential cut-on time. The index n is in the range from 1 to 3, and T is typically in the range from 5 ks to 10 ks. The goodness of fit is typically better than 0.9. We derive the tailward extent, W, from the best fit parameters for each comet, and find that it is typically several thousand kilometers. We also derive the total radiated kinetic energy, E, and find that it is typically in the range from 10^36 to 10^37 J. For the brightest comets, we estimate the comet's gas production rate, Q, from the observed luminosity, L, using the relation L \u221d \u03c0 r^2 dQ/v, where r is the radius, d is the distance, and v is the heliocentric velocity. We find that Q is in the range from 3 \u00d7 10^19 to 1 \u00d7 10^20 cm3 s^(\u22121), and that it is anti-correlated with the comet's gas to dust ratio, with the highest values (and the most dusty comets) having the lowest gas production rates. We also find that Q is correlated with the comet's orbital eccentricity, with the highest values having the most eccentric orbits. We discuss these results in the context of the current theories of comet luminosity, and find that our observations are consistent with a model in which the energy radiated by the comet is controlled by the rate at which gas is produced, provided that the comet has a relatively long tail.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vortices in Bose-Einstein Condensates: Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0146, "human_text": "  Vortices are pervasive in nature, representing the breakdown of laminar fluid flow and hence playing a key role in turbulence. The fluid rotation associated with a vortex can be parameterized by the circulation $\\Gamma=\\oint {\\rm d}{\\bf r}\\cdot{\\bf v}({\\bf r})$ about the vortex, where ${\\bf v}({\\bf r})$ is the fluid velocity field. While classical vortices can take any value of circulation, superfluids are irrotational, and any rotation or angular momentum is constrained to occur through vortices with quantized circulation. Quantized vortices also play a key role in the dissipation of transport in superfluids. In BECs quantized vortices have been observed in several forms, including single vortices, vortex lattices, and vortex pairs and rings. The recent observation of quantized vortices in a fermionic gas was taken as a clear signature of the underlying condensation and superfluidity of fermion pairs. In addition to BECs, quantized vortices also occur in superfluid Helium, nonlinear optics, and type-II superconductors. ", "machine_text": " We study vortices in a Bose-Einstein condensate (BEC) of atomic gases, a system in which vortices can be created, modified or destroyed by a weak probe field. We develop a theory which treats vortices as topological defects and examines the dynamics of vortex creation, evolution and annihilation in a BEC. We calculate the structure of vortex core and vortex formation probability as a function of temperature, and show that the latter has a sharp transition as a function of temperature, which can be used to identify the BEC transition temperature. We find that the total number of vortices in the BEC has a simple expression, which is consistent with the experiment observation in a one dimensional BEC. Our theory also explains quantitatively several other phenomena in vortex dynamics, such as the increase of vortex core size as the temperature decreases. Our results indicate that the behavior of vortices in a BEC is very different from that in a normal gas, and a theory which treats vortices as topological defects can provide a unified and consistent explanation of a variety of phenomena in vortex dynamics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase Transitions in the Coloring of Random Graphs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1269, "human_text": "  We consider the problem of coloring the vertices of a large sparse random graph with a given number of colors so that no adjacent vertices have the same color. Using the cavity method, we present a detailed and systematic analytical study of the space of proper colorings (solutions).   We show that for a fixed number of colors and as the average vertex degree (number of constraints) increases, the set of solutions undergoes several phase transitions similar to those observed in the mean field theory of glasses. First, at the clustering transition, the entropically dominant part of the phase space decomposes into an exponential number of pure states so that beyond this transition a uniform sampling of solutions becomes hard. Afterward, the space of solutions condenses over a finite number of the largest states and consequently the total entropy of solutions becomes smaller than the annealed one. Another transition takes place when in all the entropically dominant states a finite fraction of nodes freezes so that each of these nodes is allowed a single color in all the solutions inside the state. Eventually, above the coloring threshold, no more solutions are available. We compute all the critical connectivities for Erdos-Renyi and regular random graphs and determine their asymptotic values for large number of colors.   Finally, we discuss the algorithmic consequences of our findings. We argue that the onset of computational hardness is not associated with the clustering transition and we suggest instead that the freezing transition might be the relevant phenomenon. We also discuss the performance of a simple local Walk-COL algorithm and of the belief propagation algorithm in the light of our results. ", "machine_text": "  We consider a random graph coloring model in which the probability of any edge being present is independently and uniformly distributed on the set {0, 1/2, 1} and examine the equilibrium probability of having a given number of edges colored in color 1. We show that this probability is the same as for a uniformly random graph, thus extending a result of basil. We also consider the problem of approximating the probability of this equilibrium in a random graph by a random walk on the graph. We show that this approximation does not work in general, but it does for a large class of graphs. We analyze this random graph coloring model in several ways. In particular, we consider the distribution of the number of edges of a given color, the distribution of the number of connected components of a given color, and the distribution of the number of non-zero degree vertices of a given color. We show that the last two of these distributions are related to the distribution of the number of connected components of a given size. We also show that the distribution of the number of edges of a given color can be approximated by a random walk on the graph. We then consider the random graph coloring model on a large class of graphs that includes the Barab\u00e1si-Albert and power law random graphs. We show that on these graphs the distribution of the number of edges of a given color converges to a limiting distribution that is independent of the number of colors. We also show that the distribution of the number of connected components of a given color converges to a limiting distribution that is independent of the number of colors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Global polarization of QGP in non-central heavy ion collisions at high   energies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2852, "human_text": "  Due to the presence of a large orbital angular momentum of the parton system produced at the early stage of non-central heavy-ion collisions, quarks and anti-quarks are shown to be polarized in the direction opposite to the reaction plane which is determined by the impact-parameter and the beam momentum. The global quark polarization via elastic scattering was first calculated in an effective static potential model, then using QCD at finite temperature with the hard-thermal-loop re-summed gluon propagator. The measurable consequences are discussed. Global hyperon polarization from the hadronization of polarized quarks are predicted independent of the hadronization scenarios. It has also been shown that the global polarization of quarks and anti-quarks leads also to spin alignment of vector mesons. Dedicated measurements at RHIC are underway and some of the preliminary results are obtained. In this presentation, the basic idea and main results of global quark polarization are presented. The direct consequences such as global hyperon polarization and spin alignment are summarized. ", "machine_text": " We present a global analysis of the polarization of the quark-gluon plasma (QGP) in non-central heavy ion collisions at high energies. We find that the degree of polarization of the QGP has a strong dependence on the transverse momentum (pT) of the collision system, and on the number of participating nucleons in the system. In particular, we show that the fraction of polarized nucleons in the QGP increases strongly with the number of participating nucleons, while it is almost independent of the pT of the system. Our results are consistent with the idea that the nucleons in the QGP can be approximately described by a kinetic model in which the helical motion of the nucleons is driven by the spin of the antiquarks, and in which the polarization of the nucleons is due to the statistical correlation between the antiquarks and the nucleons. We also present a simple physical model which describes the evolution of the polarization of the QGP in heavy ion collisions. Our results suggest that the polarization of the QGP is governed by the same mechanisms which are responsible for the polarization of the hadron jets produced in heavy ion collisions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evolution of complex modular biological networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4674, "human_text": "  Biological networks have evolved to be highly functional within uncertain environments while remaining extremely adaptable. One of the main contributors to the robustness and evolvability of biological networks is believed to be their modularity of function, with modules defined as sets of genes that are strongly interconnected but whose function is separable from those of other modules. Here, we investigate the in silico evolution of modularity and robustness in complex artificial metabolic networks that encode an increasing amount of information about their environment while acquiring ubiquitous features of biological, social, and engineering networks, such as scale-free edge distribution, small-world property, and fault-tolerance. These networks evolve in environments that differ in their predictability, and allow us to study modularity from topological, information-theoretic, and gene-epistatic points of view using new tools that do not depend on any preconceived notion of modularity. We find that for our evolved complex networks as well as for the yeast protein-protein interaction network, synthetic lethal pairs consist mostly of redundant genes that lie close to each other and therefore within modules, while knockdown suppressor pairs are farther apart and often straddle modules, suggesting that knockdown rescue is mediated by alternative pathways or modules. The combination of network modularity tools together with genetic interaction data constitutes a powerful approach to study and dissect the role of modularity in the evolution and function of biological networks. ", "machine_text": "  We study the evolution of complex modular biological networks. We show that such networks display community structure, that is, groups of nodes that are more densely connected internally than with the rest of the network. We find that this community structure isscale-free, that is, the degree distribution of the nodes in each community follows a power law. We also find that the largest groups, that is, the groups with the largest number of nodes, are the most stable groups. The stability of these groups isGuarerd by the presence of a large number of links between the nodes within each group, and by the presence of only a small number of links between each group and the rest of the network. We also show that there are algorithms that can identify the communities in a complex modular network, and that these communities can be identified using only local information about the links, that is, without knowing the labels of the nodes. We discuss the implications of these results for the evolution of modularity, and for the identification of functional modules.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Enrichment of the ISM by metal-rich droplets and the abundance bias in   HII regions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1225, "human_text": "  We critically examine a scenario for the enrichment of the interstellar medium (ISM) in which supernova ejecta follow a long (10^8 yr) journey before falling back onto the galactic disk in the form of metal-rich ``droplets'', These droplets do not become fully mixed with the interstellar medium until they become photoionized in HII regions. We investigate the hypothesis that the photoionization of these highly metallic droplets can explain the observed ``abundance discrepancy factors'' (ADFs), which are found when comparing abundances derived from recombination lines and from collisionally excited lines, both in Galactic and extragalactic HII regions. We derive bounds of 10^{13}--10^{15} cm on the droplet sizes inside HII regions in order that (1) they should not have already been detected by direct imaging of nearby nebulae, and (2) they should not be too swiftly destroyed by diffusion in the ionized gas. From photoionization modelling we find that, if this inhomogeneous enrichment scenario holds, then the recombination lines strongly overestimate the metallicities of the fully mixed HII regions. The abundances derived from collisionally excited lines also suffer some bias, although to a much lesser extent. In the absence of any recipe for correcting these biases, we recommend the discarding of all objects showing large ADFs from studies of galactic chemical evolution. These biases must also be kept in mind when comparing the galactic abundance gradients for elements derived from recombination lines with those derived from collisionally excited lines. Finally, we propose a set of observations that could be undertaken to test our scenario and improve our understanding of element mixing in the ISM. ", "machine_text": "  We present an analysis of the enrichment of the Inter Stellar Medium (ISM) by metal-rich droplets and the abundance bias in HII regions. We derive a simple analytical expression for the abundance ratio of [M/H] in the ISM and the HII regions as a function of the metallicity of the former. Our results show that the [M/H] ratio in the ISM is below the universal value by about 1.5 dex for metallicities [Fe/H] > +0.4, and that the [M/H] ratio in HII regions is usually above the ISM value by 0.5\u20131.5 dex. We explain this bias in terms of the enrichment of the ISM by large metal-rich droplets that have formed and survived in the ISM for several galactic orbits, and that have not suffered significant further chemical processing. We show that such droplets can be efficiently formed by the accretion of metal-rich gas from the inner-rim regions of accretion discs around low and medium mass stars. Our results explain both the under-abundance of metals in the ISM and the abundance bias observed in HII regions, without the need of assuming different enrichment histories for different metallicities.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Matter-Wave Bright Solitons with a Finite Background in Spinor   Bose-Einstein Condensates. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0082, "human_text": "  We investigate dynamical properties of bright solitons with a finite background in the F=1 spinor Bose-Einstein condensate (BEC), based on an integrable spinor model which is equivalent to the matrix nonlinear Schr\\\"{o}dinger equation with a self-focusing nonlineality. We apply the inverse scattering method formulated for nonvanishing boundary conditions. The resulting soliton solutions can be regarded as a generalization of those under vanishing boundary conditions. One-soliton solutions are derived in an explicit manner. According to the behaviors at the infinity, they are classified into two kinds, domain-wall (DW) type and phase-shift (PS) type. The DW-type implies the ferromagnetic state with nonzero total spin and the PS-type implies the polar state, where the total spin amounts to zero. We also discuss two-soliton collisions. In particular, the spin-mixing phenomenon is confirmed in a collision involving the DW-type. The results are consistent with those of the previous studies for bright solitons under vanishing boundary conditions and dark solitons. As a result, we establish the robustness and the usefulness of the multiple matter-wave solitons in the spinor BECs. ", "machine_text": "  We investigate bright matter-wave solitons in a spinor Bose-Einstein condensate (BEC) of micron-sized dielectric particles in a homogeneous magnetic field. Such solitons can be formed by the collective interaction of a finite number of particles. They are stable against the thermal decay as long as $\\Delta\\geq \\Delta_{\\rm min}$, where $\\Delta$ is the soliton width and $\\Delta_{\\rm min}$ is the thermal instability threshold. Our main result is that, the bound-state energy of a bright soliton with a finite background in a spinor BEC is bounded from below by an explicit expression, which has a minimum value $\\Delta_{\\rm min} \\approx 0.6\\Delta$ for a soliton of a given width $\\Delta$, and depends only on the number $N$ of particles in the soliton and the total number $N_0$ of particles in the BEC. In particular, for a given $\\Delta$, there is a unique bright soliton of finite width, which is strictly stable against the thermal decay. We show that such a bright soliton can be created by a simple recipe based on the breakup of a single bright matter-wave soliton of infinite width, which is known to be stable against the thermal decay in a conventional BEC. We also derive a simple expression for the spatial profile of a bright soliton with a finite background in a spinor BEC.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vibration-Induced Conductivity Fluctuation Measurement for Soil Bulk   Density Analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0511, "human_text": "  Soil bulk density affects water storage, water and nutrient movement, and plant root activity in the soil profile. Its measurement is difficult in field conditions. Vibration-induced conductivity fluctuation was investigated to quantify soil bulk density with possible field applications in the future. The AC electrical conductivity of soil was measured using a pair of blade-like electrodes while exposing the soil to periodic vibration. The blades were positioned longitudinally and transversally to the direction of the induced vibration to enable the calculation of a normalized index. The normalized index was expected to provide data independent from the vibration strength and to reduce the effect of soil salinity and water content. The experiment was conducted on natural and salinized fine sand at two moisture conditions and four bulk densities. The blade-shaped electrodes improved electrode-soil contact compared to cylindrical electrodes, and thereby, reduced measurement noise. Simulations on a simplified resistor lattice indicate that the transversal effect increases as soil bulk density decreases. Measurement of dry sand showed a negative correlation between the normalized conductivity fluctuation and soil bulk density for both longitudinal and transversal settings. The decrease in the transversal signal was smaller than expected. The wet natural and salinized soils performed very similarly as hypothesized, but their normalized VICOF response was not significant to bulk density changes. ", "machine_text": " Soil bulk density is an important geotechnical parameter that affects the stability and performance of many civil engineering structures. Current practice for measuring soil bulk density is labor-intensive and time-consuming, as it involves drying and weighing of soil samples in the laboratory. This research proposes a new method for soil bulk density analysis based on the measurement of vibration-induced conductivity fluctuation in soil. A series of laboratory experiments were conducted on loose sand and compact clay, and the results show that the proposed method is capable of measuring the soil bulk density with an accuracy of 1.5% and 2.3% for loose sand and compact clay, respectively, without the need for soil sample drying and weighing in the laboratory. The proposed method has the potential to be developed into a rapid and cost-effective in-situ soil bulk density testing method, which could be used for quality control and verification of soil properties in geotechnical engineering projects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Refined asymptotics around solitons for gKdV equations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1178, "human_text": "  We consider the generalized Korteweg-de Vries equation $$ \\partial_t u + \\partial_x (\\partial_x^2 u + f(u))=0, \\quad (t,x)\\in [0,T)\\times \\mathbb{R}$$ with general $C^2$ nonlinearity $f$. Under an explicit condition on $f$ and $c>0$, there exists a solution in the energy space $H^1$ of the type $u(t,x)=Q_c(x-x_0-ct)$, called soliton. Stability theory for $Q_c$ is well-known.   In previous works, we have proved that for $f(u)=u^p$, $p=2,3,4$, the family of solitons is asymptotically stable in some local sense in $H^1$, i.e. if $u(t)$ is close to $Q_{c}$ (for all $t\\geq 0$), then $u(t,.+\\rho(t))$ locally converges in the energy space to some $Q_{c_+}$ as $t\\to +\\infty$, for some $c^+\\sim c$.   Then, the asymptotic stability result could be extended to the case of general assumptions on $f$ and $Q_c$.   The objective of this paper is twofold.   The main objective is to prove that in the case $f(u)=u^p$, $p=2,3,4$, $\\rho(t)-c_+ t$ has limit as $t\\to +\\infty$ under the additional assumption $x_+ u\\in L^2$.   The second objective of this paper is to provide large time stability and asymptotic stability results for two soliton solutions for the case of general nonlinearity $f(u)$, when the ratio of the speeds of the solitons is small. The motivation is to accompany forthcoming works devoted to the collision of two solitons in the nonintegrable case. The arguments are refinements of previous works specialized to the case $u(t)\\sim Q_{c_1}+Q_{c_2}$, for $0< c_2 \\ll c_1$. ", "machine_text": " We study a class of gKdV equations with rational interaction functions. These are equations in which the interaction function is related to the soliton solution by a translation and a uniform scaling. Such a relation is in general non-unique. We show that this class of equations has a natural basis of solvable asymptotic solutions. This basis is made of two types of solutions, both of which depend on a small parameter which is the ratio of the root of the polynomial in the exponential of the interaction function to the absolute value of the polynomial. One type of solution is a kind of Newton's method which starts from an initial guess based on the soliton solution and the other type is a combination of this method with a \"Variable Substitution Method\". The basic tools to obtain these results are a formula for the solution of a certain kind of gKdV equation with an exponential interaction function, and an asymptotic formula for the solution of a specific type of singular nonlinear Schr\u00f6dinger equation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Old Main-Sequence Turnoff Photometry in the Small Magellanic Cloud. I.   Constraints on the Star Formation History in Different Fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1151, "human_text": "  We present ground-based B and R-band color-magnitude diagrams (CMDs), reaching the oldest main-sequence turnoffs with good photometric accuracy for twelve fields in the Small Magellanic Cloud (SMC). Our fields, located between ~1 and ~4 degrees from the center of the galaxy, are situated in different parts of the SMC such as the \"Wing'' area, and towards the West and South. In this paper we perform a first analysis of the stellar content in our SMC fields through comparison with theoretical isochrones and color functions (CFs). We find that the underlying spheroidally distributed population is composed of both intermediate-age and old stars and that its age composition does not show strong galacto-centric gradients. The three fields situated toward the east, in the Wing region, show very active current star formation. However, only in the eastern field closest to the center do we find an enhancement of recent star formation with respect to a constant SFR(t). The fields corresponding to the western side of the SMC present a much less populated young MS, and the CF analysis indicates that the SFR(t) greatly diminished around 2 Gyr ago in these parts. Field smc0057, the closest to the center of the galaxy and located in the southern part, shows recent star formation, while the rest of the southern fields present few bright MS stars. The structure of the red clump in all the CMDs is consistent with the large amount of intermediate-age stars inferred from the CMDs and color functions. None of the SMC fields presented here are dominated by old stellar populations, a fact that is in agreement with the lack of a conspicuous horizontal branch in all these SMC CMDs. This could indicate that a disk population is ruling over a possible old halo in all the observed fields. ", "machine_text": " We present a photometric study of the old main sequence turnoff (OMST) in the Small Magellanic Cloud (SMC). We derive the cluster-galaxy luminosity ratio in different regions of the SMC. The field studied has a wide range in metallicities, with the highest metallicities in the direction of the Large Magellanic Cloud (LMC). We find that the lowest metallicities are around log(Z/Z\u2299) \u2248 1.5 and the highest metallicities are around log(Z/Z\u2299) \u2248 1.8. The lowest metallicities are found in a region close to the LMC, and there is a trend for the metallicities to increase toward the center of the SMC. We find that the relative abundance of elements in the gas is well described by the relation [Fe/H] \u2248 +0.6[Z/Z\u2299]0.5, which is consistent with the solar abundance. We derive the cluster-galaxy luminosity ratio in the different regions of the SMC, and we find that the luminosity ratio is inversely proportional to the metallicity within the interval [Fe/H] = +0.4 to +0.8. We discuss the implications of our results for the star formation history in the SMC. We compare our results with recent literature results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Correlated modulation between the redshifted Fe K alpha line and the   continuum emission in NGC 3783. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0226, "human_text": "  It has been suggested that X-ray observations of rapidly variable Seyfert galaxies may hold the key to probe the gas orbital motions in the innermost regions of accretion discs around black holes and, thus, trace flow patterns under the effect of the hole strong gravitational field. We explore this possibility analizing XMM-Newton observations of the seyfert 1 galaxy NGC 3783. A detiled time-resolved spectral analysis is performed down to the shortest possible time-scales (few ks) using \"excess maps\" and cross-correlating light curves in different energy bands. In addition to a constant core of the Fe K alpha line, we detected a variable and redshifted Fe K alpha emission feature between 5.3-6.1 keV. The line exhibits a modulation on a time-scale of 27 ks that is similar to and in phase with a modulation of the 0.3-10 keV source continuum. The time-scale of the correlated variability of the redshifted Fe line and continuum agrees with the local dynamical time-scale of the accretion disc at 10 r_g around a black hole of 10^7 M_sun. Given the shape of the redshfted line emission and the overall X-ray variability pattern, the line is likely to arise from the relativistic region near the black hole. ", "machine_text": "  We present observations of the non-linear cavity soliton in the Sy2 molecular hydrogen Sy2  line at 4100 A and of the related corridor structure in the continuum emission at 4757 A in the nearby galaxy NGC 3783. The former was observed with the MIKE thermographic imaging detector on board the Viking space probe, and the latter with the Near-Infrared Camera (NIRCam) on board the Hubble Space Telescope. We find a clear correlation between the redshift of the soliton and the depth of the 4757 A continuum, with the soliton at the redshift of the simultaneously brightest continuum. The correlation is such that if the continuum were to be faded out completely the soliton would disappear, too. We also find that the shape of the soliton changes in a way correlated with the contour of the 4757 A continuum: a depression in the continuum accompanied by a betrayal in the soliton. The correlation is such that a free-free absorption component, which would be betrayed by a depression in the soliton, would also be expected to be accompanied by a depression in the continuum. The implications of our findings for models of non-linear cavity solitons and of the ionization structure in the Sy2 region are discussed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Thermal derivation of the Coleman-De Luccia tunneling prescription. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1573, "human_text": "  We derive the rate for transitions between de Sitter vacua by treating the field theory on the static patch as a thermal system. This reproduces the Coleman-De Luccia formalism for calculating the rate, but leads to a modified interpretation of the bounce solution and a different prediction for the evolution of the system after tunneling. The bounce is seen to correspond to a sequence of configurations interpolating between initial and final configurations on either side of the tunneling barrier, all of which are restricted to the static patch. The final configuration, which gives the initial data on the static patch for evolution after tunneling, is obtained from one half of a slice through the center of the bounce, while the other half gives the configuration before tunneling. The formalism makes no statement about the fields beyond the horizon.   This approach resolves several puzzling aspects and interpretational issues concerning the Coleman-De Luccia and Hawking-Moss bounces. We work in the limit where the back reaction of matter on metric can be ignored, but argue that the qualitative aspects remain in the more general case. The extension to tunneling between anti-de Sitter vacua is discussed. ", "machine_text": "  We show that the thermal derivation of the Coleman-De Luccia tunneling prescription, as proposed in Ref., is incorrect. We analyze the relevant thermodynamics and derive the correct form of the Coleman-De Luccia tunneling prescription. The main ingredient is the relation between the thermal derivative and the ordinary derivative. We show that this relation is not valid in general. The correct tunneling prescription is more complicated than the one previously derived, but it has the same form as in the absence of thermal fluctuations. We analyze the conditions on the parameters of the system for which the tunneling prescription is exact. We also derive a simple approximation for the case in which the tunneling barrier is weakly disordered. The main conclusion of our work is that the validity of the tunneling approximation is more restricted than previously thought. However, the exact conditions for the validity of the approximation are rather technical and difficult to assess in practice. Hence, we also propose a simple practical approximation, which is more liberal than the exact conditions, but still captures the essential features of the tunneling behavior.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Parametric Learning and Monte Carlo Optimization. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1274, "human_text": "  This paper uncovers and explores the close relationship between Monte Carlo Optimization of a parametrized integral (MCO), Parametric machine-Learning (PL), and `blackbox' or `oracle'-based optimization (BO). We make four contributions. First, we prove that MCO is mathematically identical to a broad class of PL problems. This identity potentially provides a new application domain for all broadly applicable PL techniques: MCO. Second, we introduce immediate sampling, a new version of the Probability Collectives (PC) algorithm for blackbox optimization. Immediate sampling transforms the original BO problem into an MCO problem. Accordingly, by combining these first two contributions, we can apply all PL techniques to BO. In our third contribution we validate this way of improving BO by demonstrating that cross-validation and bagging improve immediate sampling. Finally, conventional MC and MCO procedures ignore the relationship between the sample point locations and the associated values of the integrand; only the values of the integrand at those locations are considered. We demonstrate that one can exploit the sample location information using PL techniques, for example by forming a fit of the sample locations to the associated values of the integrand. This provides an additional way to apply PL techniques to improve MCO. ", "machine_text": "  Parametric Learning and Monte Carlo Optimization  The problem of learning the parameters of a model from data is considered. The model is assumed to be a black box that maps input variables to output variables according to some unknown functional relationship. The standard approach to this problem is to use an optimization algorithm to search the parameter space for a configuration that minimizes a loss function that measures the discrepancy between the model's predictions and the data. The algorithm is typically guided by a derivative-based optimization method that makes use of the differential properties of the loss function. This approach is limited to cases where the optimization algorithm can be expressed in a differentiable form and where the loss function can be evaluated at all points in the parameter space. These restrictions may not apply in practice. As a result, a number of approaches have been proposed that are based on heuristic search rather than optimization. These approaches suffer from the lack of a formalism for guiding the search process. In this work, a new method is proposed for learning the parameters of a model that combines the advantages of optimization-based and heuristic approaches. The proposed method makes use of a parametric learning strategy that is formalized using a Bayes-like decision theory. The proposed method is demonstrated on the problem of learning the parameters of a mixture distribution model and a nonlinear regression model. The experimental results indicate that the proposed method can achieve significantly better performance than heuristic search techniques, while maintaining the benefits of a formal optimization-like framework.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical models with a general anisotropy profile. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4109, "human_text": "  Both numerical simulations and observational evidence indicate that the outer regions of galaxies and dark matter haloes are typically mildly to significantly radially anisotropic. The inner regions can be significantly non-isotropic, depending on the dynamical formation and evolution processes. In an attempt to break the lack of simple dynamical models that can reproduce this behaviour, we explore a technique to construct dynamical models with an arbitrary density and an arbitrary anisotropy profile. We outline a general construction method and propose a more practical approach based on a parameterized anisotropy profile. This approach consists of fitting the density of the model with a set of dynamical components, each of which have the same anisotropy profile. Using this approach we avoid the delicate fine-tuning difficulties other fitting techniques typically encounter when constructing radially anisotropic models. We present a model anisotropy profile that generalizes the Osipkov-Merritt profile, and that can represent any smooth monotonic anisotropy profile. Based on this model anisotropy profile, we construct a very general seven-parameter set of dynamical components for which the most important dynamical properties can be calculated analytically. We use the results to look for simple one-component dynamical models that generate simple potential-density pairs while still supporting a flexible anisotropy profile. We present families of Plummer and Hernquist models in which the anisotropy at small and large radii can be chosen as free parameters. We also generalize these two families to a three-parameter family that self-consistently generates the set of Veltmann potential-density pairs. (Abridged...) ", "machine_text": " We develop a class of statistical dynamical models with a general anisotropy profile. Our approach is based on the idea of replacing the Gaussian diffusion kernel, which is the basis of the celebrated Model-Free Method, by a nonlinear diffusion kernel that depends on the involved degrees of freedom. We show that this general framework is able to accommodate a large class of dynamical models with anisotropic diffusion and that the model-free formulation has several advantages over the more traditional approach based on the analysis of the dynamical equation. In particular, we show that the model-free formulation is capable of relaxing some of the assumptions that are usually made in the analysis of the dynamical equation, such as the assumption of a Gaussian diffusion kernel or the assumption that the diffusion is isotropic. We analyze the properties of the model-free approach and we illustrate its potential by studying some simple examples of statistical dynamical models with anisotropic diffusion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Magnetic Field of the Solar Corona from Pulsar Observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1869, "human_text": "  We present a novel experiment with the capacity to independently measure both the electron density and the magnetic field of the solar corona. We achieve this through measurement of the excess Faraday rotation due to propagation of the polarised emission from a number of pulsars through the magnetic field of the solar corona. This method yields independent measures of the integrated electron density, via dispersion of the pulsed signal and the magnetic field, via the amount of Faraday rotation. In principle this allows the determination of the integrated magnetic field through the solar corona along many lines of sight without any assumptions regarding the electron density distribution. We present a detection of an increase in the rotation measure of the pulsar J1801$-$2304 of approximately 160 \\rad at an elongation of 0.95$^\\circ$ from the centre of the solar disk. This corresponds to a lower limit of the magnetic field strength along this line of sight of $> 393\\mu\\mathrm{G}$. The lack of precision in the integrated electron density measurement restricts this result to a limit, but application of coronal plasma models can further constrain this to approximately 20mG, along a path passing 2.5 solar radii from the solar limb. Which is consistent with predictions obtained using extensions to the Source Surface models published by Wilcox Solar Observatory ", "machine_text": "  We present a simple method for inferring the three-dimensional structure of the solar corona from observations of radio pulsars. We show that if a pulsar is occulted by the corona, the observed properties of the pulsar's radio emission can be used to infer the three-dimensional structure of the occulting corona. We implement this method using observations of the solar eclipses of the radio pulsars B1259-63 and B1219+36, which were observed in 1999 and 2002, respectively. We find that the field-of-view-corrected light profiles of these eclipses are well described by a model in which the underlying pulsar emission is partially occulted by a smoothly-varying, three-dimensional, laminated, magnetized corona. We estimate the ambient magnetic field in the corona to be between 1 and 4 kG. We find that the structure of the corona changes as the solar cycle progresses: the corona is more structured during solar maximum and less structured during solar minimum. Our results are consistent with models in which the corona is magnetically structured, with the structure evolving with the solar cycle.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Space Velocities of L- and T-type Dwarfs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0784, "human_text": "  (Abridged) We have obtained radial velocities of a sample of 18 ultracool dwarfs (M6.5-T8) using high-resolution, near-infrared spectra obtained with NIRSPEC and the Keck II telescope. We have confirmed that the radial velocity of Gl 570 D is coincident with that of the K-type primary star Gl 570 A, thus providing additional support for their true companionship. The presence of planetary-mass companions around 2MASS J05591914-1404488 (T4.5V) has been analyzed using five NIRSPEC radial velocity measurements obtained over a period of 4.37 yr. We have computed UVW space motions for a total of 21 L and T dwarfs within 20 pc of the Sun. This population shows UVW velocities that nicely overlap the typical kinematics of solar to M-type stars within the same spatial volume. However, the mean Galactic (44.2 km/s) and tangential (36.5 km/s) velocities of the L and T dwarfs appear to be smaller than those of G to M stars. A significant fraction (~40%) of the L and T dwarfs lies near the Hyades moving group (0.4-2 Gyr), which contrasts with the 10-12% found for earlier-type stellar neighbors. Additionally, the distributions of all three UVW components (sigma_{UVW} = 30.2, 16.5, 15.8 km/s) and the distributions of the total Galactic (sigma_{v_tot} = 19.1 km/s) and tangential (sigma_{v_t} = 17.6 km/s) velocities derived for the L and T dwarf sample are narrower than those measured for nearby G, K, and M-type stars, but similar to the dispersions obtained for F stars. This suggests that, in the solar neighborhood, the L- and T-type ultracool dwarfs in our sample (including brown dwarfs) is kinematically younger than solar-type to early M stars with likely ages in the interval 0.5-4 Gyr. ", "machine_text": "  Space Velocities of L- and T-type Dwarfs  We present new observations of the space velocities of 75 L- and T-type dwarfs in an attempt to determine whether these objects follow random orbits or display evidence of communal motion. The data are from an eight-year program in which the applauded but seldom used technique of finding relative velocities from proper motion was used to obtain space velocities for these stars. The stars were observed as they passed in front of, or transited, 27 glaciers and 20 stars. The glaciers have a well-determined motion, and so their velocity is known. Thus, by measuring the difference between the glacier velocity and the dwarf velocity, the space velocity of the dwarf can be found. We find that the space velocities of the L-dwarfs are distributed randomly in a range of plus or minus 7 km/s, with no evidence of any preferred velocity. We find that the T-dwarfs display a non-random motion, with a statistically significant preference for a velocity of plus or minus 3.5 km/s. Thus, although both the L- and T-dwarfs are known to have a close relation to the giants in their respective galactic neighborhoods, the L-dwarfs are apparently not moving in as a group, while the T-dwarfs are. We discuss a number of possible physical explanations for this difference.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Covering Homology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0626, "human_text": "  We introduce the notion of \"covering homology\" of a commutative ring spectrum with respect to certain families of coverings of topological spaces. The construction of covering homology is extracted from Bokstedt, Hsiang and Madsen's topological cyclic homology. In fact covering homology with respect to the family of orientation preserving isogenies of the circle is equal to topological cyclic homology.   Our basic tool for the analysis of covering homology is a cofibration sequence involving homotopy orbits and a restriction map similar to the restriction map used in Bokstedt, Hsiang and Madsen's construction of topological cyclic homology.   Covering homology with respect to families of isogenies of a torus is constructed from iterated topological Hochschild homology. It receives a trace map from iterated algebraic K-theory and the hope is that the rich structure, and the calculability of covering homology will make covering homology useful in the exploration of J. Rognes' ``red shift conjecture''. ", "machine_text": " Covering Homology  We introduce a simple game we call Covering Homology. The game has a number of interesting properties, which we investigate. We show that the game is closely related to the theory of covering spaces of graphs and that it can be used to give a simple combinatorial description of covering homology.  Let $G$ be a graph. We say that a subset $V$ of $G$ covers $G$ if every edge of $G$ is adjacent to at least one vertex of $V$. Let $G$ and $H$ be two graphs such that $G$ covers $H$. We say that $G$ is an covering homology of $H$ if every edge of $H$ is adjacent to at least one vertex of $G$.  We show that covering homology is a generalization of cycle index to the setting of graphs. As such, many of the results about cycle index carry over to covering homology. We show that the number of non-isomorphic covering homologies of a graph $H$ is given by the formula $2^{\\text{num_edges}(H)}-1$. We also show that if $H$ is a complete graph, then the covering homology of $H$ is the complete graph $K_2$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multiperiodicity in the newly discovered mid-late Be star V2104 Cygni. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2943, "human_text": "  We obtained the first long, homogenous time-series of V2104Cyg, consisting of 679 datapoints, with the uvbybeta photometers of Sierra Nevada and San Pedro Martir Observatories with the aim to detect and subsequently interpret the intrinsic frequencies of this previously unstudied variable star, which turned out to be a Be star. We try to figure out its place among the variable B stars on the upper Main Sequence. In order to obtain additional information on physical parameters we collected a few spectra with the ELODIE and FIES instruments. We searched for frequencies in the uvby passbands using 2 different frequency analysis methods and used the S/N>4 criterion to select the significant periodicities. We obtained an estimate of the physical parameters of the underlying B star of spectral type between B5 and B7, by correcting for the presence of a circumstellar disk, using a formalism based on the strenght of the Halpha line emission. We detected 3 independent frequencies with amplitudes below 0.01mag, f1 = 4.7126 c/d, f2 = 2.2342 c/d and f3 = 4.671 c/d, and discovered that V2104Cyg is a Be star. The fast rotation (vsini=290+/-10 km/s, and 27<i<45) hampered the investigation of the associated pulsational parameters l. Nevertheless, the most plausible explanation for the observed variability of this mid-late type Be star is a non-radial pulsation model. This paper is based on observations obtained at the Observatorio Astronomico Nacional San Pedro Martir (Mexico), Observatorio de Sierra Nevada (Spain), Observatoire de Haute Provence (France), and on observations made with the Nordic Optical Telescope, Observatorio Roque de los Muchachos, La Palma, Spain. ", "machine_text": "  Mid-Late B Stars as Well as F and G Stars are Significantly affected by Planetary Systems  We present phase-resolved photometric and spectroscopic observations of the newly discovered mid-late Be star V2104 Cygni. We show that the orbital period of the star's satellite is approximately 3.7 days. The 3.7-day period is close to the fundamental 3.67-day period of the primary's photometric variability. We also show that the properties of the photometric and spectroscopic variations are consistent with the effect of a gravitational bound planetary system in which the mass of the primary is two to three times the mass of the secondary. The observations also reveal a 9.28-day cycle in the photometry and a 9.0-day cycle in the spectroscopy. We interpret these as the harmonics of the fundamental 3.67-day period. The amplitude of the harmonics is about one-half that of the primary signal, indicating that the mass of the secondary is between one-half and one-third that of the primary. We also show that a 12.5-day cycle is present in the photometry, but absent in the spectroscopy. The amplitude of this cycle is about one-third that of the primary signal, indicating that the mass of a third body, possibly a giant planet, is between one-third and one-half that of the primary. We discuss these observations in the context of the known giant exoplanets and the methods of detecting them.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Impact of dimensionless numbers on the efficiency of MRI-induced   turbulent transport. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2943, "human_text": "  The magneto-rotational instability is presently the most promising source of turbulent transport in accretion disks. However, some important issues still need to be addressed to quantify the role of MRI in disks; in particular no systematic investigation of the role of the physical dimensionless parameters of the problem on the dimensionless transport has been undertaken yet. First, we complete existing investigations on the field strength dependence by showing that the transport in high magnetic pressure disks close to marginal stability is highly time-dependent and surprisingly efficient. Second, we bring to light a significant dependence of the global transport on the magnetic Prandtl number, with $\\alpha\\propto Pm^\\delta$ for the explored range: $0.12<Pm<8$ and $200<Re<6400$ ($\\delta$ being in the range 0.25 to 0.5). We show that the dimensionless transport is not correlated to the dimensionless linear growth rate, contrarily to a largely held expectation. More generally, these results stress the need to control dissipation processes in astrophysical simulations. ", "machine_text": "  We study the effect of dimensionless numbers on the efficiency of MRI-induced turbulent transport in a simplified model. Our motivation is the need to understand the limitations of MRI-based techniques to investigate turbulent transport in real fluids, which is a topic of considerable current interest. Our key idea is to use a simplified model that captures the essential features of the problem, in order to obtain general results that can be applied to real fluids. Our methodology is to perform a large number of numerical simulations, in which we vary the values of the dimensionless numbers in the model, and study the effect of these variations on the efficiency of the transport process. We obtained results showing that the efficiency of the transport process is very sensitive to the values of the dimensionless numbers in the model, and that the transport process can be significantly enhanced by tuning the values of these numbers. Our work suggests that dimensionless numbers may play a key role in determining the efficiency of MRI-induced turbulent transport in real fluids, and that it may be possible to significantly increase the efficiency of this process by tuning the values of the relevant dimensionless numbers in the fluid.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What Makes a System Complex? an Approach to Self-Organization and   Emergence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.044, "human_text": "  The fast changing reality in technical and natural domains perceived by always more accurate observations has drawn attention on new and very broad class of systems with specific behaviour represented under the common wording complexity. From elementary system graph representation with components as nodes and interactions as vertices, systems are shown to belong to only three states : simple, complicated, and complex, the main properties of which are discussed. The first two states have been studied at length over past centuries, and last one finds its origin in the elementary fact that when system performance is pushed up, there exists a threshold above which interaction between components overtake outside interaction. Then system self-organizes and filters corresponding outer action, making it more robust to outer effect, with emergence of new behaviour not predictable from only components study. Examples in Physics and Biology are given. Three main classes of complexity behaviour are distinguished corresponding to different grades of difficulty to handle their dynamics. The interest of using complex state properties in man-made systems is stressed. Important issues concentrating on the difficult balance between relative system isolation when becoming complex and required delegation of corresponding new capability from (outside) operator are discussed. This implies giving the system some intelligence in an adequate frame between new augmented system state and supervising operator, with consequences on canonical system triplet {effector-sensor-controller} to be reorganized in this new setting. Moreover, entering complexity state opens the possibility for function to feedback onto structure, ie to mimic at technical level the invention of Nature over Her very long history. ", "machine_text": "  We propose a definition of complexity in terms of the concepts of self-organization and emergence as an alternative to more eclectic definitions of complexity that are prevalent in the literature. Our definition encompasses several key attributes of complex systems. In particular, we emphasize the important role of information in the definition of complex systems. We show that a system can be complex in one context and simple in another, and that the complexity of a system can be assessed from the perspective of an observer or an agent. We illustrate the utility of our definition with examples drawn from physics, biology, and computer science, and we show how our definition can be used to identify new examples of complex systems.  The concept of complexity is not well defined, yet it is widely used in many fields, such as physics, biology, computer science, and the social sciences. In particular, the concepts of self-organization and emergence are often used to characterize complex systems, but there is no consensus about what constitutes a complex system, nor is there agreement about what characteristics of a system make it complex. This paper proposes a definition of complexity in terms of the concepts of self-organization and emergence that encompasses several key attributes of complex systems. We emphasize the important role of information in the definition of complex systems, and we show that a system can be complex in one context and simple in another. We illustrate the utility of our definition with examples drawn from physics, biology, and computer science, and we show how our definition can be used to identify new examples of complex systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optimizing future imaging survey of galaxies to confront dark energy and   modified gravity models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2949, "human_text": "  We consider the extent to which future imaging surveys of galaxies can distinguish between dark energy and modified gravity models for the origin of the cosmic acceleration. Dynamical dark energy models may have similar expansion rates as models of modified gravity, yet predict different growth of structure histories. We parameterize the cosmic expansion by the two parameters, $w_0$ and $w_a$, and the linear growth rate of density fluctuations by Linder's $\\gamma$, independently. Dark energy models generically predict $\\gamma \\approx 0.55$, while the DGP model $\\gamma \\approx 0.68$. To determine if future imaging surveys can constrain $\\gamma$ within 20 percent (or $\\Delta\\gamma<0.1$), we perform the Fisher matrix analysis for a weak lensing survey such as the on-going Hyper Suprime-Cam (HSC) project. Under the condition that the total observation time is fixed, we compute the Figure of Merit (FoM) as a function of the exposure time $\\texp$. We find that the tomography technique effectively improves the FoM, which has a broad peak around $\\texp\\simeq {\\rm several}\\sim 10$ minutes; a shallow and wide survey is preferred to constrain the $\\gamma$ parameter. While $\\Delta\\gamma < 0.1$ cannot be achieved by the HSC weak-lensing survey alone, one can improve the constraints by combining with a follow-up spectroscopic survey like WFMOS and/or future CMB observations. ", "machine_text": "  We propose a method to optimize the design of a galaxy survey to measure the dark energy density and test modified gravity models. We consider a linear combination of the density field and the scale factor as a proxy for the dark energy density and test the reliability of this metric to measure the dark energy density as a function of redshift with different galaxy survey strategies. We find that the galaxy number density evolution is a reliable proxy if the galaxies are sufficiently distant, and that the density field evolution is a reliable proxy if the galaxies are sufficiently close. In both cases the reliability of the proxy decreases with the redshift. We then optimize the design of the survey to measure the evolution of this proxy as a function of redshift, while maximizing the reliability of the measurement and minimizing the survey cost. The optimized design is characterized by a varying density of galaxies as a function of redshift. We find that in order to have a reliable measurement of the dark energy density evolution the number density of galaxies needs to be larger at high redshift than the number density of galaxies in the local universe. We also find that in order to reliably test a modified gravity model the number density of galaxies needs to be smaller at high redshift than the number density of galaxies in the local universe. We then study the tradeoff between the survey cost and the reliability of the measurement, and find that the survey cost can be reduced by a factor of two without significantly compromising the reliability of the measurement by relaxing some of the assumptions made in the optimization. We finally discuss the practical implications of our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Light Heavy MSSM Higgs Bosons at Large tan_beta. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0977, "human_text": "  The region of MSSM Higgs parameter space currently excluded by the CDF Collaboration, based on an analysis of ~1 fb^-1 of integrated luminosity, is less than the expected sensitivity. We analyze the potential implications of the persistence of this discrepancy within the MSSM, assuming that the soft supersymmetry-breaking contributions to scalar masses are universal, apart from those to the Higgs masses (the NUHM model). We find that a light heavy MSSM Higgs signal in the unexcluded part of the sensitive region could indeed be accommodated in this simple model, even after taking into account other constraints from cold dark matter, electroweak precision observables and B physics observables. In this case the NUHM suggests that supersymmetric signatures should also be detectable in the near future in some other measurements such as BR(B_s -> mu+ mu-), BR(b -> s gamma) and (g-2)_mu, and M_h would have to be very close to the LEP exclusion limit. In addition, the dark matter candidate associated with this model should be on the verge of detection in direct detection experiments. ", "machine_text": " We study the production of heavy Higgs bosons in association with top quarks at hadron colliders, using the massive Stimulated Gravity Waves (SGW) mechanism. We find that the corresponding Higgs production cross section is enhanced compared to the Standard Model (SM) prediction, by a significant factor of  \u223c 5\u201310, provided that the mass of the heavy Higgs bosons is in the range of  \u223c 1\u20133 TeV. Our result is based on the assumption that the SGW couples to the Higgs sector in a similar way as it does to the quark sector, which is not an entirely safe assumption. If the coupling is instead much stronger to the Higgs sector, the predicted Higgs production rate can be enhanced by as much as a factor of  \u223c 100. This should be within the reach of upcoming hadron colliders such as the LHC. We also estimate the expected SGW mass threshold to be  \u223c 1\u20132 TeV. This is much smaller than the current theoretical upper limit of  \u223c 5\u201310 TeV, but still large enough to explain the non-observation of SGW so far.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Production of magnetic energy by macroscopic turbulence in GRB   afterglows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1819, "human_text": "  Afterglows of gamma-ray bursts are believed to require magnetic fields much stronger than that of the compressed pre-shock medium. As an alternative to microscopic plasma instabilities, we propose amplification of the field by macroscopic turbulence excited by the interaction of the shock with a clumpy pre-shock medium, for example a stellar wind. Using a recently developed formalism for localized perturbations to an ultra-relativistic shock, we derive constraints on the lengthscale, amplitude, and volume filling factor of density clumps required to produce a given magnetic energy fraction within the expansion time of the shock, assuming that the energy in the field achieves equipartion with the turbulence. Stronger and smaller-scale inhomogeneities are required for larger shock Lorentz factors. Hence it is likely that the magnetic energy fraction evolves as the shock slows. This could be detected by monitoring the synchrotron cooling frequency if the radial density profile ahead of the shock, smoothed over clumps, is known. ", "machine_text": " We have developed a theory of energy generation by macroscopic turbulence in GRB afterglows, based on the idea that the energy is extracted from the afterglow turbulence by a violently rotating magnetic field. We consider a homogeneous isotropic afterglow with uniform density and temperature, and a turbulence velocity distribution described by the Kolmogorov model. We find that the energy extraction by the magnetic field is highly efficient, with an efficiency of about 60-70%. We also find that the energy in the magnetic field increases approximately linearly with the Kolmogorov scale and the square of the magnetic field rotation velocity, and decreases with the inverse of the magnetic field radius. These results agree with our previous estimates based on a numerical simulation. We also analyze the energy spectrum of the magnetic field, and find that it is consistent with a Maxwell distribution with a variance proportional to the inverse of the Kolmogorov scale. We discuss the physical mechanisms that may be responsible for the energy generation in the magnetic field, and explain why the energy generation is more efficient in the afterglow than in the inflowing gas. We also suggest a method for measuring the energy density in the magnetic field in a galaxy-sized magnetic field generator.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: BL Lac Contribution to the Extragalactic Gamma-Ray Background. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3778, "human_text": "  Very high energy gamma-rays from blazars traversing cosmological distances through the metagalactic radiation field can convert into electron-positron pairs in photon-photon collisions. The converted gamma-rays initiate electromagnetic cascades driven by inverse-Compton scattering off the microwave background photons. Using a model for the time-dependent metagalactic radiation field consistent with all currently available far-infrared-to-optical data, we calculate the cascade contribution from faint, unresolved high- and low-peaked blazars to the extragalactic gamma-ray background as measured by EGRET. For low-peaked blazars, we adopt a spectral index consistent with the mean spectral index of EGRET detected blazars, and the luminosity function determined by Chiang and Mukherjee (1998). For high-peaked blazars, we adopt template spectra matching prototype sources observed with air-Cherenkov telescopes up to 30 TeV, and a luminosity function based on X-ray measurements. The low number of about 20 for nearby high-peaked blazars with a flux exceeding 10^-11 cm^-2 s^-1 above 300 GeV inferred from the luminosity function is consistent with the results from air-Cherenkov telescope observations. Including the cascade emission from higher redshifts, the total high-peaked blazar contribution to the observed gamma-ray background at GeV energies can account up to about 30. ", "machine_text": " We present a model of the extragalactic gamma-ray background (EGB) based on a parameterization of the observed spatial distribution of BL Lacertae objects. We find that a contribution of 4.2 kpc^2 from BL Lac objects is sufficient to explain the observed EGB, and we show that this is consistent with the simplest possible model in which BL Lac objects are the only population of extragalactic gamma-ray sources. We propose that BL Lac objects contribute to the EGB through a combination of (i) anisotropic diffusion of gamma rays in the intergalactic medium and (ii) a source distribution that peaks at the same scale as the EGB. We show that this model naturally explains why the EGB is nearly isotropic, despite the fact that the distribution of BL Lac objects is highly anisotropic. This model requires that the magnetic field in the BL Lac objects be less than about 1 kG, in agreement with observations. We find that this model predicts a correlation between the EGB and the large-scale structure of the Universe, and we present observations that are consistent with this prediction. We show that this model has several testable predictions, and we discuss prospects for testing these predictions with current and future gamma-ray telescopes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Corbino experimental set-up for Cooper pair mass spectroscopy and   determination of mobility in normal phase. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2582, "human_text": "  We are suggesting an electronic method for Cooper pair mass spectroscopy of thin superconducting films. The method can be applied, for example, for 100 nm thin high-T_c films grown on insulator substrate 10 mm X 10 mm. In Corbino geometry two Ohmic contacts have to be made on the film evaporating Ag or using silver paste: one circle with radius r_a (1) and a ring electrode with internal radius r_b (2). In the in-between space (r_a,r_b) a ring electrode from mylar assures a capacitive connection between the superconducting layer and the metallized surface (3) of the mylar. In such a way we have an field effect transistor (FET) type structure with a circular gate. When at low enough temperatures T << T_c an AC current with frequency omega is applied between the circle source (1) and the ring-shaped drain (2) an AC Bernoulli voltage with double frequency 2f appears between the gate (3) and the source (1). The 2f signal depends on Cooper pair effective mass and its systematic investigation gives a Cooper pair mass spectroscopy. In the normal phase 2f gives logarithmic derivative of the density of states (DOS) with respect of Fermi energy. Applying a gate voltage in the same structure gives the mobility of the normal phase. ", "machine_text": "  We report on a Corbino experimental set-up which we have developed for Cooper pair mass spectroscopy and for the determination of the mobility in normal phase. The set-up is based on the use of a single layer of Corbino cups on a microstrip line. The modulation frequency of the radio frequency field in the Corbino cups is kept at 6.8 GHz, and the carrier frequency at 1.37 GHz. A 100% duty cycle is used. The experimental set-up is fed with a generator for the radio frequency field, a generator for the magnetic field, a circuit for the measurement of the current, and a computer for the control of the parameters and for the treatment of the data. The operation of the set-up is similar to that of a Mass Spectrometer. We use the Ronchi-Ferry method for the determination of the mobility, and the Huffman method for the determination of the ion mass. We obtained the mobility of a polymer and we obtained the mass of several ions. We also obtained the mass and the mobility of a biopolymer in different stages of degradation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Collision Between The Milky Way And Andromeda. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.117, "human_text": "  We use a N--body/hydrodynamic simulation to forecast the future encounter between the Milky Way and the Andromeda galaxies, given current observational constraints on their relative distance, relative velocity, and masses. Allowing for a comparable amount of diffuse mass to fill the volume of the Local Group, we find that the two galaxies are likely to collide in a few billion years - within the Sun's lifetime. During the the interaction, there is a chance that the Sun will be pulled away from its present orbital radius and reside in an extended tidal tail. The likelihood for this outcome increases as the merger progresses, and there is a remote possibility that our Sun will be more tightly bound to Andromeda than to the Milky Way before the final merger. Eventually, after the merger has completed, the Sun is most likely to be scattered to the outer halo and reside at much larger radii (>30 kpc). The density profiles of the stars, gas and dark matter in the merger product resemble those of elliptical galaxies. Our Local Group model therefore provides a prototype progenitor of late--forming elliptical galaxies. ", "machine_text": "  We present a numerical investigation of the collision between the Milky Way and Andromeda galaxies. We solve numerically the equations for conservation of momentum and energy, and for the correct numerical procedure we use the particle method. The initial conditions for the two galaxies are taken from the galaxies' actual motions. The total number of particles is set to 2 x 10^6, and the time-step is chosen to be 0.5%. We run the model for several initial conditions and for different mass for the dark matter in the two galaxies. For all the runs we monitor the total number of particles, and the distribution of particles in the two galaxies after the collision. We found that the total number of particles is reduced in the collision, and we observe a clear difference in the distribution of particles in the two galaxies, with more particles in the trailing galaxy. We discuss our results in the framework of the actual collision, and we show that the difference in the number of particles in the two galaxies is consistent with the distribution of the observed dark matter in the two galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coalition Games with Cooperative Transmission: A Cure for the Curse of   Boundary Nodes in Selfish Packet-Forwarding Wireless Networks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3292, "human_text": "  In wireless packet-forwarding networks with selfish nodes, applications of a repeated game can induce the nodes to forward each others' packets, so that the network performance can be improved. However, the nodes on the boundary of such networks cannot benefit from this strategy, as the other nodes do not depend on them. This problem is sometimes known as the curse of the boundary nodes. To overcome this problem, an approach based on coalition games is proposed, in which the boundary nodes can use cooperative transmission to help the backbone nodes in the middle of the network. In return, the backbone nodes are willing to forward the boundary nodes' packets. The stability of the coalitions is studied using the concept of a core. Then two types of fairness, namely, the min-max fairness using nucleolus and the average fairness using the Shapley function are investigated. Finally, a protocol is designed using both repeated games and coalition games. Simulation results show how boundary nodes and backbone nodes form coalitions together according to different fairness criteria. The proposed protocol can improve the network connectivity by about 50%, compared with pure repeated game schemes. ", "machine_text": "  We consider a class of games that arise in the analysis of cooperative transmission in wireless networks. These are coalition games with an odd number of players, in which the coalition formation is accompanied by a division of the transmission load among the coalition members. We show that the curse of boundary nodes, which plagues many selfish packet-forwarding wireless networks, can be cured by allowing the boundary nodes to cooperate in the transmission process. We show that this leads to a more efficient network, in terms of the cost-rate performance metric. We consider both the case where the transmission load is divided equally among the coalition members, and the case where the load is not equally divided, but is instead allocated in proportion to the residual capacity of the coalition members. We also consider the impact of a hybrid strategy, where a given node may cooperate with its neighbors on some links and yet still retain the ability to act selfishly on other links. We show that such a hybrid strategy can lead to a further improvement in the cost-rate performance metric.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Solutions of fractional reaction-diffusion equations in terms of the   H-function. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0329, "human_text": "  This paper deals with the investigation of the solution of an unified fractional reaction-diffusion equation associated with the Caputo derivative as the time-derivative and Riesz-Feller fractional derivative as the space-derivative. The solution is derived by the application of the Laplace and Fourier transforms in closed form in terms of the H-function. The results derived are of general nature and include the results investigated earlier by many authors, notably by Mainardi et al. (2001, 2005) for the fundamental solution of the space-time fractional diffusion equation, and Saxena et al. (2006a, b) for fractional reaction- diffusion equations. The advantage of using Riesz-Feller derivative lies in the fact that the solution of the fractional reaction-diffusion equation containing this derivative includes the fundamental solution for space-time fractional diffusion, which itself is a generalization of neutral fractional diffusion, space-fractional diffusion, and time-fractional diffusion. These specialized types of diffusion can be interpreted as spatial probability density functions evolving in time and are expressible in terms of the H-functions in compact form. ", "machine_text": " We consider the solution of a class of reaction-diffusion equations in which the coefficients may be singular and in which the reaction term is given by a sum of coefficients times the fractional Laplacian. The solution of these equations is given in terms of the H-function, a special function which has been extensively used in the study of partial differential equations. The motivation for this work is twofold: to extend the theory of solutions of reaction-diffusion equations to a class of nonlinear equations which includes the Coupey- Harding equation and to obtain new properties of the H-function. The main ideas and methodology used to obtain the results are as follows. We show that the solution of a class of reaction-diffusion equations which contains the Coupey-Harding equation can be obtained in terms of the H-function. We show that the H-function can be expressed in terms of a particular solution of a certain reaction-diffusion equation with singular coefficients. We then obtain the solution of the reaction-diffusion equations in terms of the H-function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Controllability of the heat and wave equations and their finite   difference approximations by the shape of the domain. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4221, "human_text": "  In this article we study a controllability problem for a parabolic and a hyperbolic partial differential equations in which the control is the shape of the domain where the equation holds. The quantity to be controlled is the trace of the solution into an open subdomain and at a given time, when the right hand side source term is known. The mapping that associates this trace to the shape of the domain is nonlinear. We show (i) an approximate controllability property for the linearized parabolic problem and (ii) an exact local controllability property for the linearized and the nonlinear equations in the hyperbolic case. We then address the same questions in the context of a finite difference spatial semi-discretization in both the parabolic and hyperbolic problems. In this discretized case again we prove a local controllability result for the parabolic problem, and an exact controllability for the hyperbolic case, applying a local surjectivity theorem together with a unique continuation property of the underlying adjoint discrete system. ", "machine_text": "  We consider the controllability of the heat and wave equations and their finite difference approximations by the shape of the domain. The motivating example is thescribbling of a line on a piece of paper. If the line is straight, then it is easy to predict the shape of the line after it has been drawn (it is a straight line). However, if the line is curved, then it is not so easy to predict the shape of the line after it has been drawn (it is a curve). We show that the ability to predict the shape of a solution to the heat or wave equation after an initial condition has been imposed is equivalent to the ability to control the solution by the shape of the domain. As such, the study of controllability by the shape of the domain is a natural generalization of the classical study of control by a line of observations. In particular, we show that the set of initial conditions that can be controlled by a particular shape is equivalent to the set of lines that can be drawn on the domain without ever having to lift the pen. For the heat equation, we show that the set of initial conditions that can be controlled by the shape of the domain is equivalent to the set of lines that can be drawn on the domain using only one intersection with each boundary. For the wave equation, we show that the set of initial conditions that can be controlled by the shape of the domain is equivalent to the set of lines that can be drawn on the domain without ever having to lift the pen and such that the total curvature is always $\\ge 0$. As an application, we consider the finite difference approximations to the heat and wave equations defined by different meshes on the domain. We show that, in a natural sense, the controllability by the shape of the domain is equivalent to the accuracy of the approximation. As such, the study of controllability by the shape of the domain provides a way to understand the properties of the solution to the heat and wave equations on a general domain.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Complementarity in the Einstein-Bohr Photon Box. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2764, "human_text": "  The photon box thought experiment can be considered a forerunner of the EPR-experiment: by performing suitable measurements on the box it is possible to ``prepare'' the photon, long after it has escaped, in either of two complementary states. Consistency requires that the corresponding box measurements be complementary as well. At first sight it seems, however, that these measurements can be jointly performed with arbitrary precision: they pertain to different systems (the center of mass of the box and an internal clock, respectively). But this is deceptive. As we show by explicit calculation, although the relevant quantities are simultaneously measurable, they develop non-vanishing commutators when calculated back to the time of escape of the photon. This justifies Bohr's qualitative arguments in a precise way; and it illustrates how the details of the dynamics conspire to guarantee the requirements of complementarity. In addition, our calculations exhibit a ``fine structure'' in the distribution of the uncertainties over the complementary quantities: depending on when the box measurement is performed, the resulting quantum description of the photon differs. This brings us close to the argumentation of the later EPR thought experiment. ", "machine_text": "  We investigate a quantum system composed of two uncorrelated photons, which can be thought of as a special case of the Einstein-Bohr photon box. We find a strong analogy with the usual (classical) photon box, in the sense that one can define a suitable analogue of the meta-stable state which has a real probability to be realized. However, unlike the classical case, the state with two photons has a very peculiar statistical structure: although the individual photon detectors have a 50 % chance to register a photon, the probability that both detectors simultaneously register a photon is only about 10 %. We analyze this incompleteness from the point of view of the formalism of quantum mechanics, and we show that it can be understood as a consequence of the non-locality of the quantum state. We finally draw a lesson from this example, in the form of a heuristic principle which we call \"complementarity of the resources\". This principle, which is inspired on the complementarity of the outcomes in the Einstein-Bohr photon box, can be thought of as a generalization of the usual concept of quantum complementarity. We illustrate the application of this principle with the example of a thought experiment concerning a \"quantum Cheshire cat\".", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stability of spinor Fermi gases in tight waveguides. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0937, "human_text": "  The two and three-body correlation functions of the ground state of an optically trapped ultracold spin-1/2 Fermi gas (SFG) in a tight waveguide (1D regime) are calculated in the plane of even and odd-wave coupling constants, assuming a 1D attractive zero-range odd-wave interaction induced by a 3D p-wave Feshbach resonance, as well as the usual repulsive zero-range even-wave interaction stemming from 3D s-wave scattering. The calculations are based on the exact mapping from the SFG to a ``Lieb-Liniger-Heisenberg'' model with delta-function repulsions depending on isotropic Heisenberg spin-spin interactions, and indicate that the SFG should be stable against three-body recombination in a large region of the coupling constant plane encompassing parts of both the ferromagnetic and antiferromagnetic phases. However, the limiting case of the fermionic Tonks-Girardeau gas (FTG), a spin-aligned 1D Fermi gas with infinitely attractive p-wave interactions, is unstable in this sense. Effects due to the dipolar interaction and a Zeeman term due to a resonance-generating magnetic field do not lead to shrinkage of the region of stability of the SFG. ", "machine_text": "  We investigate the stability of spinor Fermi gases in tight waveguides. We find a rich variety of dynamic behavior, including several types of lasing and a new type of radiationless decay that we call a superradiation. Our results suggest new ways to achieve laser action in atomic gases and may be useful for improving the performance of atomic refrigerators.  We consider a one-dimensional (1D) model of a spin-1/2 Fermi gas in a tight waveguide, that is, a model in which the atoms are localized in a narrow channel. We find a rich variety of dynamic behavior, including several types of lasing and a new type of radiationless decay that we call a superradiation. Our results suggest new ways to achieve laser action in atomic gases and may be useful for improving the performance of atomic refrigerators.  We consider a one-dimensional (1D) model of a spin-1/2 Fermi gas in a tight waveguide, that is, a model in which the atoms are localized in a narrow channel. We find a rich variety of dynamic behavior, including several types of lasing and a new type of radiationless decay that we call a superradiation. Our results suggest new ways to achieve laser action in atomic gases and may be useful for improving the performance of atomic refrigerators.  We find a rich variety of dynamic behavior, including several types of lasing and a new type of radiationless decay that we call a superradiation. Our results suggest new ways to achieve laser action in atomic gases and may be useful for improving the performance of atomic refrigerators.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Linear pre-metric electrodynamics and deduction of the light cone. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2193, "human_text": "  We formulate a general framework for describing the electromagnetic properties of spacetime. These properties are encoded in the `constitutive tensor of the vacuum', a quantity analogous to that used in the description of material media. We give a generally covariant derivation of the Fresnel equation describing the local properties of the propagation of electromagnetic waves for the case of the most general possible linear constitutive tensor. We also study the particular case in which a light cone structure is induced and the circumstances under which such a structure emerges. In particular, we will study the relationship between the dual operators defined by the constitutive tensor under certain conditions and the existence of a conformal metric. Closure and symmetry of the constitutive tensor will be found as conditions which ensure the existence of a conformal metric. We will also see how the metric components can be explicitly deduced from the constitutive tensor if these two conditions are met. Finally, we will apply the same method to explore the consequences of relaxing the condition of symmetry and how this affects the emergence of the light cone. ", "machine_text": "  We study the problem of detecting an electric field along a line in the presence of a magnetic field which is perpendicular to the line and constant along the line. We show that in this case the detected electric field is a constant multiple of the incident field, and that this multiple is proportional to the ratio of the strengths of the two fields. We deduce a method for measuring the two fields simultaneously which does not depend on any scalar parameter, and hence is applicable in any inertial frame. This method can be used to measure the ratio of the strengths of the two fields, provided that the strengths of the two fields are different at the two ends of the line. We show that if the two fields are not orthogonal at every point along the line, then the detected field is not proportional to the ratio of the strengths of the two fields. We deduce a geometric construction which shows that the orthogonal condition is equivalent to the statement that the two fields are equal at every point along the line. This deduction is made by means of a suitable choice of coordinate system. We also show that if the two fields are not equal at every point along the line, then there is a point along the line at which the detected field is equal to zero.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Direct CP violation in $\\bar{B}^0 \\to \\rho^0(\\omega)\\rho^0(\\omega) \\to   \\pi^+\\pi^-\\pi^+\\pi^-$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3132, "human_text": "  We study the direct CP violation in $\\bar{B}^0 \\to \\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$ (with unpolarized $\\rho^0(\\omega)$) via the $\\rho-\\omega$ mixing mechanism which causes a large strong phase difference and consequently a large CP violating asymmetry when the masses of the $\\pi^+\\pi^-$ pairs are in the vicinity of the $\\omega$ resonance. Since there are two $\\rho (\\omega)$ mesons in the intermediate state $\\rho-\\omega$ mixing contributes twice to the first order of isospin violation, leading to an even larger CP violating asymmetry (could be 30% -- 50% larger) than in the case where only one $\\rho (\\omega)$ meson is involved. The CP violating asymmetry depends on the Cabibbo-Kobayashi-Maskawa (CKM) matrix elements and the hadronic matrix elements. The factorization approach is applied in the calculation of the hadronic matrix elements with the nonfactorizable effects being included effectively in an effective parameter, $N_c$. We give the constraint on the range of $N_c$ from the latest experimental data for the branching ratios for $\\bar{B}^0 \\to\\rho^0\\rho^0$ and $\\bar{B}^0 \\to\\rho^+\\rho^-$. We find that the CP violating asymmetry could be very large (even more than 90% for some values of $N_c$). It is shown that the sensitivity of the CP violating asymmetry to $N_c$ is large compared with its smaller sensitivity to the CKM matrix elements. We also discuss the possibility to remove the mod $(\\pi)$ ambiguity in the determination of the CP violating phase angle $\\alpha$ through the measurement of the CP violating asymmetry in the decay $\\bar{B}^0\\to \\rho^0(\\omega)\\rho^0(\\omega) \\to \\pi^+\\pi^-\\pi^+\\pi^-$. ", "machine_text": " We study the direct CP violation in $\\bar{B}^0 \\to \\rho^0(\\omega)\\rho^0(\\omega) \\to   \\pi^+\\pi^-\\pi^+\\pi^-$. We show that the direct CP violation in this channel is small and its direct CP asymmetry is not sensitive to the intermediate $\\rho^0(\\omega)$ and $\\omega$, where $\\omega$ is the first harmonic resonance.  This is an interesting problem since the Standard Model (SM) prediction for the direct CP violation in this channel is very large, about $10^{-5}$. The huge direct CP violation in this channel could be a serious problem for the SM. We show that the direct CP violation in this channel could be reduced to a very small number, about $10^{-8}$, by a simple trick, i.e. to consider the direct CP violation only in the massless case. Since the massless case is very close to the massive case in this channel, the direct CP violation in this channel is small in the massive case as well. Therefore the large direct CP violation in the SM is not a serious problem.  We also show that the direct CP asymmetry in this channel is not sensitive to the intermediate $\\rho^0(\\omega)$ and $\\omega$, where $\\omega$ is the first harmonic resonance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measuring the spin polarization and Zeeman energy of a spin-polarized   electron gas: Comparison between Raman scattering and photoluminescence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1255, "human_text": "  We compare resonant electronic Raman scattering and photoluminescence measurements for the characterization of a spin-polarized two-dimensional electron gas embedded in $\\text{Cd}_{1-x}\\text{Mn}_x\\text{Te}$ single quantum wells. From Raman scattering by single-particle excitations in a zero magnetic field, we measure the Fermi velocity and then obtain the Fermi energy (as well as the electron density), which is comparable to that extracted from photoluminescence for moderate electron densities, assuming a bare band-edge mass. At large electron densities, the Fermi energies derived from Raman scattering and photoluminescence differ. For an applied in-plane magnetic field and zero wave vector transferred to the electron gas, Raman scattering spectra show peaks at both the Zeeman energy $Z$, resulting from collective excitations of the spin-polarized electron gas, and the one electron spin-flip energy $Z^*$. Magneto-photoluminescence spectra show conduction band splitting that are equivalent to $Z$, suggesting that collective effects are present in the photoluminescence spectra. Assuming (as before) an uncorrected mass, the degree of spin polarization $\\zeta$ determined from the magneto-photoluminescence lineshape is found to differ from that derived from the magnetic field dependent Raman scattering measurements for large electron densities. We attribute the discrepancy in measuring $\\zeta$ and the Fermi energy to the renormalized mass resulting from many-body electron-electron interactions. ", "machine_text": " We report a theoretical investigation of the spin-dependent optical response of a spin-polarized electron gas. Two methods are employed: photoluminescence and Raman scattering. We evaluate the absolute value of the spin polarization and the Zeeman energy by comparison with measurements on a spin- ensembles in solid state quantum dots. Our main results can be summarized as follows. The spin- dependent photoluminescence is very sensitive to the mutual spin exchange interaction, which can be screened by a weak dipole-dipole interaction. We show that the relative strength of the two interactions can be extracted from the ratio of the two photoluminescence intensities. The sign of the spin polarization can be determined from the polarization of the photoluminescence. In the case of Raman scattering the situation is more complicated, because the spin- dependent Raman scattering process involves two different molecular vibrations. We show that in this case the intensity of the spin- dependent signal is not proportional to the square of the spin polarization, but rather to the absolute value of the spin polarization. Furthermore, the sign of the spin polarization can be determined from the polarization of the Raman scattering, provided that the ratio of the intensities of the two molecular vibrations is known.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geometry of PT-symmetric quantum mechanics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2959, "human_text": "  Recently, much research has been carried out on Hamiltonians that are not Hermitian but are symmetric under space-time reflection, that is, Hamiltonians that exhibit PT symmetry. Investigations of the Sturm-Liouville eigenvalue problem associated with such Hamiltonians have shown that in many cases the entire energy spectrum is real and positive and that the eigenfunctions form an orthogonal and complete basis. Furthermore, the quantum theories determined by such Hamiltonians have been shown to be consistent in the sense that the probabilities are positive and the dynamical trajectories are unitary. However, the geometrical structures that underlie quantum theories formulated in terms of such Hamiltonians have hitherto not been fully understood. This paper studies in detail the geometric properties of a Hilbert space endowed with a parity structure and analyses the characteristics of a PT-symmetric Hamiltonian and its eigenstates. A canonical relationship between a PT-symmetric operator and a Hermitian operator is established. It is shown that the quadratic form corresponding to the parity operator, in particular, gives rise to a natural partition of the Hilbert space into two halves corresponding to states having positive and negative PT norm. The indefiniteness of the norm can be circumvented by introducing a symmetry operator C that defines a positive definite inner product by means of a CPT conjugation operation. ", "machine_text": "  We introduce a class of 2D mechanical systems which have a natural generalization of the privileged signature of particles in Euclidean space, to signatures which are only determined up to an overall non-signed rotation. We show that this class of systems contains examples which are symmetric under a generalization of the proper Lorentz transformation to the 2D plane, and derive an action principle for this class of systems. The resulting system is symmetric under the full Lorentz group, but in general not under the proper Lorentz group. We analyze this system and find a close connection with the Poincare group. We show that for this class of systems the configuration space has a structure of a Poincare-space, and that this structure is related to the signatures of the particles. As an application, we show that the structure of the Poincare space of this class of systems can be used to construct an exotic type of mechanical system, with two different types of particles with different masses and moments of inertia.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Comparative study of complex N- and O-bearing molecules in hot molecular   cores. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1637, "human_text": "  We have observed several emission lines of two Nitrogen-bearing (C2H5CN and C2H3CN) and two Oxygen-bearing (CH3OCH3 and HCOOCH3) molecules towards a sample of well-known hot molecular cores (HMCs) in order to check whether the chemical differentiation seen in the Orion-HMC and W3(H_2O) between O- and N-bearing molecules is a general property of HMCs. With the IRAM-30m telescope we have observed 12 HMCs in 21 bands, centered at frequencies from 86250 to 258280 MHz. The rotational temperatures obtained range from ~100 to ~150 K in these HMCs. Single Gaussian fits performed to unblended lines show a marginal difference in the line peak velocities of the C2H5CN and CH3OCH3 lines, indicating a possible spatial separation between the region traced by the two molecules. On the other hand, neither the linewidths nor the rotational temperatures and column densities confirm such a result. By comparing the abundance ratio of the pair C2H5CN/C2H3CN with the predictions of theoretical models, we derive that the age of our cores ranges between 3.7 and 5.9x10^{4} yrs. The abundances of C2H5CN and C2H3CN are strongly correlated, as expected from theory which predicts that C2H3CN is formed through gas phase reactions involving C2H5CN. A correlation is also found between the abundances of C2H3CN and CH3OCH3, and C2H5CN and CH3OCH3. In all tracers the fractional abundances increase with the H_2 column density while they are not correlated with the gas temperature. ", "machine_text": " We have performed a comparative study of the complex N- and O-bearing molecules in hot molecular cores. Our objectives were to investigate the relative abundances of these species in the cores, and to determine the conditions under which they are formed. We have used a combination of observations of molecular lines and non-molecular lines from HCl and H2O to determine the relative abundances of these species in a sample of 20 hot molecular cores. We have found that the relative abundances of these species are very different in different cores. The most striking result is that in most cores the relative abundance of N2 is much larger than that of CO, while in some cores the reverse is true. We have also found that the relative abundances of O-bearing species are often different in different cores. We have found that the formation of these species is closely related to the physical conditions in the cores, especially the temperature and the abundance of C and H. In particular, we have found that the formation of N2 is strongly favored in cores with low C/H ratios, while the formation of CO is favored in cores with high C/H ratios. We have also found that the formation of O-bearing species is favored in cores with low C/H ratios.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measuring energy dependent polarization in soft gamma-rays using Compton   scattering in PoGOLite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1603, "human_text": "  Linear polarization in X- and gamma-rays is an important diagnostic of many astrophysical sources, foremost giving information about their geometry, magnetic fields, and radiation mechanisms. However, very few X-ray polarization measurements have been made, and then only mono-energetic detections, whilst several objects are assumed to have energy dependent polarization signatures. In this paper we investigate whether detection of energy dependent polarization from cosmic sources is possible using the Compton technique, in particular with the proposed PoGOLite balloon-experiment, in the 25-100 keV range. We use Geant4 simulations of a PoGOLite model and input photon spectra based on Cygnus X-1 and accreting magnetic pulsars (100 mCrab). Effective observing times of 6 and 35 hours were simulated, corresponding to a standard and a long duration flight respectively. Both smooth and sharp energy variations of the polarization are investigated and compared to constant polarization signals using chi-square statistics. We can reject constant polarization, with energy, for the Cygnus X-1 spectrum (in the hard state), if the reflected component is assumed to be completely polarized, whereas the distinction cannot be made for weaker polarization. For the accreting pulsar, constant polarization can be rejected in the case of polarization in a narrow energy band with at least 50% polarization, and similarly for a negative step distribution from 30% to 0% polarization. ", "machine_text": " We have developed a new method to measure the energy-dependent linear polarization of soft gamma-rays using the Compton scattering in a large, thick, rigid, parallel-plate avalanche counter (PPAC) made of lead-glass (PoGOLite). The motivation for this work is to improve the statistics of polarization measurement in the energy region around the polarization peak of the Compton scattered photon in PoGOLite, to study the depolarization effects in this energy region. The key idea is to use a large-area, thick, rigid, PoGOLite detector, which is robust against the thermal effect, and to increase the number of detector elements to improve the statistics. The improvement in the statistics is important to be able to study the polarization properties of the Compton scattered photon in a PoGOLite detector. The methodology we used is to prepare a large-area, thick, rigid, PoGOLite detector, and to use a multi-channel Anger camera to obtain the spatially-resolved, energy- and polarization-dependent detection probabilities. We obtained the energy- and polarization-dependent detection probabilities for a thick, rigid, PoGOLite detector with 462 detector elements. From the measured detection probabilities, we obtained the energy- and polarization-dependent mean-square-error and the energy- and polarization-dependent depolarization factors. We obtained the results for the energy region around the polarization peak of the Compton scattered photon in PoGOLite. From the results, we studied the energy- and polarization-dependent depolarization effects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Finite Euler products and the Riemann Hypothesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3448, "human_text": "  We show that if the Riemann Hypothesis is true, then in a region containing most of the right-half of the critical strip, the Riemann zeta-function is well approximated by short truncations of its Euler product. Conversely, if the approximation by products is good in this region, the zeta-function has at most finitely many zeros in it. We then construct a parameterized family of non-analytic functions with this same property. With the possible exception of a finite number of zeros off the critical line, every function in the family satisfies a Riemann Hypothesis. Moreover, when the parameter is not too large, they have about the same number of zeros as the zeta-function, their zeros are all simple, and they \"repel\". The structure of these functions makes the reason for the simplicity and repulsion of their zeros apparent and suggests a mechanism that might be responsible for the corresponding properties of the zeta-function's zeros. Computer evidence suggests that the zeros of functions in the family are remarkably close to those of the zeta-function (even for small values of the parameter), and we show that they indeed converge to them as the parameter increases. Furthermore, between zeros of the zeta-function, the moduli of functions in the family tend to twice the modulus of the zeta-function. Both assertions assume the Riemann Hypothesis. We end by discussing analogues for other L-functions and show how they give insight into the study of the distribution of zeros of linear combinations of L-functions. ", "machine_text": " We introduce and study a generalization of Euler products to functions meromorphic at the pole $\\infty$ of the Riemann zeta function. We show that, if the Riemann Hypothesis is true, then the coefficients of the expanded functions in the Riemann zeta function and its derivatives are constrained by a congruence relation. As an application, we show that the recent results of Bruner and Koornwinder and of foraginga on the periodicity of the values of $\\zeta(2\\cdot \\mathbb{Z})$ and $\\zeta(2\\cdot \\mathbb{Z}+1)$, respectively, can be understood as consequences of the finiteness of certain Euler products.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Higher order antibunching in intermediate states. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0697, "human_text": "  Since the introduction of binomial state as an intermediate state, different intermediate states have been proposed. Different nonclassical effects have also been reported in these intermediate states. But till now higher order antibunching or higher order subpoissonian photon statistics is predicted only in one type of intermediate state, namely shadowed negative binomial state. Recently we have shown the existence of higher order antibunching in some simple nonlinear optical processes to establish that higher order antibunching is not a rare phenomenon (J. Phys. B 39 (2006) 1137). To establish our earlier claim further, here we have shown that the higher order antibunching can be seen in different intermediate states, such as binomial state, reciprocal binomial state, hypergeometric state, generalized binomial state, negative binomial state and photon added coherent state. We have studied the possibility of observing the higher order subpoissonian photon statistics in different limits of intermediate states. The effect of different control parameters have also been studied in this connection and it has been shown that the depth of nonclassicality can be tuned by controlling various physical parameters. ", "machine_text": "  We investigate the statistics of the evolution of quantum states which are initially occupied by several entangled particles, but not in a pure state. For a large class of such states, a precise analytical formula for the evolution is derived, in the framework of Gaussian perturbation theory. The resulting evolution is found to be well described by a generalized outline of the Landau-Ginzburg- Wilson (LGW) theory. In particular, a parameter related to the violation of the Bell inequality and a parameter related to the fidelity of the evolution are introduced. Our results show that the evolution is mostly governed by the former parameter, in a way which is very similar to the well-known LGW evolution in pure states. However, we also find a strong dependence on the latter parameter, which leads to a number of surprising effects, some of which can be exploited for quantum information processing. Our results also imply a general method for finding simplified models which describe the evolution of mixed states well, for a large class of mixed states.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relating two standard notions of secrecy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0502, "human_text": "  Two styles of definitions are usually considered to express that a security protocol preserves the confidentiality of a data s. Reachability-based secrecy means that s should never be disclosed while equivalence-based secrecy states that two executions of a protocol with distinct instances for s should be indistinguishable to an attacker. Although the second formulation ensures a higher level of security and is closer to cryptographic notions of secrecy, decidability results and automatic tools have mainly focused on the first definition so far.   This paper initiates a systematic investigation of the situations where syntactic secrecy entails strong secrecy. We show that in the passive case, reachability-based secrecy actually implies equivalence-based secrecy for digital signatures, symmetric and asymmetric encryption provided that the primitives are probabilistic. For active adversaries, we provide sufficient (and rather tight) conditions on the protocol for this implication to hold. ", "machine_text": "  We relate two standard notions of secrecy for symmetric encryption algorithms. One is the notion of a family of encryption algorithms $\\mathcal{F}$ being (cca) secure, i.e., an encryption algorithm from $\\mathcal{F}$ is secure if any algorithm in $\\mathcal{F}$ is secure. The other notion is the one of (adaptively) chosen-key secure encryption algorithms, which roughly means that for any encryption algorithm $E$ there exists a (black-box) encryption algorithm $A$ such that $E$ is secure if and only if $A$ is secure. We show that if $\\mathcal{F}$ is (cca) secure, then for any encryption algorithm $E$ in $\\mathcal{F}$, there exists an (adaptively) chosen-key secure encryption algorithm $A$ such that $A$ is in $\\mathcal{F}$. We phrase this result in terms of (oca) constructions. We also show that the same result holds if $\\mathcal{F}$ is merely (adaptive) chosen-key secure. As a consequence we obtain that any (cca) secure encryption family contains (adaptive) chosen-key secure encryption algorithms, and that any (adaptive) chosen-key secure encryption family contains (cca) secure encryption algorithms.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: J1128+592: a highly variable IDV source. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0298, "human_text": "  Short time-scale radio variations of compact extragalactic radio quasars and blazars known as IntraDay Variability (IDV) can be explained in at least some sources as a propagation effect; the variations are interpreted as scintillation of radio waves in the turbulent interstellar medium of the Milky Way. One of the most convincing observational arguments in favor of a propagation-induced variability scenario is the observed annual modulation in the characteristic time scale of the variation due to the Earth's orbital motion. So far there are only two sources known with a well-constrained seasonal cycle. Annual modulation has been proposed for a few other less well-documented objects. However, for some other IDV sources source-intrinsic structural variations which cause drastic changes in the variability time scale were also suggested. J1128+592 is a recently discovered, highly variable IDV source. Previous, densely time-sampled flux-density measurements with the Effelsberg 100-m radio telescope (Germany) and the Urumqi 25-m radio telescope (China), strongly indicate an annual modulation of the time scale. The most recent 4 observations in 2006/7, however, do not fit well to the annual modulation model proposed before. In this paper, we investigate a possible explanation of this discrepancy. ", "machine_text": "  We present photometric observations of J1128+592, a highly variable object in the non-radial IDV category. The observations were made with the 1.5-m telescope at the Fred L. Giberson Observatory, in whole photometric stereo, using a 12-bit ST-8 CCD camera. We find that the accretion history of the system can be split into three distinct episodes, the last of which is still ongoing. The accretion episodes are punctuated by large gaps of several thousand accretion epochs, during which the accretion rate is several orders of magnitude smaller. The observed phenomenology is consistent with a massive, precessing accretion disc. We estimate the accretion rate to be $6\\times 10^{-4} M_{\\odot}yr^{-1}$, with a standard deviation of $\\sim 2\\times 10^{-3} M_{\\odot}yr^{-1}$. We find that the accretion disc likely contains at most $3\\times 10^{29} M_{\\odot}$, and we discuss the possibility that it is a primordial black hole. We find that the accretion disc has a mass less than $4\\times 10^{29} M_{\\odot}$. We also present photometric observations of the outbursts of J1128+592, in which we measure the accretion rate. We find that the accretion rate has a peak value of $6\\times 10^{-3} M_{\\odot}yr^{-1}$ and a standard deviation of $\\sim 10^{-4} M_{\\odot}yr^{-1}$. The observed phenomenology is consistent with a disc accretion rate that varies by a factor of $\\sim 10$, possibly due to precession. We find that the accretion disc likely contains at most $1\\times 10^{29} M_{\\odot}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Minimum Gap-opening Planet Mass in an Irradiated Circumstellar   Accretion Disk. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3436, "human_text": "  We consider the minimum mass planet, as a function of radius, that is capable of opening a gap in an $\\alpha$-accretion disk. We estimate that a half Jupiter mass planet can open a gap in a disk with accretion rate $\\dot M \\la 10^{-8} M_\\odot$/yr for viscosity parameter $\\alpha =0.01$, and Solar mass and luminosity. The minimum mass is approximately proportional to $\\dot M^{0.48} \\alpha^{0.8} M_*^{0.42} L_*^{-0.08}$. This estimate can be used to rule out the presence of massive planets in gapless accretion disks. We identify two radii at which an inwardly migrating planet may become able to open a gap and so slow its migration; the radius at which the heating from viscous dissipation is similar to that from stellar radiation in a flared disk, and the radius at which the disk has optical depth order 1 in a self-shadowed disk. If a gap opening planet cuts off disk accretion allowing the formation of a central hole or clearing in the disk then we would estimate that the clearing radius would approximately be proportional to the stellar mass. ", "machine_text": "  We investigate the minimum gap-opening planet mass (GM) for a planet in an irradiated circumstellar accretion disk. We show that the minimum GM depends sensitively on the accretion rate onto the disk, and for high accretion rates the minimum GM can be as low as several Jupiter masses. We also find that the minimum GM depends weakly on the disk viscosity parameter, and for most values of the viscosity parameter, the minimum GM is in the range of several Jupiter masses. These results suggest that giant irradiated accretion disks can be stable against gravitational collapse only if they are supported by a planet or aproto-planetary object with a mass in the range of several Jupiter masses or greater. For the lowest accretion rates considered, the minimum GM is much greater than several Jupiter masses, and in this case the disk is stable against gravitational collapse even in the absence of a planet or a proto-planetary object. We discuss our results in the context of planet formation and the evolution of irradiated accretion disks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cassini UVIS Observations of the Io Plasma Torus. IV. Modeling Temporal   and Azimuthal Variability. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.448, "human_text": "  In this fourth paper in a series, we present a model of the remarkable temporal and azimuthal variability of the Io plasma torus observed during the Cassini encounter with Jupiter. Over a period of three months, the Cassini Ultraviolet Imaging Spectrograph (UVIS) observed a dramatic variation in the average torus composition. Superimposed on this long-term variation, is a 10.07-hour periodicity caused by an azimuthal variation in plasma composition subcorotating relative to System III longitude. Quite surprisingly, the amplitude of the azimuthal variation appears to be modulated at the beat frequency between the System III period and the observed 10.07-hour period. Previously, we have successfully modeled the months-long compositional change by supposing a factor of three increase in the amount of material supplied to Io's extended neutral clouds. Here, we extend our torus chemistry model to include an azimuthal dimension. We postulate the existence of two azimuthal variations in the number of super-thermal electrons in the torus: a primary variation that subcorotates with a period of 10.07 hours and a secondary variation that remains fixed in System III longitude. Using these two hot electron variations, our model can reproduce the observed temporal and azimuthal variations observed by Cassini UVIS. ", "machine_text": " We present an analysis of temporal and azimuthal variability in the Io plasma torus observed by the Cassini UVIS instrument during the T18 flyby on December 31, 2010. We use a simple model in which the torus is treated as a plane layer of a constant density and we perform a temporal Fourier analysis of both the observed density distribution and the relative torus width. We find that the observed density distribution is well described by a sum of a DC term, a low-frequency ( ~ 1 day) sine wave, and a high-frequency ( ~ 6 hours) sine wave. We show that these two sine waves are related to the first and second harmonics of the orbital period of Io. In contrast, the torus width is not well described by any simple model, but we show that this is likely due to the projection effect. We discuss a number of possible physical causes of these non-negligible temporal and azimuthal variations in the Io plasma torus, including the intrinsic variability of the ionospheric plasma and the effects of the traveling torus on the surrounding plasma. We show that these causes are not mutually exclusive and that a combination of several physical processes can explain the observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Laplacian instability of planar streamer ionization fronts - an example   of pulled front analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2088, "human_text": "  Streamer ionization fronts are pulled fronts propagating into a linearly unstable state; the spatial decay of the initial condition of a planar front selects dynamically one specific long time attractor out of a continuous family. A transverse stability analysis has to take these features into account. In this paper we introduce a framework for this transverse stability analysis, involving stable and unstable manifolds in a weighted space. Within this framework, a numerical dynamical systems method for the calculation of the dispersion relation as an eigenvalue problem is defined and dispersion curves for different values of the electron diffusion constant and of the electric field ahead of the front are derived. Numerical solutions of the initial value problem confirm the eigenvalue calculations. The numerical work is complemented with analytical expressions for the dispersion relation in the limit of small and large wave numbers and with a fit formula for intermediate wave numbers. This empirical fit supports the conjecture that the smallest unstable wave length of the Laplacian instability is proportional to the diffusion length that characterizes the leading edge of the pulled ionization front. ", "machine_text": " We consider a diffusive planar streamer instability driven by the Laplacian term in the equations of hydrodynamics. The analysis is based on the idea of the so-called pulled front method, which enables one to study the streamer dynamics in the presence of an external force that acts to pull the front in the direction of the instability growth. The main aim of this work is to determine the necessary and sufficient conditions for the unbounded growth of the instability and the corresponding properties of the limit cycle, as well as to discuss the properties of the most unstable regime of the Laplacian instability. We show that the most unstable regime corresponds to the case when the strength of the pulling force is small compared to the front's growth rate. In this case, the corresponding limit cycle is a thin, long and very sensitive structure, which is able to be quickly excited by a small perturbation. The theoretical results are illustrated by numerical simulations in a simple model problem.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A unified shear-thinning treatment of both film thickness and traction   in EHD. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1798, "human_text": "  A conclusive demonstration has been provided that the nature of the shear-thinning, that affects both film thickness and traction in EHL contacts, follows the ordinary power-law rule that has been described by many empirical models of which Carreau is but one example. This was accomplished by accurate measurements in viscometers of the shear response of a PAO that possesses a very low critical stress for shear-thinning and accurate measurements in-contact of film thickness and traction under conditions which accentuate the shear-thinning effect. The in-contact central film thickness and traction were entirely predictable from the rheological properties obtained from viscometers using simple calculations. These data should be invaluable to researchers endeavoring to accurately simulate Hertz zone behavior since the shear-thinning rheology is extensively characterized and accurate in-contact data are available to test. In addition, a new model has been introduced that may be useful for the rheological characterization of mixtures. ", "machine_text": " We present a unified shear-thinning treatment of both film thickness and traction in EHD. The motivation for the research is that, first, the dewetting transition temperature Td depends on the shear rate, and second, the thickness and traction must be related in a general EHD model. Our key idea is to use the Ma-Leonard model as the basis for the analysis, and to generalize it by using a different expression for the shear-thinning coefficient in each of the two areas of the film where different boundary conditions are applied. We analyze the resulting model analytically and obtain a simple expression for the film thickness. Our methodology is in the form of a series of assumptions and simplifications, which are stated at the beginning of the paper and which we believe to be physically reasonable. Our results are in good quantitative agreement with previous work. The problem we attempt to solve is how to include the shear-thinning effect in a general EHD model. The practical application of our work is in the design of droplet-based microfluidic devices, where the contact angle and the thickness of the film are important parameters that are affected by the shear-thinning behavior of the fluid. Our findings have theoretical implications for a deeper understanding of the EHD problem, in which the effect of shear-thinning is not yet well-understood.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: H$_2$D$^+$ line emission in Proto-Planetary Disks. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.104, "human_text": "  %Context: {Previous studies have indicated that the 372.4 GHz ground transition of ortho-H$_2$D$^+$ might be a powerful probe of Proto-Planetary Disks. The line could be especially suited for study of the disk mid-plane, where the bulk of the mass resides and where planet formation takes place.} %Aims: {Provide detailed theoretical predictions for the line intensity, profile and maps expected for representative disk models.} %Methods: {We determine the physical and chemical structure of the disks from the model developed by Ceccarelli & Dominik (2005). The line emission is computed with the new radiative transfer method developed recently by Elitzur & Asensio Ramos (2006).} %Results: {We present intensity maps convolved with the expected ALMA resolution, which delineate the origin of the H$_2$D$^+$ 372.4 GHz line. In the disk inner regions, the line probes the conditions in the mid-plane out to radial distances of a few tens of AU, where Solar-like planetary systems might form. In the disk outermost regions, the line originates from slightly above the mid-plane. When the disk is spatially resolved, the variation of line profile across the image provides important information about the velocity field. Spectral profiles of the entire disk flux show a double peak shape at most inclination angles.} %Conclusions: {Our study confirms that the 372.4 GHz H$_2$D$^+$ line provides powerful diagnostics of the mid-plane of Proto-Planetary Disks. Current submillimeter telescopes are capable of observing this line, though with some difficulties. The future ALMA interferometer will have the sensitivity to observe and even spatially resolve the H$_2$D$^+$ line emission.} ", "machine_text": "  We present here results of a systematic study of the H$_{2}$D^{+}$ line in proto-planetary disks. Our data set consists of 19 disks observed with ALMA at 1.3 mm, 8 of which are new detections. We derive basic properties such as the line flux, width, and derived molecular abundance. We find that the H$_{2}$D^{+}$ line fluxes are correlated with the disk accretion rate, but not with the disk mass. The line width is anti-correlated with the disk mass, but not with the accretion rate. We have developed a model to explain these relationships. We find that the H$_{2}$D^{+}$ line in disks arises from discrete sources, which are likely to be embedded in the disk rather than above it. The observed correlation of the line with the accretion rate can be explained if the rate of source formation is proportional to the accretion rate. We find that the anti-correlation of the line width with disk mass can be explained if the size of the sources decreases with increasing disk mass. Our model further predicts that the line flux should decrease with increasing disk mass, which is in agreement with our data except for a few outliers. We discuss the implications of our model for the chemical and physical structure of proto-planetary disks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Identifying Dark Matter Burners in the Galactic center. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1324, "human_text": "  If the supermassive black hole (SMBH) at the center of our Galaxy grew adiabatically, then a dense \"spike\" of dark matter is expected to have formed around it. Assuming that dark matter is composed primarily of weakly interacting massive particles (WIMPs), a star orbiting close enough to the SMBH can capture WIMPs at an extremely high rate. The stellar luminosity due to annihilation of captured WIMPs in the stellar core may be comparable to or even exceed the luminosity of the star due to thermonuclear burning. The model thus predicts the existence of unusual stars, i.e. \"WIMP burners\", in the vicinity of an adiabatically grown SMBH. We find that the most efficient WIMP burners are stars with degenerate electron cores, e.g. white dwarfs (WD) or degenerate cores with envelopes. If found, such stars would provide evidence for the existence of particle dark matter and could possibly be used to establish its density profile. In our previous paper we computed the luminosity from WIMP burning for a range of dark matter spike density profiles, degenerate core masses, and distances from the SMBH. Here we compare our results with the observed stars closest to the Galactic center and find that they could be consistent with WIMP burners in the form of degenerate cores with envelopes. We also cross-check the WIMP burner hypothesis with the EGRET observed flux of gamma-rays from the Galactic center, which imposes a constraint on the dark matter spike density profile and annihilation cross-section. We find that the EGRET data is consistent with the WIMP burner hypothesis. New high precision measurements by GLAST will confirm or set stringent limits on a dark matter spike at the Galactic center, which will in turn support or set stringent limits on the existence of WIMP burners at the Galactic center. ", "machine_text": "  We present a method to identify dark matter (DM) burners in the galactic center, based on the analysis of the DM distribution in galaxies in the Local Volume. We select galaxies within 80 Mpc that have DM masses within 20% of the Milky Way's, and with face-on orbits. We find a correlation between the total DM content and the distribution of DM in the inner 10 kpc, with a power law index of -0.8. We show that this correlation is consistent with a model in which the inner 10 kpc is occupied by a spherical halo with a peak DM density of $2.3 \\times 10^{-3}$ GeV$^{-2}$. The mean distance to the center of this spherical halo is 6.4 kpc, which corresponds to the inner boundary of the Galactic bar. We conclude that the dominant process of DM burning in the Galactic center is the accretion of DM-laden gas clouds from the inner halo, and that the main accretion shock is located at the inner boundary of the bar. We estimate that $0.5 \\times 10^{12}$ DM kg-1 is accreted by the Galactic center per Myr, which is equivalent to a mass flow rate of 1.6%. This mass flow rate is an order of magnitude higher than the loss rate due to DM-hole formation in the Galactic disc, and implies that the Galactic DM fraction has been reduced by $\\sim 5 \\%$ since the accretion process started. We discuss a possible explanation for the origin of the excess loss rate, and show that the accretion process is likely to have started during the early stage of the formation of the Galactic disc.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantifying social group evolution. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0744, "human_text": "  The rich set of interactions between individuals in the society results in complex community structure, capturing highly connected circles of friends, families, or professional cliques in a social network. Thanks to frequent changes in the activity and communication patterns of individuals, the associated social and communication network is subject to constant evolution. Our knowledge of the mechanisms governing the underlying community dynamics is limited, but is essential for a deeper understanding of the development and self-optimisation of the society as a whole. We have developed a new algorithm based on clique percolation, that allows, for the first time, to investigate the time dependence of overlapping communities on a large scale and as such, to uncover basic relationships characterising community evolution. Our focus is on networks capturing the collaboration between scientists and the calls between mobile phone users. We find that large groups persist longer if they are capable of dynamically altering their membership, suggesting that an ability to change the composition results in better adaptability. The behaviour of small groups displays the opposite tendency, the condition for stability being that their composition remains unchanged. We also show that the knowledge of the time commitment of the members to a given community can be used for estimating the community's lifetime. These findings offer a new view on the fundamental differences between the dynamics of small groups and large institutions. ", "machine_text": "  Quantifying social group evolution  We are motivated by the question of how the structure of social groups changes over time. We consider a setting with two types of social groups: cliques and stars. A clique is a group of people who are all friends with each other, while a star is a group of one person and his or her N friends, where N > 2. We assume that groups are relatively stable and that the number of groups is small. Given a set of group memberships over time, our goal is to detect the changes in group structure that have occurred. We focus on the following two questions: (1) What is the rate of change of the number of groups and the number of people per group? (2) What is the rate of change of the number of cliques and the number of stars? We present a technique for quantifying the rates of change in the number of groups and the number of people per group. We show that the number of cliques decreases with a rate that is proportional to the number of cliques that exist at the previous time step. We also show that the number of stars increases with a rate that is proportional to the number of stars that exist at the previous time step. These results provide a simple way to quantify the evolution of social group structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum-like Representation of Macroscopic Configurations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3898, "human_text": "  The aim of this paper is to apply a contextual probabilistic model (in the spirit of Mackey, Gudder, Ballentine) to represent and to generalize some results of quantum logic about possible macroscopic quantum-like (QL) behaviour. The crucial point is that our model provides QL-representation of macroscopic configurations in terms of complex probability amplitudes -- wave functions of such configurations. Thus, instead of the language of propositions which is common in quatum logic, we use the language of wave functions which is common in the conventional presentation of QM. We propose a quantum-like representation algorithm, QLRA, which maps probabilistic data of any origin in complex (or even hyperbolic) Hilbert space. On the one hand, this paper clarifyes some questions in foundations of QM, since some rather mystical quantum features are illustrated on the basis of behavior of macroscopic systems. On the other hand, the approach developed in this paper may be used e.g. in biology, sociology, or psychology. Our example of QL-representation of hidden macroscopic configurations can find natural applications in those domains of science. ", "machine_text": "  We propose and investigate a general framework of quantum-like representations for macroscopic configurations. We show that such a framework can be constructed byextending the notion of spatial symmetry to the macroscopic level, and that this extension can be used to formulate a quantization procedure for such representations. Our main results are as follows. First, we show that if a macroscopic configuration possesses a certain kind of symmetry, the corresponding quantum-like representation can be obtained by means of a one-to-one mapping from the set of macroscopic degrees of freedom to the set of quantum degrees of freedom. Second, we show that if the mapping is not one-to-one, the quantum-like representation can still be obtained by means of a many-to-one mapping from the set of macroscopic degrees of freedom to the set of quantum degrees of freedom, which results in a representation with an excess number of quantum degrees of freedom. In both cases, the quantum-like representation can be obtained by a simple change of basis in the space of the macroscopic degrees of freedom. As an application, we show that the proposed framework can be used to represent the position and orientation of a macroscopic object in a gravitational field, and that the framework is consistent with the principles of general relativity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cooperative action in eukaryotic gene regulation: physical properties of   a viral example. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1852, "human_text": "  The Epstein-Barr virus (EBV) infects more than 90% of the human population, and is the cause of several both serious and mild diseases. It is a tumorivirus, and has been widely studied as a model system for gene (de)regulation in human. A central feature of the EBV life cycle is its ability to persist in human B cells in states denoted latency I, II and III. In latency III the host cell is driven to cell proliferation and hence expansion of the viral population, but does not enter the lytic pathway, and no new virions are produced, while the latency I state is almost completely dormant. In this paper we study a physico-chemical model of the switch between latency I and latency III in EBV. We show that the unusually large number of binding sites of two competing transcription factors, one viral and one from the host, serves to make the switch sharper (higher Hill coefficient), either by cooperative binding between molecules of the same species when they bind, or by competition between the two species if there is sufficient steric hindrance. ", "machine_text": " Cooperative action in eukaryotic gene regulation: physical properties of a viral example  We have recently proposed a simple model of cooperative gene regulation in which gene expression is governed by the binding of transcription factors to their cognate DNA-binding sites. In this model, the DNA-binding sites are assumed to be separated by a small distance, and the binding of a single transcription factor is insufficient to bridge the gap between the binding sites, resulting in cooperative binding of multiple transcription factors. We proposed that such cooperative binding could explain the rapid and efficient gene activation seen in many gene regulatory systems.  In this paper, we investigate the physical properties of cooperative gene regulation by analyzing a viral example. We consider the herpes simplex virus (HSV) gene regulatory system which is responsible for the switch from latency to lytic growth. This system is controlled by the binding of transcription factors to a set of DNA-binding sites located in the viral genome. We analyze the binding of these transcription factors to their cognate DNA-binding sites, and we show that this binding is cooperative, resulting in the rapid and efficient gene activation observed in the viral gene regulatory system.  We also investigate the physical properties of the viral genome, and we show that the cooperative binding of the transcription factors is a consequence of the physical properties of the viral genome. In particular, we show that the cooperative binding is a result of the long-range electrostatic interactions between the transcription factors and their cognate DNA-binding sites. We propose that cooperative gene regulation is a general feature of gene regulatory systems, and that it is a consequence of the physical properties of the genome.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Endogenous and exogenous dynamics of pressure fluctuations in an   impinging entrained-flow gasifier. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2832, "human_text": "  This paper has been withdrawn by the authors due to a fatal error in the analysis. The manuscript was submitted to Chemical Engineering Science. To clarify the situation, we copy the main comment from an anonymous referee here: \"To my understanding, the authors analyze i = 1 ... 63 time series and calculate their mean and standard deviation. These time series correspond to individual, single ignition processes. Is this correct? If yes, these processes, as Fig. 3 shows very clearly, are not stationary, and the pressure difference (i.e., the signal) quickly decays to zero. In this case both the mean and the standard deviation are poorly defined, for example because both depend in a trivial fashion on the observation period T. I am not aware of any study (including those cited by the authors) which allows for any conclusion from such non-stationary signals. The results of Menezes and Barabasi are strictly only valid for stationary time series, and they cannot be applied at all in this case.\" We agree with this insightful comment that our data are not stationary and the method adopted in our manuscript does not apply. We do not see any possibility to correct this error and decide to withdraw it. We would like to thank gratefully the referee and apologize for any inconvenience caused by our oversight. ", "machine_text": "  This article presents a new approach to modeling pressure fluctuations in an impinging entrained-flow gasifier. This approach is based on a two-phase flow model for the gasifier. The two-phase flow model was validated with experimental data obtained from a facility that has been instrumented with pressure taps at several locations. The model is used to investigate the influence of fuel injection location, operating conditions, and other parameters on the pressure fluctuations in the gasifier. The results of this investigation are used to develop a model for the endogenous dynamics of pressure fluctuations in the gasifier. The exogenous dynamics of the pressure fluctuations are also investigated and a model for these dynamics is developed. The models for the endogenous and exogenous dynamics of the pressure fluctuations in the gasifier are combined to obtain a model for the overall dynamics of the pressure fluctuations. This model is used to investigate the impact of various parameters on the dynamics of the pressure fluctuations. The results of this investigation are used to develop a model for the optimal operation of the gasifier.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Diagnostic tools for 3D unstructured oceanographic data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0189, "human_text": "  Most ocean models in current use are built upon structured meshes. It follows that most existing tools for extracting diagnostic quantities (volume and surface integrals, for example) from ocean model output are constructed using techniques and software tools which assume structured meshes. The greater complexity inherent in unstructured meshes (especially fully unstructured grids which are unstructured in the vertical as well as the horizontal direction) has left some oceanographers, accustomed to traditional methods, unclear on how to calculate diagnostics on these meshes. In this paper we show that tools for extracting diagnostic data from the new generation of unstructured ocean models can be constructed with relative ease using open source software. Higher level languages such as Python, in conjunction with packages such as NumPy, SciPy, VTK and MayaVi, provide many of the high-level primitives needed to perform 3D visualisation and evaluate diagnostic quantities, e.g. density fluxes. We demonstrate this in the particular case of calculating flux of vector fields through isosurfaces, using flow data obtained from the unstructured mesh finite element ocean code ICOM, however this tool can be applied to model output from any unstructured grid ocean code. ", "machine_text": "  Unstructured oceanographic data is a valuable source of information for ocean monitoring. However, the analysis and interpretation of such data is a challenging task, especially for 3D data sets. We have developed a set of diagnostic tools for 3D unstructured oceanographic data that allows for the interactive and semi-automatic analysis and interpretation of such data sets. The tools are based on the concept of identifying and tracking significant features in the data set, which can be used to identify different ocean phenomena, such as eddies, fronts, and vortices. The tools also provide a means for visualizing the data in a way that makes it easier to identify and understand the underlying ocean processes. The tools have been tested on a number of 3D data sets, including data from ocean monitoring programs and from various research projects, and have been shown to be effective in the analysis and interpretation of such data. The tools are available for download and use, and have been incorporated into the analysis workflow of a number of research groups.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Converting genetic network oscillations into somite spatial pattern. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3071, "human_text": "  In most vertebrate species, the body axis is generated by the formation of repeated transient structures called somites. This spatial periodicity in somitogenesis has been related to the temporally sustained oscillations in certain mRNAs and their associated gene products in the cells forming the presomatic mesoderm. The mechanism underlying these oscillations have been identified as due to the delays involved in the synthesis of mRNA and translation into protein molecules [J. Lewis, Current Biol. {\\bf 13}, 1398 (2003)]. In addition, in the zebrafish embryo intercellular Notch signalling couples these oscillators and a longitudinal positional information signal in the form of an Fgf8 gradient exists that could be used to transform these coupled temporal oscillations into the observed spatial periodicity of somites. Here we consider a simple model based on this known biology and study its consequences for somitogenesis. Comparison is made with the known properties of somite formation in the zebrafish embryo . We also study the effects of localized Fgf8 perturbations on somite patterning. ", "machine_text": "  We present a method to convert a genetic network dynamics into a spatial pattern. We consider a generic boolean genetic network and we show that, if the logical depth of the network is larger than two, the spatial pattern exhibits quasi-oscillations of the spatial frequency. We show that this is due to a slow-down of the dynamics at the spatial boundaries, which results in the formation of standing waves. We characterize the threshold spatial frequency for which the dynamics is stable against changes in the initial conditions. If the spatial frequency is lower than this threshold, the dynamics is stable against changes in the initial conditions, and we show that the associated spatial pattern is robust to changes in the underlying boolean network. As an application, we consider the evolution of the segmental identity in the context of a small genetic network and we show that the dynamics can be stable against changes in the initial conditions, provided that the spatial frequency is lower than a threshold. We discuss the relation between the dynamics of the underlying genetic network and the resulting spatial pattern.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Learning more from the Lorentz transformations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1786, "human_text": "  Admitting the validity of Lorentz transformations for the space as time coordinates of the same event we derive their differential form in order to underline the correct prerequisites for the application of time and length contraction or dilation effects. Furthermore we quantify the simultaneity error occurring in the relativity theory. Having done this, we analyse the root cause of these effects and identify it with a finite phase velocity associated with the moving frame. We define this phase velocity by analogy to the de Broglie wave associated with a moving particle. Based on this construct we demonstrate that the phase of the de Broglie waves further extended for stationary particles is a relativistic invariant being the same for all corresponding observers. Also the phase of the electromagnetic waves transporting energy at light speed is a relativistic invariant. Therefore the universe and its matter / energy may be seen as a superposition of waves propagating such that their phase is the same for all corresponding observers. The wave phase may replace the time as an invariant and universal reference. ", "machine_text": " We present a careful derivation of the Lorentz transformations for the case of a point particle. To this end, we make use of the formalism of geometric algebra. We show that, if the relative velocity is small compared to the speed of light, the ordinary Doppler effect can be obtained as a special case of the general theory. This general theory is applicable to any frame of reference and any velocity, even if the relative velocity tends to infinity. We show that the transformation parameters can be obtained by solving a set of consistent and independent constraints. This set of constraints is a direct consequence of the properties of the non-Euclidean geometry of 4-dimensional spacetime. Therefore our derivation is not based on any assumption about the structure of spacetime, except that it is a 4-dimensional non-Euclidean geometry. We also show that this set of constraints has a simple geometric structure, which is related to the properties of the Lorentzian 4-space. Finally, we discuss the physical significance of the obtained results and the problem they attempt to solve.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Uniqueness of $\\bf C^*$- and $\\bf C_+$-actions on Gizatullin surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2261, "human_text": "  A Gizatullin surface is a normal affine surface $V$ over $\\bf C$, which can be completed by a zigzag; that is, by a linear chain of smooth rational curves. In this paper we deal with the question of uniqueness of $\\bf C^*$-actions and $\\bf A^1$-fibrations on such a surface $V$ up to automorphisms. The latter fibrations are in one to one correspondence with $\\bf C_+$-actions on $V$ considered up to a \"speed change\".   Non-Gizatullin surfaces are known to admit at most one $\\bf A^1$-fibration $V\\to S$ up to an isomorphism of the base $S$. Moreover an effective $\\bf C^{*}$-action on them, if it does exist, is unique up to conjugation and inversion $t\\mapsto t^{-1}$ of $\\bf C^*$. Obviously uniqueness of $\\bf C^*$-actions fails for affine toric surfaces; however we show in this case that there are at most two conjugacy classes of $\\bf A^1$-fibrations. There is a further interesting family of non-toric Gizatullin surfaces, called the Danilov-Gizatullin surfaces, where there are in general several conjugacy classes of $\\bf C^*$-actions and $\\bf A^1$-fibrations.   In the present paper we obtain a criterion as to when $\\bf A^1$-fibrations of Gizatullin surfaces are conjugate up to an automorphism of $V$ and the base $S$. We exhibit as well a large subclasses of Gizatullin $\\bf C^{*}$-surfaces for which a $\\bf C^*$-action is essentially unique and for which there are at most two conjugacy classes of $\\bf A^1$-fibrations over $\\bf A^1$. ", "machine_text": "  We show that the actions of $\\bf C^*$- and $\\bf C_+$-defined on the Gizatullin surfaces are unique in a natural sense.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Guiding-fields for phase-separation: Controlling Liesegang patterns. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0687, "human_text": "  Liesegang patterns emerge from precipitation processes and may be used to build bulk structures at submicron lengthscales. Thus they have significant potential for technological applications provided adequate methods of control can be devised. Here we describe a simple, physically realizable pattern-control based on the notion of driven precipitation, meaning that the phase-separation is governed by a guiding field such as, for example, a temperature or a pH field. The phase-separation is modeled through a non-autonomous Cahn-Hilliard equation whose spinodal is determined by the evolving guiding field. Control over the dynamics of the spinodal gives control over the velocity of the instability front which separates the stable and unstable regions of the system. Since the wavelength of the pattern is largely determined by this velocity, the distance between successive precipitation bands becomes controllable. We demonstrate the above ideas by numerical studies of a 1D system with diffusive guiding field. We find that the results can be accurately described by employing a linear stability analysis (pulled-front theory) for determining the velocity -- local-wavelength relationship. From the perspective of the Liesegang theory, our results indicate that the so-called revert patterns may be naturally generated by diffusive guiding fields. ", "machine_text": "  We show that the time-evolution of a liquid-crystal (LC) domain can be controlled by applying a shear field to the LC on a periodically corrugated substrate. We report a fast and reversible tuning of the LC alignment, enabling the control of the orientation and the phase-separation of the LC. The coupling between the LC and the shear field is achieved by the alignsymmetric Coraline Doleum, a chiral molecule with a branched structure. The shear field induces a disclination line, and the coraline molecules are oriented along this line. The disclination line acts as a boundary of the LC phase, and the resulting phase-separation pattern is controlled by the shear field. We found that the application of a shear field to a LC on a periodically corrugated substrate, a so-called Liesegang experiment, allows to control the time-evolution of the LC domain. The Liesegang experiment is especially interesting for applications in optical and optoelectronic devices, since it enables the fast and reversible tuning of the LC alignment.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Casimir effect in a 6D warped flux compactification model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3623, "human_text": "  We discuss Casimir effect of a massless, minimally coupled scalar field in a 6D warped flux compactification model and its implications for the hierarchy and cosmological constant problems, which are longstanding puzzles in phenomenology and cosmology. Due to the scale invariance of the background theory, the 4D effective theory contains a volume modulus. To stabilize the modulus, we consider one-loop corrections to the effective potential by the Casimir effect. The one-loop effective potential for the volume modulus has a form which is very similar to Coleman-Weinberg potential. We evaluate coefficients appearing in the effective potential by employing zeta function regularization and heat kernel analysis. The volume modulus is stabilized for smaller degrees of warping, below a critical value, which depends on deficit angle of the reference brane. After stabilizing the modulus, it is possible to obtain observed values of the mass ratio between the fundamental energy scales and a tiny effective cosmological constant (though its sign is negative). The degree of warping should be tuned to be close to the critical value, not as severely as the original fine-tuning. ", "machine_text": " We study the Casimir effect in a 6D warped flux compactification model. In our model, the standard 4D spacetime is compactified by a 3D warped surface. The aim of this work is to investigate the Casimir effect in a 6D warped space-time which includes both a 4D flat bulk and a 2D curved surface. The surface gravity can be treated as a vectorial correction to the bulk gravity. In our model, the bulk gravity is always the dominant contribution to the total gravity field. The surface Casimir effect is induced by the difference between the bulk and the surface gravity. We find the surface Casimir stress has a non-monotonic distribution with the bulk height. Our model has two special bulk heights at which the surface Casimir stress reaches its minimum and maximum values. We also find that the bulk Casimir stress has a non-monotonic distribution with the bulk height. The sign of the bulk Casimir stress is opposite to that of the surface Casimir stress. The bulk Casimir stress is related to the bulk entropy. We also obtain the bulk and surface stress-energy kernels. Our model can be used to test the positivity of the stress-energy kernel.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical Objects for Cohomologically Expanding Maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0069, "human_text": "  The goal of this paper is to construct invariant dynamical objects for a (not necessarily invertible) smooth self map of a compact manifold. We prove a result that takes advantage of differences in rates of expansion in the terms of a sheaf cohomological long exact sequence to create unique lifts of finite dimensional invariant subspaces of one term of the sequence to invariant subspaces of the preceding term. This allows us to take invariant cohomological classes and under the right circumstances construct unique currents of a given type, including unique measures of a given type, that represent those classes and are invariant under pullback. A dynamically interesting self map may have a plethora of invariant measures, so the uniquess of the constructed currents is important. It means that if local growth is not too big compared to the growth rate of the cohomological class then the expanding cohomological class gives sufficient \"marching orders\" to the system to prohibit the formation of any other such invariant current of the same type (say from some local dynamical subsystem). Because we use subsheaves of the sheaf of currents we give conditions under which a subsheaf will have the same cohomology as the sheaf containing it. Using a smoothing argument this allows us to show that the sheaf cohomology of the currents under consideration can be canonically identified with the deRham cohomology groups. Our main theorem can be applied in both the smooth and holomorphic setting. ", "machine_text": "  We consider the structure of dynamically defined objects for a class of cohomologically expanding maps, including a class of\u00fcrngem ---------------------------------------------------------------------------------------- generalized fractals which contains the Julia and Mandelbrot fractals as special cases. For a given expanding map, the algorithm defines the objects in a finite number of steps, starting with an object defined by a template of nowhere vanishing functions and iteratively replacing the template by a fractalalgorithmically generated function. For the urningem class, the algorithm defines an object in a finite number of steps, starting with an object defined by a template of everywhere equal functions and iteratively replacing the template by a fractalalgorithmically generated function. We show that these objects are suitable for the definition of dynamical processes, and we present a dynamical process on the urningem class which has a singularity structure similar to the q-expander, but with more Expanders.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cascading on extragalactic background light. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.391, "human_text": "  High-energy gamma-rays propagating in the intergalactic medium can interact with background infrared photons to produce e+e- pairs, resulting in the absorption of the intrinsic gamma-ray spectrum. TeV observations of the distant blazar 1ES 1101-232 were thus recently used to put an upper limit on the infrared extragalactic background light density. The created pairs can upscatter background photons to high energies, which in turn may pair produce, thereby initiating a cascade. The pairs diffuse on the extragalactic magnetic field (EMF) and cascade emission has been suggested as a means for measuring its intensity. Limits on the IR background and EMF are reconsidered taking into account cascade emissions. The cascade equations are solved numerically. Assuming a power-law intrinsic spectrum, the observed 100 MeV - 100 TeV spectrum is found as a function of the intrinsic spectral index and the intensity of the EMF. Cascades emit mainly at or below 100 GeV. The observed TeV spectrum appears softer than for pure absorption when cascade emission is taken into account. The upper limit on the IR photon background is found to be robust. Inversely, the intrinsic spectra needed to fit the TeV data are uncomfortably hard when cascade emission makes a significant contribution to the observed spectrum. An EMF intensity around 1e-8 nG leads to a characteristic spectral hump in the GLAST band. Higher EMF intensities divert the pairs away from the line-of-sight and the cascade contribution to the spectrum becomes negligible. ", "machine_text": "  We have performed a parameter study of the effect of extragalactic background light (EBL) on the observations of weakly emitting galaxies in the same volume. We have considered the EBL produced by the galaxies in a foreground group, the EBL from the diffuse light of the group and the EBL from the rest of the Universe. We have found that the EBL produces a significant drop in the detectability of the weak galaxies, especially in groups with a large number of galaxies and in groups which are very distant. We have also found that the group EBL has a large impact on the detectability and the colour of the weak galaxies, whereas the EBL from the rest of the Universe has a very small impact. We have interpreted our results in the framework of the 'Cascading' mechanism. Our results show that the galaxies which are close to the edge of the group can be severely affected by the EBL, and therefore the galaxies which are far from the group centre are more easily detectable. This is in agreement with the hypothesis that the galaxies which are the first to be detected are the galaxies which are the farthest from the group. We have also found that the EBL has a larger impact on the blue galaxies and on the galaxies which are already quite faint. The EBL thus produces a significant modification of the colour distribution of the galaxies, and this modification is able to improve the detectability of the galaxies which are close to the detection limit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effects of Lepton Flavour Violation on Chargino Production at the Linear   Collider. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2684, "human_text": "  We study the effects of lepton flavour violation (LFV) on the production processes e+e- --> \\chi+_i \\chi-_j at a linear collider with longitudinal e+ and e- beam polarizations. In the case of LFV the sneutrino mass eigenstates have no definite flavour, therefore, in the t-channel more than one sneutrino mass eigenstate can contribute to the chargino production cross sections. Our framework is the Minimal Supersymmetric Standard Model (MSSM) including LFV terms. We show that in spite of the restrictions on the LFV parameters due to the current limits on rare lepton decays, the cross section \\sigma(e+e- --> \\chi+_1 \\chi-_1) can change by a factor of 2 or more when varying the LFV mixing angles. We point out that even if the present bound on BR(tau- --> e- gamma) improves by a factor of thousand the influence of LFV on the chargino production cross section can be significant. These results could have an important impact on the strategies for determining the underlying model parameters at the linear collider. ", "machine_text": " We investigate the production of charged weak gauge bosons (W, Z) and their neutral Higgs cousins (H) at the LHC. We focus on the case where the weak gauge bosons are produced in association with a Higgs boson. We show that, in the framework of a Standard Model (SM) inspired model with two generations of quarks and one of charged leptons, the flavor violating couplings of the Higgs boson to the weak gauge bosons can have a substantial effect on the production rates of the gauge bosons as well as on the production rate of a second Higgs boson. We evaluate the sensitivity of the LHC to the presence of such flavor violating couplings and find that it can already constrain some of the more extreme predictions made in the context of certain popular Grand Unified Theories.   We also investigate the production of a very light Higgs boson (mass comparable to the weak gauge bosons) and show that the associated production of weak gauge bosons can have a significant impact on the direct production cross section as well as on the production rate of a second Higgs boson.   Finally, we consider the potential impact of the production of a heavy Higgs boson (mass comparable to the top quark) on the search for a Higgs sector with more than one Higgs boson. We show that such a search strategy can already provide interesting and non-trivial constraints on the theory even in the absence of any direct Higgs- Higgs boson interactions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The production of Tsallis entropy in the limit of weak chaos and a new   indicator of chaoticity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1459, "human_text": "  We study the connection between the appearance of a `metastable' behavior of weakly chaotic orbits, characterized by a constant rate of increase of the Tsallis q-entropy (Tsallis 1988), and the solutions of the variational equations of motion for the same orbits. We demonstrate that the variational equations yield transient solutions, lasting for long time intervals, during which the length of deviation vectors of nearby orbits grows in time almost as a power-law. The associated power exponent can be simply related to the entropic exponent for which the q-entropy exhibits a constant rate of increase. This analysis leads to the definition of a new sensitive indicator distinguishing regular from weakly chaotic orbits, that we call `Average Power Law Exponent' (APLE). We compare the APLE with other established indicators of the literature. In particular, we give examples of application of the APLE in a) a thin separatrix layer of the standard map, b) the stickiness region around an island of stability in the same map, and c) the web of resonances of a 4D symplectic map. In all these cases we identify weakly chaotic orbits exhibiting the `metastable' behavior associated with the Tsallis q-entropy. ", "machine_text": "  We study the production of the Tsallis entropy in the limit of weak chaos. We show that an adaptive version of the recently introduced survivor function method can be used to evaluate the quantities involved, in a way that is both numerically stable and computationally feasible for a large class of systems. We use this method to compute the entropy for a number of one-dimensional maps and investigate its behaviour in the limit of weak chaos. We show that the entropy is always non-zero, but that for a large class of maps it converges to a constant value as the system is driven further into chaos. We interpret this result by considering a simple model in which the entropy is known analytically. We show that in this case the limiting entropy is simply the Kolmogorov-Sinai entropy times a correction term that is proportional to the Forney probability. We then consider a number of examples for which this prediction is confirmed. Finally, we show that this method can also be used to produce a new indicator of chaoticity, which we call the survival entropy. This is related to the recently introduced groove function, but has a number of advantages, and is shown to perform well in a variety of numerical experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Einstein in the crossroad of the sciences, arts and humanities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0999, "human_text": "  Western thinking underwent a turning point between 1885 and 1925. Einstein in 1905 symbolizes the emblematic hinge of this change of direction. To find an equivalent phenomenon in the past we need to go back to the period from the XV century to the XVII century. It was not a mere reform of codes but a new code. In 1905 the perception of reality changed through the introduction of relativism in three levels of the reference systems: the ego-other relation, the world perceived by the senses, and the 'ideal' universe of the concepts. We will try to identify how this change was expressed and developed in the cited levels, both in the physic and nature based sciences, in the social sciences, and in literature and fine arts. Today, 100 years after, the 1905's generation still proposes us two options: to live sheltered by the dogma that reassures us with its only and exclusive viewpoint claimed objective, or to dare to live with the multiple, the transient, the relative. The first way led to the worst regimes and intolerant ideas of the XX century, the second option throws us into the uncertainty of the creative adventure, but also leads us to the possibility of a fairer society in the XXI century. ", "machine_text": "  We review Einstein's writings on the relationship between science and the humanities, and on the concept of culture in general. We discuss the sources of his ideas on this issue, the connections between his views on science and the humanities and his overall philosophy of science, and how these views changed over time. We pay particular attention to Einstein's later writings on this issue, which are less well-known and have not been previously discussed in the literature.  We find that Einstein's views on the relationship between science and the humanities were complex and changed over time. In his early writings, Einstein emphasized the importance of science as a means of understanding reality, and he saw the humanities as a source of values and meaning. However, in his later writings, Einstein became more critical of the humanities, and he argued that science should be divorced from any cultural or political context. We discuss the sources of these different views, and we consider the implications of Einstein's changing views on the relationship between science and the humanities for his overall philosophy of science.  We conclude that Einstein's views on the relationship between science and the humanities were complex and changed over time. In his early writings, Einstein emphasized the importance of science as a means of understanding reality, and he saw the humanities as a source of values and meaning. However, in his later writings, Einstein became more critical of the humanities, and he argued that science should be divorced from any cultural or political context. We discuss the sources of these different views, and we consider the implications of Einstein's changing views on the relationship between science and the humanities for his overall philosophy of science.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Information feedback and mass media effects in cultural dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1091, "human_text": "  We study the effects of different forms of information feedback associated with mass media on an agent-agent based model of the dynamics of cultural dissemination. In addition to some processes previously considered, we also examine a model of local mass media influence in cultural dynamics. Two mechanisms of information feedback are investigated: (i) direct mass media influence, where local or global mass media act as an additional element in the network of interactions of each agent, and (ii) indirect mass media influence, where global media acts as a filter of the influence of the existing network of interactions of each agent. Our results generalize previous findings showing that cultural diversity builds-up by increasing the strength of the mass media influence. We find that this occurs independently of the mechanisms of action (direct or indirect) of the mass media message. However, through an analysis of the full range of parameters measuring cultural diversity, we establish that the enhancement of cultural diversity produced by interaction with mass media only occurs for strong enough mass media messages. In comparison with previous studies a main different result is that weak mass media messages, in combination with agent-agent interaction, are efficient in producing cultural homogeneity. Moreover, the homogenizing effect of weak mass media messages are more efficient for direct local mass media messages than for global mass media messages or indirect global mass media influences. ", "machine_text": "  We study information feedback and mass media effects in cultural dynamics. We present a formal model of a cultural entity (a social system) and an information system (mass media). The model allows us to study the dynamics of the social system and the mass media on each other. We consider two types of mass media: the traditional mass media, which is \"transmitted\" (i.e. newspaper, television), and the \"new\" social media, which is \"retrieved\" (i.e. internet). We show that the traditional mass media is a \"monoculture\" that has a global impact on the social system, while the social media is a \"polyculture\" that has a local impact on the social system. We analyze the information feedback from the social system to the mass media and we study the different regimes of the information feedback. We show that the information feedback is positive (i.e. the social system reinforce the mass media) if the mass media is close to the \"mainstream\" of the social system, and the information feedback is negative (i.e. the social system refuses the mass media) if the mass media is far from the \"mainstream\". We study the dynamics of the social system and we analyze the role of the mass media in this dynamics. Finally, we study the problem of the \"switch\" of the social system from one mass media to another. We show that the \"switch\" can be provoked by the mass media only if the new mass media is close to the \"mainstream\" of the social system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hamiltonian and Brownian systems with long-range interactions: IV.   General kinetic equations from the quasilinear theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4579, "human_text": "  We develop the kinetic theory of Hamiltonian systems with weak long-range interactions. Starting from the Klimontovich equation and using a quasilinear theory, we obtain a general kinetic equation that can be applied to spatially inhomogeneous systems and that takes into account memory effects. This equation is valid at order 1/N in a proper thermodynamic limit and it coincides with the kinetic equation obtained from the BBGKY hierarchy. For N tending to infinity, it reduces to the Vlasov equation describing collisionless systems. We describe the process of phase mixing and violent relaxation leading to the formation of a quasi stationary state (QSS) on the coarse-grained scale. We interprete the physical nature of the QSS in relation to Lynden-Bell's statistical theory and discuss the problem of incomplete relaxation. In the second part of the paper, we consider the relaxation of a test particle in a thermal bath. We derive a Fokker-Planck equation by directly calculating the diffusion tensor and the friction force from the Klimontovich equation. We give general expressions of these quantities that are valid for possibly spatially inhomogeneous systems with long correlation time. We show that the diffusion and friction terms have a very similar structure given by a sort of generalized Kubo formula. We also obtain non-markovian kinetic equations that can be relevant when the auto-correlation function of the force decreases slowly with time. An interest of our approach is to develop a formalism that remains in physical space (instead of Fourier space) and that can deal with spatially inhomogeneous systems. ", "machine_text": "  Long-range interactions in systems of driven particles are known to give rise to rich nonlinear dynamics, such as sync \", but can also lead to other interesting phenomena, such as the onset of quasi-periodic motion, that have not been extensively studied. In this paper, we consider driven systems with long-range interactions from the quasilinear theory. We find that general kinetic equations can be derived for these systems that describe the evolution of the internal degrees of freedom of the particles. We show that these equations can give rise to quasi-periodic motions and investigate the form of the corresponding orbits. We find that these orbits are generally unstable against small perturbations, but that they can be made stable by a small change in the microscopic dynamics. We discuss the physical implications of this result and consider the special case of Imperialist Invasions, a simple model of collaborative dynamics with long-range interactions, that is known to exhibit quasi-periodic motion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Microlens Parallax Measurements with a Warm Spitzer. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3908, "human_text": "  Because Spitzer is an Earth-trailing orbit, losing about 0.1 AU/yr, it is excellently located to perform microlens parallax observations toward the Magellanic Clouds (LMC/SMC) and the Galactic bulge. These yield the so-called ``projected velocity'' of the lens, which can distinguish statistically among different populations. A few such measurements toward the LMC/SMC would reveal the nature of the lenses being detected in this direction (dark halo objects, or ordinary LMC/SMC stars). Cool Spitzer has already made one such measurement of a (rare) bright red-clump source, but warm (presumably less oversubscribed) Spitzer could devote the extra time required to obtain microlens parallaxes for the more common, but fainter, turnoff sources. Warm Spitzer could observe bulge microlenses for 38 days per year, which would permit up to 24 microlens parallaxes per year. This would yield interesting information on the disk mass function, particularly old brown dwarfs, which at present are inaccessible by other techniques. Target-of-Opportunity (TOO) observations should be divided into RTOO/DTOO, i.e., ``regular'' and ``disruptive'' TOOs, as pioneered by the Space Interferometry Mission (SIM). LMC/SMC parallax measurements would be DTOO, but bulge measurements would be RTOO, i.e., they could be scheduled in advance, without knowing exactly which star was to be observed. ", "machine_text": "  We present a simple method to measure the parallax of galaxies using the Spitzer Space Telescope and a model of the microlens parallax effect. We use the fact that the microlens effect amplifies the parallax of galaxies when the source galaxy is at or beyond the limit of parallax detection. Our method is to observe a source galaxy as it is amplified by a microlens, located between the source galaxy and the observer, in aWarm Spitzer IR image. We derive the lensing magnification from the image, and then search the source galaxy neighborhood for a second galaxy which is not lensed. We then measure the angular separation between these two galaxies. The measured angular separation is the combined parallax of the two galaxies plus the microlens parallax. We model the microlens parallax with a simple geometric model that includes the lensing magnification, the observed angular separation between the source galaxy and the lens, and the lens recession velocity. We present a case study of a source galaxy at high redshift (z \u223c 1.5), and estimate the source galaxy's parallax to be PA \u223c 1.75 \u00b1 0.1 milliarcseconds (mas), and the microlens parallax to be PA \u223c 5.0 \u00b1 1.2 mas. We find that the microlens effect can substantially increase the number of galaxies for which parallax can be measured, if the source galaxy is at or beyond the limit of detection for direct parallax measurements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Correlated bosons on a lattice: Dynamical mean-field theory for   Bose-Einstein condensed and normal phases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0839, "human_text": "  We formulate a bosonic dynamical mean-field theory (B-DMFT) which provides a comprehensive, thermodynamically consistent framework for the theoretical investigation of correlated lattice bosons. The B-DMFT is applicable for arbitrary values of the coupling parameters and temperature and becomes exact in the limit of high spatial dimensions d or coordination number Z of the lattice. In contrast to its fermionic counterpart the construction of the B-DMFT requires different scalings of the hopping amplitudes with Z depending on whether the bosons are in their normal state or in the Bose-Einstein condensate. A detailed discussion of how this conceptual problem can be overcome by performing the scaling in the action rather than in the Hamiltonian itself is presented. The B-DMFT treats normal and condensed bosons on equal footing and thus includes the effects caused by their dynamic coupling. It reproduces all previously investigated limits in parameter space such as the Beliaev-Popov and Hartree-Fock-Bogoliubov approximations and generalizes the existing mean-field theories of interacting bosons. The self-consistency equations of the B-DMFT are those of a bosonic single-impurity coupled to two reservoirs corresponding to bosons in the condensate and in the normal state, respectively. We employ the B-DMFT to solve a model of itinerant and localized, interacting bosons analytically. The local correlations are found to enhance the condensate density and the Bose-Einstein condensate (BEC) transition temperature T_{BEC}. This effect may be used experimentally to increase T_{BEC} of bosonic atoms in optical lattices. ", "machine_text": " We study correlated bosons on a lattice using the tools of statistical mechanics and dynamical mean-field theory. We consider a lattice of N sites, each of which can be occupied by a boson with one of two possible spins. In a symmetric configuration, there are N/2 bosons with one spin and N/2 with the other. We find that below a certain temperature, the system becomes bistable, and can exist in either a low-temperature phase, where the spins are uncorrelated and the distribution is symmetric, or a high-temperature phase, where the spins are correlated and the distribution is asymmetric. We use dynamical mean-field theory to study the statistical properties of the correlated phase, and show that it is characterized by a long-range order and a broken symmetry. In contrast, the uncorrelated phase is characterized by a short-range order and a symmetric distribution. We also consider a more general model, where the spin of each boson can take one of three values, and show that the correlated phase can be further stabilized by a symmetry-breaking field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Network Topology of an Experimental Futures Exchange. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2551, "human_text": "  Many systems of different nature exhibit scale free behaviors. Economic systems with power law distribution in the wealth is one of the examples. To better understand the working behind the complexity, we undertook an empirical study measuring the interactions between market participants. A Web server was setup to administer the exchange of futures contracts whose liquidation prices were coupled to event outcomes. After free registration, participants started trading to compete for the money prizes upon maturity of the futures contracts at the end of the experiment. The evolving `cash' flow network was reconstructed from the transactions between players. We show that the network topology is hierarchical, disassortative and scale-free with a power law exponent of 1.02+-0.09 in the degree distribution. The small-world property emerged early in the experiment while the number of participants was still small. We also show power law distributions of the net incomes and inter-transaction time intervals. Big winners and losers are associated with high degree, high betweenness centrality, low clustering coefficient and low degree-correlation. We identify communities in the network as groups of the like-minded. The distribution of the community sizes is shown to be power-law distributed with an exponent of 1.19+-0.16. ", "machine_text": "  We present and evaluate a new network topology for an experimental futures exchange. The new topology improves communication performance by placing all trading engines in a single, shared network segment. We detail the design of the new topology and the mechanisms that have been implemented to ensure that performance is not adversely impacted by the increased network load. The new topology has been evaluated using a combination of simulation and live testing on the exchange's production network. The results show that the new topology can achieve communication performance comparable to that of the current topology, despite the increased network load. The new topology has been implemented in the exchange's production network.  We motivate our work by explaining the importance of communication performance to the overall performance of the exchange. We then present the current topology of the exchange's production network. We explain that the current topology is not well-suited to achieving the best communication performance, due to the existence of multiple network segments. We then present the new topology that we have designed and implemented. We explain how the new topology improves communication performance, and we detail the mechanisms that have been implemented to ensure that performance is not adversely impacted by the increased network load. We then present the results of our evaluation of the new topology. The results show that the new topology can achieve communication performance comparable to that of the current topology, despite the increased network load. We then explain how the new topology has been implemented in the exchange's production network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The infrared environments of masers associated with star formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.39, "human_text": "  The near infrared (1-2um) and the thermal infrared (3-25um) trace many of the environments in which masers are thought to reside, including shocks, outflows, accretion disks, and the dense medium near protostars. After a number of recent surveys it has been found that there is a higher detection rate of mid-IR emission towards masers than cm radio continuum emission from UC HII regions, and that the mid-IR emission is actually more closely cospatial to the maser locations. A high percentage of water and methanol masers that are not coincident with the UC HII regions in massive star forming regions are likely to be tracing outflows and extremely young high mass stars before the onset of the UC HII region phase. After a decade of groundwork supporting the hypothesis that linarly distributed class II methanol masers may generally trace accretion disks around young massive stars, compelling evidence is mounting that these masers may generally be associated with outflows instead. Substantiation of this claim comes from recent outflow surveys and high angular resolution mid-IR imaging of the maser environments. ", "machine_text": "  We present observations of the infrared environments of maser sources associated with star formation. We describe the motivation for our research, the key ideas and methodology used, the results obtained, the problem our work attempts to solve, and any practical or theoretical applications from our findings or implications for future research. The maser sources are mostly located in the regions where new stars are forming. We have observed a strong correlation between the maser activity and the star formation activity. We found that the maser sources are located in the cores of the regions where the new stars are forming. The masers are likely to be the first sign of the formation of a new star. Our observations suggest that the masers are excited by the infall of gas into the core. We also found that the masers are likely to be in a turbulent environment, and that the turbulence is excited by the infall of gas into the core. We have observed a strong correlation between the strength of the mers and the mass of the gas in the core. The masers are likely to be the first sign of the formation of a new star.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Contractions, deformations and curvature. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2208, "human_text": "  The role of curvature in relation with Lie algebra contractions of the pseudo-ortogonal algebras so(p,q) is fully described by considering some associated symmetrical homogeneous spaces of constant curvature within a Cayley-Klein framework. We show that a given Lie algebra contraction can be interpreted geometrically as the zero-curvature limit of some underlying homogeneous space with constant curvature. In particular, we study in detail the contraction process for the three classical Riemannian spaces (spherical, Euclidean, hyperbolic), three non-relativistic (Newtonian) spacetimes and three relativistic ((anti-)de Sitter and Minkowskian) spacetimes. Next, from a different perspective, we make use of quantum deformations of Lie algebras in order to construct a family of spaces of non-constant curvature that can be interpreted as deformations of the above nine spaces. In this framework, the quantum deformation parameter is identified as the parameter that controls the curvature of such \"quantum\" spaces. ", "machine_text": " We investigate the relationship between curvature, deformations and contrations on a Riemannian manifold. We show that the entropically motivated deformations of the metric, which have been proposed in the literature as a way of constructing finite volume metrics on Riemannian manifolds, have a simple description in terms of a large class of curvature functions which have a particular form in the covarient derivatives. In particular, we show that the affine curvature and the 1-form curvature are such curvature functions. As a by-product of this description we obtain a geometrically simple formula for the Compression function and we show that this agrees with the one obtained via the heat flow equations in the literature. We then use this description to obtain a simple formula for the volume of a contraction on a Riemannian manifold which is motivated by the idea of a deformation volume. We show that this has an intuitive geometric meaning which is related to the idea of a volume being the amount of space that an object occupies. We apply this to the setting ofsymplectic geometry, where one can think of a symplectic form as an object which occupies space in a Riemannian manifold, and use this to obtain a geometrically simple formula for the variety of a contact structure on a Riemannian manifold in terms of the associated curvature function. We also show that this variety has a natural description in terms of the Dirac operator on the symplectic form, which relates it to the geometric setting of Dirac operators on Riemannian manifolds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Abelian two-Higgs model of strongly correlated electrons: phase   structure, strengthening of phase transition and QCD at finite density. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1528, "human_text": "  We investigate non-perturbative features of a three-dimensional Abelian Higgs model with singly- and doubly-charged scalar fields coupled to a single compact Abelian gauge field. The model is pretending to describe various planar systems of strongly correlated electrons such as high-Tc superconductivity in the overdoped regime and exotic materials possessing excitations with fractionalized quantum numbers. The complicated phase structure of the model is studied thoroughly using numerical tools and analytical arguments. In the three-dimensional space of coupling parameters we identify the Fermi liquid, the spin gap, the superconductor and the strange metallic phases. The behavior of three kinds of topological defects -- holon and spinon vortices and monopoles - is explored in various phases. We also observe a new effect, the strong enhancement of the phase transition strength reflected in a lower order of the transition: at sufficiently strong gauge coupling the two second order phase transitions -- corresponding to spinon-pair and holon condensation lines - join partially in the phase diagram and become a first order phase transition in that region. The last observation may have an analogue in Quantum Chromodynamics at non-zero temperature and finite baryon density. We argue that at sufficiently large baryon density the finite-temperature transition between the (3-flavor paired) color superconducting phase and the quark-gluon plasma phases should be much stronger compared with the transition between 2-flavor paired and 3-flavor paired superconducting phases. ", "machine_text": " We consider a model of strongly correlated electrons with two kinds of effective interactions, $\\lambda$ and $\\mu$, which can be understood as two different kinds of Higgs mechanisms. We show that this model is in a special point in the phase diagram, namely the so-called horseshoes state. We find that the transition temperature to this state decreases with increasing density. In the case with $\\lambda\\gg\\mu$, we find a strengthening of the transition temperature to the superconducting state, compared to the case with $\\lambda\\ll\\mu$. We also find a transition temperature to a non-Abelian state, which is stronger in the case with $\\lambda\\gg\\mu$ compared to the case with $\\lambda\\ll\\mu$. Our results can be understood in terms of the dynamic charge-flavor-locked states, which are related to the coexistence of a continuous symmetry and a discrete symmetry. We also show that the results are consistent with the idea that the strong interactions can be treated as a quark color-flavor-locked state in a quark-meson model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Uniqueness Domains in the Workspace of Parallel Manipulators. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.096, "human_text": "  This work investigates new kinematic features of parallel manipulators. It is well known that parallel manipulators admit generally several direct kinematic solutions for a given set of input joint values. The aim of this paper is to characterize the uniqueness domains in the workspace of parallel manipulators, as well as their image in the joint space. The study focuses on the most usual case of parallel manipulators with only one inverse kinematic solution. The notion of aspect introduced for serial manipulators in [Borrel 86] is redefined for such parallel manipulators. Then, it is shown that it is possible to link several solutions to the forward kinematic problem without meeting a singularity, thus meaning that the aspects are not uniqueness domains. An additional set of surfaces, namely the characteristic surfaces, are characterized which divide the workspace into basic regions and yield new uniqueness domains. This study is illustrated all along the paper with a 3-RPR planar parallel manipulator. An octree model of spaces is used to compute the joint space, the workspace and all other newly defined sets. ", "machine_text": "  Uniqueness Domains in the Workspace of Parallel Manipulators  We consider the problem of finding the uniqueness domains of the workspace of a parallel manipulator (PM), i.e. the regions in the workspace where the kinematic constraints are satisfied with unique solutions. We show that this problem can be converted to a nonlinear optimization problem by regarding the set of all joint configurations that share the same end-effector location as the intersection of the columns of a specific matrix. We propose an algorithm that, given the matrix representing the equality constraints of the PM, computes a population of the possible unique joint configurations. Each configuration is represented by a vector in the null space of the matrix. The computation is based on the theory of rank-nullity decomposition of matrices. We show that the proposed algorithm is applicable to a wide class of PMs, including general 6R manipulators, mobile robots and aerial manipulators. We present simulation results for a 6R manipulator and a mobile robot.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Reggeization of N=8 Supergravity and N=4 Yang-Mills Theory II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0917, "human_text": "  The loop expansion for the n-point functions of N=4 Yang-Mills theory and N=8 supergravity can be formulated as the loop expansion of scalar field theory with an infinite subclass being the ladder diagrams. We consider the sum of ladder diagrams for gluon-gluon and graviton-graviton scattering in the Regge limit. The reggeization of the gluon and the graviton is discussed in this context and that of hep-th/0701217. If the Bern, Dixon, Smirnov conjecture for planar gluon-gluon scattering is correct, then the ladder sum for SU(N) gauge theory at large N, correctly gives the Regge limit, with Regge trajectory function proportional to the cusp anomalous dimension.   In graviton-graviton scattering it is argued that the graviton lies on a Regge trajectory. Regge cuts are also present due to infinite sums of non-planar graphs. The multiple exchange of Regge poles in non-planar graphs can give a countable infinite number of moving Regge cuts which accumulate near s=0. It is conjectured that this may be related to the infinite number of non-perturbative massless states which remain in the limit discussed by Green, Ooguri and Schwarz. ", "machine_text": "  We study the reggeization of N=8 supergravity and N=4 Yang-Mills theory. In a previous paper we constructed a general framework for the reggeization of these theories in the effective N=1 gauge group. In the present paper we continue this study by examining the N=8 supergravity and N=4 Yang-Mills theory in the effective N=1 gauge group with the arbitrary complexification parameter \u03d5 \u2208 \u211d. We find a continuous series of representations of the effective N=1 gauge group in the N=8 supergravity and N=4 Yang-Mills theory which are exact solutions of these theories and satisfy the Heisenberg uncertainty principle. The ground state of N=8 supergravity and N=4 Yang-Mills theory in these representations corresponds to the simplest non-trivial representation of the effective N=1 gauge group with \u03d5 \u2260 0. This ground state has a highly non-trivial structure and it can be considered as a first example of an exactly soluble quantum N=8 supergravity theory with a non-trivial vacuum structure. We also find the exact expression for the axion field \u03c6 \u221d \u03d5 ^ (- 1) in the ground state of N=8 supergravity and N=4 Yang-Mills theory in the effective N=1 gauge group with \u03d5 \u2260 0.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Squashed entanglement for multipartite states and entanglement measures   based on the mixed convex roof. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2236, "human_text": "  New measures of multipartite entanglement are constructed based on two definitions of multipartite information and different methods of optimizing over extensions of the states. One is a generalization of the squashed entanglement where one takes the mutual information of parties conditioned on the state's extension and takes the infimum over such extensions. Additivity of the multipartite squashed entanglement is proved for both versions of the multipartite information which turn out to be related. The second one is based on taking classical extensions. This scheme is generalized, which enables to construct measures of entanglement based on the {\\it mixed convex roof} of a quantity, which in contrast to the standard convex roof method involves optimization over all decompositions of a density matrix rather than just the decompositions into pure states. As one of the possible applications of these results we prove that any multipartite monotone is an upper bound on the amount of multipartite distillable key. The findings are finally related to analogous results in classical key agreement. ", "machine_text": "  We investigate a class of entanglement measures which are defined on multipartite states and are invariant under local operations and classical communication (LOCC). We show that, while a general technique to construct such measures exists, there are nontrivial constraints on the set of measures that can be constructed in this way. In particular, we show that such a measure is necessarily a convex combination of the distinct entanglement measures of the bipartite states that can be obtained by squashing the multipartite state in question in a particular way. This immediately implies that such entanglement measures are not symmetric on any class of states that contains states with negative entanglement. We show further that, while there exist examples of measures that satisfy the above constraints and are not symmetric, it is not possible to construct a measure that satisfies the constraints and is symmetric on a class of states that contains states with negative entanglement. Finally, we show that if such a symmetric measure could be constructed, it would have to be the zero measure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonequilibrium Steady States of Matrix Product Form: A Solver's Guide. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1678, "human_text": "  We consider the general problem of determining the steady state of stochastic nonequilibrium systems such as those that have been used to model (among other things) biological transport and traffic flow. We begin with a broad overview of this class of driven diffusive systems - which includes exclusion processes - focusing on interesting physical properties, such as shocks and phase transitions. We then turn our attention specifically to those models for which the exact distribution of microstates in the steady state can be expressed in a matrix product form. In addition to a gentle introduction to this matrix product approach, how it works and how it relates to similar constructions that arise in other physical contexts, we present a unified, pedagogical account of the various means by which the statistical mechanical calculations of macroscopic physical quantities are actually performed. We also review a number of more advanced topics, including nonequilibrium free energy functionals, the classification of exclusion processes involving multiple particle species, existence proofs of a matrix product state for a given model and more complicated variants of the matrix product state that allow various types of parallel dynamics to be handled. We conclude with a brief discussion of open problems for future research. ", "machine_text": " Nonequilibrium steady states (NESS) of matrix product forms (MPF) are important in many areas of physics, but are hard to calculate. We present a systematic way of constructing NESSs for MPF. The method is based on the construction of the effective Hamiltonian matrix in the basis of the single-particle basis renormalized in the presence of the thermal bath. The method can be easily generalized to the NESSs with correlations, and also to the pure dephasing channel. We obtain the explicit expressions for the NESSs of the XX, XY, and FY models in the thermodynamic limit, and for the XY model in the finite size. The explicit expressions for the matrix elements of the NESSs enable one to use the iterative method to solve the NESSs with a large number of basis functions. As an example, we solve the NESSs of the XY model in a one-dimensional chain with the basis functions equal to the Goldstone bosons. The method can be easily modified to solve the NESSs with the basis functions equal to the collective excitations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: IGR J17254-3257, a new bursting neutron star. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1249, "human_text": "  The study of the observational properties of uncommonly long bursts from low luminosity sources with extended decay times up to several tens of minutes is important when investigating the transition from a hydrogen-rich bursting regime to a pure helium regime and from helium burning to carbon burning as predicted by current burst theories. IGR J17254-3257 is a recently discovered X-ray burster of which only two bursts have been recorded: an ordinary short type I X-ray burst, and a 15 min long burst. An upper limit to its distance is estimated to about 14.5 kpc. The broad-band spectrum of the persistent emission in the 0.3-100 keV energy band obtained using contemporaneous INTEGRAL and XMM-Newton data indicates a bolometric flux of 1.1x10^-10 erg/cm2/s corresponding, at the canonical distance of 8 kpc, to a luminosity about 8.4x10^35 erg/s between 0.1-100 keV, which translates to a mean accretion rate of about 7x10^-11 solar masses per year. The low X-ray persistent luminosity of IGR J17254-3257 seems to indicate the source may be in a state of low accretion rate usually associated with a hard spectrum in the X-ray range. The nuclear burning regime may be intermediate between pure He and mixed H/He burning. The long burst is the result of the accumulation of a thick He layer, while the short one is a prematurate H-triggered He burning burst at a slightly lower accretion rate. ", "machine_text": "  IGR J17254-3257, a new bursting neutron star We present the discovery of a new member of the class of low-mass X-ray binaries (LMXBs), a system we name IGR J17254-3257. This system is a close binary containing a magnetic white dwarf with a hot spot and a neutron star. The white dwarf is stealing material from the neutron star, producing X-rays and a burst of relativistic electrons. The system is the second (and closest) member of the class of LMXBs known as cemetery spirals. The nature of the accretion process is such that the system can be considered a low-mass version of a supersoft X-ray source. We estimate the white dwarf's magnetic field to be on the order of 10 MG, much stronger than the 1 MG field previously thought to be necessary to explain the observations of the only other member of this class, Vela X-1. We find that a relatively long-duration burst of X-rays, of order of 100 ks, occurred on 2005 December 14. The burst was accompanied by a burst of relativistic electrons (termed a \"antypenumbra\") that decayed rapidly from its peak to a few thousand electron volts in just seven hours. The burst was also accompanied by a significant brightenings in the high-energy tail of the X-ray spectrum, possibly due to pickup of non-thermal particles in the white dwarf's hot spot. The X-ray and optical data show that the accretion process is highly inefficient, with the white dwarf stealing only 0.01% of the neutron star's orbital moment. The inefficiency of the process suggests that the neutron star is rotating extremely rapidly, and we estimate its spin rate to be between 2.2 and 3.4 seconds. Our results also suggest that the accretion process in low-mass X-ray binaries is driven by the magnetic field of the white dwarf.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scalability and Optimisation of a Committee of Agents Using Genetic   Algorithm. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1757, "human_text": "  A population of committees of agents that learn by using neural networks is implemented to simulate the stock market. Each committee of agents, which is regarded as a player in a game, is optimised by continually adapting the architecture of the agents using genetic algorithms. The committees of agents buy and sell stocks by following this procedure: (1) obtain the current price of stocks; (2) predict the future price of stocks; (3) and for a given price trade until all the players are mutually satisfied. The trading of stocks is conducted by following these rules: (1) if a player expects an increase in price then it tries to buy the stock; (2) else if it expects a drop in the price, it sells the stock; (3)and the order in which a player participates in the game is random. The proposed procedure is implemented to simulate trading of three stocks, namely, the Dow Jones, the Nasdaq and the S&P 500. A linear relationship between the number of players and agents versus the computational time to run the complete simulation is observed. It is also found that no player has a monopolistic advantage. ", "machine_text": "  We present a Scalability and Optimisation of a Committee of Agents Using Genetic Algorithm. The motivation for the research is that we have a new committee of agents architecture that has been developed for the problem of decision making in a virtual power plant. The new architecture is composed of several intelligent agents that collaborate to make a decision. Each agent has its own genetic algorithm and is able to evolve. The architecture is designed to be scalable so that it can be used with any number of agents. The problem that we attempt to solve is that we do not know the optimal configuration of the genetic algorithm for each agent. The objective of this work is to find the optimal configuration of the genetic algorithm for each agent so that the committee of agents can make the best decision. The methodology that we use is to evaluate the performance of the committee of agents using different configurations of the genetic algorithm for each agent. We then compare the performance of the committee of agents using the different configurations. The results that we obtain show that there is a significant difference in the performance of the committee of agents using different configurations of the genetic algorithm for each agent. We are able to find the optimal configuration of the genetic algorithm for each agent that gives the best performance to the committee of agents. The practical application of our work is that we can use the committee of agents with the optimal configuration to make the best decision in the virtual power plant. The theoretical application of our work is that we have shown that the performance of a committee of agents can be improved by optimising the configuration of the genetic algorithm for each agent.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observation of Landau levels of Dirac fermions in graphite. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1185, "human_text": "  The low energy electronic excitations in single layer and bilayer graphite (graphene) resemble quantum-relativistic particles also known as Dirac Fermions (DF). They possess an internal degree of freedom, chirality, that leads to unusual Landau Level (LL) energy sequences in a magnetic field and profoundly alters the magneto-transport properties. One of the consequences is an anomalous Quantum-Hall effect, recently detected in both single layer and bi-layer graphene. However the underlying cause, the unusual LL sequence, was never observed. Here we report the direct observation of LL of DF by means of low temperature Scanning-Tunnelling-Spectroscopy (STS) on the surface of graphite in fields up to 12 Tesla. We find evidence of coexistence of massless and massive DF, and identify the zero-energy LL which is a unique consequence of their quantum-relativistic nature. Surprisingly these strictly two-dimensional properties emerge even on bulk graphite in samples where the interlayer coupling is weak. ", "machine_text": "  We report the observation of Landau levels of Dirac fermions in graphite. We show that the Landau levels are well described by a three-band model that includes the spin-density-wave and the s-wave as well as the previously predicted 3/2-dimensional topological defect states. We determine the Landau levels from a systematic dependence of the conductivity on the magnetic field in a wide temperature range below the charge-transport transition temperature, T_c. The order parameter of the Landau levels is found to be equal to the square of the Chern number of the 3/2-dimensional defect state. Our results suggest that the Chern number is a universal topological invariant of a large class of semimetals, including the entire family of group-VI semimetals (as well as some group-V semimetals) with a non-centrosymmetric structure.   We have also determined the bulk conductivity of the non-conductive state by measuring the resistivity as a function of temperature for a large range of magnetic fields applied along the easy direction in the magnetic field. Our results show that the resistivity has a minimum as a function of temperature, in strong contrast to the traditional metallic behavior, and that this minimum is directly related to the 3/2-dimensional topological defect state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Luminous Red Galaxy Population in Clusters at $0.2\\le z\\le 0.6$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0727, "human_text": "  We investigate statistical properties of LRGs in a sample of X-ray selected galaxy clusters at intermediate redshift ($0.2\\le z\\le0.6$). The LRGs are selected based on carefully designed color criteria, and the cluster membership is assessed via photometric redshifts. As clusters and LRGs are both viewed as promising tracer of the underlying dark matter distribution, understanding the distribution of LRGs within clusters is an important issue.   Our main findings include:   1. The halo occupation distribution of LRGs inside our cluster sample is $N(M) = k\\times (M/10^{14})^{a}$ where $a=0.620\\pm 0.105 $ and $k=1.425\\pm0.285 $ assuming a Poisson distribution for $N(M)$.   2. The halo occupation distribution of LRGs ($N(M)$) and the satellite distribution of LRGs ($N-1(M)$) are both consistent with being Poisson. To be more quantitative, we find $Var(N)/<N>= 1.428\\pm 0.351$ and $Var(N-1)/<N-1> = 1.823 \\pm 0.496$   3. The radial profile of LRGs within clusters when fitted with a NFW profile gives a concentration of $17.5^{+7.1}_{-4.3}$ ($6.0^{+3.2}_{-1.9}$) including (excluding) BLRGs (Brightest LRGs).   We also discuss the implications of these observations on the evolution of massive galaxies in clusters. ", "machine_text": "  We present photometric and spectroscopic observations of galaxies in clusters at $0.2\\le z\\le 0.6$. We find that the cluster red sequence is dominated by galaxies that are still quite blue in color, with the number of galaxies becoming increasingly red with clustercentric distance. The average redshift of the cluster red sequence is $z\\sim 1.5$. We find that the observed correlation between clustercentric distance and galaxy color is consistent with an increase in the star formation efficiency with clustercentric distance of $\\sim 1$ mag. We also present a simple model in which the decrease in the effective radius of a cluster with increasing redshift is included. The model produces a good fit to the data, and allows a prediction of the evolution of the number density of luminous galaxies in clusters. We find that the number density of luminous galaxies in clusters increases with clustercentric distance and then decreases with increasing redshift, with a peak number density at $z\\sim 1$. This is consistent with the hypothesis that the peak number density is determined by the number of clusters in the survey, while the decrease with redshift is due to the galaxies in the most distant clusters being drawn away from the clusters by the expansion of the Universe. We also present an analysis of the variation of the color of the cluster red sequence as a function of clustercentric distance, and find that the color distribution of the cluster red sequence is consistent with a single burst of star formation per cluster. We discuss the implications of our results for the future of cluster galaxies, and for the evolution of the large-scale structure in the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Linear Tabling Strategies and Optimizations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3468, "human_text": "  Recently, the iterative approach named linear tabling has received considerable attention because of its simplicity, ease of implementation, and good space efficiency. Linear tabling is a framework from which different methods can be derived based on the strategies used in handling looping subgoals. One decision concerns when answers are consumed and returned. This paper describes two strategies, namely, {\\it lazy} and {\\it eager} strategies, and compares them both qualitatively and quantitatively. The results indicate that, while the lazy strategy has good locality and is well suited for finding all solutions, the eager strategy is comparable in speed with the lazy strategy and is well suited for programs with cuts. Linear tabling relies on depth-first iterative deepening rather than suspension to compute fixpoints. Each cluster of inter-dependent subgoals as represented by a top-most looping subgoal is iteratively evaluated until no subgoal in it can produce any new answers. Naive re-evaluation of all looping subgoals, albeit simple, may be computationally unacceptable. In this paper, we also introduce semi-naive optimization, an effective technique employed in bottom-up evaluation of logic programs to avoid redundant joins of answers, into linear tabling. We give the conditions for the technique to be safe (i.e. sound and complete) and propose an optimization technique called {\\it early answer promotion} to enhance its effectiveness. Benchmarking in B-Prolog demonstrates that with this optimization linear tabling compares favorably well in speed with the state-of-the-art implementation of SLG. ", "machine_text": "  Linear Tabling Strategies and Optimizations  This work presents the first formal study of linear tabling, an important yet under-examined subarea of parameterized algorithmics. We consider several strategies for solving linear tabling problems and show that a simple strategy, calledJM, is nearly-optimal in several cases. We then present an optimization of this strategy that results in a parameterized algorithm for several natural problems, including a variation of the quadratic sensor network problem, the kissing number problem on the projective plane, and a problem related to fast exponentiation. Along the way, we show that a significant number of lower bounds on the running time of linear tabling heuristics are tight. In particular, we show that the previously known tight lower bounds for the hitting time of a line and the d-hitting time of a line are also tight for several other natural linear tabling problems, including the longest increasing subsequence on a line, the convex hull of a set of points on a line, and the minimum vertex degree problem on a line. We conclude by presenting several open problems in this area.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Co-orbital Oligarchy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1079, "human_text": "  We present a systematic examination of the changes in semi-major axis caused by the mutual interactions of a group of massive bodies orbiting a central star in the presence of eccentricity dissipation. For parameters relevant to the oligarchic stage of planet formation, dynamical friction keeps the typical eccentricities small and prevents orbit crossing. Interactions at impact parameters greater than several Hill radii cause the protoplanets to repel each other; if the impact parameter is instead much less than the Hill radius, the protoplanets shift slightly in semi-major axis but remain otherwise unperturbed. If the orbits of two or more protoplanets are separated by less than a Hill radius, they are each pushed towards an equilibrium spacing between their neighbors and can exist as a stable co-orbital system. In the shear-dominated oligarchic phase of planet formation we show that the feeding zones contain several oligarchs instead of only one. Growth of the protoplanets in the oligarchic phase drives the disk to an equilibrium configuration that depends on the mass ratio of protoplanets to planetesimals, $\\Sigma/\\sigma$. Early in the oligarchic phase, when $\\Sigma/\\sigma$ is low, the spacing between rows of co-orbital oligarchs are about 5 Hill radii wide, rather than the 10 Hill radii cited in the literature. It is likely that at the end of oligarchy the average number of co-orbital oligarchs is greater than unity. In the outer solar system this raises the disk mass required to form the ice giants. In the inner solar system this lowers the mass of the final oligarchs and requires more giant impacts than previously estimated. This result provides additional evidence that Mars is not an untouched leftover from the oligarchic phase, but must be composed of several oligarchs assembled through giant impacts. ", "machine_text": "  Co-orbital Oligarchy  We investigate the onset of cooperation and the stability of oligarchic regimes in the tragedy of the commons. We consider a system of co-orbital planets, where each planet extracts a renewable resource from its orbit. We find that cooperation can arise if the resource extraction rate is low. However, if the resource extraction rate is high, the common pool resource is soon depleted, and the system evolves into an oligarchy. We determine the necessary and sufficient conditions for the stability of an oligarchy, and show that the most stable oligarchy is one where the resource extraction rate is proportional to the cube of the population. We find that the most stable regime is a direct power-law regime, where the influencer has a power law distribution of the number of followers. We analyze the effect of the influencer's reputation on the stability of the regime. We also analyze the role of a gossip network in the evolution of the system. We discuss the implications of our findings for the design of cooperative institutions to achieve sustainable development.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The tensor part of the Skyrme energy density functional. I. Spherical   nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0731, "human_text": "  We perform a systematic study of the impact of the J^2 tensor term in the Skyrme energy functional on properties of spherical nuclei. In the Skyrme energy functional, the tensor terms originate both from zero-range central and tensor forces. We build a set of 36 parameterizations, which covers a wide range of the parameter space of the isoscalar and isovector tensor term coupling constants, with a fit protocol very similar to that of the successful SLy parameterizations. We analyze the impact of the tensor terms on a large variety of observables in spherical mean-field calculations, such as the spin-orbit splittings and single-particle spectra of doubly-magic nuclei, the evolution of spin-orbit splittings along chains of semi-magic nuclei, mass residuals of spherical nuclei, and known anomalies of charge radii. Our main conclusion is that the currently used central and spin-orbit parts of the Skyrme energy density functional are not flexible enough to allow for the presence of large tensor terms. ", "machine_text": " The tensor part of the Skyrme energy density functional. I. Spherical nuclei.  We consider the structure of spherical nuclei in the framework of the Skyrme energy density functional. We show that the singularity of the functional at the center is removable in a natural way by a particular choice of the parameters of the functional. As a result, a regular and very general energy density functional is obtained, which can be viewed as a generalization of the Skyrme functional to the case of spherical nuclei. The parameters of this functional are related to the well-known Skyrme parameters. The corresponding Hamiltonian is given in the form of a sum of contributions from Skyrme interactions and a tensor interaction, which is a generalization of the Gauss-Bonnet interaction to the spherical case. The properties of this functional are investigated by means of the nudged-chain method. The resulting properties of spherical nuclei are consistent with the properties of the Skyrme functional and, in addition, some new properties appear, which are related to the properties of the tensor interaction.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Wightman function and vacuum densities for a Z_2-symmetric thick brane   in AdS spacetime. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2245, "human_text": "  Positive frequency Wightman function, vacuum expectation values of the field square and the energy-momentum tensor induced by a Z_{2}-symmetric brane with finite thickness located on (D+1)- dimensional AdS background are evaluated for a massive scalar field with general curvature coupling parameter. For the general case of static plane symmetric interior structure the expectation values in the region outside the brane are presented as the sum of free AdS and brane induced parts. For a conformally coupled massless scalar the brane induced part in the vacuum energy-momentum tensor vanishes. In the limit of strong gravitational fields the brane induced parts are exponentially suppressed for points not too close to the brane boundary. As an application of general results a special model is considered in which the geometry inside the brane is a slice of the Minkowski spacetime orbifolded along the direction perpendicular to the brane. For this model the Wightman function, vacuum expectation values of the field square and the energy-momentum tensor inside the brane are evaluated as well and their behavior is discussed in various asymptotic regions of the parameters. It is shown that for both minimally and conformally coupled scalar fields the interior vacuum forces acting on the brane boundaries tend to decrease the brane thickness. ", "machine_text": "  We calculate the Wightman function and vacuum densities for a Z_2-symmetric thick brane in AdS spacetime. Our calculation shows that the vacuum state has a non-zero Wightman function, which is in sharp contrast to the Wightman function of the vacuum state for a thin brane in AdS spacetime, which was shown by to be identically zero. We also show that the vacuum density is symmetric under a Z_2-symmetry transformation of the bulk fields, which in general is not the case for the Wightman function. The difference between the Wightman function and the vacuum density for the thick brane is related to the difference between the Wightman function and the vacuum density for the thin brane. The connection between the Wightman function and the vacuum density for the thick brane is also related to the bulk variables. The difference between the Wightman function and the vacuum density for the thick brane can be regarded as the twist of the bulk variables. We show that this twist is related to the complex structure of the moduli, and thus can be obtained by using the analytical continuation method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Viscous Torque and Dissipation in the Inner Region of a Thin Accretion   Disk: Implications for Measuring Black Hole Spin. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2244, "human_text": "  We consider a simple Newtonian model of a steady accretion disk around a black hole. The model is based on height-integrated hydrodynamic equations, alpha-viscosity, and a pseudo-Newtonian potential that results in an innermost stable circular orbit (ISCO) that closely approximates the one predicted by GR. We find that the hydrodynamic models exhibit increasing deviations from the standard disk model of Shakura & Sunyaev as disk thickness H/R or the value of alpha increases. The latter is an analytical model in which the viscous torque is assumed to vanish at the ISCO. We consider the implications of the results for attempts to estimate black hole spin by using the standard disk model to fit continuum spectra of black hole accretion disks. We find that the error in the spin estimate is quite modest so long as H/R < 0.1 and alpha < 0.2. At worst the error in the estimated value of the spin parameter is 0.1 for a non-spinning black hole; the error is much less for a rapidly spinning hole. We also consider the density and disk thickness contrast between the gas in the disk and that inside the ISCO. The contrast needs to be large if black hole spin is to be successfully estimated by fitting the relativistically-broadened X-ray line profile of fluorescent iron emission from reflection off an accretion disk. In our hydrodynamic models, the contrast in density and thickness is low when H/R>0.1, sugesting that the iron line technique may be most reliable in extemely thin disks. We caution that these results have been obtained with a viscous hydrodynamic model and need to be confirmed with MHD simulations of radiatively cooled thin disks. ", "machine_text": "  We consider the problem of measuring the spin of a black hole from its accretion disk. The viscous torque in the inner region of a thin accretion disk is found to be anisotropic. We show that this can be used to measure the black hole spin, provided that the disk is able to supply the needed viscous torque. The maximum measurable spin depends on the thickness of the disk, and on the inner edge of the disk. A practical spin measurement would require a rather thick disk with a large inner edge, which is not present in most accretion disks. We also consider the problem of measuring the spin from the viscous torque in a wind falling onto the black hole. A maximum spin measurement is found to be possible without special assumptions, provided that the torque is supplied in a sufficiently strong wind. The accuracy of the measurement is limited by the dynamic memory of the system. A practical spin measurement would require a wind with a high specific entropy, which is not present in most accretion winds. We also derive a simple formula for the viscous torque in the inner region of a thin accretion disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Exotic Mott phases of the extended t--J model on the checkerboard   lattice at commensurate densities. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4198, "human_text": "  Coulomb repulsion between electrons moving on a frustrated lattice can give rise, at simple commensurate electronic densities, to exotic insulating phases of matter. Such a phenomenon is illustrated using an extended t--J model on a planar pyrochlore lattice for which the work on the quarter-filled case [cond-mat/0702367] is complemented and extended to 1/8- and 3/8-fillings. The location of the metal-insulator transition as a function of the Coulomb repulsion is shown to depend strongly on the sign of the hopping. Quite generally, the metal-insulator transition is characterized by lattice symmetry breaking but the nature of the insulating Mott state is more complex than a simple Charge Density Wave. Indeed, in the limit of large Coulomb repulsion, the physics can be described in the framework of (extended) quantum fully-packed loop or dimer models carrying extra spin degrees of freedom. Various diagonal and off-diagonal plaquette correlation functions are computed and the low-energy spectra are analyzed in details in order to characterize the nature of the insulating phases. We provide evidence that, as for an electronic density of n=1/2 (quarter-filling), the system at $n=1/4$ or $n=3/4$ exhibits also plaquette order by forming a (lattice rotationally-invariant) Resonating-Singlet-Pair Crystal, although with a quadrupling of the lattice unit cell (instead of a doubling for $n=1/2$) and a 4-fold degenerate ground state. Interestingly, qualitative differences with the bosonic analog (e.g. known to exhibit columnar order at n=1/4) emphasize the important role of the spin degrees of freedom in e.g. stabilizing plaquette phases w.r.t. rotational symmetry-breaking phases. ", "machine_text": " We study the occurrence of exotic Mott phases in the extended t--J model on the checkerboard lattice at commensurate densities. We consider the model Hamiltonian in the basis of the transverse Ni-- Cu--Ni--Cu sandwiching structure, where the three types of quasiparticles can be viewed as different combinations of a pair of oppositely charged intruders and a pair of spin--aligned electrons. Our calculations show the existence of a rich set of exotic phases, including a non--collapsing phase with large self--energy and a novel type of charge order as well as a host of different spin--ordered phases, such as the (S, F) and (S, P) phases, the latter of which exhibits a large and tunable band gap. In addition, we find a strong dependence of the properties of these exotic phases on the filling fraction, the nature of the exchange interaction, and the onsite Coulomb repulsion U. The results provide a possible route to engineer novel electronic phases using a combination of lattice and spin degrees of freedom.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hydrodynamical simulation of detonations in superbursts. I. The   hydrodynamical algorithm and some preliminary one-dimensional results. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2674, "human_text": "  Aims. This work presents a new hydrodynamical algorithm to study astrophysical detonations. A prime motivation of this development is the description of a carbon detonation in conditions relevant to superbursts, which are thought to result from the propagation of a detonation front around the surface of a neutron star in the carbon layer underlying the atmosphere. Methods. The algorithm we have developed is a finite-volume method inspired by the original MUSCL scheme of van Leer (1979). The algorithm is of second-order in the smooth part of the flow and avoids dimensional splitting. It is applied to some test cases, and the time-dependent results are compared to the corresponding steady state solution. Results. Our algorithm proves to be robust to test cases, and is considered to be reliably applicable to astrophysical detonations. The preliminary one-dimensional calculations we have performed demonstrate that the carbon detonation at the surface of a neutron star is a multiscale phenomenon. The length scale of liberation of energy is $10^6$ times smaller than the total reaction length. We show that a multi-resolution approach can be used to solve all the reaction lengths. This result will be very useful in future multi-dimensional simulations. We present also thermodynamical and composition profiles after the passage of a detonation in a pure carbon or mixed carbon-iron layer, in thermodynamical conditions relevant to superbursts in pure helium accretor systems. ", "machine_text": " We present a hydrodynamical algorithm to simulate detonations in superbursts. The algorithm is based on the solution of the 3-D Euler equations with appropriate boundary conditions at the detonation front. The detonation is described by a thermodynamically consistent constitutive relation which includes the effects of both of the main thermodynamic processes, i.e. the work done on the gas and the energy release due to the explosion. The equation of state used is a thermodynamically consistent form of the ideal gas law. We solve the 3-D Euler equations with the help of a streamtube decomposition which reduces the 3-D problem to a 1-D problem and allows to solve the gas dynamics in the streamtube with the help of a implicit, finite volume method. In the framework of this method the constitutive relation is implemented in a simple, but consistent way. We present results for one-dimensional (1-D) gas dynamics which show the influence of the different parameters on the dynamics of the detonation and the structure of the detonation front.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Baryon Fractions and Mass-to-Light Ratios of Early-Type Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3647, "human_text": "  We jointly model 22 early-type gravitational lens galaxies with stellar dynamical measurements using standard CDM halo models. The sample is inhomogeneous in both its mass distributions and the evolution of its stellar populations unless the true uncertainties are significantly larger than the reported measurement errors. In general, the individual systems cannot constrain halo models, in the sense that the data poorly constrains the stellar mass fraction of the halo. The ensemble of systems, however, strongly constrains the average stellar mass represented by the visible galaxies to $0.026\\pm0.006$ of the halo mass if we neglect adiabatic compression, rising to $0.056\\pm0.011$ of the halo mass if we include adiabatic compression. Both estimates are significantly smaller than the global baryon fraction, corresponding to a star formation efficiency for early-type galaxies of $10%-30%$. In the adiabatically compressed models, we find an average local B-band stellar mass-to-light ratio of $(M/L)_0 = (7.2\\pm0.5)(M_{\\sun}/L_{\\sun})$ that evolves by $d\\log(M/L)/dz = -0.72\\pm0.08$ per unit redshift. Adjusting the isotropy of the stellar orbits has little effect on the results. The adiabatically compressed models are strongly favored if we impose either local estimates of the mass-to-light ratios of early-type galaxies or the weak lensing measurements for the lens galaxies on 100 kpc scales as model constraints. ", "machine_text": "  The Baryon Fractions and Mass-to-Light Ratios of Early-Type Galaxies  We present baryon fraction and mass-to-light ratio measurements for galaxies in the local volume from the SDSS, and a comparison with the results from the 2MASS Redshift Survey. We find that the local baryon fraction is consistent with the value found in the 2MASS Redshift Survey, but the local M/L is smaller than the value found in the 2MASS Redshift Survey by about 5%, suggesting that the local galaxies are more efficient in converting baryonic matter into non-baryonic matter. The mass-to-light ratios of the local galaxies are consistent with the simple relation, M/L \u221d (M/R)^(3/2), where M/R is the surface mass density profile, but the local M/L is systematically smaller than the prediction based on the observed relationship by about 6%, suggesting that the local galaxies have higher concentrations of dark matter. We discuss these results in the context of the recent results of the SDSS MaNGA survey, which suggests that the M/L of galaxies is well described by the M/R^(3/2) relation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Universal Substructure Distributions in LCDM halos: Can we find a Fossil   Group?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2604, "human_text": "  We use large cosmological N-body simulations to study the subhalo population in galaxy group sized halos. In particular, we look for fossil group candidates with typical masses ~10-25% of Virgo cluster but with an order of magnitude less substructure. We examine recent claims that the earliest systems to form are deficient enough in substructure to explain the luminosity function found in fossil groups. Although our simulations show a correlation between the halo formation time and the number of subhalos, the maximum suppression of subhalos is a factor of 2-2.5, whereas a factor of 6 is required to match fossil groups and galaxies. While the number of subhalos depends weakly on the formation time, the slope of the halo substructure velocity function does not. The satellite population within Cold Dark Matter (CDM) halos is self-similar at scales between galaxies and galaxy clusters regardless of mass, whereas current observations show a break in self-similarity at a mass scale corresponding to group of galaxies. ", "machine_text": " We present an analysis of the correlation functions of the matter density, temperature, and equation of state radial distributions in dark matter halos in a LCDM cosmology. We show that these correlation functions can be related to the universal substructure distributions in the halos. In particular, we show that the correlation functions of the matter density, temperature, and equation of state radial distributions in halos are well described by a sum of multiple terms, each of which depends only on the scale of the halo. The n-th term in the sum is a functional form of the n-th universal substructure distribution. Our result provides a new approach to extract the universal substructure distributions in LCDM halos. We also show that the extraction of the exact form of the functional relation between the correlation functions and the universal substructure distributions can be non-trivial. In particular, we show that the universal substructure distributions can be related to the correlation functions by a non-trivial power law relation in a certain range of the scale of the halo. This range can be considered as a \"fossil group\" of the halos, where the evolution of the correlation functions and the universal substructure distributions is very slow. We show that this fossil group can be found by fitting the correlation functions with a power law relation. Our results suggest that the theory of halos with anisotropic accretion can successfully describe the correlation functions of the matter density, temperature, and equation of state radial distributions in halos, and provide a new way to extract the universal substructure distributions in LCDM halos.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An X-ray Spectral Analysis of the Central Regions of NGC 4593. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1083, "human_text": "  We present a detailed analysis of XMM-Newton EPIC-pn data for the Seyfert-1 galaxy NGC 4593. We discuss the X-ray spectral properties of this source as well as its variations with time. The 0.5-10 keV spectrum shows significant complexity beyond a simple power-law form, with clear evidence existing for a \"soft excess\" as well as absorption by highly ionized plasma (a warm absorber) within the central engine of this active galactic nucleus. We show that the soft excess is best described as originating from thermal Comptonization by plasma that is appreciably cooler than the primary X-ray emitting plasma; we find that the form of the soft excess cannot be reproduced adequately by reflection from an ionized accretion disk. The only measurable deviation from the power-law continuum in the hard spectrum comes from the presence of cold and ionized fluorescent iron-K emission lines at 6.4 and 6.97 keV, respectively. While constraints on the ionized iron line are weak, the cold line is found to be narrow at CCD-resolution with a flux that does not track the temporal changes in the underlying continuum, implying an origin in the outer radii of the accretion disk or the putative molecular torus of Seyfert unification schemes. The X-ray continuum itself varies on all accessible time scales. We detect a ~230-second time-lag between soft and hard EPIC-pn bands that, if interpreted as scattering timescales within a Comptonizing disk corona, can be used to constrain the physical size of the primary X-ray source to a characteristic length scale of ~2 gravitational radii. Taken together, the small implied coronal size and the large implied iron line emitting region indicate a departure from the current picture of a \"typical\" AGN geometry. ", "machine_text": "  We present here an analysis of the X-ray emission from the central regions of NGC 4593, a barred spiral galaxy in which a low-ionization nuclear ring and a prominent X-ray cavity have been discovered. We find that the ionization structure in the ring is maintained by both a central ionizing source and the reprocessing of accretion shock ionization. The ionization structure in the inner 30 arcsec is well described by a formalism that assumes a Gaussian distribution of ionizing source functions. The principal components of the X-ray spectrum can be accounted for by a model in which the ionizing source is a 0.6 kpc long, 1 kpc wide radio source (centrically located within the bar) that is optically thick and able to produce a full ionization spectrum with a photon index of 1.4. We show that this source is able to maintain the observed ionization structure in the ring, but that the same source cannot produce the ionization in the inner 30 arcsec, in which the spectrum isdominated by a power law with a photon index of 1.9. We show that this power law can be explained by a model in which the ionizing source is an optically thin, 1.4 kpc long, 1.5 kpc wide region (centered 3.5 kpc from the nucleus) that produces an ionization spectrum with a photon index of 1.0. We discuss a physical explanation for the presence of such a source in the form of a radioactive ring. We also discuss a model in which the X-ray emitting region in the inner 30 arcsec is due to reprocessing of ionization from the accretion shock. We point out that the combination of both of these effects may be needed to explain the ionization structure in the central regions of NGC 4593.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Long-Term Evolution of Massive Black Hole Binaries. III. Binary   Evolution in Collisional Nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2745, "human_text": "  [Abridged] In galactic nuclei with sufficiently short relaxation times, binary supermassive black holes can evolve beyond their stalling radii via continued interaction with stars. We study this \"collisional\" evolutionary regime using both fully self-consistent N-body integrations and approximate Fokker-Planck models. The N-body integrations employ particle numbers up to 0.26M and a direct-summation potential solver; close interactions involving the binary are treated using a new implementation of the Mikkola-Aarseth chain regularization algorithm. Even at these large values of N, two-body scattering occurs at high enough rates in the simulations that they can not be simply scaled to the large-N regime of real galaxies. The Fokker-Planck model is used to bridge this gap; it includes, for the first time, binary-induced changes in the stellar density and potential. The Fokker-Planck model is shown to accurately reproduce the results of the N-body integrations, and is then extended to the much larger N regime of real galaxies. Analytic expressions are derived that accurately reproduce the time dependence of the binary semi-major axis as predicted by the Fokker-Planck model. Gravitational wave coalescence is shown to occur in <10 Gyr in nuclei with velocity dispersions below about 80 km/s. Formation of a core results from a competition between ejection of stars by the binary and re-supply of depleted orbits via two-body scattering. Mass deficits as large as ~4 times the binary mass are produced before coalescence. After the two black holes coalesce, a Bahcall-Wolf cusp appears around the single hole in one relaxation time, resulting in a nuclear density profile consisting of a flat core with an inner, compact cluster, similar to what is observed at the centers of low-luminosity spheroids. ", "machine_text": " We present a systematic study of the long-term evolution of a large sample of massive black hole binaries in collisional nuclei. We consider the relaxation of the orbits due to gravitational radiation and tidal interactions, and the effect of these interactions on the spin and temperature evolution of the black holes. We find that the frequency distribution of the orbital period is well described by a power law with a direct current cut-off, and that the black holes can be efficiently spun-up by gravitational interactions, but only for orbital periods larger than a few hours. We also find that the black hole temperature is influenced by the efficiency of the spin-up process, which can be very efficient for low-mass X-ray binaries in tight orbits, leading to very hot black holes. For massive black hole binaries, the evolution of the temperature is governed by the energy exchange between the two objects, and the efficiency of the spin-up process is very small, leading to low-mass X-ray binaries in wide orbits and with very low temperature. We discuss the implications of our results for the evolution of massive black hole binaries and the origin of the different populations of low-mass X-ray binaries observed in the Galaxy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Uncovering the Internal Structure of the Indian Financial Market:   Cross-correlation behavior in the NSE. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2115, "human_text": "  The cross-correlations between price fluctuations of 201 frequently traded stocks in the National Stock Exchange (NSE) of India are analyzed in this paper. We use daily closing prices for the period 1996-2006, which coincides with the period of rapid transformation of the market following liberalization. The eigenvalue distribution of the cross-correlation matrix, $\\mathbf{C}$, of NSE is found to be similar to that of developed markets, such as the New York Stock Exchange (NYSE): the majority of eigenvalues fall within the bounds expected for a random matrix constructed from mutually uncorrelated time series. Of the few largest eigenvalues that deviate from the bulk, the largest is identified with market-wide movements. The intermediate eigenvalues that occur between the largest and the bulk have been associated in NYSE with specific business sectors with strong intra-group interactions. However, in the Indian market, these deviating eigenvalues are comparatively very few and lie much closer to the bulk. We propose that this is because of the relative lack of distinct sector identity in the market, with the movement of stocks dominantly influenced by the overall market trend. This is shown by explicit construction of the interaction network in the market, first by generating the minimum spanning tree from the unfiltered correlation matrix, and later, using an improved method of generating the graph after filtering out the market mode and random effects from the data. Both methods show, compared to developed markets, the relative absence of clusters of co-moving stocks that belong to the same business sector. This is consistent with the general belief that emerging markets tend to be more correlated than developed markets. ", "machine_text": " We investigate the internal structure of the Indian financial market by analyzing the cross-correlation behavior in the National Stock Exchange (NSE). We find that the cross-correlation function (CCF) exhibits a clear structure, which we analyze by using the Hilbert-Huang transformation (HHT). Our results show that the HHT-based descriptors capture the underlying structure of the NSE market, and the subsequent segmentation of the market based on these descriptors reveals the existence of different market states. We further analyze the local structure of the market by using the empirical mode decomposition (EMD) method, and show that the market dynamics can be described by a small number of components. We also investigate the evolution of these components over time, and find that the market dynamics is characterized by long-memory behavior. Our results provide new evidence on the internal structure of the Indian financial market, and have important implications for both theory and practice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Near-Infrared and X-ray Observations of the Enigmatic G70.7+1.2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2415, "human_text": "  We present high resolution imaging of the puzzling radio and optical nebula G70.7+1.2 with the Keck Observatory's laser guide star adaptive optics (LGS-AO) system and the Chandra X-ray Observatory. The archival X-ray observations show a hard (Gamma ~ 1.8), low luminosity (L_X ~ 4 x 10^31 ergs/s) point source at the center of the nebula. Follow-up LGS-AO near-infrared imaging of the Chandra error circle reveals a relatively bright (K' ~ 14 magnitude) counterpart. Both its color and brightness are consistent with a heavily obscured B-star or possibly a late-G/early-K giant. The most plausible explanation is that this newly discovered X-ray source is a non-accreting B-star/pulsar binary powering the radio and optical nebula. If so, the luminous Be-star discussed in the literature seemingly embedded in the nebula is not the dominant force responsible for shaping G70.7+1.2. Thus, we suggest that G70.7+1.2 is the result of two unrelated objects (a B-star X-ray binary and a Be star) interacting with a dense molecular cloud. With this explanation we believe we have solved the mystery of the origin of G70.7+1.2. ", "machine_text": "  We present high spatial resolution (19.5 ''') imaging observations in the near-infrared (NIR) and X-ray of the peculiar galaxy G70.7+1.2. We find that the nuclear region of G70.7+1.2 is populated by a number of sources, including an unresolved supermassive black hole (SMBH) at the galaxy's center. The NIR and X-ray images are not well-correlated, indicating that the nuclear region is probably strongly coupled to the circumnuclear region. We find that the non-SMBH sources in the nuclear region are too bright to be explained by accretion onto a SMBH. A simple model in which a SMBH is surrounded by a ball of hot gas can quantitatively explain the observed NIR and X-ray emission from the central region. However, the SMBH mass required is much larger than the galaxy's total stellar mass, suggesting that this SMBH has accreted gas from its surroundings. We discuss two possible physical mechanisms for this: a wind driven by the SMBH and the tidally stripping of gas from a SMBH's accretion disc. Our results suggest that SMBHs can have a profound impact on the evolution of their host galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gamma-Ray Burst Afterglows as Probes of Environment and Blastwave   Physics II: the Distribution of p and Structure of the Circumburst Medium. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3718, "human_text": "  We constrain blastwave parameters and the circumburst media of a subsample of ten BeppoSAX Gamma-Ray Bursts. For this sample we derive the values of the injected electron energy distribution index, p, and the density structure index of the circumburst medium, k, from simultaneous spectral fits to their X-ray, optical and nIR afterglow data. The spectral fits have been done in count space and include the effects of metallicity, and are compared with the previously reported optical and X-ray temporal behaviour. Using the blastwave model and some assumptions which include on-axis viewing and standard jet structure, constant blastwave energy and no evolution of the microphysical parameters, we find a mean value of p for the sample as a whole of 2.04 +0.02/-0.03. A statistical analysis of the distribution demonstrates that the p values in this sample are inconsistent with a single universal value for p at the 3-sigma level or greater, which has significant implications for particle acceleration models. This approach provides us with a measured distribution of circumburst density structures rather than considering only the cases of k=0 (homogeneous) and k=2 (wind-like). We find five GRBs for which k can be well constrained, and in four of these cases the circumburst medium is clearly wind-like. The fifth source has a value of 0<k<1, consistent with a homogeneous circumburst medium. ", "machine_text": " Gamma-ray bursts (GRBs) are the most energetic events in the universe, thought to occur when a supermassive black hole is launched from a dying star. The nature of the launches is not well understood, but the sprays of charged particles which are launched along with the black hole can interact with the surrounding medium, producing a diffuse glow known as an afterglow. We present here results of a systematic, multiwavelength study of the distribution of the afterglow in the circumburst medium of 25 nearby (D/L < 2000) gamma-ray bursts. We find that the average distribution is well described by a spherical volume distribution with the burst source at the center. We determine the scale-length (r0) of the distribution to be 1.6 \u00b1 0.8 kpc, and the metallicity of the circumburst medium to be Z \u2248 1.5 \u00b1 1.3 Z\u2299. We determine the density structure of the circumburst medium by modeling the time-integrated optical/NIR afterglow as a function of radius. We find that the density has a substantial radial gradient, with an outer scale-length (r1) of 4.6 \u00b1 1.1 kpc. The mean density in the circumburst medium is \u03c10 \u2248 3.6 \u00b1 2.4 kg m\u22123, with an inner fraction (r < r0) of \u03c11 \u2248 6.7 \u00b1 2.7 kg m\u22123. We estimate the metallicity of the burst-propulsion medium to be Z \u2248 1.2 \u00b1 1.0 Z\u2299. We discuss the implications of our results for the burst mechanism and the nature of the circumburst medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flow instabilities of magnetic flux tubes II. Longitudinal flow. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3685, "human_text": "  Flow-induced instabilities are relevant for the storage and dynamics of magnetic fields in stellar convection zones and possibly also in other astrophysical contexts. We continue the study started in the first paper of this series by considering the stability properties of longitudinal flows along magnetic flux tubes. A linear stability analysis was carried out to determine criteria for the onset of instability in the framework of the approximation of thin magnetic flux tubes. In the non-dissipative case, we find Kelvin-Helmholtz instability for flow velocities exceeding a critical speed that depends on the Alfv{\\'e}n speed and on the ratio of the internal and external densities. Inclusion of a friction term proportional to the relative transverse velocity leads to a friction-driven instability connected with backward (or negative energy) waves. We discuss the physical nature of this instability. In the case of a stratified external medium, the Kelvin-Helmholtz instability and the friction-driven instability can set in for flow speeds significantly lower than the Alfv{\\'e}n speed. Dissipative effects can excite flow-driven instability below the thresholds for the Kelvin-Helmholtz and the undulatory (Parker-type) instabilities. This may be important for magnetic flux storage in stellar convection zones and for the stability of astrophysical jets. ", "machine_text": " We continue our study of the flow instabilities of magnetic flux tubes in a simple model of a flux tube in a uniform flow. In Part I we considered the steady state of a vertical flux tube in a longitudinal flow and showed that it is unstable against a flow-induced perturbation in a direction perpendicular to the flux tube and the flow. Here we consider the limit of a large vertical tube and a small longitudinal flow. We show that this limit is stable against a flow-induced perturbation in a direction perpendicular to the flux tube and the flow. We then consider the limit of a small vertical tube and a large longitudinal flow. We show that this limit is also stable against a flow-induced perturbation in a direction perpendicular to the flux tube and the flow. In both cases the tube deforms in the longitudinal direction but returns to its original shape after the perturbation has died out. We also show that these limits are stable against a vertical perturbation which does not change the total magnetic flux through the tube.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A new chaotic attractor in a basic multi-strain epidemiological model   with temporary cross-immunity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3174, "human_text": "  An epidemic multi-strain model with temporary cross-immunity shows chaos, even in a previously unexpected parameter region. Especially dengue fever models with strong enhanced infectivity on secondary infection have previously shown deterministic chaos motivated by experimental findings of antibody-dependent-enhancement (ADE). Including temporary cross-immunity in such models, which is common knowledge among field researchers in dengue, we find a deterministically chaotic attractor in the more realistic parameter region of reduced infectivity on secondary infection (''inverse ADE'' parameter region). This is realistic for dengue fever since on second infection people are more likely to be hospitalized, hence do not contribute to the force of infection as much as people with first infection.   Our finding has wider implications beyond dengue in any multi-strain epidemiological systems with altered infectivity upon secondary infection, since we can relax the condition of rather high infectivity on secondary infection previously required for deterministic chaos. For dengue the finding of wide ranges of chaotic attractors open new ways to analysis of existing data sets. ", "machine_text": " We introduce a new chaotic attractor in a basic multi-strain epidemiological model with temporary cross-immunity. The model consists of a system of three differential equations describing the evolution of the three different strains. Temporary cross-immunity causes the infection to switch between different strains. Our analysis shows that the new attractor is stable against changes in the initial conditions and remains stable in the limit of large populations. By using the newly obtained attractor we are able to give a detailed qualitative description of the dynamics of the system in the case without vaccination. We find that in this case the epidemiological model can exhibit three different types of behaviour: (i) an outbreak of one of the strains, (ii) a constant presence of all three strains at their carrying capacity, and (iii) a fast alternating sequence of outbreaks of the three strains. The first case occurs if the basic reproduction number of one of the strains is larger than the sum of the basic reproduction numbers of the other two strains. The second case occurs if the basic reproduction numbers of all three strains are equal. The third case is a generalization of the first case and occurs if the basic reproduction number of each strain is larger than the sum of the basic reproduction numbers of the other two strains. In all three cases the total population size is constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Line and continuum variability of two intermediate-redshift,   high-luminosity quasars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1958, "human_text": "  It has been shown that the luminosity of AGNs and the size of their broad line region obey a simple relation of the type R=a L^g, from faint Seyfert nuclei to bright quasars, allowing single-epoch determination of the central black hole mass M=b L^g D^2 from their luminosity L and width of H_beta emission line. Adopting this mass determination for cosmological studies requires the extrapolation to high z and L of a relation whose calibration relies so far on reverberation mapping measurements performed for L<10^46 erg/s and z<0.4. We initiated a campaign for the monitoring of a few luminous, intermediate z quasars whose apparent magnitude V<15.7 allows observations with a 1.8m telescope, aimed at proving that emission lines vary and respond to continuum variations even for luminosities >10^47 erg/s, and determining eventually their M_BH from reverberation mapping. We have repeatedly performed simultaneous observations of quasars and reference stars to determine relative variability of continuum and emission lines. We describe the observations and methods of analysis. For the quasars PG1634+706 and PG1247+268 we obtain light-curves respectively for CIII], MgII and for CIV, CIII] emission lines with the relevant continua. During 3.2 years of observation, in the former case no continuum variability has been detected and the evidence for line variability is marginal, while in the latter case both continuum and line variability are detected with high significance and the line variations appear correlated with continuum variations. The detection of the emission line variability in a quasar with L~10^47 erg/s encourages the prosecution of the campaign which should provide a black hole mass estimate in other 5-6 years, constraining the M_BH-L relation in a poorly explored range of luminosity. ", "machine_text": "  We present a detailed study of the line and continuum variability of two bright quasars, QB1 and QB2, at intermediate redshift (z ~ 1.1), selected from a sample of over 2000 quasars with available high-resolution echelle spectra. We find that both quasars exhibit extremely large (by an order of magnitude) continuum variability on timescales of weeks, which we attribute to the intrinsic variability of the accretion disc around the black hole. The observed continuum variability can be described using a simple model in which the accretion disc is treated as a uniform disk with an assumed turbulent velocity field, the solution of which gives a simple, power law continuum variability as a function of time. We show that this simple model can be used to reliably predict the continuum variability as a function of time for quasars with unknown continuum variability. In addition, we show that this model can be used to determine the size of the accretion disc, the duration of a typical accretion event, and the accretion rate of the quasar. We also find that both quasars exhibit non-negligible line variability, with the line-center optical depth varying by  \u223c 1.5%. We show this line variability is consistent with a model in which the line-forming region is treated as a cylindrical shell with an assumed velocity field, the solution of which gives a line variability that is in agreement with our observations. We conclude that this model can be used to describe the line variability of quasars with an unknown line variability, given knowledge of the continuum variability.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: High-energy Cosmic Rays and Neutrinos from Semi-relativistic Hypernovae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0027, "human_text": "  The origin of the ultrahigh-energy (UHE) cosmic rays (CRs) from the second knee ($\\sim6\\times10^{17}$eV) above in the CR spectrum is still unknown. Recently, there has been growing evidence that a peculiar type of supernovae, called hypernovae, are associated with sub-energetic gamma-ray bursts (GRBs), such as SN1998bw/GRB980425 and SN2003lw/GRB031203. Such hypernovae appear to have high (up to mildly relativistic) velocity ejecta, which may be linked to the sub-energetic GRBs. Assuming a continuous distribution of the kinetic energy of the hypernova ejecta as a function of its velocity $E_k\\propto (\\Gamma\\beta)^{-\\alpha}$ with $\\alpha\\sim 2$, we find that 1) the external shock wave produced by the high velocity ejecta of a hypernova can accelerate protons up to energies as high as $10^{19} {\\rm eV}$; 2) the cosmological hypernova rate is sufficient to account for the energy flux above the second knee; and 3) the steeper spectrum of CRs at these energies can arise in these sources. In addition, hypernovae would also give rise to a faint diffuse UHE neutrino flux, due to $p\\gamma$ interactions of the UHE CRs with hypernova optical-UV photons. ", "machine_text": "  We consider the problem of the origin of high-energy cosmic rays and neutrinos in the framework of thefishbone mechanism. According to this scenario, the high-energy particles are producedby the semi-relativistic jet that is formed during the collapse of a massive star. It is shownthat the relative strength of the high-energy neutrino flux as compared to the flux of high-energycosmic rays is related to the relative content of the exotic hadron-like particles (like omega,sigma, and gluinos) in the final hadron shower. This, in its turn, depends on the initialmagnetic field configuration in the star and the jet. We analyze the three simplest cases ofthe magnetic field configuration in the jet and show that in all these cases the relative content ofthe exotic hadron-like particles in the final shower is small, which explains the relative weaknessof the neutrino flux as compared to the cosmic ray flux observed on Earth. We also discuss thepossible mechanisms of the particle energy distribution in the jet, and show that the only themethat can explain the observed energy distribution of the particles in the jet is the exponentialenergy distribution function with the index of 1.8. This result was obtained by us earlier for thecosmological sources of the high-energy cosmic rays and neutrinos. We also analyze theproportions of the different hadron-like particles in the jet, and show that in all cases themajority of the hadron-like particles in the jet are the light ones, like protons and alphas. Theonly exception is the case with the magnetic field parallel to the jet, when the heavy hadron-like particles (with the mass number A > 2) can be dominant. In all other cases theproportion of the heavy hadron-like particles is small.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sensitivity of low degree oscillations to the change in solar abundances. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2294, "human_text": "  Context. The most recent determination of the solar chemical composition, using a time-dependent, 3D hydrodynamical model of the solar atmosphere, exhibits a significant decrease of C, N, O abundances compared to their previous values. Solar models that use these new abundances are not consistent with helioseismological determinations of the sound speed profile, the surface helium abundance and the convection zone depth. Aims. We investigate the effect of changes of solar abundances on low degree p-mode and g-mode characteristics which are strong constraints of the solar core. We consider particularly the increase of neon abundance in the new solar mixture in order to reduce the discrepancy between models using new abundances and helioseismology. Methods. The observational determinations of solar frequencies from the GOLF instrument are used to test solar models computed with different chemical compositions. We consider in particular the normalized small frequency spacings in the low degree p-mode frequency range. Results. Low-degree small frequency spacings are very sensitive to changes in the heavy-element abundances, notably neon. We show that by considering all the seismic constraints, including the small frequency spacings, a rather large increase of neon abundance by about (0.5 +/- 0.05)dex can be a good solution to the discrepancy between solar models that use new abundances and low degree helioseismology, subject to adjusting slightly the solar age and the highest abundances. We also show that the change in solar abundances, notably neon, considerably affects g-mode frequencies, with relative frequency differences between the old and the new models higher than 1.5% ", "machine_text": "  We have performed a detailed study of the sensitivity of low degree oscillations to the change in solar abundances. We find that the properties of low degree oscillations are very sensitive to the change in solar abundances, and the change in the relative abundances of different elements can lead to a significant change in the low degree oscillations. Our results suggest that the study of low degree oscillations can be used as a tool to study the change in solar abundances. We have also developed a new method to extract the relative abundances of different elements from the low degree oscillations. Our method is based on the use of the Fourier transform of the power spectrum, and we show that our method is more sensitive to the change in relative abundances of different elements than the traditional method based on the analysis of the power spectrum.  Our work attempts to solve the problem of how to extract the relative abundances of different elements from low degree oscillations, and how to make the extraction more sensitive to the change in relative abundances. Our work has practical applications in the study of solar physics, and can be used to study the evolution of solar abundances. Our work also has theoretical implications for the understanding of low degree oscillations, and suggests that the study of low degree oscillations can be used to study the change in solar abundances.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: AMBER on the VLTI: data processing and calibration issues. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1636, "human_text": "  We present here the current performances of the AMBER / VLTI instrument for standard use and compare these with the offered modes of the instrument. We show that the instrument is able to reach its specified precision only for medium and high spectral resolution modes, differential observables and bright objects. For absolute observables, the current achievable accuracy is strongly limited by the vibrations of the Unit Telescopes, and also by the observing procedure which does not take into account the night-long transfer function monitoring. For low-resolution mode, the current limitation is more in the data reduction side, since several effects negligible at medium spectral resolution are not taken into account in the current pipeline. Finally, for faint objects (SNR around 1 per spectral channel), electromagnetic interferences in the VLTI interferometric laboratory with the detector electronics prevents currently to get unbiased measurements. Ideas are under study to correct in the data processing side this effect, but a hardware fix should be investigated seriously since it limits seriously the effective limiting magnitude of the instrument. ", "machine_text": "  AMBER on the VLTI: data processing and calibration issues  A major aspect of the VLTI is the combination of the light from the different telescopes, referred to as interferometry. This requires precise knowledge of the baseline lengths between the telescopes, as well as of the optical path differences between the different arms. We report on the methods that we have developed to measure these quantities, on the basis of the data that we have obtained with AMBER during the first year of observations. We have been able to show that the VLTI can provide visibilities with an accuracy of a few percent, when using the two-channel techniques that we have developed. This is significantly better than what can be achieved with theMichelson interferometer, and it is only limited by the accuracy with which the absolute visibilities can be measured. We discuss the limitations of the data processing, and in particular the effect of decorrelation in the pupil images. We show that AMBER is already providing data with an accuracy that is close to the theoretical limit, and that this will improve further with longer integrations. We also discuss the limitations of the current model of the atmosphere, and in particular of the model of the telluric contributions. We estimate that this will limit the accuracy of the VLTI to a few tens of milliarcseconds in the coming years, and that a better model would enable a factor of two improvement. We also report on the effort that we have made to reduce the scattered light in the AMBER data, and on the relative importance of the different contributions. We show that the dominant contribution to the scattered light is from the atmosphere, and that this can be reduced by a factor of a few.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Common Envelope Evolution Redux. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.028, "human_text": "  Common envelopes form in dynamical time scale mass exchange, when the envelope of a donor star engulfs a much denser companion, and the core of the donor plus the dense companion star spiral inward through this dissipative envelope. As conceived by Paczynski and Ostriker, this process must be responsible for the creation of short-period binaries with degenerate components, and, indeed, it has proven capable of accounting for short-period binaries containing one white dwarf component. However, attempts to reconstruct the evolutionary histories of close double white dwarfs have proven more problematic, and point to the need for enhanced systemic mass loss, either during the close of the first, slow episode of mass transfer that produced the first white dwarf, or during the detached phase preceding the final, common envelope episode. The survival of long-period interacting binaries with massive white dwarfs, such as the recurrent novae T CrB and RS Oph, also presents interpretative difficulties for simple energetic treatments of common envelope evolution. Their existence implies that major terms are missing from usual formulations of the energy budget for common envelope evolution. The most plausible missing energy term is the energy released by recombination in the common envelope, and, indeed, a simple reformulation the energy budget explicitly including recombination resolves this issue. ", "machine_text": "  Common Envelope Evolution Redux  We present observations of the optical and near-infrared photometry and spectroscopy of the first non- solar companions to be discovered, the original planets of the solar system: Mercury, Venus, Earth, and Mars. Our data include new observations of the steady-state photometry of Mars in the 2-micron band, which we use to constrain the size of the Martian photosphere. We find that the photospheres of all four planets are significantly larger than the surfaces of their respective atmospheres. This is consistent with a significant fraction of the photosphere being bled off into an extended, unlit atmosphere. We have developed a model that relates the observed photosphere-to-atmosphere ratio to the escape probability of the atmosphere. In this model, the photosphere is treated as a perfect black body, while the atmosphere is treated either as a perfect absorber or a perfect emitter. We use this model to constrain the fraction of the photosphere that has been lost into the atmosphere for each planet, and we use the results to determine the scale height of the atmosphere for each planet. For the cases in which the atmosphere is treated as a perfect absorber, the scale height is found to be in the range of 4 to 7 km, while for the cases in which the atmosphere is treated as a perfect emitter, the scale height is in the range of 1 to 2 km. These results are consistent with a significant fraction of the original photospheres having been lost to the atmospheres of all four planets, and they suggest that the atmospheres of all four planets are thermally supported. We discuss the implications of our results for the evolution of the common envelopes of the planets, and for the general problem of atmosphere escape from solar system bodies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mass Loss and Evolution of Stars and Star Clusters: a Personal   Historical Perspective. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3159, "human_text": "  The development and progress of the studies of winds and mass loss from hot stars, from about 1965 up to now, is discussed in a personal historical perspective. The present state of knowledge about stellar winds, based on papers presented at this workshop, is described. About ten years ago the mechanisms of the winds were reasonably well understood, the mass loss rates were known, and the predictions of stellar evolution theory with mass loss agreed with observations. However, recent studies especially those based on FUSE observations, have resulted in a significant reduction of the mass loss rates, that disagrees with predictions from radiation driven wind models. The situation is discussed and future studies that can clarify the situation are suggested.   I also discuss what is known about the dissolution of star clusters in different environments. The dissolution time can be derived from the mass and age distributions of cluster samples. The resulting dissolution times of clusters in the solar neighborhood (SN) and in interacting galaxies are shorter than predicted by two-body relaxation of clusters in a tidal field. Encounters with giant molecular clouds can explain the fate of clusters in the SN and are the most likely cause of the short lifetime of clusters in interacting galaxies. ", "machine_text": "  Mass Loss and Evolution of Stars and Star Clusters: a Personal   Historical Perspective  We present a personal historical perspective on the research topics of mass loss and evolutionary theory of stars and star clusters. We review our own contributions to these topics, and place them in the context of the overall evolution of these research areas. We then discuss outstanding problems and questions, and describe future prospects for theoretical and observational advances. We focus on the three fundamental issues of mass loss and evolution: the relative importance of mass loss and evolutionary theory for the determination of the properties and evolution of stars and star clusters; the use of observations, especially of high-resolution spectroscopy, to constrain theoretical models of mass loss and evolution; and the confrontation and eventual reconciliation of different theoretical models of mass loss and evolution. We also discuss in some detail the problem of low-mass star formation and the evolution of planetary systems, and we highlight the key role that the study of mass loss and evolution must play in the investigation of the galactic habitable zone and the frequency and characteristics of life in the Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Instabilities in the time-dependent neutrino disc in Gamma-Ray Bursts. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1325, "human_text": "  We investigate the properties and evolution of accretion tori formed after the coalescence of two compact objects. At these extreme densities and temperatures, the accreting torus is cooled mainly by neutrino emission produced primarily by electron and positron capture on nucleons (beta reactions). We solve for the disc structure and its time evolution by introducing a detailed treatment of the equation of state which includes photodisintegration of helium, the condition of beta-equilibrium, and neutrino opacities. We self-consistently calculate the chemical equilibrium in the gas consisting of helium, free protons, neutrons and electron-positron pairs and compute the chemical potentials of the species, as well as the electron fraction throughout the disc. We find that, for sufficiently large accretion rates (> 10 solar masses per second), the inner regions of the disk become opaque and develop a viscous and thermal instability. The identification of this instability might be relevant for GRB observations. ", "machine_text": " We present a detailed study of the time-dependent neutrino disc in Gamma-Ray Bursts (GRBs). We consider a basic model consisting of a burst with a hard spectrum, a cut-off power-law and a exponential cutoff at the high energy end, in a uniform and homogenous interstellar medium. We solve the diffusion equation for the neutrinos in a spherical shell, that describes the burst, in the presence of a sink at the center. We determine the critical density of the medium, above which the burst is unstable, and the critical distance from the burst, below which the burst is unstable. The study is made for different values of the burst spectrum parameters and the density of the interstellar medium. We find that for realistic values of these parameters the burst is unstable at a large volume around the burst. The critical distance depends weakly on the density of the medium. We discuss the relevance of our results for different scenarios, such as the burst from a supernova (SN) or a giant flare on a magnetar. For SNe our results show that the neutrinos can travel a large distance before they are completely thermalized, provided that the burst is hard enough. For magnetars our results show that even if the burst is not hard, a large number of neutrinos will be thermalized in the inner few stellar radii.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The 74MHz System on the Very Large Array. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3088, "human_text": "  The Naval Research Laboratory and the National Radio Astronomy Observatory completed implementation of a low frequency capability on the VLA at 73.8 MHz in 1998. This frequency band offers unprecedented sensitivity (~25 mJy/beam) and resolution (~25 arcsec) for low-frequency observations. We review the hardware, the calibration and imaging strategies, comparing them to those at higher frequencies, including aspects of interference excision and wide-field imaging. Ionospheric phase fluctuations pose the major difficulty in calibrating the array. Over restricted fields of view or at times of extremely quiescent ionospheric ``weather'', an angle-invariant calibration strategy can be used. In this approach a single phase correction is devised for each antenna, typically via self-calibration. Over larger fields of view or at times of more normal ionospheric ``weather'' when the ionospheric isoplanatic patch size is smaller than the field of view, we adopt a field-based strategy in which the phase correction depends upon location within the field of view. This second calibration strategy was implemented by modeling the ionosphere above the array using Zernike polynomials. Images of 3C sources of moderate strength are provided as examples of routine, angle-invariant calibration and imaging. Flux density measurements indicate that the 74 MHz flux scale at the VLA is stable to a few percent, and tied to the Baars et al. value of Cygnus A at the 5 percent level. We also present an example of a wide-field image, devoid of bright objects and containing hundreds of weaker sources, constructed from the field-based calibration. We close with a summary of lessons the 74 MHz system offers as a model for new and developing low-frequency telescopes. (Abridged) ", "machine_text": "  The 74MHz System on the Very Large Array  We describe here the hardware and software of the 74MHz system on the Very Large Array (VLA). This system is an array of 180 Intel i7-based computers with four dual-core processors per computer. It is the second-generation hardware system for the VLA, the first being the 36MHz system. The new system has a higher clock frequency, more processors per computer, and larger data memories. The computing cluster is connected to the VLA over a 100Gbps Ethernet network.  We describe the design and implementation of the 74MHz system. The design is based on a cluster of commodity computers, each running a standard 64-bit version of Linux and an OpenMP-based application. We describe the selection of the hardware, the network, and the software stack. We outline the software development process and the software architecture. We discuss the implementation of the real-time aspects of the system and the data acquisition components.  The 74MHz system has been in routine operation for more than two years. We outline the lessons learned during this period. We describe the application of the system to the observing modes of the VLA and to the development of new observing modes. We discuss the ongoing development of the system and the plans for the next-generation hardware.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Massive Yang-Mills Theory based on the Nonlinearly Realized Gauge   Group. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2339, "human_text": "  We propose a subtraction scheme for a massive Yang-Mills theory realized via a nonlinear representation of the gauge group (here SU(2)). It is based on the subtraction of the poles in D-4 of the amplitudes, in dimensional regularization, after a suitable normalization has been performed. Perturbation theory is in the number of loops and the procedure is stable under iterative subtraction of the poles. The unphysical Goldstone bosons, the Faddeev-Popov ghosts and the unphysical mode of the gauge field are expected to cancel out in the unitarity equation. The spontaneous symmetry breaking parameter is not a physical variable. We use the tools already tested in the nonlinear sigma model: hierarchy in the number of Goldstone boson legs and weak power-counting property (finite number of independent divergent amplitudes at each order). It is intriguing that the model is naturally based on the symmetry SU(2)_L local times SU(2)_R global. By construction the physical amplitudes depend on the mass and on the self-coupling constant of the gauge particle and moreover on the scale parameter of the radiative corrections. The Feynman rules are in the Landau gauge. ", "machine_text": "  We propose a massive Yang-Mills theory based on the nonlinearly realized gauge group $G=SU(N)$. In the framework of this theory, we show that the strong CP problem is solved in a very natural way. This solution does not require theStandard Model to be embedded in a larger theory, as is the case for the standard massive Yang-Mills theory. Our approach is very general and flexible. It can be used to construct other massive theories which are based on the nonlinearly realized gauge group.  We consider a massive Yang-Mills theory based on the nonlinearly realized gauge group $G=SU(N)$. Such a theory can be constructed by using the nonlinear realization of $G$ to define the massive yang-mills fields. In this way the theory is different from the standard massive Yang-Mills theory in which the Standard Model is embedded in a larger theory.  We show that the strong CP problem is solved in a very natural way in the framework of this theory. This solution does not require the Standard Model to be embedded in a larger theory, as is the case for the standard massive Yang-Mills theory.  Our approach is very general and flexible. It can be used to construct other massive theories which are based on the nonlinearly realized gauge group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generation interval contraction and epidemic data analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2024, "human_text": "  The generation interval is the time between the infection time of an infected person and the infection time of his or her infector. Probability density functions for generation intervals have been an important input for epidemic models and epidemic data analysis. In this paper, we specify a general stochastic SIR epidemic model and prove that the mean generation interval decreases when susceptible persons are at risk of infectious contact from multiple sources. The intuition behind this is that when a susceptible person has multiple potential infectors, there is a ``race'' to infect him or her in which only the first infectious contact leads to infection. In an epidemic, the mean generation interval contracts as the prevalence of infection increases. We call this global competition among potential infectors. When there is rapid transmission within clusters of contacts, generation interval contraction can be caused by a high local prevalence of infection even when the global prevalence is low. We call this local competition among potential infectors. Using simulations, we illustrate both types of competition.   Finally, we show that hazards of infectious contact can be used instead of generation intervals to estimate the time course of the effective reproductive number in an epidemic. This approach leads naturally to partial likelihoods for epidemic data that are very similar to those that arise in survival analysis, opening a promising avenue of methodological research in infectious disease epidemiology. ", "machine_text": "  Motivation Epidemic data can be characterized by a large number of events that occur in a short period of time. If this occurs, the generation interval (GI) will be contracted. This can be a challenge when using conventional surveillance systems that rely on a fixed GI to detect and monitor health events. We examined whether the use of flexible GIs could improve surveillance of epidemic data.  Key ideas and methodology We compared conventional and flexible GI surveillance systems using simulated and real epidemic data.  Results The flexible GI surveillance system detected events earlier than the conventional system in both simulated and real data. The flexible system also performed better in estimating the magnitude of events.  Problem solved We showed that the use of flexible GIs can improve the detection and monitoring of epidemics.  Applications Our results suggest that flexible GI surveillance systems could be used to improve the detection and monitoring of health events in real-world data.  Implications for future research We need to further evaluate the use of flexible GIs for surveillance in different settings and for different health events. We also need to determine the optimal way to use flexible GIs to improve surveillance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Insulating state and the importance of the spin-orbit coupling in   Ca$_3$CoRhO$_6$. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4538, "human_text": "  We have carried out a comparative theoretical study of the electronic structure of the novel one-dimensional Ca$_3$CoRhO$_6$ and Ca$_3$FeRhO$_6$ systems. The insulating antiferromagnetic state for the Ca$_3$FeRhO$_6$ can be well explained by band structure calculations with the closed shell high-spin $d^5$ (Fe$^{3+}$) and low-spin $t_{2g}^{6}$ (Rh$^{3+}$) configurations. We found for the Ca$_3$CoRhO$_6$ that the Co has a strong tendency to be $d^7$ (Co$^{2+}$) rather than $d^6$ (Co$^{3+}$), and that there is an orbital degeneracy in the local Co electronic structure. We argue that it is the spin-orbit coupling which will lift this degeneracy thereby enabling local spin density approximation + Hubbard U (LSDA+U) band structure calculations to generate the band gap. We predict that the orbital contribution to the magnetic moment in Ca$_3$CoRhO$_6$ is substantial, i.e. significantly larger than 1 $\\mu_B$ per formula unit. Moreover, we propose a model for the contrasting intra-chain magnetism in both materials. ", "machine_text": "  We have performed a systematic study of the effect of the spin-orbit coupling (SOC) on the insulating state of Ca3CoRhO6. We found that the break down of the insulating state, in general, is induced by the existence of a non-trivial symmetry of the spin-orbital ordered state, and is always accompanied by a phase transition to a non-centrosymmetric state. In particular, we found a new type of charge ordering, which we call the spin-orbital charge ordering, for the first time in a real material. The spin-orbital charge ordering is very robust against the deformation of the crystal lattice, and does not change its nature by the breaking of the rotational symmetry, while the conventional charge ordering is sensitive to the lattice symmetry. We also found that the insulating state can be recovered by a field-induced symmetry breaking of the non-centrosymmetric state, and the recovered insulating state is different from the original one. Our results suggest that the spin-orbital coupling plays an essential role in the realization of the insulating state in a real material.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optimizing Scrip Systems: Efficiency, Crashes, Hoarders, and Altruists. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.411, "human_text": "  We discuss the design of efficient scrip systems and develop tools for empirically analyzing them. For those interested in the empirical study of scrip systems, we demonstrate how characteristics of agents in a system can be inferred from the equilibrium distribution of money. From the perspective of a system designer, we examine the effect of the money supply on social welfare and show that social welfare is maximized by increasing the money supply up to the point that the system experiences a ``monetary crash,'' where money is sufficiently devalued that no agent is willing to perform a service. We also examine the implications of the presence of altruists and hoarders on the performance of the system. While a small number of altruists may improve social welfare, too many can also cause the system to experience a monetary crash, which may be bad for social welfare. Hoarders generally decrease social welfare but, surprisingly, they also promote system stability by helping prevent monetary crashes. In addition, we provide new technical tools for analyzing and computing equilibria by showing that our model exhibits strategic complementarities, which implies that there exist equilibria in pure strategies that can be computed efficiently. ", "machine_text": " We present a framework for optimizing scrip systems, which are common in online games. A scrip system is a mechanism where players can spend in-game resources to acquire items. These items may be persistent, such as an equipment slot or a pets, or may be single-use, such as a consumable item. We consider a setting where players may crash the system by repeatedly acquiring items in a short period of time. We also consider a setting where players may hoard the system by acquiring items and never consuming them. We use a model where players have a selfish utility that they attempt to maximize by acquiring and consuming items, and where players are also embedded in a social network. We find that scrip systems are most efficient when the social network is utilized to police the system, as opposed to imposing top-down rules. We also find that a system is more stable when players can acquire items that are only useful to them, as opposed to items that are useful to many players. Finally, we find that a small number of players cangame the system by repeatedly acquiring and consuming items. We discuss how our results impact the design of scrip systems, and how our results are important for any game system where a small number of players cangame the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multi-site observations of Delta Scuti stars 7 Aql and 8 Aql (a new   Delta Scuti variable): The twelfth STEPHI campaign in 2003. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0576, "human_text": "  We present an analysis of the pulsation behaviour of the Delta Scuti stars 7 Aql (HD 174532) and 8 Aql (HD 174589) -- a new variable star -- observed in the framework of STEPHI XII campaign during 2003 June--July. 183 hours of high precision photometry were acquired by using four-channel photometers at three sites on three continents during 21 days. The light curves and amplitude spectra were obtained following a classical scheme of multi-channel photometry. Observations in different filters were also obtained and analyzed. Six and three frequencies have been unambiguously detected above a 99% confidence level in the range 0.090 mHz--0.300 mHz and 0.100 mHz-- 0.145 mHz in 7 Aql and 8 Aql respectively. A comparison of observed and theoretical frequencies shows that 7 Aql and 8 Aql may oscillate with p modes of low radial orders, typical among Delta Scuti stars. In terms of radial oscillations the range of 8 Aql goes from n=1 to n=3 while for 7 Aql the range spans from n=4 to n=7. Non-radial oscillations have to be present in both stars as well. The expected range of excited modes according to a non adiabatic analysis goes from n=1 to n=6 in both stars. ", "machine_text": "  Multi-site observations of Delta Scuti stars 7 Aql and 8 Aql (a new Delta Scuti variable): The twelfth STEPHI campaign in 2003.  We present the results of a multi-site campaign of photometric observations of the young stars 7 Aql and 8 Aql. These stars are both members of the young open cluster Collinder 91. 7 Aql is a well-known Delta Scuti star, while 8 Aql has been suspected of being a member of the same class of variables. Our observations were made with the 1.5-m telescope at CKO value, the 1.0-m telescope at Boyden Station (Australia), and the 0.57-m telescope at Fairborn Observatory (Canada) during the period from December 2002 to March 2003. We obtained a total of 78 photometric observations of 7 Aql and 51 observations of 8 Aql. We find that 8 Aql is indeed a Delta Scuti star, although it spends much more time at minimum light than at maximum light, and therefore has a very different behaviour from 7 Aql. We determine the periods of both stars, as well as the amplitudes and phases of 8 Aql. We discuss these results in the context of other Delta Scuti stars in young open clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Intrinsic ripples in graphene. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1793, "human_text": "  The stability of two-dimensional (2D) layers and membranes is subject of a long standing theoretical debate. According to the so called Mermin-Wagner theorem, long wavelength fluctuations destroy the long-range order for 2D crystals. Similarly, 2D membranes embedded in a 3D space have a tendency to be crumpled. These dangerous fluctuations can, however, be suppressed by anharmonic coupling between bending and stretching modes making that a two-dimensional membrane can exist but should present strong height fluctuations. The discovery of graphene, the first truly 2D crystal and the recent experimental observation of ripples in freely hanging graphene makes these issues especially important. Beside the academic interest, understanding the mechanisms of stability of graphene is crucial for understanding electronic transport in this material that is attracting so much interest for its unusual Dirac spectrum and electronic properties. Here we address the nature of these height fluctuations by means of straightforward atomistic Monte Carlo simulations based on a very accurate many-body interatomic potential for carbon. We find that ripples spontaneously appear due to thermal fluctuations with a size distribution peaked around 70 \\AA which is compatible with experimental findings (50-100 \\AA) but not with the current understanding of stability of flexible membranes. This unexpected result seems to be due to the multiplicity of chemical bonding in carbon. ", "machine_text": "  We investigated intrinsic ripples in graphene. We found that ripples are formed due to the long range Coulomb interaction between electrons and the strain dependent band structure. We used a first principles based tight binding model to evaluate the ripple formation energy and compared it with the experimental results. Our theory explained the experimental results well and provided a framework to understand the origin of intrinsic ripples. We also found that ripples can be formed by applying a perpendicular electric field. Our theoretical predictions for the ripple formation energy as a function of the applied electric field agreed well with the available experimental data.  We have investigated the electronic and structural properties of intrinsic ripples in graphene. We found that the ripples are formed due to the long range Coulomb interaction between electrons and the strain dependent band structure. We used a first principles based tight binding model to evaluate the ripple formation energy and compared it with the experimental results. Our theory explained the experimental results well and provided a framework to understand the origin of intrinsic ripples. We also found that ripples can be formed by applying a perpendicular electric field. Our theoretical predictions for the ripple formation energy as a function of the applied electric field agreed well with the available experimental data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Logic of Reachable Patterns in Linked Data-Structures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.361, "human_text": "  We define a new decidable logic for expressing and checking invariants of programs that manipulate dynamically-allocated objects via pointers and destructive pointer updates. The main feature of this logic is the ability to limit the neighborhood of a node that is reachable via a regular expression from a designated node. The logic is closed under boolean operations (entailment, negation) and has a finite model property. The key technical result is the proof of decidability. We show how to express precondition, postconditions, and loop invariants for some interesting programs. It is also possible to express properties such as disjointness of data-structures, and low-level heap mutations. Moreover, our logic can express properties of arbitrary data-structures and of an arbitrary number of pointer fields. The latter provides a way to naturally specify postconditions that relate the fields on entry to a procedure to the fields on exit. Therefore, it is possible to use the logic to automatically prove partial correctness of programs performing low-level heap mutations. ", "machine_text": "  A Logic of Reachable Patterns in Linked Data-Structures  We introduce a new framework for reasoning about reachability and containment in data structures such as trees and graphs. We focus on data structures that are formed by linking basic data structures together, such as linked lists, trees, and graphs. We present a logic that formalizes the intuitive notion of reachability in such structures. Our logic is founded on the basic principles of first-order logic, but includes new kinds of axioms and inference rules that capture important properties of linked data structures. For example, our logic includes an axiom that expresses the fact that a node in a linked list can be reached by repeatedly following the next pointers. As another example, our logic includes an inference rule that expresses the fact that if a node is reached by repeatedly following the children of a particular node, then that node is contained in a subtree rooted at that particular node. We show that our logic is sound and complete with respect to a suitable notion of model. We also show that our logic has several other desirable properties, such as the ability to represent and reason about operations that remove or add nodes to a data structure. We illustrate the use of our logic by formalizing several properties of linked lists, trees, and graphs that are commonly used in programming.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modelling the clumping-induced polarimetric variability of hot star   winds. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2569, "human_text": "  Clumping in the winds of massive stars may significantly reduce empirical mass-loss rates, and which in turn may have a large impact on our understanding of massive star evolution. Here, we investigate wind-clumping through the linear polarization induced by light scattering off the clumps. Through the use of an analytic wind clumping model, we predict the time evolution of the linear polarimetry over a large parameter space. We concentrate on the Luminous Blue Variables, which display the greatest amount of polarimetric variability and for which we recently conducted a spectropolarimetric survey. Our model results indicate that the observed level of polarimetric variability can be reproduced for two regimes of parameter space: one of a small number of massive, optically-thick clumps; and one of a very large number of low-mass clumps. Although a systematic time-resolved monitoring campaign is required to distinguish between the two scenarios, we currently favour the latter, given the short timescale of the observed polarization variability. As the polarization is predicted to scale linearly with mass-loss rate, we anticipate that all hot stars with very large mass-loss rates should display polarimetric variability. This is consistent with recent findings that intrinsic polarization is more common in stars with strong H$\\alpha$ emission. ", "machine_text": " We present a modelling study of the polarimetric variability of hot star winds resulting from clumping of the surrounding molecular cloud. We solve numerically the radiative transfer equation in a clumpy medium, taking into account both the clumping and the non-linearity of the polarimetric response. We show that the observed variability of the polarimetric signature of hot star winds can be explained by our clumping model, provided that the clumps are sufficiently large compared to the optical depth of the medium. We find that for a given clumpy medium the variability of the polarimetric signature increases with the clump size, and it decreases with the optical depth. We also discuss the physical origin of the polarimetric variability of hot star winds in terms of the different spatial distribution of the clumps and the cloud temperature gradient. Our results suggest that the analysis of the polarimetric variability of hot star winds can provide important information on the structure and physical properties of the surrounding medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: El universo de Einstein: 1905 - annus mirabilis - 2005. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4266, "human_text": "  Year 2005 was the World Year of Physics, and it was commemorated worldwide as the 100th anniversary of Albert Einstein's legendary works in which the foundations of at least three areas of modern physics were laid: statistical mechanics, quantum mechanics and special relativity. These works turned year 1905 in what deservedly was called the \"miraculous year\" (annus mirabilis) of Einstein. However, the influence of this great mind was not limited to science. As it is well known, his fingerprint remains engraved in many aspects of our daily life. Because of that, in this work we have tried to cover almost all the subjects in which Einstein was involved during the last century and, of course, try and reveal the future projection his actions will have in this new century that has just begun. Among the subjects covered in the volume one can find the possible connection between Einstein and the artistic vanguard movement, his religiosity, his days in Argentina, the Nobel Prize, the Einstein-Freud correspondence, his pacifism and the nuclear energy, science and politics under the Second Empire and the Weimar Republic, and even a description of his patents and experiments, the studies performed to search for \"built-in\" features in his brain and the doubts many had regarding whether Einstein was a genius or a crank. Also included are essays on Einstein and Borges, philosophy and relativity, Mach's principle, the relation among science, arts and humanities, and, closer to Einstein's own theoretical research, the twin paradox, chance and quantum mechanics, the arrow of time, gravitational lenses, string theory, holography and black holes, gravitomagnetism, superconductivity, gravitational waves, the photoelectric effect and the alternative theories for gravitation. ", "machine_text": "  El universo de Einstein: 1905 - annus mirabilis - 2005. Einstein's universe: 1905 - annus mirabilis - 2005. The purpose of this article is to discuss some of the principal ideas Einstein contributed to the field of physics, in the light of the latest advances in the subject. In the article we review the development of the theory of relativity and quantum mechanics, two theories which have revolutionised our understanding of the universe, and which, together with the work of Einstein, have laid the foundations for the current theory of the universe.  In the early years of the twentieth century, the development of physics was characterised by the search for a single theory that would unify the laws of physics, and which would describe the behaviour of all types of matter and energy. The first attempt to develop such a theory was made by Einstein in 1905, with his theory of relativity. This theory revolutionised our understanding of space and time, and laid the foundations for the current theory of the universe.  Einstein's theory of relativity was followed by the development of quantum mechanics, which described the behaviour of subatomic particles, and which has also had a major impact on our understanding of the universe. The two theories, relativity and quantum mechanics, are now known as the theory of general relativity and the theory of quantum mechanics, and are the basis for our current understanding of the universe.  In the article we review the development of these two theories, and discuss some of the key ideas which have emerged from them. We also discuss the current state of the field, and the future directions of research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Growing Networks: Limit in-degree distribution for arbitrary out-degree   one. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1847, "human_text": "  We compute the stationary in-degree probability, $P_{in}(k)$, for a growing network model with directed edges and arbitrary out-degree probability. In particular, under preferential linking, we find that if the nodes have a light tail (finite variance) out-degree distribution, then the corresponding in-degree one behaves as $k^{-3}$. Moreover, for an out-degree distribution with a scale invariant tail, $P_{out}(k)\\sim k^{-\\alpha}$, the corresponding in-degree distribution has exactly the same asymptotic behavior only if $2<\\alpha<3$ (infinite variance). Similar results are obtained when attractiveness is included. We also present some results on descriptive statistics measures %descriptive statistics such as the correlation between the number of in-going links, $D_{in}$, and outgoing links, $D_{out}$, and the conditional expectation of $D_{in}$ given $D_{out}$, and we calculate these measures for the WWW network. Finally, we present an application to the scientific publications network. The results presented here can explain the tail behavior of in/out-degree distribution observed in many real networks. ", "machine_text": "  We consider the problem of determining the number of edges in a random graph with a given degree sequence. Such a graph is obtained by independently and uniformly selecting the endpoints of each edge, with each edge connecting a pair of distinct endpoints with degree at most one. We show that for every degree sequence, this random graph has a probability of 1 of having an edge number at most twice the number of edges in a complete graph with that degree sequence. We show this by determining a limiting distribution for the number of edges in a growing network with an arbitrary degree sequence and an in-degree limit of one. In particular, the limit has the same distribution as the number of edges in a random graph with the same degree sequence. We show that this limit has a trivial proof using only basic combinatorics if and only if the degree sequence contains at most one element. We also consider the problem of selecting a subgraph of a given size from a growing network, and show that the probability of selecting a subgraph with a given degree sequence approaches 1 as the number of edges grows.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Forward stagewise regression and the monotone lasso. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0269, "human_text": "  We consider the least angle regression and forward stagewise algorithms for solving penalized least squares regression problems. In Efron, Hastie, Johnstone & Tibshirani (2004) it is proved that the least angle regression algorithm, with a small modification, solves the lasso regression problem. Here we give an analogous result for incremental forward stagewise regression, showing that it solves a version of the lasso problem that enforces monotonicity. One consequence of this is as follows: while lasso makes optimal progress in terms of reducing the residual sum-of-squares per unit increase in $L_1$-norm of the coefficient $\\beta$, forward stage-wise is optimal per unit $L_1$ arc-length traveled along the coefficient path. We also study a condition under which the coefficient paths of the lasso are monotone, and hence the different algorithms coincide. Finally, we compare the lasso and forward stagewise procedures in a simulation study involving a large number of correlated predictors. ", "machine_text": "  Forward stagewise regression and the monotone lasso  We consider the problem of statistical learning from datasets with many variables that are correlated with each other, where the goal is to predict a single response variable. We propose a forward stagewise regression model, which is an adaptation of the backward stagewise regression model to the setting of statistical learning from many variables. We show that the proposed model is equivalent to an application of the monotone lasso to the problem of learning a monotone function that maps variables to a response. The model selection aspects of the lasso are formalized in a way that allows us to relate the model selection problem to the problem of identifying the set of informative variables. We develop an algorithm to compute the optimal solution to the forward stagewise regression problem, and we show that the proposed algorithm has the same parameter as the well-known forward selection algorithm. We provide an experimental comparison of the proposed model with several other statistical learning methods on simulated and real datasets, and we show that the proposed model can be easily implemented using existing software packages.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Stern-Volmer Modeling of Steady-State Forster Energy Transfer Between   Dilute, Freely Diffusing Membrane-Bound Fluorophores. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3218, "human_text": "  Two different metrics are used to assess Forster resonance energy transfer (FRET) between fluorophores in the steady state: (1) acceptor-quenching of donor fluorescence, E (a.k.a. transfer efficiency); and (ii) donor-excited acceptor fluorescence, F-A-Dex. While E is still more widely used, F-A-Dex has been gaining in popularity for practical reasons among experimentalists who study biomembranes. Here, for the special case of membrane-bound fluorophores, we present a substantial body of experimental evidence that justifies the use of simple Stern-Volmer expressions when modeling either FRET metric under dilute-probe conditions. We have also discovered a dilute-regime correspondence between our Stern-Volmer expression for E and Wolber and Hudson's series approximation for steady-state Forster quenching in 2D. This novel correspondence allows us to interpret each of our 2D quenching constants in terms of both (i) an effective Forster distance, and (ii) two maximum acceptor-concentration limits, each of which defines its own useful experimental regime. Taken together, our results suggest a three-step strategy toward designing more effective steady-state FRET experiments for the study of biomembranes. ", "machine_text": "  Stern-Volmer Modeling of Steady-State Forster Energy Transfer Between Dilute, Freely Diffusing Membrane-Bound Fluorophores. We present Stern-Volmer expressions for the steady-state Forster energy transfer between two freely diffusing fluorophores in the same membrane microenvironment. Our analysis demonstrates that the Forster mechanism of energy transfer can be significant in certain biological systems, such as in the case of membrane-bound fluorophores, even when the fluorophores are extremely dilute. To obtain the Stern-Volmer equations, we consider the donor-acceptor complex to be in equilibrium with the freely diffusing unbound donor and acceptor molecules. We obtain an analytical expression for the dissociation constant of the donor-acceptor complex and use this expression to derive the Stern-Volmer equations for the donor-acceptor complex, as well as for the donor and acceptor molecules. We then verify the predictions of our theory by comparison with numerical solutions of the corresponding set of differential equations. Our results suggest that the principles of physical chemistry may be useful in the analysis of non-equilibrium processes in biology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Line Emission in the Brightest Cluster Galaxies of the NOAO Fundamental   Plane and Sloan Digital Sky Surveys. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3242, "human_text": "  We examine the optical emission line properties of Brightest Cluster Galaxies (BCGs) selected from two large, homogeneous datasets. The first is the X-ray selected National Optical Astronomy Observatory Fundamental Plane Survey (NFPS), and the second is the C4 catalogue of optically selected clusters built from the Sloan Digital Sky Survey Data Release ~3 (SDSS DR3). Our goal is to better understand the optical line emission in BCGs with respect to properties of the galaxy and the host cluster. Throughout the analysis we compare the line emission of the BCGs to that of a control sample made of the other bright galaxies near the cluster centre. Overall, both the NFPS and SDSS show a modest fraction of BCGs with emission lines (~15%). No trend in the fraction of emitting BCGs as a function of galaxy mass or cluster velocity dispersion is found. However we find that, for those BCGs found in cooling flow clusters, 71^{+9}_{-14}% have optical emission. Furthermore, if we consider only BCGs within 50kpc of the X-ray centre of a cooling flow cluster, the emission-line fraction rises further to 100^{+0}_{-15}%. Excluding the cooling flow clusters, only ~10% of BCGs are line emitting, comparable to the control sample of galaxies. We show that the physical origin of the emission line activity varies: in some cases it has LINER-like line ratios, whereas in others it is a composite of star-formation and LINER-like activity. We conclude that the presence of emission lines in BCGs is directly related to the cooling of X-ray gas at the cluster centre. ", "machine_text": "  We present a detailed study of line emission in a sample of the brightest cluster galaxies (BCGs) selected from the NOAO Fundamental Plane and Sloan Digital Sky Surveys. We use a principal component analysis to separate the different line components and decompose their contribution to the total line flux. We find that the BCGs are dominated by a strong metal line atrest wavelength, which we attribute to the ionization of the intergalactic medium by the hot intracluster gas. We show that this metal line component varies in a manner consistent with the variations in the gas temperature, and that it is an excellent tracer of the gas distribution. The temperature-ionization relationship inferred from the metal line is consistent with the prediction of the simple version of the Epstein-Jackson-Mueller model, but the high ionization states inferred for some clusters require a more sophisticated treatment. We also present a catalog of the ionizing sources in the clusters, and find that the sources are distributed in a manner consistent with a central cluster ionizing source and an outer ring of satellite sources. We discuss our results in the context of recent theoretical work on the Epstein-Jackson-Mueller model, and find that our data are consistent with a model in which the central ionizing source has a temperature several times higher than the satellite sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An annular gap acceleration model for $\\gamma$-ray emission of pulsars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3801, "human_text": "  If the binding energy of the pulsar's surface is not so high (the case of a neutron star), both the negative and positive charges will flow out freely from the surface of the star. The annular free flow model for $\\gamma$-ray emission of pulsars is suggested in this paper. It is emphasized that: (1). Two kinds of acceleration regions (annular and core) need to be taken into account. The annular acceleration region is defined by the magnetic field lines that cross the null charge surface within the light cylinder. (2). If the potential drop in the annular region of a pulsar is high enough (normally the cases of young pulsars), charges in both the annular and the core regions could be accelerated and produce primary gamma-rays. Secondary pairs are generated in both regions and stream outwards to power the broadband radiations. (3). The potential drop in the annular region grows more rapidly than that in the core region. The annular acceleration process is a key point to produce wide emission beams as observed. (4). The advantages of both the polar cap and outer gap models are retained in this model. The geometric properties of the $\\gamma$-ray emission from the annular flow is analogous to that presented in a previous work by Qiao et al., which match the observations well. (5). Since charges with different signs leave the pulsar through the annular and the core regions, respectively, the current closure problem can be partially solved. ", "machine_text": " We propose a new model for the acceleration of particles in the annular gap between a rotating and a stationary conductor, which can be used to explain the basic features of the pulsar $\\gamma$-ray emission, in particular the temperature dependence and the fast rise of the emission. Our model is based on a rigorous solution of the 2-dimensional hydrodynamic equations for the conservation of the mass and the momentum, which are valid in the gap for all conductor temperatures. The model predicts that the temperature dependence of the $\\gamma$-ray flux is related to the transition between the convection and the ballistic regime. We show that the ballistic regime is characterized by a constant flux level, independent of the temperature. Within this regime the temperature may have a strong influence on the energy distribution of the $\\gamma$-ray emission. Our model also explains the fast rise of the $\\gamma$-ray flux, if the particle acceleration is caused by a shock, induced by the plasma instability at the boundary between the rotating and the stationary conductor. We discuss the problem of the energy distribution of the $\\gamma$-ray emission and we show that a simple analytical model, based on the assumption of a Maxwellian energy distribution, is consistent with our basic model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Improved constraints on dark energy from Chandra X-ray observations of   the largest relaxed galaxy clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0033, "human_text": "  We present constraints on the mean matter density, Omega_m, dark energy density, Omega_de, and the dark energy equation of state parameter, w, using Chandra measurements of the X-ray gas mass fraction (fgas) in 42 hot (kT>5keV), X-ray luminous, dynamically relaxed galaxy clusters spanning the redshift range 0.05<z<1.1. Using only the fgas data for the 6 lowest redshift clusters at z<0.15, for which dark energy has a negligible effect on the measurements, we measure Omega_m=0.28+-0.06 (68% confidence, using standard priors on the Hubble Constant, H_0, and mean baryon density, Omega_bh^2). Analyzing the data for all 42 clusters, employing only weak priors on H_0 and Omega_bh^2, we obtain a similar result on Omega_m and detect the effects of dark energy on the distances to the clusters at ~99.99% confidence, with Omega_de=0.86+-0.21 for a non-flat LCDM model. The detection of dark energy is comparable in significance to recent SNIa studies and represents strong, independent evidence for cosmic acceleration. Systematic scatter remains undetected in the fgas data, despite a weighted mean statistical scatter in the distance measurements of only ~5%. For a flat cosmology with constant w, we measure Omega_m=0.28+-0.06 and w=-1.14+-0.31. Combining the fgas data with independent constraints from CMB and SNIa studies removes the need for priors on Omega_bh^2 and H_0 and leads to tighter constraints: Omega_m=0.253+-0.021 and w=-0.98+-0.07 for the same constant-w model. More general analyses in which we relax the assumption of flatness and/or allow evolution in w remain consistent with the cosmological constant paradigm. Our analysis includes conservative allowances for systematic uncertainties. The small systematic scatter and tight constraints bode well for future dark energy studies using the fgas method. (Abridged) ", "machine_text": "  We present improved constraints on the equation of state (EOS) of dark energy from Chandra X-ray observations of the largest relaxed galaxy clusters. We use the clusters as cosmic rulers to measure the scale dependence of the large-scale structure (LSS) power spectrum, P(k), and the cluster abundance distribution, N(z), in order to constrain the EOS. We find that the cluster abundance distribution is consistent with a simple model in which the number density of clusters is proportional to the volume density of the universe, with a power law index of 1.91 \u00b1 0.05. This implies that the clusters trace the LSS with a scale dependence given by P(k) = 1 + \u03c1bn(0)ek, where \u03c1 is the power law index, b is the bias factor, and n(0) is the minimum power law scale. The measured scale dependence of P(k) is consistent with this prediction, with \u03c1 = 1.35 \u00b1 0.06 and n(0) = 7.58 \u00b1 0.07. The combination of these results implies a stringent constraint on the EOS, with a non-zero deceleration parameter q < 1.4.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Keck/DEIMOS spectroscopic survey of faint Galactic satellites:   searching for the least massive dwarf galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4622, "human_text": "  [abridged] We present the results of a spectroscopic survey of the recently discovered faint Milky Way satellites Boo, UMaI, UMaII and Wil1. Using the DEIMOS spectrograph on Keck, we have obtained samples that contain from 15 to 85 probable members of these satellites for which we derive radial velocities precise to a few km/s down to i~21-22. About half of these stars are observed with a high enough S/N to estimate their metallicity to within \\pm0.2 dex. From this dataset, we show that UMaII is the only object that does not show a clear radial velocity peak. However, the measured systemic radial velocity (v_r=115\\pm5 km/s) is in good agreement with recent simulations in which this object is the progenitor of the recently discovered Orphan Stream. The three other satellites show velocity dispersions that make them highly dark-matter dominated systems. In particular the Willman 1 object is not a globular cluster given its metallicity scatter over -2.0<[Fe/H]<-1.0 and is therefore almost certainly a dwarf galaxy or dwarf galaxy remnant. We measure a radial velocity dispersion of only 4.3_{-1.3}^{+2.3} km/s around a systemic velocity of -12.3\\pm2.3 km/s which implies a mass-to-light ratio of ~700 and a total mass of ~5x10^5 Msun for this satellite, making it the least massive satellite galaxy known to date. Such a low mass could mean that the 10^7 Msun limit that had until now never been crossed for Milky Way and Andromeda satellite galaxies may only be an observational limit and that fainter, less massive systems exist within the Local Group. However, more modeling and an extended search for potential extra-tidal stars are required to rule out the possibility that these systems have not been significantly heated by tidal interaction. ", "machine_text": "  We present a Keck/DEIMOS spectroscopic survey of 70 faint Galactic satellites with Mp > 18.5 mag, in order to search for the least massive dwarf galaxies. We find that the satellites have an average stellar mass of 1.5 x 10^8 M_{\\odot} and a mean orbital period of 51.4 kpc. Our sample contains several members of the proposed Mock bayesian cluster and a possible member of the Sculptor group. Most of the galaxies show no evidence of ongoing dynamical interaction, but we do find two cases of interactions in progress: the globular cluster M 92 and the irregular galaxy NGC 1569. We use our data to derive a relationship between stellar mass and orbital period for satellites in the range 18 < Mp < 5 x 10^9 M_{\\odot} and 50 < period < 300 kpc. The relationship is well described by a power law with a negative power of -1.58, implying a strong correlation between orbital period and stellar mass for satellite galaxies. We also find a positive correlation between stellar mass and central surface brightness, suggesting that the most massive satellites tend to be the most luminous in the centers.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The SAURON project - XI. Stellar Populations from Absorption Line   Strength Maps of 24 Early-Type Spirals. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2839, "human_text": "  We present absorption line strength maps of a sample of 24 representative early-type spiral galaxies, mostly of type Sa, obtained as part of the SAURON survey of nearby galaxies using our custom-built integral-field spectrograph. Using high-quality spectra, spatially binned to a constant signal-to-noise, we measure several key age, metallicity and abundance ratio sensitive indices from the Lick/IDS system over a contiguous two-dimensional field including bulge and inner disc. We present maps of H beta, Fe 5015 and Mg b, for each galaxy   The absorption line maps show that many galaxies contain some younger populations (<= 1 Gyr), distributed in small or large inner discs, or in circumnuclear star forming rings. In many cases these young stars are formed in circumnuclear mini-starbursts, which are dominating the light in the centres of some of the early-type spirals. These mini-starburst cause a considerable scatter in index-index diagrams such as Mg b- H beta and Mg b -Fe 5015, more than is measured for early-type galaxies. We find that the central regions of Sa galaxies display a wide range in ages, even within the galaxies. 50% of the sample show velocity dispersion drops in their centres.   All of the galaxies of our sample lie on or below the Mg b- $\\sigma$ relation for elliptical galaxies in the Coma cluster, and above the H beta absorption line - $\\sigma$ relation for elliptical galaxies. If those relations are considered to be relations for the oldest local galaxies we see that our sample of spirals has a considerable scatter in age, with the largest scatter at the lowest $\\sigma$. This is in disagreement with highly inclined samples, in which generally only old stellar populations are found in the central regions.   All this can be understood if ... (see paper for rest of abstract) ", "machine_text": "  We present a database of 23 spiral galaxies observed with the SAURON Multi-Object Spectrograph to map in absorption the stellar populations in the outer regions of the galaxies. The sample includes 17 galaxies in the local volume and six galaxies in the distant 50-Mpc volume. We find that the local galaxies in our sample are in general less massive, less gas-rich, and contain fewer stars than the distant galaxies. We show that this difference is correlated with the galaxies' star formation rates, with the local galaxies having on average lower star formation rates than the distant galaxies. We also find that the strength of the metal lines in the local galaxies is on average higher than in the distant galaxies, suggesting that the local galaxies are more efficient at creating metals. Our results suggest that the local galaxies in our sample have evolved to become more efficient at converting gas to stars and metals. We also present a comparison of the local and distant galaxies in terms of their projected surface star formation density, and find that a correlation exists between this quantity and the strength of the metal lines. We discuss our results in the context of the galaxies' evolution, and in terms of the feedback processes that may be responsible for the conversion of gas to stars and metals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Construction of Bayesian Deformable Models via Stochastic Approximation   Algorithm: A Convergence Study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0787, "human_text": "  The problem of the definition and the estimation of generative models based on deformable templates from raw data is of particular importance for modelling non aligned data affected by various types of geometrical variability. This is especially true in shape modelling in the computer vision community or in probabilistic atlas building for Computational Anatomy (CA). A first coherent statistical framework modelling the geometrical variability as hidden variables has been given by Allassonni\\`ere, Amit and Trouv\\'e (JRSS 2006). Setting the problem in a Bayesian context they proved the consistency of the MAP estimator and provided a simple iterative deterministic algorithm with an EM flavour leading to some reasonable approximations of the MAP estimator under low noise conditions. In this paper we present a stochastic algorithm for approximating the MAP estimator in the spirit of the SAEM algorithm. We prove its convergence to a critical point of the observed likelihood with an illustration on images of handwritten digits. ", "machine_text": "  We consider the construction of Bayesian deformable models via stochastic approximation. The motivation for our work is the difficulty of learning such models from data in a high-dimensional space. We show that the convergence rate of the stochastic approximation algorithm is related to the geometry of the model space and the choice of the prior distribution. In particular, we show that the convergence rate is faster if the prior is a Gaussian process, as opposed to a simple Gaussian distribution. This conclusion is derived from a rigorous analysis of the mean of the algorithm. The analysis also provides a general framework for studying the convergence of stochastic approximation algorithms for non-convex optimization problems. In order to illustrate our theory, we consider two examples. The first example is a bayesian linear regression model with a Gaussian process prior. The second example is a bayesian elastic net model with a Gaussian process prior. In both examples the algorithm is shown to converge to the true model with probability one, as the number of iterations goes to infinity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: And in the Darkness Bind Them: Equatorial Rings, B[e] Supergiants, and   the Waists of Bipolar Nebulae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3054, "human_text": "  We report the discovery of two new circumstellar ring nebulae in the western Carina Nebula. The brighter object, SBW1, resembles a lidless staring eye and encircles a B1.5 Iab supergiant. Its size is identical to the inner ring around SN1987A, but SBW1's low N abundance indicates that the star didn't pass through a RSG phase. The fainter object, SBW2, is a more distorted ring, is N-rich, and has a central star that seems to be invisible. We discuss these two new nebulae in context with rings around SN1987A, Sher25, HD168625, RY Scuti, WeBo1, SuWt2, and others. The ring bearers fall into two groups: Five rings surround hot supergiants, and all except for the one known binary are carbon copies of the ring around SN1987A. We propose a link between these rings and B[e] supergiants, where the rings derive from the same material in an earlier B[e] phase. The remaining four rings surround evolved intermediate-mass stars; all members of this ring fellowship are close binaries, hinting that binary interactions govern the forging of such rings. We estimate that there may be several thousand more dark rings in the Galaxy, but we are scarcely aware of their existence due to selection effects. The lower-mass objects might be the equatorial density enhancements often invoked to bind the waists of bipolar PNe. ", "machine_text": "  We present a model of the equatorial rings observed in many bipolar nebulae. Our model consists of an axisymmetric dark cloud with a hole in the middle, the boundary between the molecular and ionized gas. We solve the radiative transfer in this model in the frequency domain and in the presence of the self-absorption. We show that the equatorial rings are a natural outcome of this solution, provided that the cloud's inner layer is more dense than its outer layer. We derive a simple expression for the radius of the equatorial rings in terms of the physical properties of the cloud. We show that this radius is in agreement with the observed values provided that the mass of the cloud is in the range 10^2\u201310^3 M\u2299, which corresponds to the mass of the gas in a Class 0 protostar. We discuss the properties of the equatorial rings in the context of our model and of the observational data. We also discuss the mechanism by which the equatorial rings are created. In our model the equatorial rings are created by a process of gravitational collapse in the cloud's inner layer. We show that the time needed for this process to produce the observed equatorial rings is on the order of the lifetime of a Class 0 protostar, provided that the cloud's inner layer is at least three times more dense than its outer layer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spontaneous Symmetry Breaking as a Basis of Particle Mass. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2232, "human_text": "  Electroweak theory joins electromagnetism with the weak force in a single quantum field theory, ascribing the two fundamental interactions--so different in their manifestations--to a common symmetry principle. How the electroweak gauge symmetry is hidden is one of the most urgent and challenging questions facing particle physics. The provisional answer incorporated in the \"standard model\" of particle physics was formulated in the 1960s by Higgs, by Brout & Englert, and by Guralnik, Hagen & Kibble: The agent of electroweak symmetry breaking is an elementary scalar field whose self-interactions select a vacuum state in which the full electroweak symmetry is hidden, leaving a residual phase symmetry of electromagnetism. By analogy with the Meissner effect of the superconducting phase transition, the Higgs mechanism, as it is commonly known, confers masses on the weak force carriers W and Z. It also opens the door to masses for the quarks and leptons, and shapes the world around us. It is a good story--though an incomplete story--and we do not know how much of the story is true. Experiments that explore the Fermi scale (the energy regime around 1 TeV) during the next decade will put the electroweak theory to decisive test, and may uncover new elements needed to construct a more satisfying completion of the electroweak theory. The aim of this article is to set the stage by reporting what we know and what we need to know, and to set some \"Big Questions\" that will guide our explorations. ", "machine_text": "  We motivate and establish the basis for a new approach to the problem of the origin of the inertial mass of fundamental particles. The key idea is to consider the possible roles of spontaneous symmetry breaking in the formation of the gravitational sector of the universe, and of the inertial mass of elementary particles. We show that this approach can provide a solution to the long-standing problem of the origin of the vast inequality in the masses of elementary particles, and of the relative weakness of gravity with respect to the other fundamental forces. We focus on a particular mechanism of symmetry breaking which is based on the use of a cosmological constant, and which can be applied to both the formation of the structure of the universe, and to the mass generation process. The main tool for the analysis of the proposed mechanism is the Lagrangian formalism of the standard model of elementary particle physics. Within this approach we show that the mass generation process can be described by a generalized Taylor expansion of the Lagrangian, in which the cosmological constant appears as a Lagrange multiplier which provides a correction to the mass generation potential. We evaluate this correction, and show that it is capable of generating the desired inequality in the masses of elementary particles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Adding Environmental Gas Physics to the Semi-Analytic Method for Galaxy   Formation: Gravitational Heating. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2418, "human_text": "  We present results of an attempt to include more detailed gas physics motivated from hydrodynamical simulations within semi-analytic models (SAM) of galaxy formation, focusing on the role that environmental effects play. The main difference to previous SAMs is that we include 'gravitational' heating of the intra-cluster medium (ICM) by the net surplus of gravitational potential energy released from gas that has been stripped from infalling satellites. Gravitational heating appears to be an efficient heating source able to prevent cooling in environments corresponding to dark matter halos more massive than $\\sim 10^{13} $M$_{\\odot}$. The energy release by gravitational heating can match that by AGN-feedback in massive galaxies and can exceed it in the most massive ones. However, there is a fundamental difference in the way the two processes operate. Gravitational heating becomes important at late times, when the peak activity of AGNs is already over, and it is very mass dependent. This mass dependency and time behaviour gives the right trend to recover down-sizing in the star-formation rate of massive galaxies. Abridged... ", "machine_text": " Adding Environmental Gas Physics to the Semi-Analytic Method for Galaxy Formation: Gravitational Heating  We extend the semi-analytic method for galaxy formation to include the effects of gas heating and cooling in a simple manner. We show that the method is very sensitive to the feedback of gas heating on the galaxy formation process. In particular, the inclusion of gas physics can produce galaxies that are more compact, with higher central mass, than those produced by the standard semi-analytic method. We analyze the physical origin of this effect and find that the main contribution comes from the cooling of gas in the outer parts of the galaxy, due to the increase of the surface area with the expansion of the galaxy. We quantify this cooling effect and find that it is in agreement with the results of other recent studies. We also analyze the effects of gas heating in the inner part of the galaxy, and find that they are less important than the cooling effect in the outer regions. We also discuss the effects of other physical processes, such as gas dynamical friction, and find that while they are important in shaping thegalaxy structure, they do not modify the main conclusion that we obtain by including gas cooling in the semi-analytic method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamical heterogeneities and the breakdown of the Stokes-Einstein and   Stokes-Einstein-Debye relations in simulated water. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4475, "human_text": "  We study the Stokes-Einstein (SE) and the Stokes-Einstein-Debye (SED) relations using molecular dynamics simulations of the extended simple point charge model of water. We find that both the SE and SED relations break down at low temperature. To explore the relationship between these breakdowns and dynamical heterogeneities (DH), we also calculate the SE and SED relations for subsets of the 7% ``fastest'' and 7% ``slowest'' molecules. We find that the SE and SED relations break down in both subsets, and that the breakdowns occur on all scales of mobility. Thus these breakdowns appear to be generalized phenomena, in contrast with the view where only the most mobile molecules are the origin of the breakdown of the SE and SED relations, embedded in an inactive background where these relations hold. At low temperature, the SE and SED relations in both subsets of molecules are replaced with ``fractional'' SE and SED relations, $D_t\\sim(\\tau/T)^{-\\xi_t}$ and $D_r\\sim(\\tau/T)^{-\\xi_r}$ where $\\xi_t\\approx0.84<1$ and $\\xi_r\\approx0.75<1$. We also find that there is a decoupling between rotational and translational motion, and that this decoupling occurs in both fastest and slowest subsets of molecules. We also find that when the decoupling increases, upon cooling, the probability of a molecule being classified as both translationally and rotationally fastest also increases. To study the effect of time scale for SE and SED breakdown and decoupling, we introduce a time-dependent version of the SE and SED relations, and a time-dependent function that measures the extent of decoupling. Our results suggest that both the decoupling and SE and SED breakdowns are originated at the time scale corresponding to the end of the cage regime, when diffusion starts. This is also the time scale when the DH are more relevant. ", "machine_text": " We present a new method for generating weak dynamical heterogeneities in idealized simulated water. We observe the breakdown of the Stokes-Einstein and Stokes-Einstein-Debye relations in our system, and show that this breakdown is due to the presence of these dynamical heterogeneities. Our method consists of adding a small Gaussian noise to the position of the particle every time it is moved according to the viscous equation of motion. The noise is small in comparison to the mean-square displacement, and has a variance that is small in comparison to the viscosity. Therefore, this noise does not change the mean-flow velocity or the mean-square displacement, but does change the instantaneous velocity and the instantaneous displacement. Our results show that the instantaneous displacement grows proportional to the viscosity, while the instantaneous velocity grows superlinearly. We show that this deviation from the Stokes-Einstein-Debye relations can be explained by a simple model in which the viscosity is related to the displacement and the instantaneous velocity is related to the mean-square displacement.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ultra-relativistic geometrical shock dynamics and vorticity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1818, "human_text": "  Geometrical shock dynamics, also called CCW theory, yields approximate equations for shock propagation in which only the conditions at the shock appear explicitly; the post-shock flow is presumed approximately uniform and enters implicitly via a Riemann invariant. The nonrelativistic theory, formulated by G. B. Whitham and others, matches many experimental results surprisingly well. Motivated by astrophysical applications, we adapt the theory to ultra-relativistic shocks advancing into an ideal fluid whose pressure is negligible ahead of the shock, but one third of its proper energy density behind the shock. Exact results are recovered for some self-similar cylindrical and spherical shocks with power-law pre-shock density profiles. Comparison is made with numerical solutions of the full hydrodynamic equations. We review relativistic vorticity and circulation. In an ultrarelativistic ideal fluid, circulation can be defined so that it changes only at shocks, notwithstanding entropy gradients in smooth parts of the flow. ", "machine_text": " We investigate the dynamics of a geometrically shocked relativistic fluid with vorticity, in the limit of strong vorticity and large shock strength, inspired by recent observations of geometrically shocked high-energy-density plasmas in magnetospheric multiscale (MMS) tornadoes. In our model the fluid is subject to a sudden acceleration, which results in the development of a shocked region with vorticity. We find that the velocity distribution function is well described by a WKB-type solution in the limit of a large and fast-growing shocked region, which shows the development of a vortex sheet and helical vorticity patterns. The slowly decaying core region is characterized by strong vorticity and is crowned by a vortex filament. We also discuss the limit of a large and slowly decaying shocked region, which is well described by a Buongiorno-Soul\u00e9-type solution with a slowly rotating core. Our findings suggest that geometrically shocked MMS plasmas with strong vorticity can be well described by a simple fluid model with a WKB-type solution, provided that the shocked region is large and fast-growing, while a more complex model is needed for slowly decaying shocked regions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Helicity generation and alpha-effect by Vandakurov-Tayler instability   with z-dependent differential rotation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0448, "human_text": "  We investigate in isothermal MHD simulations the instability of toroidal magnetic fields resulting by the action of z-dependent differential rotation on a given axial field B^0 in a cylindrical enclosure where in particular the helicity of the resulting nonaxisymmetric flow is of interest. The idea is probed that helicity H is related to the external field and the differential rotation as H ~ B^0_i B^0_j Omega_i,j. The observed instability leads to a nonaxisymmetric solution with dominating mode m=1. With the onset of instability both kinematic and current helicity are produced which fulfill the suggested relation. Obviously, differential rotation dOmega/dz only needs an external axial field B^0_z to produce remarkable amounts of the helicities. Any regular time-dependency of the helicity could not be found. The resulting axial alpha-effect is mainly due to the current helicity, the characteristic time scale between both the values is of order of the rotation time. If the axial field is switched off then the helicity and the alpha-effect disappear. ", "machine_text": " We consider the helicity generation and the alpha-effect by the Vandakurov-Tayler instability with z-dependent differential rotation. We show that the generated helicity is related to the structure of the instability kernel and the differential rotation. We find that the helicity generation by the instability is sensitive to the choice of the reference frame as well as the assumption of the small helix radius. We analyze the problem using the Fundamnetal Theorem of helicopter dynamics and find that the Helicity Generation Efficiency (HGE) is proportional to the second derivative of the density contrast with respect to the helix radius. The obtained HGE has a maximum value of about 0.6 for the kernel with a double maximum and the smallest helix radius is about 10 km for this case. We also found that the alpha-effect by the instability is related to the amplitude of the density waves and the initial conditions. The analysis of the problem using the Fundamental Theorem of helicopter dynamics shows that the Alpha-effect Efficiency (AE) has a maximum value of about 1.5 for the kernel with a double maximum and the amplitude of the density waves is about 0.05.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing the Impact of Stellar Duplicity on Planet Occurrence with   Spectroscopic and Imaging Observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3173, "human_text": "  Although it is commonly agreed that the presence of a close stellar companion is likely to affect planet formation and evolution, the precise effects and their actual impact on planet occurrence and properties are still debated. In particular, observational constraints are sparse, a consequence of the discrimination against close binaries in Doppler planet searches. To bring observational constraints on the occurrence and properties of planets in binaries and multiple stars, we have been conducting two dedicated observing programs using both adaptive optics imaging and radial-velocity monitoring. In this chapter we explain our approach and present preliminary results from these two programs. A simplified statistical analysis of the data from our VLT/NACO imaging survey brings the first observational evidence that the occurrence of planets is reduced in binaries closer than ~120 AU. On the radial-velocity side, current results confirm that the use of two-dimensional correlation allows to search for circumprimary giant planets in many types of spectroscopic binaries. Definitive results from our ongoing planet search in spectroscopic binaries should yield important constraints on the closest binaries susceptible of hosting circumprimary giant planets. ", "machine_text": "  We present an analysis of planet occurrence rates (PORs) using data from the Kepler Mission, thehadoop Earth-sized planet survey, and the first three years of the TESS mission. We determine the PORs for all stars that are single (i.e. not in a binary system) that have an observed transiting planet, and for all stars that are in a binary system that have an observed transiting planet. We use a single-population model for the single-star data, and a two-population model for the binary-star data, and we fit both models to the data to determine the PORs for each. We find that the PORs for single stars are consistent with the current theories on planet formation, but the PORs for binary stars are higher than expected. This result suggests that the presence of a secondary star has a protoplanetary disk. We also find that the difference between the two PORs increases as the separation between the stars increases, supporting the theory that the most efficient method for planet formation is in a disk that is gravitationally lensed by a giant planet.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Selection Against Demographic Stochasticity in Age-Structured   Populations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2607, "human_text": "  It has been shown that differences in fecundity variance can influence the probability of invasion of a genotype in a population, i.e. a genotype with lower variance in offspring number can be favored in finite populations even if it has a somewhat lower mean fitness than a competitor. In this paper, Gillespie's results are extended to population genetic systems with explicit age structure, where the demographic variance (variance in growth rate) calculated in the work of Engen and colleagues is used as a generalization of \"variance in offspring number\" to predict the interaction between deterministic and random forces driving change in allele frequency. By calculating the variance from the life history parameters, it is shown that selection against variance in the growth rate will favor a genotypes with lower stochasticity in age specific survival and fertility rates. A diffusion approximation for selection and drift in a population with two genotypes with different life history matrices (and therefore, different growth rates and demographic variances) is derived and shown to be consistent with individual based simulations. It is also argued that for finite populations, perturbation analyses of both the growth rate and demographic variances may be necessary to determine the sensitivity of \"fitness\" (broadly defined) to changes in the life history parameters. ", "machine_text": "  We investigate the selection against demographic stochasticity in age-structured populations. We develop a new exact method of computing the selection gradient relating fitness to changes in age structure. We apply our method to an empirical model of the demographic dynamics of great apes. We find selection against stochasticity in age structure is very strong in all species and is equivalent to a selection pressure of several percent per generation. This is sufficient to maintain age structure and predicts that any demographic model with an incorrect assumption of age structure will be rejected by selection in the wild. Selection against demographic stochasticity is stronger at younger ages, indicating that younger individuals are more sensitive to the effects of stochasticity. We find that including a measure of temperature as a covariate in the selection gradient computation reduces the strength of selection against stochasticity, indicating that temperature reduces the importance of age structure. Our method can be used to investigate selection against demographic stochasticity in other populations and is generally applicable to computing selection gradients relating fitness to any covariate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Statistical analyses of long-term variability of AGN at high radio   frequencies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3293, "human_text": "  We present a study of variability time scales in a large sample of Active Galactic Nuclei at several frequencies between 4.8 and 230 GHz. We investigate the differences of various AGN types and frequencies and correlate the measured time scales with physical parameters such as the luminosity and the Lorentz factor. Our sample consists of both high and low polarization quasars, BL Lacertae objects and radio galaxies. The basis of this work is the 22 GHz, 37 GHz and 87 GHz monitoring data from the Metsahovi Radio Observatory spanning over 25 years. In addition,we used higher 90 GHz and 230 GHz frequency data obtained with the SEST-telescope between 1987 and 2003. Further lower frequency data at 4.8 GHz, 8 GHz and 14.5 GHz from the University of Michigan monitoring programme have been used. We have applied three different statistical methods to study the time scales: The structure function, the discrete correlation function and the Lomb-Scargle periodogram. We discuss also the differences and relative merits of these three methods. Our study reveals that smaller flux density variations occur in these sources on short time scales of 1-2 years, but larger outbursts happen quite rarely, on the average only once in every 6 years. We do not find any significant differences in the time scales between the source classes. The time scales are also only weakly related to the luminosity suggesting that the shock formation is caused by jet instabilities rather than the central black hole. ", "machine_text": "  We present statistical analyses of long-term variability of 539 active galactic nuclei (AGN) at radio frequencies (8-hubis GHz) observed with the VLA and VLBA. We search for long-term (month-scale to decade-scale) trends in the radio continuum and parallel optical data sets. We find that the variability in the radio data sets can be described by a power law with a 1/f index of \u22121.05 \u00b1 0.05. The scatter in the power law is larger for galaxies with higher redshift and higher radio luminosity. We find that the probability distribution of the number of months between radio variability events is described by an exponential with a decay rate of 1.16 \u00b1 0.14 years. The average lifetime of variability events is 16.7 \u00b1 1.9 years. We find a correlation between the variability amplitude and the variability length in optical data sets: the variability amplitude is proportional to the variability length raised to the power of \u22120.45 \u00b1 0.13. We also find a correlation between the variability amplitude and the optical luminosity: the variability amplitude is proportional to the luminosity raised to the power of 0.72 \u00b1 0.11. We find a correlation between the 1/f index of the radio data sets and the optical luminosity: the 1/f index is proportional to the luminosity raised to the power of 0.58 \u00b1 0.11. These results suggest that the variability of AGN at radio frequencies can be described by a simple power law with a 1/f index of \u22121.05 \u00b1 0.05. We discuss the results in the framework of a model in which the accretion torque depends on the ionization state of the accretion flow.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Yield design formulation for porous media subjected to flow, using   approximate pressure field. Calcul \\`a la rupture en pr\\'esence d'un   \\'ecoulement : formulation cin\\'ematique avec un champ de pression approch\\'e. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2364, "human_text": "  Yield design formulation for porous media subjected to flow, using approximate pressure field. We attempt here to use the kinematic method of yield design in the case of a porous medium subjected to flow (with or without free surface), without looking for the exact solution of the pressure field. The method proposed here is based on the use of approximate pressure fields. In this paper, we show how, under different conditions concerning the yield criterion and the velocity field, the use of such approximate fields allows to obtain a necessary condition for stability without having to find the real pressure field. Nous cherchons ici \\`a utiliser la m\\'ethode cin\\'ematique du calcul \\`a la rupture dans le cas d'un milieu poreux soumis \\`a un \\'ecoulement avec ou sans surface libre sans conna\\^itre la solution exacte du champ de pression. La m\\'ethode propos\\'ee ici repose sur l'utilisation de champs de pression approch\\'es par d\\'efaut. Nous montrerons comment sous certaines conditions portant sur le crit\\`ere de r\\'esistance et sur le champ de vitesse utilis\\'e, l'utilisation de tels champs de pression approch\\'es permet d'obtenir une condition n\\'ecessaire de stabilit\\'e sans avoir \\`a d\\'eterminer exactement l'\\'ecoulement. ", "machine_text": " We propose a formulation for the problem of yield design in the presence of a flow in a porous medium. This is an original approach to this problem, based on the definition of an approximate pressure field. It leads to a set of coupled equations which are simpler than the Navier-Stokes equations, but still have all the physical effects related to the flow in the medium. The difficulty of the problem lies in the fact that the pressure field is not anymore a differential equation, as in the case of the Navier-Stokes equations, but an integral equation which involves a double integral. Therefore we have developed an original method based on the introduction of a parameter which allows to transform the integral equation into a differential equation. The resulting formulation is therefore much simpler and can be solved analytically. We have tested our approach on simple test cases, and the results are in good agreement with the solutions obtained with the Navier-Stokes equations, for various values of the flow velocity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Elastic theory of low-dimensional continua and its applications in bio-   and nano-structures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0001, "human_text": "  This review presents the elastic theory of low-dimensional (one- and two-dimensional) continua and its applications in bio- and nano-structures. First, the curve and surface theory, as the geometric representation of the low-dimensional continua, is briefly described through Cartan moving frame method. The elastic theory of Kirchhoff rod, Helfrich rod, bending-soften rod, fluid membrane, and solid shell is revisited. Secondly, the application and availability of the elastic theory of low-dimensional continua in bio-structures, including short DNA rings, lipid membranes, and cell membranes, are discussed. The kink stability of short DNA rings is addressed by using the theory of Kirchhoff rod, Helfrich rod, and bending-soften rod. The lipid membranes obey the theory of fluid membrane. A cell membrane is simplified as a composite shell of lipid bilayer and membrane skeleton, which is a little similar to the solid shell. It is found that the membrane skeleton enhances highly the mechanical stability of cell membranes. Thirdly, the application and availability of the elastic theory of low-dimensional continua in nano-structures, including graphene and carbon nanotubes, are discussed. A revised Lenosky lattice model is proposed based on the local density approximation. Its continuum form up to the second order terms of curvatures and strains is the same as the free energy of 2D solid shells. Several typical mechanical properties of carbon nanotubes are revisited and investigated based on this continuum form. It is possible to avoid introducing the controversial concepts, the Young's modulus and thickness of graphene and single-walled carbon nanotubes, with this continuum form. ", "machine_text": "  We propose a new type of continuum theory which is based on the assumptions that the material is homogeneous and isotropic, and that the body has a low dimension. As an application, we consider the problem of the stability of a nano-rod to elastic deformations. We show that the standard continuum theory, which is applicable to an infinite dimensional body, is not applicable to a body with a low dimension. Then, we propose a new theory which takes into account the fact that the degrees of freedom are limited. We show that, in this case, the constitutive law which is derived from the standard continuum theory is not anymore equivalent to the Newton's law of motion, and that a correction term has to be introduced. We show that this correction term has a simple physical meaning: it represents the elastic energy which is released when the deformation becomes too large. Then, we use this theory to study the stability of a nano-rod to bending and torsion. We show that the standard continuum theory is not able to describe the stability to bending of a rod with a low diameter, and that a correction term has to be introduced. We also show that the stability to torsion is influenced by the limited number of degrees of freedom.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A case for variational geomagnetic data assimilation: insights from a   one-dimensional, nonlinear, and sparsely observed MHD system. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1777, "human_text": "  Secular variations of the geomagnetic field have been measured with a continuously improving accuracy during the last few hundred years, culminating nowadays with satellite data. It is however well known that the dynamics of the magnetic field is linked to that of the velocity field in the core and any attempt to model secular variations will involve a coupled dynamical system for magnetic field and core velocity. Unfortunately, there is no direct observation of the velocity. Independently of the exact nature of the above-mentioned coupled system -- some version being currently under construction -- the question is debated in this paper whether good knowledge of the magnetic field can be translated into good knowledge of core dynamics. Furthermore, what will be the impact of the most recent and precise geomagnetic data on our knowledge of the geomagnetic field of the past and future? These questions are cast into the language of variational data assimilation, while the dynamical system considered in this paper consists in a set of two oversimplified one-dimensional equations for magnetic and velocity fields. This toy model retains important features inherited from the induction and Navier-Stokes equations: non-linear magnetic and momentum terms are present and its linear response to small disturbances contains Alfv\\'en waves. It is concluded that variational data assimilation is indeed appropriate in principle, even though the velocity field remains hidden at all times; it allows us to recover the entire evolution of both fields from partial and irregularly distributed information on the magnetic field. This work constitutes a first step on the way toward the reassimilation of historical geomagnetic data and geomagnetic forecast. ", "machine_text": "  We present a case for variational data assimilation in nonlinear geodynamical systems, motivated by recent progress in the field of statistical physics. In particular, we consider a one-dimensional, nonlinear, and sparsely observed magnetohydrodynamic system and show that the variational framework is capable of efficiently and accurately recovering the underlying evolution of the system. In this regard, we pay particular attention to the role of the geometric structure of the system, which in general leads to a substantial gain in the number of degrees of freedom as compared to the conventional evolution parameterization. In addition, we show that in this setting the use of an underlying flow field in the assimilated variables is key to an effective and efficient data assimilation. Our results provide a concrete example of an application of statistical physics ideas to geodynamical systems and might be useful in developing an optimal data assimilation strategy for this type of systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the expressive power of planar perfect matching and permanents of   bounded treewidth matrices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3751, "human_text": "  Valiant introduced some 25 years ago an algebraic model of computation along with the complexity classes VP and VNP, which can be viewed as analogues of the classical classes P and NP. They are defined using non-uniform sequences of arithmetic circuits and provides a framework to study the complexity for sequences of polynomials. Prominent examples of difficult (that is, VNP-complete) problems in this model includes the permanent and hamiltonian polynomials. While the permanent and hamiltonian polynomials in general are difficult to evaluate, there have been research on which special cases of these polynomials admits efficient evaluation. For instance, Barvinok has shown that if the underlying matrix has bounded rank, both the permanent and the hamiltonian polynomials can be evaluated in polynomial time, and thus are in VP. Courcelle, Makowsky and Rotics have shown that for matrices of bounded treewidth several difficult problems (including evaluating the permanent and hamiltonian polynomials) can be solved efficiently. An earlier result of this flavour is Kasteleyn's theorem which states that the sum of weights of perfect matchings of a planar graph can be computed in polynomial time, and thus is in VP also. For general graphs this problem is VNP-complete. In this paper we investigate the expressive power of the above results. We show that the permanent and hamiltonian polynomials for matrices of bounded treewidth both are equivalent to arithmetic formulas. Also, arithmetic weakly skew circuits are shown to be equivalent to the sum of weights of perfect matchings of planar graphs. ", "machine_text": "  We show that the expressive power of planar perfect matching and the permanents of bounded treewidth matrices is the same. This answers a question of Leinster and leaves the path to a solution of the positive instances problem for the Million Book Challenge. We show further that every family of circuits that can be recognized by a fixed planar perfect matching algorithm (as well as by a fixed algorithm that recognizes the permanent of bounded treewidth matrices) can be recognized by an exponential-space algorithm that makes polynomially many queries to a fixed perfect matching algorithm (as well as to a fixed algorithm that recognizes the permanent of bounded treewidth matrices). As a by-product, we show that a perfect matching algorithm (as well as an algorithm that recognizes the permanent of bounded treewidth matrices) that makes polynomially many queries to a fixed perfect matching algorithm (as well as to a fixed algorithm that recognizes the permanent of bounded treewidth matrices) runs in exponential time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-resonant and Resonant X-ray Scattering Studies on Multiferroic   TbMn2O5. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0533, "human_text": "  Comprehensive x-ray scattering studies, including resonant scattering at Mn L-edge, Tb L- and M-edges, were performed on single crystals of TbMn2O5. X-ray intensities were observed at a forbidden Bragg position in the ferroelectric phases, in addition to the lattice and the magnetic modulation peaks. Temperature dependences of their intensities and the relation between the modulation wave vectors provide direct evidences of exchange striction induced ferroelectricity. Resonant x-ray scattering results demonstrate the presence of multiple magnetic orders by exhibiting their different temperature dependences. The commensurate-to-incommensurate phase transition around 24 K is attributed to discommensuration through phase slipping of the magnetic orders in spin frustrated geometries. We proposed that the low temperature incommensurate phase consists of the commensurate magnetic domains separated by anti-phase domain walls which reduce spontaneous polarizations abruptly at the transition. ", "machine_text": " We have performed non-resonant and resonant X-ray scattering studies on single crystals of TbMn2O5, a paramagnetic metal with a canting magnetic structure below its Curie temperature. The non-resonant results show a non-monotonic temperature dependence of the X-ray intensities in the magnetic reflection, consistent with the existence of a structural phase transition at T ~ 100 K. Resonant X-ray scattering results show a clear dependence of the X-ray intensity in the magnetic reflection on the magnetic field applied along the canting direction. The temperature dependence of the X-ray intensity in the magnetic reflection for a magnetic field applied along the easy axis follows a monotonic curve, consistent with the existence of a magnetic phase transition at T ~ 120 K. In addition, we have observed a clear signature of a skyrmion lattice in the X-ray data for a magnetic field applied along the hard axis. Our results suggest that the magnetic skyrmion lattice is formed by the coupling between the magnetic and structural degrees of freedom.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: (Co)cyclic (co)homology of bialgebroids: An approach via (co)monads. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.319, "human_text": "  For a (co)monad T_l on a category M, an object X in M, and a functor \\Pi: M \\to C, there is a (co)simplex Z^*:=\\Pi T_l^{* +1} X in C. Our aim is to find criteria for para-(co)cyclicity of Z^*. Construction is built on a distributive law of T_l with a second (co)monad T_r on M, a natural transformation i:\\Pi T_l \\to \\Pi T_r, and a morphism w: T_r X \\to T_l X in M. The relations i and w need to satisfy are categorical versions of Kaygun's axioms of a transposition map. Motivation comes from the observation that a (co)ring T over an algebra R determines a distributive law of two (co)monads T_l=T \\otimes_R (-) and T_r = (-)\\otimes_R T on the category of R-bimodules. The functor \\Pi can be chosen such that Z^n= T\\hat{\\otimes}_R... \\hat{\\otimes}_R T \\hat{\\otimes}_R X is the cyclic R-module tensor product. A natural transformation i:T \\hat{\\otimes}_R (-) \\to (-) \\hat{\\otimes}_R T is given by the flip map and a morphism w: X \\otimes_R T \\to T\\otimes_R X is constructed whenever T is a (co)module algebra or coring of an R-bialgebroid. Stable anti Yetter-Drinfel'd modules over certain bialgebroids, so called x_R-Hopf algebras, are introduced. In the particular example when T is a module coring of a x_R-Hopf algebra B and X is a stable anti Yetter-Drinfel'd B-module, the para-cyclic object Z_* is shown to project to a cyclic structure on T^{\\otimes_R *+1} \\otimes_B X. For a B-Galois extension S \\to T, a stable anti Yetter-Drinfel'd B-module T_S is constructed, such that the cyclic objects B^{\\otimes_R *+1} \\otimes_B T_S and T^ {\\hat{\\otimes}_S *+1} are isomorphic. As an application, we compute Hochschild and cyclic homology of a groupoid with coefficients, by tracing it back to the group case. In particular, we obtain explicit expressions for ordinary Hochschild and cyclic homology of a groupoid. ", "machine_text": "  We show that the (co)cyclic (co)homology of a bialgebra (or a bialgebroid) is isomorphic to the (co)homology of a certain monad on the category of covariant functors. As an application, we give a description of the (co)acyclic (co)homology of a bialgebroid in terms of a certain (co)monad on the category of functors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Scheduling Dags under Uncertainty. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1876, "human_text": "  This paper introduces a parallel scheduling problem where a directed acyclic graph modeling $t$ tasks and their dependencies needs to be executed on $n$ unreliable workers. Worker $i$ executes task $j$ correctly with probability $p_{i,j}$. The goal is to find a regimen $\\Sigma$, that dictates how workers get assigned to tasks (possibly in parallel and redundantly) throughout execution, so as to minimize the expected completion time. This fundamental parallel scheduling problem arises in grid computing and project management fields, and has several applications.   We show a polynomial time algorithm for the problem restricted to the case when dag width is at most a constant and the number of workers is also at most a constant. These two restrictions may appear to be too severe. However, they are fundamentally required. Specifically, we demonstrate that the problem is NP-hard with constant number of workers when dag width can grow, and is also NP-hard with constant dag width when the number of workers can grow. When both dag width and the number of workers are unconstrained, then the problem is inapproximable within factor less than 5/4, unless P=NP. ", "machine_text": "  Scheduling Dags under Uncertainty  We consider the problem of scheduling dags, which are directed acyclic graphs representing the dependencies between tasks, under uncertainty. We assume that the execution times of the tasks are independently and identically distributed random variables with known means and variances. We introduce the notion of a potential function that allows us to capture the degree to which a solution to the scheduling problem is affected by the uncertainty. We then show that the problem of finding a solution that minimizes the potential function can be converted to a semi-dynamic programming problem. We propose a solution to this semi-dynamic programming problem that is based on a generalized scheduledEarliestDueDate(EDD) policy, where the scheduled-EDD policy is defined by selecting the task with the earliest scheduled due date and then performing the task if its execution time is less than or equal to its scheduled due date. We evaluate the performance of the generalized scheduled-EDD policy by comparing its performance to that of the EarliestDueDate policy, which is the policy that selects the task with the earliest due date and then performs the task if its execution time is less than or equal to its due date, on several standard scheduling problems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamics of Baryons from String Theory and Vector Dominance. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2632, "human_text": "  We consider a holographic model of QCD from string theory, a la Sakai and Sugimoto, and study baryons. In this model, mesons are collectively realized as a five-dimensional \\$U(N_F)=U(1)\\times SU(N_F)$ Yang-Mills field and baryons are classically identified as $SU(N_F)$ solitons with a unit Pontryagin number and $N_c$ electric charges. The soliton is shown to be very small in the large 't Hooft coupling limit, allowing us to introduce an effective field ${\\cal B}$. Its coupling to the mesons are dictated by the soliton structure, and consists of a direct magnetic coupling to the $SU(N_F)$ field strength as well as a minimal coupling to the $U(N_F)$ gauge field. Upon the dimensional reduction, this effective action reproduces all interaction terms between nucleons and an infinite tower of mesons in a manner consistent with the large $N_c$ expansion. We further find that all electromagnetic interactions, as inferred from the same effective action via a holographic prescription, are mediated by an infinite tower of vector mesons, rendering the baryon electromagnetic form factors completely vector-dominated as well. We estimate nucleon-meson couplings and also the anomalous magnetic moments, which compare well with nature. ", "machine_text": "  We investigate the dynamics of baryons from string theory and vector dominance. In the framework of string theory, we study the generation and dynamics of baryons from the 16 and 28 dimensional frameworks of type II and type I string theory, respectively. We find that the dynamics of baryons is closely related to the geometry of the string theory and the imposed boundary conditions. In the case of type I string theory, we show that the states with large baryon number can be obtained by an appropriate choice of the boundary conditions. In the case of type II string theory, we find that the generated baryons are in general tied to the geometry of the string theory. In particular, we find that the massless baryons are in general Page- operator super governed. We also show that the choice of the string framework and the geometry of the string theory can lead to non-standard behavior of the baryons, such as the baryon number violation and the appearance of several generations of baryons.  We also study the dynamics of baryons in the framework of vector dominance. We show that the baryons in this case are in general related to the Lorentz invariance of the theory. We find that, even if the Lorentz invariance is broken by the gravity, the baryons can be generated in the theory. We also find that the generated baryons are in general related to the Lorentz violating operators, and the behavior of the baryons can be used to test the Lorentz invariance of the theory. We show that the dynamics of baryons in the framework of vector dominance can lead to non-standard behavior of the baryons, such as the baryon number violation and the appearance of several generations of baryons.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Matter density perturbations and effective gravitational constant in   modified gravity models of dark energy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1032, "human_text": "  We derive the equation of matter density perturbations on sub-horizon scales for a general Lagrangian density f(R, phi, X) that is a function of a Ricci scalar R, a scalar field phi and a kinetic term X=-(nabla phi)^2/2. This is useful to constrain modified gravity dark energy models from observations of large-scale structure and weak lensing. We obtain the solutions for the matter perturbation delta_m as well as the gravitational potential Phi for some analytically solvable models. In a f(R) dark energy model with the Lagrangian density f(R)=alpha R^{1+m}-Lambda, the growth rates of perturbations exhibit notable differences from those in the standard Einstein gravity unless m is very close to 0. In scalar-tensor models with the Lagrangian density f=F(phi)R+2p(phi,X) we relate the models with coupled dark energy scenarios in the Einstein frame and reproduce the equations of perturbations known in the current literature by making a conformal transformation. We also estimate the evolution of perturbations in both Jordan and Einstein frames when the energy fraction of dark energy is constant during the matter-dominated epoch. ", "machine_text": "  We consider matter density perturbations in two-component models of modified gravity that are able to reproduce the evolution of the effective gravitational constant, $\\Gamma_{\\rm effective}$, and the matter power spectrum, $\\alpha_{\\rm matter}$, as functions of redshift in a way consistent with the standard model of cosmology. We find that the effective density field is always in local thermal equilibrium (LTE) with the matter power spectrum, $\\alpha_{\\rm matter}$, whatever the values of the model parameters. We then use the assumptions of local thermal equilibrium and a flat matter power spectrum to derive a simple formula for the matter density perturbations in the effective theory. We show that this formula is consistent with the recent observations of the cosmic microwave background and the large scale structure of the universe. This provides a strong motivation for models of modified gravity that are able to reproduce the evolution of $\\Gamma_{\\rm effective}$ and $\\alpha_{\\rm matter}$ in a way consistent with the standard model of cosmology.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Statistical Behavior Of Domain Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2619, "human_text": "  We study the statistical behavior of two out of equilibrium systems. The first one is a quasi one-dimensional gas with two species of particles under the action of an external field which drives each species in opposite directions. The second one is a one-dimensional spin system with nearest neighbor interactions also under the influence of an external driving force. Both systems show a dynamical scaling with domain formation. The statistical behavior of these domains is compared with models based on the coalescing random walk and the interacting random walk. We find that the scaling domain size distribution of the gas and the spin systems is well fitted by the Wigner surmise, which lead us to explore a possible connection between these systems and the circular orthogonal ensemble of random matrices. However, the study of the correlation function of the domain edges, show that the statistical behavior of the domains in both gas and spin systems, is not completely well described by circular orthogonal ensemble, nor it is by other models proposed such as the coalescing random walk and the interacting random walk. Nevertheless, we find that a simple model of independent intervals describe more closely the statistical behavior of the domains formed in these systems. ", "machine_text": "  We introduce and study a class of domain systems, which we call statistical behavior domain systems. We give a motivation for their study by formulating several problems in statistics and probability theory in which the considered domain systems are employed. We show that the behavior of the domain systems is closely related to the statistical behavior of the observed quantities. This approach allows us to introduce and study a general setting of domain systems which are endowed with a statistical behavior and to consider statistical problems as problems of domain systems. In this way, we obtain a generalization of the classical theory of dynamical systems in the spirit of G. D. Birkhoff. The approach also allows us to study stochastic processes by means of the theory of domain systems. As an example, we consider a stochastic process which describes the statistical behavior of the trajectory of a domain system. The study of statistical behavior domain systems is an important and active field of research in the theory of dynamical systems and is related to many problems in statistics, probability theory, and mathematical physics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Residual correlations between decay products of $\\pi^0\\pi^0$ and   $p\\Sigma^0$ systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.329, "human_text": "  Residual correlations between decay products due to a combination of both correlations between parents at small relative velocities and small decay momenta are discussed. Residual correlations between photons from pion decays are considered as a new possible source of information on direct photon fraction. Residual correlations in $p\\gamma$ and $p\\Lambda$ systems due to $p\\Sigma^0$ interaction in final state are predicted based on the $p\\Sigma^0$ low energy scattering parameters deduced from the spin-flavour SU$_6$ model by Fujiwara et al. including effective meson exchange potentials and explicit flavour symmetry breaking to reproduce the properties of the two-nucleon system and the low-energy hyperon-nucleon cross section data. The $p\\gamma_{\\Sigma^0}$ residual correlation is concentrated at $k^* \\approx 70$ Mev/$c$ and its shape and intensity appears to be sensitive to the scattering parameters and space-time dimensions of the source. The $p\\Lambda_{\\Sigma^0}$ residual correlation recovers the negative parent $p\\Sigma^0$ correlation for $k^* > 70$ Mev/$c$. The neglect of this negative residual correlation would lead to the underestimation of the parent $p\\Lambda$ correlation effect and to an overestimation of the source size. ", "machine_text": " We have performed a systematic study of the residual correlations between the decay products of $\\pi^0\\pi^0$ and $p\\Sigma^0$ systems, in the framework of the quasiparticle random phase approximation. The correlation functions $\\langle\\omega_1\\omega_2\\rangle$, $\\langle\\omega_1\\omega_3\\rangle$, and $\\langle\\omega_1\\omega_4\\rangle$ are calculated exactly in the $\\pi^0\\pi^0$ and $p\\Sigma^0$ channels, in the small-$\\epsilon$ approximation, and the standard approximation, respectively. We show that in the small-$\\epsilon$ approximation, the three correlation functions have a common factor, which depends only on the relative phases of the $\\omega_1$ and $\\omega_2$ waves, and is independent of the $\\omega_3$ and $\\omega_4$ waves. This common factor is related to the non-monotonic structure of the $\\pi^0\\pi^0$ and $p\\Sigma^0$ amplitudes in the channel space. We evaluate the small-$\\epsilon$ correction to the common factor, and show that it is small in the massless limit, and is proportional to the relative magnitude of the $\\omega_3$ and $\\omega_4$ waves. The corresponding correction to the $\\langle\\omega_1\\omega_2\\rangle$ correlation function is also evaluated, and its small-$\\epsilon$ correction is shown to be proportional to the $\\omega_3$ and $\\omega_4$ waves, and the corresponding correction to the $\\langle\\omega_1\\omega_3\\rangle$ and $\\langle\\omega_1\\omega_4\\rangle$ correlation functions is shown to be negligible.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Second-Order Type Isomorphisms Through Game Semantics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4226, "human_text": "  The characterization of second-order type isomorphisms is a purely syntactical problem that we propose to study under the enlightenment of game semantics. We study this question in the case of second-order &#955;$\\mu$-calculus, which can be seen as an extension of system F to classical logic, and for which we de&#64257;ne a categorical framework: control hyperdoctrines. Our game model of &#955;$\\mu$-calculus is based on polymorphic arenas (closely related to Hughes' hyperforests) which evolve during the play (following the ideas of Murawski-Ong). We show that type isomorphisms coincide with the \"equality\" on arenas associated with types. Finally we deduce the equational characterization of type isomorphisms from this equality. We also recover from the same model Roberto Di Cosmo's characterization of type isomorphisms for system F. This approach leads to a geometrical comprehension on the question of second order type isomorphisms, which can be easily extended to some other polymorphic calculi including additional programming features. ", "machine_text": " Second-Order Type Isomorphisms Through Game Semantics  We show that every second-order type theory with free second-order variables is isomorphic to a theory of games with perfect information and initial positions that are fixed by a finite set of symmetry conditions. We draw a connection between the game-theoretic interpretation of type theory and the standard interpretation of first-order logic. We show that every game that can be interpreted as a second-order type theory has a natural symmetry-based Initial Condition. We introduce a new class of games called Perfect-Information Symmetric Games (PISG) and show that every game in this class has a natural type theory interpretation. We show that, although PISG are closed under backward induction, they are not closed under induction in general. We present a general procedure for constructing a PISG and use this procedure to construct the Generalized Majority Game, which is a PISG with the additional property that, if all players but one have the same strategy, the remaining player can force a draw by repeatedly choosing his own strategy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electro-optically tunable microring resonators in lithium niobate. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2392, "human_text": "  Optical microresonators have recently attracted a growing attention in the photonics community. Their applications range from quantum electro-dynamics to sensors and filtering devices for optical telecommunication systems, where they are likely to become an essential building block. The integration of nonlinear and electro-optical properties in the resonators represents a very stimulating challenge, as it would incorporate new and more advanced functionality. Lithium niobate is an excellent candidate material, being an established choice for electro-optic and nonlinear optical applications. Here we report on the first realization of optical microring resonators in submicrometric thin films of lithium niobate. The high index contrast films are produced by an improved crystal ion slicing and bonding technique using benzocyclobutene. The rings have radius R=100 um and their transmission spectrum has been tuned using the electro-optic effect. These results open new perspectives for the use of lithium niobate in chip-scale integrated optical devices and nonlinear optical microcavities. ", "machine_text": "  Electro-optically tunable microring resonators in lithium niobate A high-Q optical resonator can be formed by confining light in a microring structure, which can be implemented in a semiconductor microcavity or in a crystalline resonator. One advantage of the crystalline resonator is that it can provide strong light confinement in a tiny core while achieving a high quality factor, and therefore it can be integrated with various other photonic devices. In this article, we demonstrate a tunable microring resonator in lithium niobate (LN), a ferroelectric crystal, which can be used for optical switching and cavity quantum electro-optics. The resonator has a high-Q factor of 10000 in the absence of a perturbation, and the free-spectral range is 4.3 nm. By utilizing the electro-optic effect in LN, the resonator can be tuned by an electrical signal, and the tuning range can be as large as 70 nm. Our results show that the resonator can be applied to optical switching and that it has potential for use in cavity quantum electro-optics.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The formation of S0 galaxies: evidence from globular clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0623, "human_text": "  We test the theory that lenticular (S0) galaxies form from spirals whose star formation has been shut down. We use the globular cluster specific frequency S_N, defined as the number of globular clusters normalised by the galaxy luminosity as a diagnostic. NTT/EMMI long-slit spectroscopic observations of 11 S0 galaxies at z < 0.006 are used to measure the absorption-line indices, Hdelta, Hgamma, Mgb, Fe5270 and Fe5335 within the central r_e/8. By inverting single-stellar population models, luminosity-weighted mean ages, metallicities and alpha-element abundance ratios are derived. We estimate the amount of fading a galaxy has undergone by comparing each galaxy's S_N with its deviation from the mean spiral S_N. Galaxies with higher S_N have older stellar populations. Moreover, we find that the zero-point and amount of fading is consistent with a scenario where lenticulars are formed by the quenching of star formation in spiral galaxies. Our data also rule out any formation method for S0s which creates a large number of new globular clusters. We confirm that previous results showing a relationship between S_N and color are driven by the S_N - Age relation. Five galaxies show detectable Hbeta, [OIII], Halpha or [NII] emission lines. However, only in the two youngest galaxies is this emission unambiguously from star formation. Our results are consistent with the theory that S0 galaxies are formed when gas in normal spirals is removed, possibly as a result of a change in environment. The on-going star formation in the youngest galaxies hints that the timescale of quenching is ~< 1 Gyr. We speculate, therefore, that the truncation of star formation is a rather gentle process unlikely to involve a rapid burst of star formation. ", "machine_text": "  We present photometric and spectroscopic observations of 13 globular clusters in the S0 galaxy NGC 3pager 2ter, which suggests that the globular clusters in S0 galaxies are different from those in later-type galaxies. The clusters in NGC 3pager 2ter have a much larger number of blue (i.e. metal-poor) stars. We show this in a color-magnitude diagram, where the clusters in NGC 3pager 2ter tend to lie below the 'solar metallicity' line. The cluster ages are derived from the main sequence turn-off point, and show a large spread, which is typical for clusters in S0 galaxies. We find no correlation between cluster metallicity and age. This supports the hypothesis that the clusters in S0 galaxies were formed by several population of stars, instead of one single population, as is the case in Galactic globular clusters. Our results also show that a large fraction of the clusters in S0 galaxies contain a substantial number of blue stragglers. We discuss this in the context of a possible method of estimating the cluster's metallic content, by counting the number of blue stragglers in the cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral study on the dips of Cir X-1. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.401, "human_text": "  We present X-ray spectral analyses of low mass X-ray binary Cir X-1 during X-ray dips, using the Rossi X-ray Timing Explorer (RXTE) data. Each dip was divided into several segments, and the spectrum of each segment was fitted with a three-component blackbody model, in which two components are affected by partial covering and the third one is unaffected. A Gaussian emission line is also included in the spectral model to represent the Fe Ka line at ~ 6.4 keV. The fitted temperatures of the two partially covered components are about 2 keV and 1 keV, while the uncovered component has a temperature of ~ 0.5-0.6 keV. The equivalent blackbody emission radius of the hottest component is the smallest and that of the coolest component is the biggest. During dips, the fluxes of the two hot components are linearly correlated, while that of the third component doesn't show any significant variation. The Fe line flux remains constant within errors during the short dips. However, during the long dips the line flux changes significantly and is positively correlated with the fluxes of the two hot components. These results suggest: (1) the temperature of the X-ray emitting region decreases with radius, (2) the Fe Ka line emitting region is close to the hot continuum emitting region, and (3) the size of the Fe line emitting region is bigger than the size of the obscuring matters causing short dips but smaller than the sizes of those causing long dips. ", "machine_text": "  We present a spectral study of the dips in the light curve of the low-mass X-ray binary Cir X-1. We find that the rise times of the dips are well described by a power law with a photon index of 1.3 \u00b1 0.1. This is consistent with a single temperature structure in the accretion disc, with a temperature gradient of 3 K cm-1. We show that this result can be obtained by balancing the energy budget of the system, provided that the accretion disc is geometrically thick and that the temperature is uniform on scales larger than the size of the accretion disc. We discuss this result in the framework of the double-disc model, and we show that a simple prescription that the inner disc is colder than the outer disc is sufficient to reproduce our observations. We show that the excess scatter in the power law is consistent with a simple model in which the accretion disc is surrounded by a cavity, with a few non-thermal ionisation contributions along the lines of sight. We discuss this in the framework of the model proposed by 2018A&AS...637..116L, according to which the excess scatter is caused by temperature inhomogeneities on the surface of the disc. We show that a model in which the disc is surrounded by a cavity gives a slightly better fit to the data, but that the physical interpretation is very similar. We conclude that the spectral shape of the dips in the light curve of Cir X-1 is consistent with a double-disc structure, with the inner disc being cooler than the outer disc, and that there are few contributions along the lines of sight that are not consistent with a single temperature structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Noncommutative tori and the Riemann-Hilbert correspondence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1076, "human_text": "  We study the interplay between noncommutative tori and noncommutative elliptic curves through a category of equivariant differential modules on $\\mathbb{C}^*$. We functorially relate this category to the category of holomorphic vector bundles on noncommutative tori as introduced by Polishchuk and Schwarz and study the induced map between the corresponding K-theories. In addition, there is a forgetful functor to the category of noncommutative elliptic curves of Soibelman and Vologodsky, as well as a forgetful functor to the category of vector bundles on $\\mathbb{C}^*$ with regular singular connections.   The category that we consider has the nice property of being a Tannakian category, hence it is equivalent to the category of representations of an affine group scheme. Via an equivariant version of the Riemann-Hilbert correspondence we determine this group scheme to be (the algebraic hull of) $\\mathbb{Z}^2$. We also obtain a full subcategory of the category of holomorphic bundles of the noncommutative torus, which is equivalent to the category of representations of $\\mathbb{Z}$. This group is the proposed topological fundamental group of the noncommutative torus (understood as a degenerate elliptic curve) and we study Nori's notion of \\'etale fundamental group in this context. ", "machine_text": "  We consider noncommutative tori, i.e. tori with a noncommutative group structure, and show that their spaces of harmonic functions are not necessarily injective. We show further that the injectivity of the space of harmonic functions on a noncommutative torus is equivalent to the injectivity of the associated Hilbert-Riemann space. As an application, we show that the injectivity of the space of harmonic functions on a finite dimensional noncommutative torus is lower than that of the space of continuous functions. As another application, we show that the injectivity of the space of harmonic functions on a noncommutative torus is lower than that of the space of continuous functions if and only if the noncommutative torus is a injective algebra. We show also that the injectivity of the space of harmonic functions on a noncommutative torus is lower than that of the space of continuous functions if and only if the noncommutative torus is a division ring.  We also consider the Riemann-Hilbert correspondence on noncommutative tori and show that the spaces of harmonic functions on noncommutative tori are not necessarily isometric to the spaces of harmonic functions on commutative tori. As an application, we show that the Riemann-Hilbert correspondence on a noncommutative torus is lower than that on a commutative torus if and only if the noncommutative torus is a division ring.  We show further that the Riemann-Hilbert correspondence on a noncommutative torus is equivalent to the Riemann-Hilbert correspondence on the commutative torus if and only if the noncommutative torus is an injective algebra.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Total Number of Giant Planets in Debris Disks with Central Clearings. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1684, "human_text": "  Infrared spectra from the Spitzer Space Telescope (SSC) of many debris disks are well fit with a single black body temperature which suggest clearings within the disk. We assume that inside the clearing orbital instability due to planets removes dust generating planetesimal belts and dust generated by the outer disk that is scattered or drifts into the clearing. From numerical integrations we estimate a minimum planet spacing required for orbital instability (and so planetesimal and dust removal) as a function of system age and planet mass. We estimate that a 10^8 year old debris disk with a dust disk edge at a radius of 50 AU hosted by an A star must contain approximately 5 Neptune mass planets between the clearing radius and the iceline in order to remove all primordial objects within it. We infer that known debris disk systems contain at least a fifth of a Jupiter mass in massive planets. The number of planets and spacing required is insensitive to the assumed planet mass. However an order of magnitude higher total mass in planets could reside in these systems if the planets are more massive. ", "machine_text": "  We present an analysis of giant planets in debris disk systems with central clearings. We estimate the fraction of debris disk systems with giant planets that display a central clearing, and use this fraction to derive a frequency for giant planets in general. We show that the number of giant planets in the disks we observe is consistent with the giant planet frequency estimated in a previous study, but is not consistent with a lower frequency. This suggests that either the number of giant planets in our galaxy is higher than expected, or that the disks we observe are not representative of the general population of debris disk systems. We discuss this in the context of our current understanding of giant planet formation, and present a simple model in which the properties of giant planets and debris disk systems can be used to constrain the giant planet formation rate. This model indicates that the number of giant planets in debris disk systems is probably close to the number expected from giant planet formation, given the current estimates of the number of protoplanets.  We present estimates of the frequency of giant planets in debris disk systems, and use these estimates to constrain the giant planet formation rate. We find that the number of giant planets in debris disk systems is probably close to the number expected from giant planet formation, given the current estimates of the number of protoplanets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fourier analysis of active-region plage. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2014, "human_text": "  We study the dynamical interaction of the solar chromosphere with the transition region in mossy and non-mossy active-region plage. We carefully align image sequences taken with the Transition Region And Coronal Explorer (TRACE) in the ultraviolet passbands around 1550, 1600, and 1700 A and the extreme ultraviolet passbands at 171 and 195 A. We compute Fourier phase-difference spectra that are spatially averaged separately over mossy and non-mossy plage to study temporal modulations as a function of temporal frequency. The 1550 versus 171 A comparison shows zero phase difference in non-mossy plage. In mossy plage, the phase differences between all UV and EUV passbands show pronounced upward trends with increasing frequency, which abruptly changes into zero phase difference beyond 4-6 mHz. The phase difference between the 171 and 195 A sequences exhibits a shallow dip below 3 mHz and then also turns to zero phase difference beyond this value. We attribute the various similarities between the UV and EUV diagnostics that are evident in the phase-difference diagrams to the contribution of the C IV resonance lines in the 1550 and 1600 A passbands. The strong upward trend at the lower frequencies indicates the presence of upward-traveling disturbances. It points to correspondence between the lower chromosphere and the upper transition region, perhaps by slow-mode magnetosonic disturbances, or by a connection between chromospheric and coronal heating mechanisms. The transition from this upward trend to zero phase difference at higher frequencies is due to the intermittent obscuration by fibrils that occult the foot points of hot loops, which are bright in the EUV and C IV lines, in oscillatory manner. ", "machine_text": "  We present a detailed Fourier analysis of plage in active regions (ARs) and investigate the physical origin of the frequency-dependent optical depths. We use a new algorithm that combines spectral synthesis with a multitaper method to obtain the power spectrum of plage intensity. The analysis reveals that the plage spectrum has a cut-off frequency that depends on the magnetic flux and the geometry of the AR. The low-frequency limit of the plage spectrum is consistent with a spectrum that can be described by a single power law. We show that a simple model in which the frequency-dependent absorption is caused by the superposition of plage along magnetic field lines can quantitatively reproduce the shape of the plage spectrum. Within this model the absorption is caused by an impedance miss-match between the plage and the background plasma. We determine the scaling of the plage spectrum by fitting our model to the low-frequency regime of the plage spectrum. We find that the plage spectrum is well described by a power law with a cut-off frequency that depends on the magnetic flux and geometry of the AR.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Long Term Fate of Our Digital Belongings: Toward a Service Model for   Personal Archives. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3653, "human_text": "  We conducted a preliminary field study to understand the current state of personal digital archiving in practice. Our aim is to design a service for the long-term storage, preservation, and access of digital belongings by examining how personal archiving needs intersect with existing and emerging archiving technologies, best practices, and policies. Our findings not only confirmed that experienced home computer users are creating, receiving, and finding an increasing number of digital belongings, but also that they have already lost irreplaceable digital artifacts such as photos, creative efforts, and records. Although participants reported strategies such as backup and file replication for digital safekeeping, they were seldom able to implement them consistently. Four central archiving themes emerged from the data: (1) people find it difficult to evaluate the worth of accumulated materials; (2) personal storage is highly distributed both on- and offline; (3) people are experiencing magnified curatorial problems associated with managing files in the aggregate, creating appropriate metadata, and migrating materials to maintainable formats; and (4) facilities for long-term access are not supported by the current desktop metaphor. Four environmental factors further complicate archiving in consumer settings: the pervasive influence of malware; consumer reliance on ad hoc IT providers; an accretion of minor system and registry inconsistencies; and strong consumer beliefs about the incorruptibility of digital forms, the reliability of digital technologies, and the social vulnerability of networked storage. ", "machine_text": "  The Long Term Fate of Our Digital Belongings: Toward a Service Model for Personal Archives  The explosive growth of personal digital archives, in the form of emails, documents, photographs, videos, and music, creates an unprecedented challenge for the individuals who must preserve these files over the long term. We are failing to preserve our digital belongings, with profound consequences for both the present and the future. The primary cause of this failure is that individuals lack the necessary skills and resources to preserve their digital archives. We describe a system that empowers individuals to preserve their digital belongings. This system is based on an infrastructure of network services that individuals can invoke directly, or via user-level tools that automate the process of archive preservation. Our approach is grounded in a service-oriented architecture, in which the services are stitched together to form a flexible and powerful system. We discuss the implementation of a prototype of this system, and describe our ongoing work to evaluate the system and improve its functionality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bose-Einstein-condensed gases in arbitrarily strong random potentials. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3768, "human_text": "  Bose-Einstein-condensed gases in external spatially random potentials are considered in the frame of a stochastic self-consistent mean-field approach. This method permits the treatment of the system properties for the whole range of the interaction strength, from zero to infinity, as well as for arbitrarily strong disorder. Besides a condensate and superfluid density, a glassy number density due to a spatially inhomogeneous component of the condensate occurs. For very weak interactions and sufficiently strong disorder, the superfluid fraction can become smaller than the condensate fraction, while at relatively strong interactions, the superfluid fraction is larger than the condensate fraction for any strength of disorder. The condensate and superfluid fractions, and the glassy fraction always coexist, being together either nonzero or zero. In the presence of disorder, the condensate fraction becomes a nonmonotonic function of the interaction strength, displaying an antidepletion effect caused by the competition between the stabilizing role of the atomic interaction and the destabilizing role of the disorder. With increasing disorder, the condensate and superfluid fractions jump to zero at a critical value of the disorder parameter by a first-order phase transition. ", "machine_text": "  We study a dilute gas of ultracold atoms in a shallow potential with a random component of strength $\\Delta\\sim\\sqrt{g/\\Phi}$, where $g$ is the depth of the shallow potential and $\\Phi$ is the thermal potential. We show that the system is unstable against a phase transition to a Bose-Einstein condensate (BEC) in a random potential of strength $\\Delta$. The transition is driven by a jump in the mean-square displacement of the atoms, which becomes infinite when $\\Delta\\geq g/\\Phi$. The dependence of the transition on the parameters of the system is discussed. We also show that the contact time $\\tau_{\\rm contact}$, which is the time that a given atom spends in contact with other atoms in a finite size system, has a universal scaling behavior. The only parameter that affects $\\tau_{\\rm contact}$ is the thermal length $\\Delta\\ll \\lambda$. We find that $\\tau_{\\rm contact}$ is inversely proportional to the system size $L$, and directly proportional to the thermal length $\\Delta$. Our results suggest that $\\tau_{\\rm contact}$ may be used as a probe of the system dynamics in a shallow potential with a random component.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Recursive calculation of effective resistances in distance-regular   networks based on Bose-Mesner algebra and Christoffel-Darboux identity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.248, "human_text": "  Recently in \\cite{jss1}, the authors have given a method for calculation of the effective resistance (resistance distance) on distance-regular networks, where the calculation was based on stratification introduced in \\cite{js} and Stieltjes transform of the spectral distribution (Stieltjes function) associated with the network. Also, in Ref. \\cite{jss1} it has been shown that the resistance distances between a node $\\alpha$ and all nodes $\\beta$ belonging to the same stratum with respect to the $\\alpha$ ($R_{\\alpha\\beta^{(i)}}$, $\\beta$ belonging to the $i$-th stratum with respect to the $\\alpha$) are the same. In this work, an algorithm for recursive calculation of the resistance distances in an arbitrary distance-regular resistor network is provided, where the derivation of the algorithm is based on the Bose-Mesner algebra, stratification of the network, spectral techniques and Christoffel-Darboux identity. It is shown that the effective resistance on a distance-regular network is an strictly increasing function of the shortest path distance defined on the network. In the other words, the two-point resistance $R_{\\alpha\\beta^{(m+1)}}$ is strictly larger than $R_{\\alpha\\beta^{(m)}}$. The link between the resistance distance and random walks on distance-regular networks is discussed, where the average commute time (CT) and its square root (called Euclidean commute time (ECT)) as a distance are related to the effective resistance. Finally, for some important examples of finite distance- regular networks, the resistance distances are calculated.   {\\bf Keywords: resistance distance, association scheme, stratification, distance-regular networks, Christoffel-Darboux identity}   {\\bf PACs Index: 01.55.+b, 02.10.Yn} ", "machine_text": "  We propose a new recursive algorithm for calculating the effective resistance of distance-regular networks based on the Bose-Mesner algebra and the Christoffel-Darboux identity. The proposed algorithm is simple and can be easily implemented. The proposed algorithm is exact and does not introduce any additional error into the effective resistance calculation. The proposed algorithm can be used to calculate the effective resistance of distance-regular networks with a large number of nodes and links. The proposed algorithm is based on the idea of iteratively calculating the effective resistance of the network by summing up the effective resistances of the smaller sub-networks. The calculation of the effective resistance of a network can be divided into two steps: (1) calculation of the effective resistances of the sub-networks and (2) calculation of the effective resistance of the whole network by adding up the effective resistances of the sub-networks. We propose a recursive algorithm for calculating the effective resistance of the sub-networks. The proposed algorithm is based on the Bose-Mesner algebra and the Christoffel-Darboux identity. The Bose-Mesner algebra is a useful tool for calculating the effective resistance of distance-regular networks. The Christoffel-Darboux identity is a useful tool forcalculating the effective resistance of distance-regular networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Keck spectroscopy and Spitzer Space Telescope analysis of the outer disk   of the Triangulum Spiral Galaxy M33. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.027, "human_text": "  In an earlier study of the spiral galaxy M33, we photometrically identified arcs or outer spiral arms of intermediate age (0.6 Gyr - 2 Gyr) carbon stars precisely at the commencement of the HI-warp. Stars in the arcs were unresolved, but were likely thermally-pulsing asymptotic giant branch carbon stars. Here we present Keck I spectroscopy of seven intrinsically bright and red target stars in the outer, northern arc in M33. The target stars have estimated visual magnitudes as faint as V \\sim 25 mag. Absorption bands of CN are seen in all seven spectra reported here, confirming their carbon star status. In addition, we present Keck II spectra of a small area 0.5 degree away from the centre of M33; the target stars there are also identified as carbon stars. We also study the non-stellar PAH dust morphology of M33 secured using IRAC on board the Spitzer Space Telescope. The Spitzer 8 micron image attests to a change of spiral phase at the start of the HI warp. The Keck spectra confirm that carbon stars may safely be identified on the basis of their red J-K_s colours in the outer, low metallicity disk of M33. We propose that the enhanced number of carbon stars in the outer arms are an indicator of recent star formation, fueled by gas accretion from the HI-warp reservoir. ", "machine_text": "  We present a Keck spectroscopy and Spitzer Space Telescope analysis of the outer disk of the Triangulum Spiral Galaxy M33. We aim to investigate the disk structure and kinematics, and the properties of the disk star formation. We find that the disk is warped and the warp is almost certainly the result of a density wave created by the massive inner disk. The radially-integrated star formation density is a factor of two higher in the high-density edge of the warp than in the interior of the disk, indicating that the warp triggers additional star formation. We also find a clear signature of the disk accretion shock at the inner boundary of the high-density edge of the warp. Using the Spitzer data we determine the stellar mass of the disk, which is a factor of four lower than found from optical observations. We discuss this in the context of recent results suggesting that the baryonic mass of the disk is a factor of two lower than the stellar mass. We propose that the baryonic mass is dominated by cold gas, which is tightly coupled to the stars. The lower stellar mass could either be due to a lower gas fraction in the outer disk, or to a lower efficiency of the star formation process.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Asymmetric superconductivity in metallic systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1201, "human_text": "  Different types of superfluid ground states have been investigated in systems of two species of fermions with Fermi surfaces that do not match. This study is relevant for cold atomic systems, condensed matter physics and quark matter. In this paper we consider this problem in the case the fermionic quasi-particles can transmute into one another and only their total number is conserved. We use a BCS approximation to study superconductivity in two-band metallic systems with inter and intra-band interactions. Tuning the hybridization between the bands varies the mismatch of the Fermi surfaces and produces different instabilities. For inter-band attractive interactions we find a first order normal-superconductor and a homogeneous metastable phase with gapless excitations. In the case of intra-band interactions, the transition from the superconductor to the normal state as hybridization increases is continuous and associated with a quantum critical point. The case when both interactions are present is also considered. ", "machine_text": " We have developed a microscopic theory of asymmetric superconductivity in metallic systems, which are capable of supporting both a normal conducting state and a superconducting state at different temperatures. The theory describes the temperature dependence of the superconducting transition temperature, the superconducting gap and the density of states in a wide range of metallic systems, including heavy fermion and organic superconductor materials. The theory is based on a simple microscopic model, which is capable of describing the essential features of the superconductivity in these materials, including the finite temperature dependent transition temperature, the finite superconducting gap and the density of states with very broad states. The model successfully predicts the temperature dependence of these quantities in a wide range of metallic superconductors, including the well studied heavy fermion superconductors and the less well studied organic superconductors. The successful prediction of the temperature dependence of the superconducting properties in these materials, which was not possible within the framework of the conventional theory of superconductivity, is an important example of the fruitful application of the renormalization group approach to the theory of superconductivity. The theory also suggests a possible mechanism of the formation of the large scale superconducting order, which is based on the collective motion of the charge carriers on the elementary bonds.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gravitational waves from galaxy encounters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3009, "human_text": "  We discuss the emission of gravitational radiation produced in encounters of dark matter galactic halos. To this aim we perform a number of numerical simulations of typical galaxy mergers, computing the associated gravitational radiation waveforms as well as the energy released in the processes. Our simulations yield dimensionless gravitational wave amplitudes of the order of $10^{-13}$ and gravitational wave frequencies of the order of $10^{-16}$ Hz, when the galaxies are located at a distance of 10 Mpc. These values are of the same order as those arising in the gravitational radiation originated by strong variations of the gravitational field in the early Universe, and therefore, such gravitational waves cannot be directly observed by ground-based detectors. We discuss the feasibility of an indirect detection by means of the B-mode polarization of the Cosmic Microwave Background (CMB) induced by such waves. Our results show that the gravitational waves from encounters of dark matter galactic halos leave much too small an imprint on the CMB polarization to be actually observed with ongoing and future missions. ", "machine_text": "  We consider the detection of gravitational waves from a dominant population of massive black holes in galactic nuclei, driven by the galactic tidal forces from encounters between galaxies in the local group. We show that a burst of gravitational waves, with a moment magnitude of $M_{GW} \\sim 10^{-10}$, could be detected by advanced LIGO interferometers if the black holes are close enough to the galaxies' centers. We derive an expression for the characteristic frequency of the gravitational waves, $f_{GW} \\sim M_{black hole}/R_{galactic center}$, where $M_{black hole}$ is the mass of the black hole and $R_{galactic center}$ is the radius of the host galaxy. The expected gravitational waves from the galactic nuclei would have a frequency of  \u223c 10 Hz, and would be much stronger than the background noise of LIGO interferometers. Thus, we would be able to detect such gravitational waves without advanced LIGO, and to observe the bursts of gravitational waves from the galactic nuclei would be a unique opportunity to study the properties of massive black holes.  We have proposed a new method to detect and observe the gravitational waves from the galactic nuclei. In our method, we detect the signal by searching for a burst of gravitational waves, and then we observe the properties of the gravitational waves by measuring the frequency, amplitude and power of the signal. We show that our method is feasible with the current technology of LIGO interferometers.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A very massive runaway star from Cygnus OB2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0676, "human_text": "  Aims: We analyze the available information on the star BD+43 3654 to investigate the possibility that it may have had its origin in the massive OB association Cygnus OB2.   Methods: We present new spectroscopic observations allowing a reliable spectral classification of the star, and discuss existing MSX observations of its associated bow shock and astrometric information not previously studied.   Results: Our observations reveal that BD+43 3654 is a very early and luminous star of spectral type O4If, with an estimated mass of (70 +/- 15) solar masses and an age of about 1.6 Myr. The high spatial resolution of the MSX observations allows us to determine its direction of motion in the plane of the sky by means of the symmetry axis of the well-defined bow shock, which matches well the orientation expected from the proper motion. Tracing back its path across the sky we find that BD+43 3654 was located near the central, densest region of Cygnus OB2 at a time in the past similar to its estimated age.   Conclusions: BD+43 3654 turns out to be one of the three most massive runaway stars known, and it most likely formed in the central region of Cygnus OB2. A runaway formation mechanism by means of dynamical ejection is consistent with our results. ", "machine_text": "  A very massive runaway star from Cygnus OB2  We present observations of a very massive runaway star from Cygnus OB2. The star was observed in 2015 with the Gaia space telescope and was found to have a proper motion of about 1.7 arcseconds per year, which is unusually high for a star in the local molecular cloud. Follow-up observations with the Hubble space telescope have shown that the star is moving away from the molecular cloud at a velocity of about 20 km/s. We estimate that the star must have had a mass of about 20 M\u2299 when it was born, and it has now lost about 5 M\u2299 due to its runaway motion. This is the most massive runaway star observed so far. The high velocity of the star means that it has a large peculiar motion with respect to the local standard of rest. We show that this peculiar motion is likely to be due to the influence of the global molecular cloud. The massive runaway star could have originated in the Cygnus OB2 association, but it is now moving out of the association and will soon be unaffiliated.   The motivation for the research was to study massive runaway stars in order to better understand the process of massive star formation. The key ideas and methodology used were to observe the proper motion of a large sample of massive stars in the Cygnus OB2 association, and to determine the kinematic properties of those stars. The results obtained were that one of the stars in the sample had a very high proper motion, indicating that it was a runaway star. The problem that this work attempts to solve is the question of how massive stars are formed and how they evolve. The practical application of this work is that it helps us to understand the origin and evolution of massive stars, which are the most massive objects in the universe and have a profound influence on the evolution of the universe. The theoretical application of this work is that it provides new data that can be used to test theories of massive star formation and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On global solution to the Klein-Gordon-Hartree equation below energy   space. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1866, "human_text": "  In this paper, we consider the Cauchy problem for Klein-Gordon equation with a cubic convolution nonlinearity in $\\R^3$. By making use of Bourgain's method in conjunction with a precise Strichartz estimate of S.Klainerman and D.Tataru, we establish the $H^s (s<1)$ global well-posedness of the Cauchy problem for the cubic convolution defocusing Klein-Gordon-Hartree equation. Before arriving at the previously discussed conclusion, we obtain global solution for this non-scaling equation with small initial data in $H^{s_0}\\times H^{s_0-1}$ where $s_0=\\frac\\gamma 6$ but not $\\frac\\gamma2-1$, for this equation that we consider is a subconformal equation in some sense. In doing so a number of nonlinear prior estimates are already established by using Bony's decomposition, flexibility of Klein-Gordon admissible pairs which are slightly different from that of wave equation and a commutator estimate. We establish this commutator estimate by exploiting cancellation property and utilizing Coifman and Meyer multilinear multiplier theorem. As far as we know, it seems that this is the first result on low regularity for this Klein-Gordon-Hartree equation. ", "machine_text": " We consider a solution to the Klein-Gordon-Hartree equation in energy space for a single massive point-particle in a potential field. In particular we assume that the solution has a singularity at the origin and that the total energy is bounded below. We show that the solution must have the form of aCosW(z)e\u00afZW(z) \u2261 (e\u00afW/z) CosW(z), where W(z) is a transcendental function and e\u00afW \u2261 e\u00afz/z is the inverse function of W(z). The result is exact for any choice of W(z) and has a simple physical interpretation in terms of an oscillating motion of the point-particle in the potential field. We show that the solution is well-defined for a large class of W(z), but that it may fail to exist for some choices of W(z). We also show that the solution is unique in a certain class of W(z), but that it may be non-unique for some choices of W(z). We finally consider the solution to the Klein-Gordon-Hartree equation below the singularity at the origin. We show that this solution is in general non-unique, but that it can be made unique by requiring that the solution is analytic in a neighbourhood of the origin.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optical investigations of quantum-dot spin dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3557, "human_text": "  We have performed all-optical measurements of spin relaxation in single self-assembled InAs/GaAs quantum dots (QD) as a function of static external electric and magnetic fields. To study QD spin dynamics we measure the degree of resonant absorption which results from a competition between optical spin pumping induced by the resonant laser field and spin relaxation induced by reservoirs. Fundamental interactions that determine spin dynamics in QDs are hyperfine coupling to QD nuclear spin ensembles, spin-phonon coupling and exchange-type interactions with a nearby Fermi sea of electrons. We show that the strength of spin relaxation generated by the three fundamental interactions can be changed by up to five orders of magnitude upon varying the applied electric and magnetic fields. We find that the strength of optical spin pumping that we use to study the spin relaxation is determined predominantly by hyperfine-induced mixing of single-electron spin states at low magnetic fields and heavy-light hole mixing at high magnetic fields. Our measurements allow us to determine the rms value of the hyperfine (Overhauser) field to be ~15 mTesla with an electron g-factor of g_e=0.6 and a hole mixing strength of |epsilon|^2 = 0.0005. ", "machine_text": " We report on a series of optical investigations of quantum-dot spin dynamics. We show that, by using a combination of different experimental techniques, it is possible to gain a profound understanding of the elementary processes that govern the dynamics of single spins in semiconductor quantum dots. Our approach is based on a detailed analysis of the optical responses of single spins in a quantum dot, as a function of an external magnetic field, a laser pulse sequence, or a combination of both. We demonstrate a clear signature of single-spin dynamics in the optical response of a quantum dot, even in the presence of a large number of spins in the quantum dot. We show that by using different experimental techniques it is possible to elucidate the mechanism of light-driven spin dynamics in quantum dots, and to distinguish between different theoretical models. Our results are relevant for the realization of spin-based quantum information processing and quantum communication protocols using semiconductor spins in quantum dots.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Radio Spectral Evolution of an X-ray Poor Impulsive Solar Flare:   Implications for Plasma Heating and Electron Acceleration. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2413, "human_text": "  We present radio and X-ray observations of an impulsive solar flare that was moderately intense in microwaves, yet showed very meager EUV and X-ray emission. The flare occurred on 2001 Oct 24 and was well-observed at radio wavelengths by the Nobeyama Radioheliograph (NoRH), the Nobeyama Radio Polarimeters (NoRP), and by the Owens Valley Solar Array (OVSA). It was also observed in EUV and X-ray wavelength bands by the TRACE, GOES, and Yohkoh satellites. We find that the impulsive onset of the radio emission is progressively delayed with increasing frequency relative to the onset of hard X-ray emission. In contrast, the time of flux density maximum is progressively delayed with decreasing frequency. The decay phase is independent of radio frequency. The simple source morphology and the excellent spectral coverage at radio wavelengths allowed us to employ a nonlinear chi-squared minimization scheme to fit the time series of radio spectra to a source model that accounts for the observed radio emission in terms of gyrosynchrotron radiation from MeV-energy electrons in a relatively dense thermal plasma. We discuss plasma heating and electron acceleration in view of the parametric trends implied by the model fitting. We suggest that stochastic acceleration likely plays a role in accelerating the radio-emitting electrons. ", "machine_text": " We present a study of the evolution of the radio spectral and temporal structure of a large impulsive solar flare, which was observed on 2017 February 14. The radio emission in this flare is dominated by a number of small-scale impulsive transients, which exhibit extremely fast evolution in both spectral and temporal domains. Our analysis reveals that the transient sources maintain their identity in the radio sky over the course of the flare, with their locations shifting only by a few tens of kilometers. We find that the spectral and temporal evolutions of these transient sources can be described by a simple model in which a small-scale impulsive phase is followed by a large-scale slowly-decaying phase. The initial impulsive phase of each transient has a duration of about one minute, during which the radio flux density increases rapidly from a few Jy to about 100 Jy, and then decreases with a time constant of about 30 seconds. The large-scale phase exhibits a steady decay of the radio flux density with a time constant of about 1800 seconds. We estimate the size of the emitting region to be about 10 \u2212 100 km across. Our results suggest that small-scale impulsive processes can produce large-scale slowly-decaying radio emissions in solar flares, and the combination of these two types of processes can explain the diversity of radio spectral and temporal structures observed in solar flares.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Can We Detect the Anisotropic Shapes of Quasar HII Regions During   Reionization Through The Small-Scale Redshifted 21cm Power Spectrum?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0981, "human_text": "  Light travel time delays distort the apparent shapes of HII regions surrounding bright quasars during early stages of cosmic reionization. Individual HII regions may remain undetectable in forthcoming redshifted 21 cm experiments. However, the systematic deformation along the line of sight may be detectable statistically, either by stacking tomographic 21cm images of quasars identified, for example, by JWST, or as small-scale anisotropy in the three-dimensional 21cm power spectrum. Here we consider the detectability of this effect. The anisotropy is largest when HII regions are large and expand rapidly, and we find that if bright quasars contributed to the early stages of reionization, then they can produce significant anisotropy, on scales comparable to the typical sizes of HII regions of the bright quasars (approx. 30 Mpc and below). The effect therefore cannot be ignored when analyzing future 21cm power spectra on small scales. If 10 percent of the volume of the IGM at redshift z=10 is ionized by quasars with typical ionizing luminosity of S= 5 x 10^{56} photons/second, the distortions can enhance by more than 10 percent the 21cm power spectrum in the radial (redshift) direction, relative to the transverse directions. The level of this anisotropy exceeds that due to redshift-space distortion, and has the opposite sign. We show that on-going experiments such as MWA should be able to detect this effect. A detection would reveal the presence of bright quasars, and shed light on the ionizing yield and age of the ionizing sources, and the distribution and small-scale clumping of neutral intergalactic gas in their vicinity. ", "machine_text": " We present a study of the small-scale structure of the 21 cm power spectrum of the intergalactic medium, based on an analysis of the data obtained with the Low Frequency Array (LOFAR) telescope. We find that the power spectrum is well described by a two- parameter model, with a cut-off scale of approximately 5-10 Mpc and a power law index of -1.7 \u00b1 0.2. The quality of the fit is improved when a small contribution from a broad component with a power law index of -0.4 \u00b1 0.2 is included. The best-fit parameters are consistent with the small-scale structure being due to turbulence, with a correlation length of approximately 5-10 Mpc. The small contribution from the broad component could be a signature of large-scale flows with a correlation length of approximately 100 Mpc. We show that the data are consistent with the presence of a single power law index in the range of redshifts investigated, despite the large variation in the density of the intergalactic medium. The best-fit model has a correlation length that decreases with increasing redshift, which is consistent with a picture where the turbulence is driven by the evolution of the large-scale structure and the growth of supermassive black holes. We discuss the prospects of using the 21 cm power spectrum to detect the anisotropic shapes of quasar H II regions during reionization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Towards Informative Statistical Flow Inversion. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1939, "human_text": "  A problem which has recently attracted research attention is that of estimating the distribution of flow sizes in internet traffic. On high traffic links it is sometimes impossible to record every packet. Researchers have approached the problem of estimating flow lengths from sampled packet data in two separate ways. Firstly, different sampling methodologies can be tried to more accurately measure the desired system parameters. One such method is the sample-and-hold method where, if a packet is sampled, all subsequent packets in that flow are sampled. Secondly, statistical methods can be used to ``invert'' the sampled data and produce an estimate of flow lengths from a sample.   In this paper we propose, implement and test two variants on the sample-and-hold method. In addition we show how the sample-and-hold method can be inverted to get an estimation of the genuine distribution of flow sizes. Experiments are carried out on real network traces to compare standard packet sampling with three variants of sample-and-hold. The methods are compared for their ability to reconstruct the genuine distribution of flow sizes in the traffic. ", "machine_text": "  We propose a new methodology for statistical flow inversion that is both mathematically rigorous and practically applicable. The key idea is to recast the statistical flow inversion problem as a constrained optimization problem, with the constraint being the equality of the number of arrivals at the sensors and the number of molecules in the flow. We show that under suitable regularity conditions on the flow, this optimization problem can be solved in a closed form. The resulting solution is a generalization of the familiarLegendre-Fenchel transform to the statistical flow inversion problem. This solution provides a rigorous justification for the commonly used techniques of singular value decomposition and QR decomposition in statistical flow inversion. The proposed methodology is applied to several examples, including the problem of determining the size distribution of particles in a flow from an image of the flow, and the problem of identifying the sources of a flow from the distribution of arrivals at a set of sensors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electronic structure of BaFeO3: an abinitio DFT study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2985, "human_text": "  First principles calculations were performed to study the ground state electronic properties of BaFeO3 (BFO) within the density functional theory (DFT). Adopting generalized gradient approximation (GGA) exchange and correlation functional and Vosko-Wilk-Nusair correlation energy functional interpolation, we have systematically conducted the band structure, density of states and electronic distribution along different crystalline planes. Calculating results show that band gap in the majority spin band structure and band gap in the minority spin band structure were found to be 2.7012 eV and 0.6867 eV respectively. Up-spin Fe t2g were fully occupied and down-spin Fe eg were empty. Moreover, the up-spin Fe eg and down-spin Fe t2g were partially occupied near the Fermi energy, leading to a finite density of states. The Fe4+-O-Fe4+ plane superexchange coupling should rearrange the magnetic order to make the ferromagnetic characteristic being possible, moreover the tetragonal displacement along the c axis could induce the perovskites materials to acquire ferroelectric property. These reasons could lead to the fact that the tetragonal phase BFO could be a potential multiferroics while it was produced under the very experimental conditions. The charge density along different crystalline planes were illustrated to show that strong covalent bonding between O and Fe can be used to investigate the exchange coupling, and this strong hybridization may further increase the superexchange coupling to enhance the magnetic ordering. ", "machine_text": " We present an ab initio density functional theory (DFT) study of the electronic structure of the perovskite superconductor BaFeO3. The electronic structure is investigated in the framework of the generalized gradient approximation (GGA). The results show that the electronic and magnetic properties of this material are governed by the Fe 3+ moments. We find a strong spin-orbit coupling (SOC) with a large orbital moment of the order of magnitude of the total magnetic moment. This large SOC couples the magnetic and electronic degrees of freedom, which are responsible for the unconventional superconducting behavior of this compound. We also found the existence of a very large two-particle singlet pairing amplitude, which is equally important for the superconductivity. We show that this large pairing amplitude can be explained by a strong three-dimensional lattice distortion in the charge density. Our results are consistent with the idea that the pairing amplitude is enhanced by a large spatial extent of the charge transfer from the Fe 3+ to the O 2\u2212 .", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Spitzer c2d Survey of Weak-line T Tauri Stars II: New Constraints on   the Timescale for Planet Building. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0563, "human_text": "  One of the central goals of the Spitzer Legacy Project ``From Molecular Cores to Planet-forming Disks'' (c2d) is to determine the frequency of remnant circumstellar disks around weak-line T Tauri stars (wTTs) and to study the properties and evolutionary status of these disks. Here we present a census of disks for a sample of over 230 spectroscopically identified wTTs located in the c2d IRAC (3.6, 4.5, 4.8, and 8.0 um) and MIPS (24 um) maps of the Ophiuchus, Lupus, and Perseus Molecular Clouds. We find that ~20% of the wTTs in a magnitude limited subsample have noticeable IR-excesses at IRAC wavelengths indicating the presence of a circumstellar disk. The disk frequencies we find in these 3 regions are ~3-6 times larger than that recently found for a sample of 83 relatively isolated wTTs located, for the most part, outside the highest extinction regions covered by the c2d IRAC and MIPS maps. The disk fractions we find are more consistent with those obtained in recent Spitzer studies of wTTs in young clusters such as IC 348 and Tr 37. From their location in the H-R diagram, we find that, in our sample, the wTTs with excesses are among the younger part of the age distribution. Still, up to ~50% of the apparently youngest stars in the sample show no evidence of IR excess, suggesting that the circumstellar disks of a sizable fraction of pre-main-sequence stars dissipate in a timescale of ~1 Myr. We also find that none of the stars in our sample apparently older than ~10 Myrs have detectable circumstellar disks at wavelengths < 24 um. Also, we find that the wTTs disks in our sample exhibit a wide range of properties (SED morphology, inner radius, L_DISK/L*, etc) which bridge the gaps observed between the cTTs and the debris disk regimes. ", "machine_text": "  We present the latest catalog of weak-line T Tauri stars (WTS) from the Spitzer c2d Survey. We find a total of 1251 WTS in the Survey area, 949 of which are new discoveries. We determine the radii of the disks for all the WTS in the catalog, and find that the median disk radius is 2.56 pc. The derived disk masses are in good agreement with the masses found in the literature for similar stars. We find a correlation between the disk radius and the disk mass, which we use to derive the relation between the two quantities. We find that the variation in the disk mass is large, even for stars with disks of similar radii. The observed correlation between disk radius and disk mass is likely to be a selection effect, with the more massive disks being larger simply because they are more evolved. We find that about half of the disks in the Survey are massive enough to have achieved the Roche limit, and that a large fraction of massive disks are likely to have evolved into close-in Jupiters. We discuss the implications of our findings for planet formation models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Equivalence principle and electromagnetic field: no birefringence, no   dilaton, and no axion. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3422, "human_text": "  The coupling of the electromagnetic field to gravity is discussed. In the premetric axiomatic approach based on the experimentally well established conservation laws of electric charge and magnetic flux, the Maxwell equations are the same irrespective of the presence or absence of gravity. In this sense, one can say that the charge \"substratum\" and the flux \"substratum\" are not influenced by the gravitational field directly. However, the interrelation between these fundamental substrata, formalized as the {\\it spacetime relation} H=H(F) between the 2-forms of the electromagnetic excitation H and the electromagnetic field strength F, is affected by gravity. Thus the validity of the equivalence principle for electromagnetism depends on the form of the spacetime relation. We discuss the nonlocal and local linear constitutive relations and demonstrate that the spacetime metric can be accompanied also by skewon, dilaton, and axion fields. All these premetric companions of the metric may eventually lead to a violation of the equivalence principle. ", "machine_text": "  We reexamine the classical equivalence principle in the light of the recent observations of the cosmic microwave background anisotropy and the accelerating expansion of the Universe. After reviewing the various explanations that have been proposed to account for the observed anisotropy, we show that the simplest explanation that is consistent with the equivalence principle is a cosmological model in which the energy density of the universe is everywhere the same, but the pressure is not. We show that such a model can be made to be consistent with the observed anisotropy, without the introduction of ad-hoc birefringent scalar fields. In the framework of such a model the anisotropic stress can be related to the one-way motion of gravity waves, thus providing a possible physical explanation for the observed anisotropy. We also show that the introduction of a dilaton scalar field is not necessary in order to explain the behavior of the universe, and that a universe without a dilaton can be described by a consistent theory. We further show that a universe without an axion can be described by a consistent theory. The model we propose is a form of Madelung's universe, in which the anisotropic stress is related to the one-way motion of gravity waves. We show that such a model is consistent with the observed anisotropy, without the introduction of ad-hoc birefringent scalar fields. In the framework of such a model the anisotropic stress can be related to the one-way motion of gravity waves, thus providing a possible physical explanation for the observed anisotropy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Forced accretion in stochastically fed AGN and quasars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1686, "human_text": "  Steady state accretion discs larger than ~ 0.01-0.1 pc are known to be gravitationally unstable for the accretion rates needed to explain super-massive black hole (SMBH) activity. We propose that SMBH are fed by a succession of mass deposition events with randomly directed angular momenta. Because of incomplete angular momentum cancellation a warped accretion disc forms in the inner few parsec. The orientation of the disc performs a random walk. Deposition of new material promotes SMBH accretion at rates much faster than viscous. Observational implications of this picture include: (i) lighter accretion discs that can fuel AGN and quasars and yet avoid star formation at R >> 0.1 pc; (ii) star formation inside the disc is not a function of mass accretion rate only. It can take place at high or low accretion rates, e.g., when too few clouds arrive in the inner region. An example of this might be the central parsec of our Galaxy. (iii) The discs can form Compton-thick obscuring structures of ~ parsec size as required in AGN unification models; (iv) faster black hole growth resulting from misalignment of the disc and the black hole spin in the early Universe; (v) Isotropic deposition of SMBH energy and momentum feedback in the galaxy bulge. This may help explain the high efficiency with which it seems to be operating in the Universe. (vi) No correlation between SMBH activity and the presence of kiloparsec scale bars or gaseous discs in galactic bulges; (vii) Bodily collisions between gaseous components of merging galaxies facilitate production of gas streams feeding the centre of the combined galaxy. Mergers should thus be catalysts of SMBH growth. (viii) Conversely, galaxies experiencing fewer mergers are more likely to form massive nuclear star clusters than feed their SMBHs. ", "machine_text": " Forced accretion in stochastically fed AGN and quasars  We present a model of forced accretion in stochastically fed active galactic nuclei (AGN) and quasars. Our goal is to investigate the role of stochasticity in the regulation of accretion, and to explain the puzzling diversity in the accretion rate of AGN and quasars. We find that this goal can be achieved by a model in which the accretion rate is anomalously regulated by a noise source in the inner accretion flow. The model can produce the full range of observed accretion rates, from \"quiescence\" to \" outburst\", while preserving the fundamental virial theorem of black hole accretion. We also show that the model can explain the observed phenomenology of the accretion process, such as the size-luminosity and size- Mass relationships, and the cut-off at very low accretion rates. The model has several interesting and non-trivial steady state solutions, and these can be used to derive physical constraints on the underlying physical mechanism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Super Low Traction under EHD and Mixed Lubrication Regimes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1799, "human_text": "  After the pioneered experimental works on superlubricity by Martin et al. on MoS2 [1], Hirano et al. on tungsten and silicon [2] and the further confirmation by Dienwiebel et al. on graphite [3], many groups around the word investigated the occurrence of near frictionless sliding contacts. This large mobilization of tribologists, material sciences specialists and physicists has lead to emerging solutions involving new materials and coatings, the most promising being carbon based like graphite, diamond, carbon composites or diamond-like-carbons. Some of them are currently used in practical applications. The situation is different especially in EHL: the highest friction coefficients are close to 10% when traction fluids are involved, i.e. fluids that have especially designed to transmit the highest friction, and they vary within 3-6% for the rest of lubricants. The range of variation is consequently very narrow and these typical values are really low compared to those obtained in dry contacts: as a consequence the gain expected from a super low traction regime in lubrication will be probably more limited, especially in the case of experiments conducted at the meso or macro scales. This weak perspective could be one explanation on the relatively low number of articles in recent literature dealing with lubricated superlubricity in the above conditions. ", "machine_text": "  We investigate the effect of electric field (EHD) on the traction properties of liquid lubricants in the superlow traction regime and mixed lubrication regime. We use the flexible multinational bearing experiment to obtain the traction curves of several lubricants in the superlow traction and mixed lubrication regimes. The traction curves exhibit a strong non-monotonic dependence on the EHD strength, which can be explained by the change of the molecular mechanic properties of the lubricants under EHD. We find that the ability of a lubricant to form a film on the surface of the counterpart is the key to the change of the traction properties in the mixed lubrication regime, while the increase of the friction under a higher EHD strength is due to the increasing non-Newtonian behavior of the lubricant in the superlow traction regime. Our work can help understand the change of the traction properties of liquid lubricants under EHD and provide guidance to design EHD-lubricated tribo-systems with superlow traction and/or mixed lubrication regimes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Optimal Algorithm to Generate Pointed Trivalent Diagrams and Pointed   Triangular Maps. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0969, "human_text": "  A trivalent diagram is a connected, two-colored bipartite graph (parallel edges allowed but not loops) such that every black vertex is of degree 1 or 3 and every white vertex is of degree 1 or 2, with a cyclic order imposed on every set of edges incident to to a same vertex. A rooted trivalent diagram is a trivalent diagram with a distinguished edge, its root. We shall describe and analyze an algorithm giving an exhaustive list of rooted trivalent diagrams of a given size (number of edges), the list being non-redundant in that no two diagrams of the list are isomorphic. The algorithm will be shown to have optimal performance in that the time necessary to generate a diagram will be seen to be bounded in the amortized sense, the bound being independent of the size of the diagrams. That's what we call the CAT property. One objective of the paper is to provide a reusable theoretical framework for algorithms generating exhaustive lists of complex combinatorial structures with attention paid to the case of unlabeled structures and to those generators having the CAT property. ", "machine_text": "  We present a simple optimal algorithm for generating pointed trivalent diagrams and pointed triangular maps. The input to the algorithm is a set of points in general position in the plane, and the output is a minimum set of lines connecting the points in general position so that the lines form a pointed trivalent diagram (i.e., so that no three lines intersect in a single point). We prove that the output of our algorithm is always a pointed trivalent diagram, and that it is the minimum possible set of lines connecting the points that will form a pointed trivalent diagram. Our algorithm is based on a new connection between the problem of generating pointed trivalent diagrams and the problem of generating pointed triangular maps, which we term the \" triangle transform.\" The triangle transform provides a simple method for reducing the problem of generating pointed trivalent diagrams to the problem of generating pointed triangular maps, for which there is a simple optimal algorithm. Our results yield a simple optimal algorithm for generating pointed trivalent diagrams, as well as a simple proof that the algorithm is optimal.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Waves and instabilities in dissipative rotating superfluid neutron stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0672, "human_text": "  We discuss wave propagation in rotating superfluid neutron star cores, taking into account the vortex mediated mutual friction force. For models where the two fluids co-rotate in the unperturbed state, our analysis clarifies the role of chemical coupling and entrainment for sound and inertial waves. We also investigate the mutual friction damping, providing results that demonstrate the well-known fact that sound waves propagating along a vortex array are undamped. We show that the same is not true for inertial waves, which are damped by the mutual friction regardless of the propagation direction. We then include the vortex tension, which arises due to local vortex curvature. Focussing on purely transverse inertial waves, we derive the small correction that the tension induces in the wave frequency. Finally, we allow for a relative linear flow in the background (along the rotation axis). In this case we show how the mutual friction coupling may induce a dynamical instability in the inertial waves. We discuss the critical flow required for the instability to be present, its physical interpretation and the possible relevance it may have for neutron star physics. ", "machine_text": " We study the structure and dynamics of surface waves and related instabilities in dissipative rotating superfluid neutron stars. We consider both the hydrodynamic and the full-f fluid equations in the limit of small amplitude waves, and we analyze the different types of instabilities that may be excited by a small perturbation of the mean flow. We find that the fast waves ( whose speed of propagation is much larger than the inverse of the frequency) are very sensitive to the rotation of the star: they either break down into a large number of small waves or evolve into steady, large-scale waves with a frequency proportional to the rotation frequency. The slow waves ( whose speed of propagation is much smaller than the inverse of the frequency), on the other hand, are very stable against the presence of a rotating background, and they may be used to probe the interior of the star. We discuss the physical origins of our findings and we suggest that the slow waves may be used to probe the properties of the superfluid core of rotating neutron stars.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Meta-nematic transitions in a bilayer system: Application to the bilayer   ruthenate. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1069, "human_text": "  It was suggested that the two consecutive metamagnetic transitions and the large residual resistivity discovered in Sr$_3$Ru$_2$O$_7$ can be understood via the nematic order and its domains in a single layer system. However, a recently reported anisotropy between two longitudinal resistivities induced by tilting the magnetic field away from the c-axis cannot be explained within the single layer nematic picture. To fill the gap in our understanding within the nematic order scenario, we investigate the effects of bilayer coupling and in-plane magnetic field on the electronic nematic phases in a bilayer system. We propose that the in-plane magnetic field in the bilayer system modifies the energetics of the domain formation, since it breaks the degeneracy of two different nematic orientations. Thus the system reveals a pure nematic phase with a resistivity anisotropy in the presence of an in-plane magnetic field. In addition to the nematic phase, the bilayer coupling opens a novel route to a hidden nematic phase that preserves the x-y symmetry of the Fermi surfaces. ", "machine_text": " We have developed a microscopic theory of meta-nematic transitions in a bilayer system which consists of a nematic and a meta-nematic liquid layer. Our theory is based on the idea that a meta-nematic transition is induced by the change of the spontaneous polarisation of the dielectric layer. We calculate the polarisation P of the dielectric layer as a function of the director n of the nematic layer for a large number of constellations of the two layers. The results are consistent with the available experimental data. Our theory predicts a strong increase of P when the director n is equal to the easy axis of the dielectric layer. This effect is especially pronounced when the easy axis of the dielectric layer is parallel to the glass substrate. We also calculate the director n of the nematic layer as a function of P for a large number of constellations of the two layers. Our results suggest that the meta-nematic transition is first order. We discuss our results in the framework of a microscopic theory of the dielectric layer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: QCD in One Dimension at Nonzero Chemical Potential. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1111, "human_text": "  Using an integration formula recently derived by Conrey, Farmer and Zirnbauer, we calculate the expectation value of the phase factor of the fermion determinant for the staggered lattice QCD action in one dimension. We show that the chemical potential can be absorbed into the quark masses; the theory is in the same chiral symmetry class as QCD in three dimensions at zero chemical potential. In the limit of a large number of colors and fixed number of lattice points, chiral symmetry is broken spontaneously, and our results are in agreement with expressions based on a chiral Lagrangian. In this limit, the eigenvalues of the Dirac operator are correlated according to random matrix theory for QCD in three dimensions. The discontinuity of the chiral condensate is due to an alternative to the Banks-Casher formula recently discovered for QCD in four dimensions at nonzero chemical potential. The effect of temperature on the average phase factor is discussed in a schematic random matrix model. ", "machine_text": "  We study the consequences of a nonzero chemical potential for the structure and dynamics of the proton and lepton numbers in QCD in one dimension. We find that the nonzero chemical potential does not change the structure of the theory but leads to a slow evolution of the proton and lepton numbers which can be described by a single parameter. The evolution of this parameter is shown to be related to the evolution of the Heaven's algorithm for the recursive definition of the axiomatically defined weak flavor group $\\mathcal{W}$, and thus the theory is completely described by the dynamics of the single parameter. We show that this parameter can be related to the Jacobian of the non-Abelian Gauguin transform $\\dot\\mu^\\mu$ defined on the octet and quarkonia states, and thus is a measure of the dynamic symmetry of the theory. We discuss the difference of this approach from the conventional description of the nonzero chemical potential in QCD where the change in the proton and lepton numbers is related to the Killing generator of the unitary group $\\mathcal{U}$, and thus is a measure of the conserved Noetherian symmetry of the theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of random Boolean networks using the average sensitivity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0197, "human_text": "  In this work we consider random Boolean networks that provide a general model for genetic regulatory networks. We extend the analysis of James Lynch who was able to proof Kauffman's conjecture that in the ordered phase of random networks, the number of ineffective and freezing gates is large, where as in the disordered phase their number is small. Lynch proved the conjecture only for networks with connectivity two and non-uniform probabilities for the Boolean functions. We show how to apply the proof to networks with arbitrary connectivity $K$ and to random networks with biased Boolean functions. It turns out that in these cases Lynch's parameter $\\lambda$ is equivalent to the expectation of average sensitivity of the Boolean functions used to construct the network. Hence we can apply a known theorem for the expectation of the average sensitivity. In order to prove the results for networks with biased functions, we deduct the expectation of the average sensitivity when only functions with specific connectivity and specific bias are chosen at random. ", "machine_text": "  We introduce and analyze a new measure of random Boolean networks, the average sensitivity, which counts the number of nodes whose status can be determined (or detected) from the status of a single node. We show that the average sensitivity is a good measure of the complexity of the network. We also show that random Boolean networks with a small average sensitivity have a large number of non-trivial cliques, while the opposite is true for large average sensitivity networks. We analyze the average sensitivity of random Boolean networks with a given number of nodes and connections, and show that the probability distribution of the average sensitivity has several interesting properties. In particular, the distribution is shown to have a power law tail, which suggests that large random Boolean networks are scale-free. We show that this power law tail can be obtained by a simple model of random Boolean networks with a small number of connections per node, and that this model can be used to estimate the average sensitivity of large random Boolean networks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geometry of Time, Axiom of Choice and Neuro-Biological Quantum Zeno   Effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1054, "human_text": "  Role of axiom of choice in quantum measurement is highlighted by suggesting that the conscious observer chooses the outcome from a mixed state. Further, in a periodically repeating universe, these outcomes must be pre-recorded within the non-physical conscious observers, which precludes free will. Free will however exists in a universe with open time, It is suggested that psychology's binding problem is connected with Cantor's original definition of set. Influence of consciousness on material outcome through quantum processes is discussed and interesting constraints derived. For example, it is predicted that quantum mechanical brain states should get frozen if monitored at sufficiently small space-time intervals - a neuro-biological version of the so called quantum zeno effect, which has been verified in domain of micro-physics. Existence of a very small micro-mini-black-hole in brain is predicted as a space-time structural interface between consciousness and brain, whose vaporization explains mass-loss reported in weighing experiments, conducting during the moments of death. ", "machine_text": " We introduce a new axiom, the axiom of temporal choice, which together with the axioms of time and symmetry, provides a rigorous foundation for the geometry of time. The axiom of temporal choice enables one to define a temporal square root of a time-like interval. We show that this temporal square root satisfies the axioms of a metric space, and hence we have a metric space which is a model of the axioms of time, symmetry and temporal choice. This new metric space has a natural structure of \" timelines \" along which \" events \" occur. We show that these timelines are equivalent to the psychological and neuro-biological concept of \" time \". We also show that any \" time \" interval, as perceived by a conscious being, can be uniquely expressed as a \" sum \" of a \" finite \" number of \" infinitesimal \" time intervals, and that this structure is consistent with the psychological and neuro-biological concept of \" time \". We show that the structure of our metric space enables one to define a time-like \" boundary condition \" for an \" event \", which is the analog of the momentum-like boundary condition for a quantum particle. This boundary condition, together with the metric structure of time, gives rise to a \" quantum \" version of time-like intervals. We show that the temporal square root of a time-like interval plays the same role in the geometry of time as the square root of a momentum-like interval plays in the geometry of space. Finally, we show that the temporal square root of a time-like interval is related to the psychological and neuro-biological concept of a \" moment \", and that it is the basic \" quantum \" of time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Alignments of the Galaxy Spins with the Real-Space Tidal Field   Reconstructed from the Two Mass Redshift Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1412, "human_text": "  We report a direct observational evidence for the existence of the galaxy spin alignments with the real space tidal field. We calculate the real space tidal field from the real space density field reconstructed recently from the Two Mass Redshift Survey (2MRS) by Erdogdu et al. in 2006. Using a total of 12122 nearby spiral galaxies from the Tully Galaxy Catalog, we calculate the orientations of their spin axes relative to the 2MRS tidal field. We find a clear signal of the intrinsic correlations between the galaxy spins and the intermediate principal axes of the tidal shears. The null hypothesis of no correlation is rejected at 99.99 % confidence level. We also investigate the dependence of the intrinsic correlations on the galaxy morphological type and the environment. It is found that (i) the intrinsic correlation depends weakly on the morphological type of the spiral galaxies but tends to decrease slightly as the type increases; (ii) it is stronger in the high-density regions than in the low-density regions. The observational result is quantitatively consistent with analytic prediction based on the tidal torque theory. It is concluded that the galaxy spin orientations may provide in principle a new complimentary probe of the dark matter distribution. ", "machine_text": " We present a method to reconstruct the alignment of the spins of visible matter with the real-space tidal field in the presence of dark matter. We use the two-mass redshift survey to measure the redshift-space peculiar velocity field and a reconstruction method based on the Karhunen-Lo\u00e8ve (KL) transform to extract the real-space velocity field from the redshift-space velocity field. The reconstruction is performed in an oversimplified model where the dark matter is ignored and the visible matter is treated as a fluid. We find that the spins of the visible matter are aligned with the real-space tidal field, in agreement with the hypothesis that the visible matter was concentrated by the tidal field. We also find that the mean velocity of the visible matter is 5% higher than the bulk velocity of the fluid, suggesting that the visible matter is slightly out of equilibrium. The level of departure from equilibrium is consistent with the hypothesis that the visible matter is transported by large-scale structure, but is not well described by the standard models of structure formation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Composite Interstellar Grains. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.158, "human_text": "  The composite grain is made up of a host silicate spheroid and graphite inclusions. The extinction efficiencies of the composite spheroidal grains for three axial ratios are computed using the discrete dipole approximation (DDA). The interstellar extinction curve is evaluated in the spectral region 3.40--0.10$\\mu m$ using the extinction efficiencies of the composite spheroidal grains. The model extinction curves are then compared with the average observed interstellar extinction curve. We also calculate the linear polarization for the spheroidal composite grains at three orientation angles and find the wavelength of maximum polarization. Further, we estimate the volume extinction factor, an important parameter from the point of view of cosmic abundance, for the composite grain models that reproduce the average observed interstellar extinction. The estimated abundances derived from the composite grain models for both carbon and silicon are found to be lower than that are predicted by the bare silicate/graphite grain models but these values are still higher than that are implied from the recent ISM values. ", "machine_text": "  We present the results of a statistical study of the distribution of voids in interplanetary and interstellar grains, as a function of grain size. We find that the probability distribution of voids follows a power law, with a characteristic size of the order of the grain size. We discuss the implications of this result for the formation and evolution of dust aggregates in the interstellar medium, the interplanetary medium, and the atmosphere. We find that the statistics of voids can be used to identify the dominant formation mechanisms, and to evaluate the effects of these mechanisms on the aggregate size distribution.  We find that the statistics of voids are consistent with the formation of aggregates by the agglomeration of particles in a stagnant gas, provided that the particles are large enough to form a void around themselves. We find that the voids are more likely to be located at the centers of the particles, rather than at their boundaries, suggesting that the particles are more likely to be captured by the aggregates than to be ejected from them. We also find that the size distribution of the voids is consistent with the growth of the aggregates by the accretion of particles that are smaller than the characteristic size of the voids.  We also discuss the implications of our results for the interpretation of observations of voids in astronomical bodies, such as comets and interplanetary dust particles. We find that the statistics of voids in such bodies are consistent with the results of our statistical study, provided that the particles that form the body are large enough to form a void around themselves.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Positivity and almost positivity of biharmonic Green's functions under   Dirichlet boundary conditions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3301, "human_text": "  In general, for higher order elliptic equations and boundary value problems like the biharmonic equation and the linear clamped plate boundary value problem neither a maximum principle nor a comparison principle or -- equivalently -- a positivity preserving property is available. The problem is rather involved since the clamped boundary conditions prevent the boundary value problem {from} being reasonably written as a system of second order boundary value problems.   It is shown that, on the other hand, for bounded smooth domains $\\Omega \\subset\\mathbb{R}^n$, the negative part of the corresponding Green's function is \"small\" when compared with its singular positive part, provided $n\\ge 3$.   Moreover, the biharmonic Green's function in balls $B\\subset\\mathbb{R}^n$ under Dirichlet (i.e. clamped) boundary conditions is known explicitly and is positive. It has been known for some time that positivity is preserved under small regular perturbations of the domain, if $n=2$. In the present paper, such a stability result is proved for $n\\ge 3$. Keywords: Biharmonic Green's functions, positivity, almost positivity, blow-up procedure. ", "machine_text": " We consider positivity and almost positivity of biharmonic Green's functions under Dirichlet boundary conditions. We show that such Green's functions are positive or almost positive on the whole domain for a large class of bounded domains. The motivation for the research is that the boundary conditions for biharmonic Green's functions are not as well understood as the boundary conditions for harmonic Green's functions, and that positivity is a natural generalization of the well-known positive harmonic functions. The key ideas and methodology are that, for a large class of bounded domains, the biharmonic Green's function can be represented as a sum of products of harmonic Green's functions, where the product of two Green's functions is again a Green's function. This allows us to use the known properties of the positivity of harmonic Green's functions. The results obtained are that, under Dirichlet boundary conditions, biharmonic Green's functions are positive or almost positive on the whole domain for a large class of bounded domains, including the class of domains which contain the ball and the disc. The problem work attempts to solve is to show that biharmonic Green's functions are positive or almost positive on the whole domain for a large class of bounded domains. The practical application of the research is that it provides a technique for constructing positive or almost positive functions on a large class of domains, which includes the ball and the disc. The theoretical application of the research is that it provides a technique for studying the positivity of biharmonic Green's functions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A unified projection formalism for the Al-Pd-Mn quasicrystal   Xi-approximants and their metadislocations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1428, "human_text": "  The approximants xi, xi' and xi'_n of the quasicrystal Al-Mn-Pd display most interesting plastic properties as for example phason-induced deformation processes (Klein, H., Audier, M., Boudard, M., de Boissieu, M., Beraha, L., and Duneau, M., 1996, Phil. Mag. A, 73, 309.) or metadislocations (Klein, H., Feuerbacher, M., Schall, P., and Urban, K., 1999, Phys. Rev. Lett., 82, 3468.). Here we demonstrate that the phases and their deformed or defected states can be described by a simple projection formalism in three-dimensional space - not as usual in four to six dimensions. With the method we can interpret microstructures observed with electron microscopy as phasonic phase boundaries. Furthermore we determine the metadislocations of lowest energy and relate them uniquely to experimentally observed ones. Since moving metadislocations in the xi'-phase can create new phason-planes, we suggest a dislocation induced phase transition from xi' to xi'_n. The methods developed in this paper can as well be used for various other complex metallic alloys. ", "machine_text": " We develop a unified projection formalism for the Al-Pd-Mn quasicrystal, which includes theHealthcare industry relevant literature review, theoretical background and methodology, results and discussion. We consider the system from the thermodynamic and kinetic point of view, in particular the growth and the static structures. The quasicrystal is projected in the first Brillouin zone, in the special case of the octahedral point group. The thermal behavior is discussed within the Ising model formalism. We determine the simple non- aestivum regeneration mechanisms and the corresponding driving forces. The effects of the Ising-like spins on the electronic structure are investigated by the use of the projected BCS wave functions. The correlation functions of the mobile spins are obtained by the use of the moment-function technique. We find that the existence of the Ising-like spins in the octahedral hole is a necessary condition for the quasiperiodic order. Our results are consistent with the existence of an extended defect called the Al-Pd-Mn skyrmion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Renormalized Quantum Yang-Mills Fields in Curved Spacetime. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.334, "human_text": "  We present a proof that quantum Yang-Mills theory can be consistently defined as a renormalized, perturbative quantum field theory on an arbitrary globally hyperbolic curved, Lorentzian spacetime. To this end, we construct the non-commutative algebra of observables, in the sense of formal power series, as well as a space of corresponding quantum states. The algebra contains all gauge invariant, renormalized, interacting quantum field operators (polynomials in the field strength and its derivatives), and all their relations such as commutation relations or operator product expansion. It can be viewed as a deformation quantization of the Poisson algebra of classical Yang-Mills theory equipped with the Peierls bracket. The algebra is constructed as the cohomology of an auxiliary algebra describing a gauge fixed theory with ghosts and anti-fields. A key technical difficulty is to establish a suitable hierarchy of Ward identities at the renormalized level that ensure conservation of the interacting BRST-current, and that the interacting BRST-charge is nilpotent. The algebra of physical interacting field observables is obtained as the cohomology of this charge. As a consequence of our constructions, we can prove that the operator product expansion closes on the space of gauge invariant operators. Similarly, the renormalization group flow is proved not to leave the space of gauge invariant operators. ", "machine_text": "  Renormalized Quantum Yang-Mills Fields in Curved Spacetime  We consider the question of the extent to which a renormalization group transformation can be used to simplify the construction of a quantum theory of gravity. We show that in a wide class of examples, the answer is encouraging. We begin by recalling the correspondence between four-dimensional (4D) spacetimes and 3D objects, which allows one to view the dynamics of a theory of gravity in a geometrically intuitive fashion. We then consider a family of 4D spacetimes which can be obtained by iterated subdivisions of a 3D fractal object. We show that a renormalization group transformation can be used to simplify the description of the quantum theory of gravity on these examples. In particular, we show that the 3D fractal can be replaced by a 2D one, and that the quantum theory can be made asymptotically free. Our results suggest that the construction of quantum theories of gravity on certain classes of 4D spacetimes can be simplified substantially, providing a kind of 'type-II' string theory in higher dimensions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bimodal AGNs in Bimodal Galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3941, "human_text": "  By their star content, the galaxies split out into a red and a blue population; their color index peaked around u-r=2.5 or u-r=1, respectively, quantifies the ratio of the blue stars newly formed from cold galactic gas, to the redder ones left over by past generations. On the other hand, upon accreting substantial gas amounts the central massive black holes energize active galactic nuclei (AGNs); here we investigate whether these show a similar, and possibly related, bimodal partition as for current accretion activity relative to the past. To this aim we use an updated semianalytic model; based on Monte Carlo simulations, this follows with a large statistics the galaxy assemblage, the star generations and the black hole accretions in the cosmological framework over the redshift span from z=10 to z=0. We test our simulations for yielding in close detail the observed split of galaxies into a red, early and a blue, late population. We find that the black hole accretion activities likewise give rise to two source populations: early, bright quasars and later, dimmer AGNs. We predict for their Eddington parameter $\\lambda_E$ -- the ratio of the current to the past black hole accretions -- a bimodal distribution; the two branches sit now under $\\lambda_E \\approx 0.01$ (mainly contributed by low-luminosity AGNs) and around $\\lambda_E \\approx 0.3-1$. These not only mark out the two populations of AGNs, but also will turn out to correlate strongly with the red or blue color of their host galaxies. ", "machine_text": " We present the first statistical study of the large-scale distribution of bimodal active galactic nuclei (AGN) in galaxies. Our sample comprises 25 galaxies with 2+xPop populations selected from the 2Mic catalog, which contains spectroscopic information for \u223c150k galaxies in the local volume. We find a clear over-abundance of bimodal AGN in galaxies with two distinct stellar populations (75% of our sample), compared to galaxies with a single stellar population (25% of our sample). We show this result is statistically robust by comparing to the simulated distribution of bimodal AGN expected from a statistical model of bimodal galaxies with a single stellar population. The bimodal AGN are found to reside in the older, more massive stellar population in the dual-population galaxies, suggesting a correlation between the stellar and AGN mass. We also find that the fraction of the galaxy's stellar mass contained in the older population is predictive of the likelihood of finding a bimodal AGN in the galaxy. We conclude that a large population of old stars is a major requirement for the formation of a bimodal AGN, and that the physical mechanisms responsible for the formation of these dual-black-hole systems are likely to be linked to the properties of the older stellar populations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Is Modified Gravity Required by Observations? An Empirical Consistency   Test of Dark Energy Models. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0165, "human_text": "  We apply the technique of parameter-splitting to existing cosmological data sets, to check for a generic failure of dark energy models. Given a dark energy parameter, such as the energy density Omega_Lambda or equation of state w, we split it into two meta-parameters with one controlling geometrical distances, and the other controlling the growth of structure. Observational data spanning Type Ia Supernovae, the cosmic microwave background (CMB), galaxy clustering, and weak gravitational lensing statistics are fit without requiring the two meta-parameters to be equal. This technique checks for inconsistency between different data sets, as well as for internal inconsistency within any one data set (e.g., CMB or lensing statistics) that is sensitive to both geometry and growth. We find that the cosmological constant model is consistent with current data. Theories of modified gravity generally predict a relation between growth and geometry that is different from that of general relativity. Parameter-splitting can be viewed as a crude way to parametrize the space of such theories. Our analysis of current data already appears to put sharp limits on these theories: assuming a flat universe, current data constrain the difference Omega_Lambda(geom) - Omega_Lambda(grow) to be -0.0044 +/- 0.0058 (68% C.L.); allowing the equation of state w to vary, the difference w(geom) - w(grow) is constrained to be 0.37 +/- 0.37 (68% C.L.). Interestingly, the region w(grow) > w(geom), which should be generically favored by theories that slow structure formation relative to general relativity, is quite restricted by data already. We find w(grow) < -0.80 at 2 sigma. As an example, the best-fit flat Dvali-Gabadadze-Porrati (DGP) model approximated by our parametrization lies beyond the 3 sigma contour for constraints from all the data sets. ", "machine_text": " We present an empirical consistency test of modified gravity models using three sets of observations: galaxy redshifts, large-scale structure, and the cosmic microwave background. The test uses a goodness-of-fit statistic that is independent of the choice of functional form for the gravity model. We show that this test is free from the unphysical region of the parameter space that is a common feature of modified gravity models, and is therefore more robust than previous tests. The test does not reject the hypothesis that the data can be explained by a model in which only general relativity is modified. We therefore conclude that current observations do not require a modification of gravity beyond general relativity, regardless of the model that is proposed to explain the data.  We present an empirical consistency test of modified gravity models using three sets of observations: galaxy redshifts, large-scale structure, and the cosmic microwave background. The test uses a goodness-of-fit statistic that is independent of the choice of functional form for the gravity model. We show that this test is free from the unphysical region of the parameter space that is a common feature of modified gravity models, and is therefore more robust than previous tests. The test does not reject the hypothesis that the data can be explained by a model in which only general relativity is modified. We therefore conclude that current observations do not require a modification of gravity beyond general relativity, regardless of the model that is proposed to explain the data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Minimal size of a barchan dune. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1778, "human_text": "  Barchans are dunes of high mobility which have a crescent shape and propagate under conditions of unidirectional wind. However, sand dunes only appear above a critical size, which scales with the saturation distance of the sand flux [P. Hersen, S. Douady, and B. Andreotti, Phys. Rev. Lett. {\\bf{89,}} 264301 (2002); B. Andreotti, P. Claudin, and S. Douady, Eur. Phys. J. B {\\bf{28,}} 321 (2002); G. Sauermann, K. Kroy, and H. J. Herrmann, Phys. Rev. E {\\bf{64,}} 31305 (2001)]. It has been suggested by P. Hersen, S. Douady, and B. Andreotti, Phys. Rev. Lett. {\\bf{89,}} 264301 (2002) that this flux fetch distance is itself constant. Indeed, this could not explain the proto size of barchan dunes, which often occur in coastal areas of high litoral drift, and the scale of dunes on Mars. In the present work, we show from three dimensional calculations of sand transport that the size and the shape of the minimal barchan dune depend on the wind friction speed and the sand flux on the area between dunes in a field. Our results explain the common appearance of barchans a few tens of centimeter high which are observed along coasts. Furthermore, we find that the rate at which grains enter saltation on Mars is one order of magnitude higher than on Earth, and is relevant to correctly obtain the minimal dune size on Mars. ", "machine_text": "  We study the minimal size of a barchan dune, that is, the minimal area of the Devil's Racetrack, a famous barchan dune in Death Valley, CA. We show that the minimal area of the Devil's Racetrack is about 3.3 km2. Further, we derive a simple formula that gives the minimal area of a barchan dune with a given length and height. Our result has important practical applications in the study of the motion and evolution of sand dunes.  We consider a simple model of a barchan dune, that is, a model that consists of a sharp-crested ridge, which is straight, and two hummocks, which are placed at the ends of the ridge. We assume that the ridge has a constant height, and the hummocks have a constant volume. We study the stability of such a model, that is, we study the conditions that guarantee the stability of the model. We find that the most important condition is the area of the base of the dune, that is, the area of the patera. We show that this area must be at least 3.3 km2. This area is independent of the height and the length of the ridge, but it depends on the shape of the base, that is, on the curvature of the patera. We also derive a simple formula that gives the minimal area of a barchan dune with a given length and height. Our result has important practical applications in the study of the motion and evolution of sand dunes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Coulomb gauge Gribov copies and the confining potential. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2718, "human_text": "  We study the approach, initiated by Marinari et al., to the static inter-quark potential based on Polyakov lines of finite temporal extent, evaluated in Coulomb gauge. We show that, at small spatial separations, the potential can be understood as being between two separately gauge invariant colour charges. At larger separations Gribov copies obstruct the non-perturbative identification of individually gauge invariant colour states. We demonstrate, for the first time, how gauge invariance can be maintained quite generally by averaging over Gribov copies. This allows us to extend the analysis of the Polyakov lines and the corresponding, gauge invariant quark-antiquark state to all distance scales. Using large scale lattice simulations, we show that this interpolating state possesses a good overlap with the ground state in the quark-antiquark sector and yields the full static inter-quark potential at all distances. A visual representation of the Gribov copies on the lattice is also presented. ", "machine_text": "  We consider the Gribov copies of a relativistic point-like massive particle in a spherically symmetric, hard-walled, non-rotating confinement. The Copies are related to the complex structure of the confining potential, which is related to the one-dimensional scalarized Coulomb potential with a shift and a twist in the scalar potential. The full complex structure of the confining potential is determined analytically by the reduction of the three-dimensional problem to a one-dimensional problem, with the help of the Faddeev-Popov ghosts. The effective scalar potential is also determined analytically by the same procedure. The structure of the full potential and its scalar part is related to the behaviour of the relativistic massive particle in a spherical mirror, which is analysed by the method of the accelerated mirrors. We show that the solution with the positive mass has two branches, that with the negative mass has three branches, and that for any value of the mass the solution has an infinite number of branches.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral methods for orthogonal rational functions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3456, "human_text": "  An operator theoretic approach to orthogonal rational functions on the unit circle with poles in its exterior is presented in this paper. This approach is based on the identification of a suitable matrix representation of the multiplication operator associated with the corresponding orthogonality measure. Two different alternatives are discussed, depending whether we use for the matrix representation the standard basis of orthogonal rational functions, or a new one with poles alternatively located in the exterior and the interior of the unit circle. The corresponding representations are linear fractional transformations with matrix coefficients acting respectively on Hessenberg and five-diagonal unitary matrices.   In consequence, the orthogonality measure can be recovered from the spectral measure of an infinite unitary matrix depending uniquely on the poles and the parameters of the recurrence relation for the orthogonal rational functions. Besides, the zeros of the orthogonal and para-orthogonal rational functions are identified as the eigenvalues of matrix linear fractional transformations of finite Hessenberg and five-diagonal matrices.   As an application of this operator approach, we obtain new relations between the support of the orthogonality measure and the location of the poles and parameters of the recurrence relation, generalizing to the rational case known results for orthogonal polynomials on the unit circle.   Finally, we extend these results to orthogonal polynomials on the real line with poles in the lower half plane. ", "machine_text": "  Spectral methods for orthogonal rational functions.  We consider spectral methods for approximating orthogonal rational functions by sums of orthonormal basis functions. Such approximations are of interest for applications in computer graphics, where fast and accurate evaluation of derivatives is a major issue. We show that if the basis functions are expanded in a local orthogonal basis, then the resulting approximation has the same orthogonality property as the original rational function. The proposed method is applicable to anisotropic metrics and provides an alternative to the celebrated non-rational basis spline method of orders 1 and 2. In particular, we show that the approximation by the proposed spectral method has the same stability as the approximation by the basis spline method, which is not the case for the well-known quadric spline method. We implement the proposed method using the fast Fourier transform, which allows to compute the approximation with a few multiplications and additions. Finally, we show that the proposed method can be viewed as a generalization of the basis spline method, where the latter is obtained by setting the basis functions to be the monomials.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Non-Parametric Field Estimation using Randomly Deployed, Noisy, Binary   Sensors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0685, "human_text": "  The reconstruction of a deterministic data field from binary-quantized noisy observations of sensors which are randomly deployed over the field domain is studied. The study focuses on the extremes of lack of deterministic control in the sensor deployment, lack of knowledge of the noise distribution, and lack of sensing precision and reliability. Such adverse conditions are motivated by possible real-world scenarios where a large collection of low-cost, crudely manufactured sensors are mass-deployed in an environment where little can be assumed about the ambient noise. A simple estimator that reconstructs the entire data field from these unreliable, binary-quantized, noisy observations is proposed. Technical conditions for the almost sure and integrated mean squared error (MSE) convergence of the estimate to the data field, as the number of sensors tends to infinity, are derived and their implications are discussed. For finite-dimensional, bounded-variation, and Sobolev-differentiable function classes, specific integrated MSE decay rates are derived. For the first and third function classes these rates are found to be minimax order optimal with respect to infinite precision sensing and known noise distribution. ", "machine_text": "  We consider the problem of estimating a continuous field variable using randomly deployed, noisy, binary sensors. The deployment of the sensors is assumed to be random in the sense that the locations of the sensors are independently and uniformly distributed on a given grid. The measurements made by the sensors are binary in the sense that each sensor is either \"on\" or \"off,\" and the on/off probability is independent of the other sensors. The measurements are also noisy in the sense that the on/off probability is unknown and assumed to be drawn from some probability distribution. The goal is to estimate the field variable at the location of each sensor using the on/off measurements of the sensors in the neighborhood of that location. We assume that the field variable has a smooth enough probability distribution, and that the effect of the noise is local in the sense that the noise affects the estimate of the field variable at each location independently. We propose a new algorithm for estimating the field variable at each location based on the ideas of maximum likelihood estimation and the binary decision tree algorithm. The proposed algorithm is simple and has a clear probabilistic interpretation. We show that the proposed algorithm is robust to the random deployment of the sensors and to the noisy nature of the measurements, and we evaluate the algorithm using simulation studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Parametrized Post-Newtonian Expansion of Chern-Simons Gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0299, "human_text": "  We investigate the weak-field, post-Newtonian expansion to the solution of the field equations in Chern-Simons gravity with a perfect fluid source. In particular, we study the mapping of this solution to the parameterized post-Newtonian formalism to 1 PN order in the metric. We find that the PPN parameters of Chern-Simons gravity are identical to those of general relativity, with the exception of the inclusion of a new term that is proportional to the Chern-Simons coupling parameter and the curl of the PPN vector potentials. We also find that the new term is naturally enhanced by the non-linearity of spacetime and we provide a physical interpretation for it. By mapping this correction to the gravito-electro-magnetic framework, we study the corrections that this new term introduces to the acceleration of point particles and the frame-dragging effect in gyroscopic precession. We find that the Chern-Simons correction to these classical predictions could be used by current and future experiments to place bounds on intrinsic parameters of Chern-Simons gravity and, thus, string theory. ", "machine_text": "  Parametrized Post-Newtonian Expansion of Chern-Simons Gravity  We consider the Post-Newtonian expansion of Chern-Simons gravity, a theory recently proposed as a candidate for a generalized theory of gravity. This theory possesses an exceptional structure which allows a direct and systematic formulation of the expansion parameter. The conventional method, based on the first order in the expansion parameter, yields an accurate description of the evolution of the orbits of celestial bodies in a certain range of the gravitational parameter, but it is unable to correctly describe the motion of a body when the gravitational parameter is very small. We show that this deficiency can be remedied by a parametrized expansion which correctly describes the motion of bodies both in the macroscopic and in the microscopic regime. The resulting theory is able to correctly describe the solar system as well as the evolution of small bodies in the universe. The expansion parameter enters the theory in a very natural way and has a clear physical meaning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Exploring the Variable Sky with the Sloan Digital Sky Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0655, "human_text": "  We quantify the variability of faint unresolved optical sources using a catalog based on multiple SDSS imaging observations. The catalog covers SDSS Stripe 82, and contains 58 million photometric observations in the SDSS ugriz system for 1.4 million unresolved sources. In each photometric bandpass we compute various low-order lightcurve statistics and use them to select and study variable sources. We find that 2% of unresolved optical sources brighter than g=20.5 appear variable at the 0.05 mag level (rms) simultaneously in the g and r bands. The majority (2/3) of these variable sources are low-redshift (<2) quasars, although they represent only 2% of all sources in the adopted flux-limited sample. We find that at least 90% of quasars are variable at the 0.03 mag level (rms) and confirm that variability is as good a method for finding low-redshift quasars as is the UV excess color selection (at high Galactic latitudes). We analyze the distribution of lightcurve skewness for quasars and find that is centered on zero. We find that about 1/4 of the variable stars are RR Lyrae stars, and that only 0.5% of stars from the main stellar locus are variable at the 0.05 mag level. The distribution of lightcurve skewness in the g-r vs. u-g color-color diagram on the main stellar locus is found to be bimodal (with one mode consistent with Algol-like behavior). Using over six hundred RR Lyrae stars, we demonstrate rich halo substructure out to distances of 100 kpc. We extrapolate these results to expected performance by the Large Synoptic Survey Telescope and estimate that it will obtain well-sampled 2% accurate, multi-color lightcurves for ~2 million low-redshift quasars, and will discover at least 50 million variable stars. ", "machine_text": "  We present an analysis of the evolution of the sky brightness distribution as a function of galaxy redshift, based on the SDSS image data. We find that the distribution is very well described by a two-parameter power law with a scale factor that increases with redshift and a power law index that decreases with redshift. The result implies that the fraction of the sky occupied by galaxies increases with redshift, while the mean surface brightness decreases. We show that this evolution can be understood within the framework of a simple model in which the galaxies are assumed to be distributed according to a Gaussian random field with a variance that increases with redshift. In this model the power law index of the sky brightness distribution is related to the variance of the random field. The main advantage of the model is that it provides a simple physical interpretation of the shape of the sky brightness distribution as a function of redshift. In particular, it explains why the distribution becomes shallower with increasing redshift. The model also predicts that the standard deviation of the distribution should increase with redshift, in agreement with previous results based on the analysis of the 2 Micron All Sky Survey data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Curious Case of NGC6908. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3813, "human_text": "  The object NGC6908 was once thought to be simply a surface-brightness enhancement in the eastern spiral arm of the nearby spiral galaxy NGC6907. Based on an examination of near-infrared imaging, the object is shown in fact to be a lenticular S0(6/7) galaxy hidden in the optical glare of the disk and spiral structure of the larger galaxy. New radial velocities of NGC6908 (3,060+/-16 (emission); 3,113+/-73 km/s (absorption)) have been obtained at the Baade 6.5m and the duPont 2.5m telescopes at Las Campanas, Chile placing NGC6908 at the same expansion-velocity distance as NGC6907 (3,190+/-5 km/s), eliminating the possibility of a purely chance line-of-sight coincidence. The once-enigmatic asymmetries in the disk and outer spiral structure of NGC6907 are now explained as being due to an advanced merger event. Newly discovered tails and debris in the outer reaches of this galaxy further support the merger scenario for this system. This pair of galaxies is a rather striking example of two objects discovered over 100 years ago, whose true nature was lost until modern detectors operating at infrared wavelengths gave us a new (high-contrast) look. Other examples of embedded merger remnants may also reveal themselves in the growing samples of near-infrared imaging of nearby galaxies; and a pilot study does reveal several other promising candidates for follow-up observations. ", "machine_text": " We present a detailed study of the curious case of NGC 6908, a low-mass star-forming region in the outer parts of the Milky Way. We have conducted a systematic search for young stellar objects in the region, and have found a large number of candidate objects with ages on the order of 10-20 million years. The objects have been detected through the 1.3 mm wavelength of the CO2 emission line, which is strong in the cold outer reaches of the galaxy. We have characterized the kinematics and chemical properties of the region, and have found that it is surprisingly chemically rich, with a wide range of elements detected in the gas. In addition, we have found a large number of molecular clouds in the region, some of which are extremely cold and dense. We have identified a large number of potential sites for future star formation, and have found that the region is likely to be a significant site for star formation in the future. We have also found a number of exotic objects in the region, including a number of potential brown dwarfs. Our results suggest that the region is a unique and potentially important site for future star formation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Extracting the ${\\bar q}q$ condensate for light quarks beyond the chiral   limit in models of QCD. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2296, "human_text": "  It has recently been suggested \\cite{Chang:2006bm} that a reliable and unambiguous definition of the non-perturbative massive quark condensate could be provided by considering a non positive-definite class of solutions to the Schwinger Dyson Equation for the quark propagator. In this paper we show that this definition is incomplete without considering a third class of solutions. Indeed, studying these three classes reveals a degeneracy of possible condensate definitions leading to a whole range of values. However, we show that the {\\it physical} condensate may in fact be extracted by simple fitting to the Operator Product Expansion, a procedure which is stabilised by considering the three classes of solution together. We find that for current quark masses in the range from zero to 25 MeV or so (defined at a scale of 2 GeV in the $\\bar{MS}$ scheme), the dynamically generated condensate increases from the chiral limit in a wide range of phenomenologically successful models of the confining QCD interaction. Lastly, the role of a fourth class of noded solutions is briefly discussed. ", "machine_text": " We extract the ${\\bar q}q$ condensate for light quarks beyond the chiral limit in models of QCD. The motivation for this research is to understand the mechanism of the extraction of the ${\\bar q}q$ condensate and to study the physical properties of the extracted condensate in the limit of small quark masses. The key ideas and methodology are to use the monopole representation to calculate the transition amplitudes of the weak interaction and to use the resulting amplitudes to extract the ${\\bar q}q$ condensate. The results obtained are that the extracted ${\\bar q}q$ condensate has a mass and a condensate density, and that the condensate density has a maximum value and a fast-flavor-changing (FFC) structure. The problem this work attempts to solve is to understand the mechanism of the extraction of the ${\\bar q}q$ condensate and to study the physical properties of the extracted condensate in the limit of small quark masses. This work has practical and theoretical applications in the study of the strong interaction and in the extraction of the ${\\bar q}q$ condensate.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Identifying network communities with a high resolution. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3759, "human_text": "  Community structure is an important property of complex networks. An automatic discovery of such structure is a fundamental task in many disciplines, including sociology, biology, engineering, and computer science. Recently, several community discovery algorithms have been proposed based on the optimization of a quantity called modularity (Q). However, the problem of modularity optimization is NP-hard, and the existing approaches often suffer from prohibitively long running time or poor quality. Furthermore, it has been recently pointed out that algorithms based on optimizing Q will have a resolution limit, i.e., communities below a certain scale may not be detected. In this research, we first propose an efficient heuristic algorithm, Qcut, which combines spectral graph partitioning and local search to optimize Q. Using both synthetic and real networks, we show that Qcut can find higher modularities and is more scalable than the existing algorithms. Furthermore, using Qcut as an essential component, we propose a recursive algorithm, HQcut, to solve the resolution limit problem. We show that HQcut can successfully detect communities at a much finer scale and with a higher accuracy than the existing algorithms. Finally, we apply Qcut and HQcut to study a protein-protein interaction network, and show that the combination of the two algorithms can reveal interesting biological results that may be otherwise undetectable. ", "machine_text": "  Identifying network communities with a high resolution.  We present a new algorithm for identifying network communities that is based on clique percolation methods. Our algorithm is guaranteed to return the optimal number of communities in an undirected network, regardless of the number of links the algorithm adds in the process. We show how to implement the algorithm efficiently, and we provide an experimental evaluation of its performance on random and real-world networks. We also present a new algorithm for calculating the quality of a division of a network into communities, based on clique percolation ideas. Our experimental results show that the new algorithms are superior to existing methods for these tasks.  We are surrounded by networks: communication and social networks, protein interaction and gene regulatory networks, metabolic and food networks, and many others. A central task in the analysis of networks is to find communities, or groups of nodes that are highly connected to each other and relatively separate from the rest of the network. The task is made difficult by the fact that the communities are not necessarily well-defined, and they can have different levels of granularity: one can identify communities within communities, and the boundaries between communities are not always clear.  We present a new algorithm for identifying network communities that is based on clique percolation methods. Our algorithm is guaranteed to return the optimal number of communities in an undirected network, regardless of the number of links the algorithm adds in the process. We show how to implement the algorithm efficiently, and we provide an experimental evaluation of its performance on random and real-world networks. We also present a new algorithm for calculating the quality of a division of a network into communities, based on clique percolation ideas. Our experimental results show that the new algorithms are superior to existing methods for these tasks.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galaxy clustering constraints on deviations from Newtonian gravity at   cosmological scales II: Perturbative and numerical analyses of power spectrum   and bispectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1311, "human_text": "  We explore observational constraints on possible deviations from Newtonian gravity by means of large-scale clustering of galaxies. We measure the power spectrum and the bispectrum of Sloan Digital Sky Survey galaxies and compare the result with predictions in an empirical model of modified gravity. Our model assumes an additional Yukawa-like term with two parameters that characterize the amplitude and the length scale of the modified gravity. The model predictions are calculated using two methods; the second-order perturbation theory and direct N-body simulations. These methods allow us to study non-linear evolution of large-scale structure. Using the simulation results, we find that perturbation theory provides reliable estimates for the power spectrum and the bispectrum in the modified Newtonian model. We also construct mock galaxy catalogues from the simulations, and derive constraints on the amplitude and the length scale of deviations from Newtonian gravity. The resulting constraints from power spectrum are consistent with those obtained in our earlier work, indicating the validity of the previous empirical modeling of gravitational nonlinearity in the modified Newtonian model. If linear biasing is adopted, the bispectrum of the SDSS galaxies yields constraints very similar to those from the power spectrum. If we allow for the nonlinear biasing instead, we find that the ratio of the quadratic to linear biasing coefficients, b_2/b_1, should satisfy -0.4 < b_2/b_1<0.3 in the modified Newtonian model. ", "machine_text": " We present the results of a detailed analysis of the large-scale structure of galaxies, as determined from the power spectrum and bispectrum of galaxy positions. We show that a simple model in which galaxies are influenced only by Newtonian gravity, with a cosmological constant to account for the observed large-scale structure, can quantitatively reproduce the power spectrum and bispectrum, provided that the strength of nonlinearity is included as a free parameter. We then use this model to set limits on the non-Newtonian corrections to the galaxy distribution. If the non-Newtonian corrections are too large, the power spectrum is too steep at large scales and too flat at small scales. If the corrections are too small, the power spectrum is too flat at large scales and too steep at small scales. We show that these limits can be used to set a simple upper bound on the non-Newtonian corrections of O(1%) for power spectrum deviations and O(10%) for bispectrum deviations, with a confidence level of 95%. We also present numerical results for a model in which the galaxies are influenced by a cosmological constant and a small-scale repulsion, with a strength proportional to the inverse cube of the distance. The model is able to reproduce the data as well as the Newtonian model, with a small non-Newtonian correction (O(0.5%) for the power spectrum and O(1%) for the bispectrum). We discuss these results in the framework of recent numerical studies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Robust Multi-Cellular Developmental Design. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1309, "human_text": "  This paper introduces a continuous model for Multi-cellular Developmental Design. The cells are fixed on a 2D grid and exchange \"chemicals\" with their neighbors during the growth process. The quantity of chemicals that a cell produces, as well as the differentiation value of the cell in the phenotype, are controlled by a Neural Network (the genotype) that takes as inputs the chemicals produced by the neighboring cells at the previous time step. In the proposed model, the number of iterations of the growth process is not pre-determined, but emerges during evolution: only organisms for which the growth process stabilizes give a phenotype (the stable state), others are declared nonviable. The optimization of the controller is done using the NEAT algorithm, that optimizes both the topology and the weights of the Neural Networks. Though each cell only receives local information from its neighbors, the experimental results of the proposed approach on the 'flags' problems (the phenotype must match a given 2D pattern) are almost as good as those of a direct regression approach using the same model with global information. Moreover, the resulting multi-cellular organisms exhibit almost perfect self-healing characteristics. ", "machine_text": "  We present a new framework for the analysis and synthesis of developmental systems. We focus on systems where the dynamics of the cells are largely non-linear and the interactions between cells are complex, such as in embryonic development or in the nervous system. We consider a large class of developmental systems, which includes systems with continuous and discrete variables, and static and dynamic components. We propose a general methodology for identifying robust developmental programs, which can robustly generate the full range of phenotypes observed in the system. We show that these programs are closely related to the concept of a developmental attractor, a subspace of developmental states where the dynamics are attracted to the normal development and where small perturbations do not significantly change the developmental outcome. We apply our framework to several examples, including the development of the vertebrate skeleton, the development of the central nervous system, and the evolution of developmental programs.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Mass Function of Active Black Holes in the Local Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.002, "human_text": "  We present the first measurement of the black hole (BH) mass function for broad-line active galaxies in the local Universe. Using the ~9000 broad-line active galaxies from the Fourth Data Release of the Sloan Digital Sky Survey, we construct a broad-line luminosity function that agrees very well with the local soft X-ray luminosity function. Using standard virial relations, we then convert observed broad-line luminosities and widths into BH masses. A mass function constructed in this way has the unique capability to probe the mass region <10^6 M_sun, which, while insignificant in terms of total BH mass density, nevertheless may place important constraints on the mass distribution of seed BHs in the early Universe. The characteristic local active BH has a mass of ~10^7 M_sun radiating at 10% of the Eddington rate. The active fraction is a strong function of BH mass; at both higher and lower masses the active mass function falls more steeply than one would infer from the distribution of bulge luminosity. The deficit of local massive radiating BHs is a well-known phenomenon, while we present the first robust measurement of a decline in the space density of active BHs at low mass. ", "machine_text": "  We present a new method for inferring the mass function of active galactic nuclei (AGN) in the local universe. We have derived a statistical scheme that allows us to distinguish between the contribution to the mass function of galaxies and that of the central AGN. Our method does not require any assumption about the functional form of the mass function and can be used to test the tightness of the relationship between the two components. We find that the mass function of the local galaxies is well described by a power law with a linear index of \u03b3 = 1.35 \u00b1 0.09, independently of the considered galaxy group or cluster. The contribution of the central AGN to the total mass function is always less tight, with a average index of \u03b3 = 1.42 \u00b1 0.1. The difference between the two components is highly significant (\u2a7e5\u03c3) whenever the mass function of the central AGN is above 10% of the total. We have also derived the first empirical evidence that the tightest possible mass function compatible with the data is a power law with an index of \u03b3 = 1.38 \u00b1 0.1. This finding suggests that the simplest form of the correspondence principle is valid, according to which the mass function of the sum of a large number of galaxies is equal to the sum of the mass functions of the galaxies, with the galaxies being located at the same positions. Our method can be used to test other hypothesis about the mass function of active galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Late-Type Red Supergiants: Too Cool for the Magellanic Clouds?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3431, "human_text": "  We have identified seven red supergiants (RSGs) in the Large Magellanic Cloud (LMC) and four RSGs in the Small Magellanic Cloud (SMC), all of which have spectral types that are considerably later than the average type observed in their parent galaxy. Using moderate-resolution optical spectrophotometry and the MARCS stellar atmosphere models, we determine their physical properties and place them on the H-R diagram for comparison with the predictions of current stellar evolutionary tracks. The radial velocities of these stars suggest that they are likely all members of the Clouds rather than foreground dwarfs or halo giants. Their locations in the H-R diagram also show us that those stars are cooler than the current evolutionary tracks allow, appearing to the right of the Hayashi limit, a region in which stars are no longer in hydrodynamic equilibrium. These stars exhibit considerable variability in their V magnitudes, and three of these stars also show changes in their effective temperatures (and spectral types) on the time-scales of months. One of these stars, [M2002] SMC 055188, was caught in an M4.5 I state, as late as that seen in HV 11423 at its recent extreme: considerable later, and cooler, than any other supergiant in the SMC. In addition, we find evidence of variable extinction due to circumstellar dust and changes in the stars' luminosities, also consistent with our recent findings for HV 11423 - when these stars are hotter they are also dustier and more luminous. We suggest that these stars have unusual properties because they are in an unstable (and short-lived) evolutionary phase. ", "machine_text": "  Late-Type Red Supergiants: Too Cool for the Magellanic Clouds?  We present photometric observations of the red supergiants (RSGs) in the Large and Small Magellanic Clouds (LMC and SMC), obtained with the 6.5 m Magellan Telescopes. Our sample consists of 62 unreddened RSGs with MK magnitudes in the range MK \u2248 \u22121 to 1, and this is the largest homogeneous RSG sample in a low-mass galaxy to date. We find that the LMC and SMC contain both relatively cool and relatively hot RSGs, but the distribution of temperatures is not uniform. The coolest RSGs tend to be concentrated in the eastern half of the LMC and in the SMC, while the hottest RSGs are found in the western half of the LMC. We determine the stellar masses of our RSGs from an updated version of the stellar evolution model by rgbde. We find that the LMC contains more massive RSGs than the SMC, and that the distribution of stellar masses in the LMC is not uniform. The lowest stellar masses are found in the eastern half of the LMC, while the highest stellar masses are in the western half. We also compare the absolute magnitude (M) - temperature (T) relation for our RSGs with theoretical predictions by theory by 1996RGB and theory by 2005RF, and find that our RSGs are consistent with these relations. However, the absolute magnitude - stellar mass relation for our RSGs is not consistent with the prediction of theory by 1996RGB, but is consistent with the prediction of theory by 2005RF. We discuss these results in the context of known associations between RSGs and stellar clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SDSS J121811.0+465501.2: a new Low Surface Brightness Galaxy with low   metallicity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2066, "human_text": "  We serendipitously find a new nearby Low Surface Brightness (LSB) galaxy from SDSS database. We estimate oxygen abundance of its H II region SDSS J121811.0+465501.2 from electron temperature, as well as for another H II region, SDSS J135440.5+535309.6, located in irregular LSB galaxy UGC 8837. These two extragalactic H II regions were classified as stars in the SDSS-DR4 database, and were found occasionally by us in the automatic recognition and classification on stellar spectra.Their optical spectra show obvious emission lines, i.e., strong [O III]4959, 5007, Balmer emission lines, but very weak [N II]6548,6583 and [S II]6317,6731, which could indicate that they are metal-poor star-forming regions. The derived oxygen abundances of the two objects are 12+log(O/H) ~ 7.88+-0.30 and 7.70+-0.30, respectively. The host of the H II region SDSS J121811.0+465501.2 is identified as a new nearly edge-on LSB disc galaxy (almost without bulge) with the B-band central surface brightness mu_0(B) as 23.68 mag arcsec^{-2} and inclination angle as ~75 degree by using the GIM2D software to analyze its g- and r-band images independently. It is a nearby dwarf galaxy with redshift z~0.00157, disk scale-length ~0.40 kpc and B-band absolute magnitude M_B ~ -13.51 mag. The very low oxygen abundances of these two objects confirm the low metallicities of LSB galaxies. ", "machine_text": "  We present SDSS J121811.0+465501.2, a new low surface brightness galaxy discovered in the SDSS with low metallicity. This galaxy is very faint, making it a valuable addition to the set of known LSB galaxies in the SDSS. We discuss the galaxy's position in the LSB galaxy distribution in metallicity space, and find that it lies in a region between the blue cloud and the red sequence. We estimate the galaxy's distance based on its Tully-Fisher relation and find that it lies at a distance of 7.7 kpc. We conclude that this galaxy is a member of the Local Volume Halo. The high metallicity of the gas in this galaxy implies that a significant fraction of the gas in this galaxy has been infalling from the intergalactic medium, possibly as a result of the strong dynamical interactions this galaxy is undergoing as it is tidally distorted by the larger galaxies in its neighborhood. We present an analysis of the dynamics of this galaxy based on its velocity field and find that this galaxy is in a state of rapid rotation, with a peak velocity of hazardous risk irl 1.4, and that it contains a large dark matter halo, implying that this galaxy is a significant influence on the dynamics of the Local Volume Halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Crossover from Impurity to Valence Band in Diluted Magnetic   Semiconductors: The Role of the Coulomb Attraction by Acceptor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0309, "human_text": "  The crossover between an impurity band (IB) and a valence band (VB) regime as a function of the magnetic impurity concentration in models for diluted magnetic semiconductors (DMS) is studied systematically by taking into consideration the Coulomb attraction between the carriers and the magnetic impurities. The density of states and the ferromagnetic transition temperature of a Spin-Fermion model applied to DMS are evaluated using Dynamical Mean-Field Theory (DMFT) and Monte Carlo (MC) calculations. It is shown that the addition of a square-well-like attractive potential can generate an IB at small enough Mn doping $x$ for values of the $p-d$ exchange $J$ that are not strong enough to generate one by themselves. We observe that the IB merges with the VB when $x >= x_c$ where $x_c$ is a function of $J$ and the Coulomb attraction strength $V$. Using MC calculations, we demonstrate that the range of the Coulomb attraction plays an important role. While the on-site attraction, that has been used in previous numerical simulations, effectively renormalizes $J$ for all values of $x$, an unphysical result, a nearest-neighbor range attraction renormalizes $J$ only at very low dopings, i.e., until the bound holes wave functions start to overlap. Thus, our results indicate that the Coulomb attraction can be neglected to study Mn doped GaSb, GaAs, and GaP in the relevant doping regimes, but it should be included in the case of Mn doped GaN that is expected to be in the IB regime. ", "machine_text": " We investigate the role of the Coulomb interaction in the crossover from an impurity band to the valence band in diluted magnetic semiconductors by means of an ab initio calculation. We find that the presence of the Coulomb interaction is essential for the crossover, in contrast to the case without the interaction. In particular, we show that the attraction between an impurity and a point-defect acceptor is the mechanism for the formation of the conducting charge-transfer (CT) state, in addition to the repulsion between an impurity and an impurity-acceptor. The competition between the attraction and the repulsion determines the depth of the impurity level in the CT state, and thus gives rise to a clear signature of the transition from the impurity band to the valence band in the form of a diverging density-of-states. We also analyze the effect of a magnetic field on the transition, and find that the interaction with the acceptor is weakened by the magnetic field, resulting in the suppression of the transition.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accretion Disk Illumination in Schwarzschild and Kerr Geometries:   Fitting Formulae. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2159, "human_text": "  We describe the methodology and compute the illumination of geometrically thin accretion disks around black holes of arbitrary spin parameter $a$ exposed to the radiation of a point-like, isotropic source at arbitrary height above the disk on its symmetry axis. We then provide analytic fitting formulae for the illumination as a function of the source height $h$ and the black hole angular momentum $a$. We find that for a source on the disk symmetry axis and $h/M > 3$, the main effect of the parameter $a$ is allowing the disk to extend to smaller radii (approaching $r/M \\to 1$ as $a/M \\to 1$) and thus allow the illumination of regions of much higher rotational velocity and redshift. We also compute the illumination profiles for anisotropic emission associated with the motion of the source relative to the accretion disk and present the fractions of photons absorbed by the black hole, intercepted by the disk or escaping to infinity for both isotropic and anisotropic emission for $a/M=0$ and $a/M=0.99$. As the anisotropy (of a source approaching the disk) increases the illumination profile reduces (approximately) to a single power-law, whose index, $q$, because of absorption of the beamed photons by the black hole, saturates to a value no higher than $q \\gtrsim 3$. Finally, we compute the fluorescence Fe line profiles associated with the specific illumination and compare them among various cases. ", "machine_text": " We investigate the structure of accretion disks in Schwarzschild and Kerr geometries, by developing two sets of fitting formulae for the solutions of the governing equations. The first set is based on the assumption that the inner disk is illuminated by a uniform radiation flux, while the second set includes a non-uniform flux distribution, which can be used to model the effects of supermassive black holes (SMBHs) on the accretion disk. In the first set of formulae, the outer disk is described by the solution of the stationary Navier-Stokes equation, in the absence of a gravity field, and the inner disk is described by the solution of the stationary Einstein equations, in the presence of a Schwarzschild-like gravity field. In the second set of formulae, the outer disk is described by the solution of the stationary Navier-Stokes equation, in the absence of a gravity field, and the inner disk is described by the solution of the stationary Einstein equations, in the presence of a Kerr-like gravity field. The fitting formulae are given in a parameter-free form and can be used to derive the evolution of the structure of the disk, as a function of the radial coordinate, for both steady and unsteady flows. Finally, we discuss the physical implications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Efficient model chemistries for peptides. I. Split-valence Gaussian   basis sets and the heterolevel approximation in RHF and MP2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3715, "human_text": "  We present an exhaustive study of more than 250 ab initio potential energy surfaces (PESs) of the model dipeptide HCO-L-Ala-NH2. The model chemistries (MCs) used are constructed as homo- and heterolevels involving possibly different RHF and MP2 calculations for the geometry and the energy. The basis sets used belong to a sample of 39 selected representants from Pople's split-valence families, ranging from the small 3-21G to the large 6-311++G(2df,2pd). The reference PES to which the rest are compared is the MP2/6-311++G(2df,2pd) homolevel, which, as far as we are aware, is the more accurate PES of a dipeptide in the literature. The aim of the study presented is twofold: On the one hand, the evaluation of the influence of polarization and diffuse functions in the basis set, distinguishing between those placed at 1st-row atoms and those placed at hydrogens, as well as the effect of different contraction and valence splitting schemes. On the other hand, the investigation of the heterolevel assumption, which is defined here to be that which states that heterolevel MCs are more efficient than homolevel MCs. The heterolevel approximation is very commonly used in the literature, but it is seldom checked. As far as we know, the only tests for peptides or related systems, have been performed using a small number of conformers, and this is the first time that this potentially very economical approximation is tested in full PESs. In order to achieve these goals, all data sets have been compared and analyzed in a way which captures the nearness concept in the space of MCs. ", "machine_text": " We describe efficient model chemistries for peptides based on the split-valence Gaussian basis sets and the heterolevel approximation in RHF and MP2. The basis sets are generated from the public domain CGenApp program, and are available for download from the authors' web site. A test set of 24 peptides of various sizes and conformations is used to evaluate the performance of the model chemistries. The results are compared with those obtained with the standard Gasteiger/Heller-Weiss and modified Toshima-Tannaka model chemistries, and with experimental data where available. We show that the split-valence basis sets perform very well in the RHF and MP2 calculations, with errors similar to those obtained with the modified Toshima-Tannaka basis sets, and significantly better than those obtained with the Gasteiger/Heller-Weiss basis sets. We also show that the performance of the split-valence basis sets is very sensitive to the number of parameterizedfunc- tional groups included in the basis set; a proper balance should be sought to obtain the best performance.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Aromatic emission from the ionised mane of the Horsehead nebula. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.151, "human_text": "  We study the evolution of the Aromatic Infrared Bands (AIBs) emitters across the illuminated edge of the Horsehead nebula and especially their survival and properties in the HII region. We present spectral mapping observations taken with the Infrared Spectrograph (IRS) at wavelengths 5.2-38 microns. A strong AIB at 11.3 microns is detected in the HII region, relative to the other AIBs at 6.2, 7.7 and 8.6 microns. The intensity of this band appears to be correlated with the intensity of the [NeII] at 12.8 microns and of Halpha, which shows that the emitters of the 11.3 microns band are located in the ionised gas. The survival of PAHs in the HII region could be due to the moderate intensity of the radiation field (G0 about 100) and the lack of photons with energy above about 25eV. The enhancement of the intensity of the 11.3 microns band in the HII region, relative to the other AIBs can be explained by the presence of neutral PAHs. Our observations highlight a transition region between ionised and neutral PAHs observed with ideal conditions in our Galaxy. A scenario where PAHs can survive in HII regions and be significantly neutral could explain the detection of a prominent 11.3 microns band in other Spitzer observations. ", "machine_text": "  We present a study of the ionised mane of the Horsehead nebula (NGC 7027), which is located behind the meridian about 3\u00b0 east of the third magnitude star Procyon. We find that the ionised gas in the mane is significantly cooler than the non-ionised gas in the head. We have made observations with the aim of investigating the relative temperatures and the velocity structure of the ionised gas in the mane, the neutral gas in the head, and the gas in the comet-tail shaped structure that appears to connect the mane to the head. Our main result is that the ionised gas in the mane is between 1.5 and 2.5 kK cooler than the non-ionised gas in the head, as determined from the ratio of the doubly ionised carbon atom C+ to the ionised carbon atom C. This result suggests that the ionised gas in the mane is moving towards us and is therefore much closer than the non-ionised gas in the head. This is supported by a comparison of the line ratios of C+ to C and CO+ to CO, which show a trend of increasing strength with line centre wavelength. The strength of the CO lines is consistent with the gas in the head being at a distance of about 85 pc, but the C+ lines require a distance of about 50 pc. The relative velocity structure of the ionised gas in the mane was determined from the difference between the observed distribution of the doubly ionised carbon atom C+ and a model distribution assuming that the gas is at the same temperature throughout. We find that the ionised gas in the mane is likely to be moving at about 30 km s$^{-1}$, and that this velocity structure is in agreement with a model in which the gas is driven by the infalling ionised matter from the Sco OB1 association. We also find that the ionised gas in the mane is likely to be much less dense than the non-ionised gas in the head.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Microscpoic Model for the Neutron Dynamic Structure Factor of Solid   Methane in phase II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0824, "human_text": "  We have constructed an approximate microscopic model for the neutron dynamic structure factor of solid methane in phase II. We expect our model to apply for neutron energies below 1\\textit{eV} at pressures near 1 bar and temperatures below 20K, where solid methane exists in a phase, called phase II, in which the tetrahedral hydrogens exist in a mixed phase of free rotors and hindered rotors. Certain matrix elements needed for the dynamic structure factor $S(Q, \\omega)$ are adapted from a calculation by Ozaki \\textit{et al.}\\cite{ozaki:3442}\\cite{ozaki2}. The model treats the effects of molecular translations, intramolecular vibrations and the free and hindered rotational degrees of freedom as uncoupled ones. Total scattering cross sections calculated from the model agree with the cross section measurements of Grieger\\cite{grieger:3161} and Whittemore\\cite{Wittemore} for the incident neutron energies of 0.5 \\textit{meV} $\\sim$ 1\\textit{eV}. The effective density of states extracted from the model was compared with the Harker $&$ Brugger frequency spectrum extracted from neutron scattering measurements conducted at 22K\\cite{HARKER1967}. ", "machine_text": " We present a microscopic model for the neutron dynamic structure factor of solid methane in phase II. The model is based on the single-particle basis-set approximation to the many-body perturbation theory and includes three-body correlations. We show that the model can reproduce the long-wavelength part of the structure factor in the entire range of momentum transfer, including the region of large momentum transfer, where the three-body contribution is dominant. The model also provides a good description of the short-wavelength part of the structure factor in the region of small momentum transfer. The motivation for the work is to provide a microscopic model that describes the structure factor of solid methane in a wide range of momentum transfer, in order to gain insight into the structure and dynamics of this system. The results obtained are in good agreement with the available experimental data, and the model provides a good description of the structure factor in the entire range of momentum transfer. The practical application of the work is that it provides a microscopic model that can be used to study the structure and dynamics of solid methane in a wide range of momentum transfer. The theoretical application of the work is that it provides a basis for understanding the structure and dynamics of solid methane in a wide range of momentum transfer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hagedorn Strings and Correspondence Principle in AdS(3). Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4514, "human_text": "  Motivated by the possibility of formulating a strings/black hole correspondence in AdS space, we extract the Hagedorn behavior of thermal AdS_3 bosonic string from 1-loop partition function of SL(2,R) WZW model. We find that the Hagedorn temperature is monotonically increasing as the AdS radius shrinks, reaches a maximum of order of string scale set by the unitarity bound of the CFT for internal space. The resulting density of states near the Hagedorn temperature resembles the form as for strings in flat space and is dominated by the space-like long string configurations. We then argue a conjectured strings/black hole correspondence in AdS space by applying the Hagedorn thermodynamics. We find the size of the corresponding black hole is a function of the AdS radius. For large AdS radius a black hole far bigger than the string scale will form. On the contrary, when the AdS and string scales are comparable a string size black hole will form. We also examine strings on BTZ background obtained through SL(2,Z) transformation. We find a tachyonic divergence for a BTZ black hole of string scale size. ", "machine_text": "  We study the Hagedorn strings in AdS(3) with an emphasis on the behavior of the partition functions in the thermodynamic limit. We show that the existence of an AdS(3) duality implies that the Hagedorn strings have a natural thermodynamic limit which in turn implies that the thermodynamic limit of the Hagedorn strings in AdS(3) is equivalent to the thermodynamic limit of the ordinary Nambu strings in AdS(2). We show that the correspondence principle for the Hagedorn strings in AdS(3) can be understood by using the ordinary Nambu strings in AdS(2) as an example. We show that the Hagedorn strings in AdS(3) are related to the odd-frequency HE string and that the Hagedorn string in AdS(3) is an infinite-dimensional generalization of the odd-frequency HE string. We show that the Hagedorn strings in AdS(3) are related to the five-string and that the Hagedorn string in AdS(3) is an infinite-dimensional generalization of the five-string. We show that the Hagedorn strings in AdS(3) are related to the two-string and that the Hagedorn string in AdS(3) is an infinite-dimensional generalization of the two-string.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Acceleration of the Universe driven by the Casimir force. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1772, "human_text": "  We investigate an evolutional scenario of the FRW universe with the Casimir energy scaling like $(-)(1+z)^4$. The Casimir effect is used to explain the vacuum energy differences (its value measured from astrophysics is so small compared to value obtained from quantum field theory calculations). The dynamics of the FRW model is represented in terms of a two-dimensional dynamical system to show all evolutional paths of this model in the phase space for all admissible initial conditions. We find also an exact solution for non flat evolutional paths of Universe driven by the Casimir effect. The main difference between the FRW model with the Casimir force and the $\\Lambda$CDM model is that their generic solutions are a set of evolutional paths with a bounce solution and an initial singularity, respectively. The evolutional scenario are tested by using the SNIa data, FRIIb radiogalaxies, baryon oscillation peak and CMB observation. We compare the power of explanation of the model considered and the $\\Lambda$CDM model using the Bayesian information criterion and Bayesian factor. Our investigation of the information criteria of model selection showed the preference of the $\\Lambda$CDM model over the model considered. However the presence of negative like the radiation term can remove a tension between the theoretical and observed primordial ${}^4$He and D abundance. ", "machine_text": " We propose that the acceleration of the Universe, recently reported by the Supernovae iiP2 and SNHBdb surveys, is driven by the Casimir force. We show that, in contrast to the attractive Casimir force between two parallel plates, the repulsive Casimir force between two Universe-sized (and flat) parallel membranes is finite and inward-directed, and its magnitude is precisely the numerical value reported by the Supernoves iiP2 and SNHBdb surveys. We evaluate the mass density needed to produce this finite and inward-directed Casimir force, and find that it is in agreement with the density required to accelerate the Universe by the observed amount. Our conclusion is that the observed acceleration of the Universe is the result of the repulsive Casimir force acting between the two parallel membranes that bound the Universe. We also show that the standard attractive Casimir force can be understood as the repulsive Casimir force acting between two very small (as small as a Planck length) and very close parallel membranes, which are present in every macroscopic attractive Casimir system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the cycling operation in braid groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.26, "human_text": "  The cycling operation is a special kind of conjugation that can be applied to elements in Artin's braid groups, in order to reduce their length. It is a key ingredient of the usual solutions to the conjugacy problem in braid groups. In their seminal paper on braid-cryptography, Ko, Lee et al. proposed the {\\it cycling problem} as a hard problem in braid groups that could be interesting for cryptography. In this paper we give a polynomial solution to that problem, mainly by showing that cycling is surjective, and using a result by Maffre which shows that pre-images under cycling can be computed fast. This result also holds in every Artin-Tits group of spherical type.   On the other hand, the conjugacy search problem in braid groups is usually solved by computing some finite sets called (left) ultra summit sets (left-USS), using left normal forms of braids. But one can equally use right normal forms and compute right-USS's. Hard instances of the conjugacy search problem correspond to elements having big (left and right) USS's. One may think that even if some element has a big left-USS, it could possibly have a small right-USS. We show that this is not the case in the important particular case of rigid braids. More precisely, we show that the left-USS and the right-USS of a given rigid braid determine isomorphic graphs, with the arrows reversed, the isomorphism being defined using iterated cycling. We conjecture that the same is true for every element, not necessarily rigid, in braid groups and Artin-Tits groups of spherical type. ", "machine_text": "  Let $\\Gamma$ be a finitely generated, not necessarily abelian, group, and let $\\Gamma^*$ be the group of all automorphisms of $\\Gamma$. The main result of this note is the following. If $\\Gamma$ is a group for which there exists an element $\\gamma\\in\\Gamma$ with the following property: for any $x,y\\in\\Gamma$ we have $[x,y]=[x,\\gamma y]$, then $\\Gamma$ is conjugated to a subgroup of $\\Gamma^*$. This generalizes a result of about fifty years ago of arbitration significance for finite groups.  Let $\\Gamma$ be a group, and let $\\Gamma^*$ be the group of all automorphisms of $\\Gamma$. If $\\Gamma$ is abelian, then $\\Gamma$ is conjugated to a subgroup of $\\Gamma^*$ if and only if $\\Gamma$ is a cyclic group. If $\\Gamma$ is not abelian, then $\\Gamma$ is conjugated to a subgroup of $\\Gamma^*$ if and only if $\\Gamma$ is a group for which there exists an element $\\gamma\\in\\Gamma$ with the following property: for any $x,y\\in\\Gamma$ we have $[x,y]=[x,\\gamma y]$.  We prove the first of these two results, and leave the second as an exercise for the reader.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ground-state magneto-optical resonances in Cesium vapour confined in an   extremely thin cell. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.301, "human_text": "  Experimental and theoretical studies are presented related to the ground-state magneto-optical resonance prepared in Cesium vapour confined in an Extremely Thin Cell (ETC, with thickness equal to the wavelength of the irradiating light). It is shown that the utilization of the ETC allows one to examine the formation of a magneto-optical resonance on the individual hyperfine transitions, thus distinguishing processes resulting in dark (reduced absorption) or bright (enhanced absorption) resonance formation. We report on an experimental evidence of the bright magneto-optical resonance sign reversal in Cs atoms confined in the ETC. A theoretical model is proposed based on the optical Bloch equations that involves the elastic interaction processes of atoms in the ETC with its walls resulting in depolarization of the Cs excited state which is polarized by the exciting radiation. This depolarization leads to the sign reversal of the bright resonance. Using the proposed model, the magneto-optical resonance amplitude and width as a function of laser power are calculated and compared with the experimental ones. The numerical results are in good agreement with the experiment. ", "machine_text": "  We report on the observation of ground-state magneto-optical resonances in Cesium vapour confined in an extremely thin cell. Our observations are in good agreement with theoretical predictions based on a model of the light-condensed Cesium vapour. We show that the dynamics of the light-condensed Cesium vapour can be very well described by a six-level model, in spite of the fact that our measurements are in the transient regime of the condensation process. Our results suggest that the dynamics of the condensation process is very fast on a optical time scale. We have derived a simple expression for the number ratio of the two lowest resonance levels in terms of the density of Cesium vapour and the length of the vapor cell. Our findings are important for the further development of optical lattices, because they demonstrate that extremely thin cells can be used to confine Cesium vapour, in spite of the fact that Cesium has a high atomic number and is therefore difficult to confine by static electric fields.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analyzing Design Process and Experiments on the AnITA Generic Tutoring   System. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1402, "human_text": "  In the field of tutoring systems, investigations have shown that there are many tutoring systems specific to a specific domain that, because of their static architecture, cannot be adapted to other domains. As consequence, often neither methods nor knowledge can be reused. In addition, the knowledge engineer must have programming skills in order to enhance and evaluate the system. One particular challenge is to tackle these problems with the development of a generic tutoring system. AnITA, as a stand-alone application, has been developed and implemented particularly for this purpose. However, in the testing phase, we discovered that this architecture did not fully match the user's intuitive understanding of the use of a learning tool. Therefore, AnITA has been redesigned to exclusively work as a client/server application and renamed to AnITA2. This paper discusses the evolvements made on the AnITA tutoring system, the goal of which is to use generic principles for system re-use in any domain. Two experiments were conducted, and the results are presented in this paper. ", "machine_text": " Analyzing Design Process and Experiments on the AnITA Generic Tutoring System This paper presents the design process and several experiments that have been carried out on the AnITA Generic Tutoring System (AGTS), a tutoring system for teaching programming that is based on the Architecture of Integrated Technological Assault (AITA) architecture. The motivation of the research is the lack of generic tutoring systems that can be used by several subjects. The main idea of the work is to analyze the impact of different factors on the performance of AGTS. The methodology used is a mixed approach that includes experimental research, design of experiments, and statistical analysis. Several experiments have been carried out in which several factors have been manipulated, such as the language used for programming, the type of exercise, and the level of assistance. The results of the experiments show that the performance of AGTS is affected by the language used, the type of exercise, and the level of assistance. The practical implications of the work are the possibility of using AGTS for teaching programming to different subjects. The theoretical implications of the work are the contribution to the understanding of the design process and the experiments in tutoring systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Statistical Evidence for Three classes of Gamma-ray Bursts. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.402, "human_text": "  Two different multivariate clustering techniques, the K-means partitioning method and the Dirichlet process of mixture modeling, have been applied to the BATSE Gamma-ray burst (GRB) catalog, to obtain the optimum number of coherent groups. In the standard paradigm, GRB are classified in only two groups, the long and short bursts. However, for both the clustering techniques, the optimal number of classes was found to be three, a result which is consistent with previous statistical analysis. In this classification, the long bursts are further divided into two groups which are primarily differentiated by their total fluence and duration and hence are named low and high fluence GRB. Analysis of GRB with known red-shifts and spectral parameters suggests that low fluence GRB have nearly constant isotropic energy output of 10^{52} ergs while for the high fluence ones, the energy output ranges from 10^{52} to 10^{54} ergs. It is speculated that the three kinds of GRBs reflect three different origins: mergers of neutron star systems, mergers between white dwarfs and neutron stars, and collapse of massive stars. ", "machine_text": "  We present statistical evidence for three classes of gamma-ray bursts (GRBs) with different properties, which could be identified by their distinctive burst durations and peak counts. The three classes are defined by a significant excess in the number of bursts with durations shorter than 1 s and peak counts larger than 10^4) compared to the number of bursts with durations longer than 1 s and peak counts larger than 10^3), a small excess in the number of bursts with durations between 1 and 2 s and peak counts larger than 10^3) compared to the number of bursts with durations between 2 and 3 s and peak counts larger than 10^2), and a significant excess in the number of bursts with durations longer than 2 s and peak counts larger than 10^2) compared to the number of bursts with durations longer than 3 s and peak counts larger than 10^1). We show that these three classes are statistically distinct from each other with high confidence (99% for the first and second class and 95% for the third class). Our results are consistent with the view that the different burst classes correspond to different physical mechanisms of energy release. We show that the three-class model can reproduce the main features of the burst population observed in our data set and provides a good description of the observed distribution of burst durations and peak counts. We find that the most powerful bursts, in terms of peak count, are distributed approximately equally among the three classes, whereas the least powerful bursts are mostly distributed in the first two classes. This suggests that the most powerful bursts are likely to be formed through a different physical mechanism than the least powerful bursts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: General Properties of Quantum Zero-Knowledge Proofs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1129, "human_text": "  This paper studies the complexity classes QZK and HVQZK of problems having a quantum computational zero-knowledge proof system and an honest-verifier quantum computational zero-knowledge proof system, respectively. The results proved in this paper include: (a) HVQZK = QZK, (b) any problem in QZK has a public-coin quantum computational zero-knowledge proof system, (c) any problem in QZK has a quantum computational zero-knowledge proof system of perfect completeness, and (d) any problem in QZK has a three-message public-coin quantum computational zero-knowledge proof system of perfect completeness with arbitrarily small constant error in soundness. All the results above are unconditional and do not rely any computational assumptions. For the classes QPZK, HVQPZK, and QSZK of problems having a quantum perfect zero-knowledge proof system, an honest-verifier quantum perfect zero-knowledge proof system, and a quantum statistical zero-knowledge proof system, respectively, the following new properties are proved: (e) HVQPZK = QPZK, (f) any problem in QPZK has a public-coin quantum perfect zero-knowledge proof system, (g) any problem in QSZK has a quantum statistical zero-knowledge proof system of perfect completeness, and (h) any problem in QSZK has a three-message public-coin quantum statistical zero-knowledge proof system of perfect completeness with arbitrarily small constant error in soundness. It is stressed that our proofs are direct and do not use complete promise problems or those equivalents. This gives a unified framework that works well for all of quantum perfect, statistical, and computational zero-knowledge proofs, and enables us to prove properties even on the computational and perfect zero-knowledge proofs for which no complete promise problems are known. ", "machine_text": "  We study the general properties of quantum zero-knowledge proofs. We show that quantum zero-knowledge proofs can be seen as a generalization of non-interactive zero-knowledge proofs to the setting of quantum computation. As a fundamental example, we construct a quantum zero-knowledge proof system for any language in NP using only (advice for) quantum circuit families. We show that this construction can be viewed as a generalization of the Nisan-Wigderson trick to the quantum setting. As a consequence, we obtain that every language in NP has a quantum zero-knowledge proof system, provided that there exists a quantum circuit family for the language. We also show that this conclusion can be obtained using only (advice for) quantum channels. As another result, we show that if there exist quantum zero-knowledge proofs for languages in NP, then the polynomial-time assumption can be removed from the security definition of quantum zero-knowledge proofs. We show that our results imply the possibility of quantum zero-knowledge proofs for the average case of languages such asppled Marilyn or OWin, for which there is currently no (known) efficient classical proof.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Negative Matter, Repulsion Force, Dark Matter, Phantom and Theoretical   Test ----Their Relations with Inflation Cosmos and Higgs Mechanism. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2908, "human_text": "  First, dark matter is introduced. Next, the Dirac negative energy state is rediscussed. It is a negative matter with some new characteristics, which are mainly the gravitation each other, but the repulsion with all positive matter. Such the positive and negative matters are two regions of topological separation in general case, and the negative matter is invisible. It is the simplest candidate of dark matter, and can explain some characteristics of the dark matter and dark energy. Recent phantom on dark energy is namely a negative matter. We propose that in quantum fluctuations the positive matter and negative matter are created at the same time, and derive an inflation cosmos, which is created from nothing. The Higgs mechanism is possibly a product of positive and negative matter. Based on a basic axiom and the two foundational principles of the negative matter, we research its predictions and possible theoretical tests, in particular, the season effect. The negative matter should be a necessary development of Dirac theory. Finally, we propose the three basic laws of the negative matter. The existence of four matters on positive, opposite, and negative, negative-opposite particles will form the most perfect symmetrical world. ", "machine_text": " We are proposing a new concept for negative matter, repulsion force, dark matter, phantom and theoretical test with inflation cosmos and Higgs mechanism. We are motivating this concept from the fact that all the forces are resulting from the exchange of their corresponding particles. In this paper we are mainly focusing on the negative matter which has a strong impact on the formation of the structure of the universe. We are describing the concept of the negative matter and the formation of the structure of the universe due to the negative matter in the framework of the General Relativity and the Quantum Theory. We are also discussing the role of the repulsion force due to the negative matter on the structure of the universe. We are also discussing the concept of the phantom and its role in the formation of the structure of the universe. We are also theoretically testing the concept of the negative matter, repulsion force, dark matter, phantom and theoretical test with inflation cosmos and Higgs mechanism.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Zgamma production and limits on anomalous ZZgamma and Zgammagamma   couplings in ppbar collisions at sqrt(s) = 1.96 TeV. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.155, "human_text": "  We present a study of eegamma and mumugamma events using 1109 (1009) pb-1 of data in the electron (muon) channel, respectively. These data were collected with the D0 detector at the Fermilab Tevatron ppbar Collider at sqrt(s) = 1.96 TeV. Having observed 453 (515) candidates in the eegamma (mumugamma) final state, we measure the Zgamma production cross section for a photon with transverse energy ET > 7 GeV, separation between the photon and leptons Delta R(lgamma) > 0.7, and invariant mass of the di-lepton pair M(ll) > 30 GeV/c^2, to be 4.96 +/- 0.30(stat. + syst.) +/- 0.30(lumi.) pb, in agreement with the standard model prediction of 4.74 +/- 0.22 pb. This is the most precise Zgamma cross section measurement at a hadron collider. We set limits on anomalous trilinear Zgammagamma and ZZgamma gauge boson couplings of -0.085 < h(30)^(gamma) < 0.084, -0.0053 < h(40)^(gamma) < 0.0054 and -0.083 < h(30)^(Z) < 0.082, -0.0053 < h(40)^(Z) < 0.0054 at the 95% C.L. for the form-factor scale Lambda = 1.2 TeV. ", "machine_text": " We study the production of Zgamma in ppbar collisions at sqrt(s) = 1.96 TeV, and we present limits on anomalous ZZgamma and Zgammagamma couplings in these collisions. We use the event-by-event tracking method based on the late-time behavior of theonia tracks, and we find that the Zgamma production cross section in ppbar collisions is consistent with the standard model prediction, and we obtain the Zgamma longitudinal production ratio to be slightly larger than one. We also present limits on the production of ZZgamma and Zgammagamma in ppbar collisions at sqrt(s) = 1.96 TeV. The limits are derived from the observation that the cross section for the production of Zgamma is small in ppbar collisions compared to that in pp collisions, and the limit is then derived from the difference between the two cross sections. We find that the standard model prediction for the cross section of ZZgamma production is consistent with our observation, and we obtain limits on the anomalous ZZgamma coupling parameter in the range of 1.0-1.5 GeV^{-1} at the level of 2.5sigma, and limits on the anomalous Zgammagamma coupling parameter in the range of 0.1-0.9 GeV^{-2} at the level of 2.5sigma.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The outburst of the eruptive young star OO Serpentis between 1995 and   2006. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1231, "human_text": "  OO Serpentis is a deeply embedded pre-main sequence star that went into outburst in 1995 and gradually faded afterwards. Its eruption resembled the well-known FU Orionis-type or EX Lupi-type outbursts. Since very few such events have ever been documented at infrared wavelengths, our aim is to study the temporal evolution of OO Ser in the infrared. OO Ser was monitored with the Infrared Space Observatory starting 4 months after peak brightness and covering 20 months. In 2004-2006 we again observed OO Ser from the ground and complemented this dataset with archival Spitzer obsevations also from 2004. We analysed these data with special attention to source confusion and constructed light curves at 10 different wavelengths as well as spectral energy distributions. The outburst caused brightening in the whole infrared regime. According to the infrared light curves, OO Ser started a wavelength-independent fading after peak brightness. Later the flux decay became slower but stayed wavelength-independent. The fading is still ongoing, and current fading rates indicate that OO Ser will not return to quiescent state before 2011. The outburst timescale of OO Ser seems to be shorter than that of FUors, but longer than that of EXors. The outburst timescale and the moderate luminosity suggest that OO Ser is different from both FUors and EXors, and shows similarities to the recently erupted young star V1647 Ori. Based on its spectral energy distribution and bolometric temperature, OO Ser seems to be an early class I object, with an age of < 10^5 yr. The object is probably surrounded by an accretion disc and a dense envelope. Due to the shorter outburst timescales, the viscosity in the circumstellar disc of OO Ser is probably an order of magnitude higher than usual for FUors. ", "machine_text": "  We present photometric observations of the young star OO Serpentis between 1995 and 2006. During this time, the accretion outburst which had begun in 1989 decayed, then resumed with a peak in 2001, and finally returned to its quiescent state. We find that the accretion rate was relatively constant during the quiescence, but that it increased abruptly at the start of the outburst. The accretion rate was higher during the first year of the outburst than in the subsequent years. We interpret these results in terms of a model in which the accretion torque on the donor is balanced by the magnetic torque from a magnetic accretion disc around the donor. We discuss the efficiency of the accretion process by comparing our observations with predictions from the model. We find that the accretion efficiency is relatively low, and that it does not decrease monotonically with accretion rate, as expected from the model. We suggest that the low accretion efficiency may be due to the fact that the accretion disc is not strongly magnetized.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Consistent reasoning about a continuum of hypotheses on the basis of   finite evidence. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2274, "human_text": "  In the modern Bayesian view classical probability theory is simply an extension of conventional logic, i.e., a quantitative tool that allows for consistent reasoning in the presence of uncertainty. Classical theory presupposes, however, that--at least in principle--the amount of evidence that an experimenter can accumulate always matches the size of the hypothesis space. I investigate how the framework for consistent reasoning must be modified in non-classical situations where hypotheses form a continuum, yet the maximum evidence accessible through experiment is not allowed to exceed some finite upper bound. Invoking basic consistency requirements pertaining to the preparation and composition of systems, as well as to the continuity of probabilities, I show that the modified theory must have an internal symmetry isomorphic to the unitary group. It thus appears that the only consistent algorithm for plausible reasoning about a continuum of hypotheses on the basis of finite evidence is furnished by quantum theory in complex Hilbert space. ", "machine_text": " We propose a framework for consistent reasoning about a continuum of hypotheses on the basis of finite evidence, which we call discriminatory sketch-based reasoning (DSBR). Given a collection of sketches representing pieces of evidence, DSBR maps the sketches into a latent space of hypotheses and uses a discrimination function to score the hypotheses. We show that DSBR is well-defined provided that the discrimination function is monotonically related to a continuous function of the sketch representations. We then develop a general framework forDSBR, and show how it can be applied to several concrete tasks, such as discriminating between handwritten digits, faces, and gestures. We also show how to optimize the performance of DSBR using a branch-and-bound method. Finally, we present an experimental evaluation of DSBR on the tasks mentioned above, as well as a new task of distinguishing between yoga and Pilates poses, and demonstrate that DSBR achieves state-of-the-art performance on all tasks while being computationally efficient.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis of Spitzer Spectra of Irradiated Planets: Evidence for Water   Vapor?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2457, "human_text": "  Published mid infrared spectra of transiting planets HD 209458b and HD 189733b, obtained during secondary eclipse by the InfraRed Spectrograph (IRS) aboard the Spitzer Space Telescope, are predominantly featureless. In particular these flux ratio spectra do not exhibit an expected feature arising from water vapor absorption short-ward of 10 um. Here we suggest that, in the absence of flux variability, the spectral data for HD 189733b are inconsistent with 8 um-photometry obtained with Spitzer's InfraRed Array Camera (IRAC), perhaps an indication of problems with the challenging reduction of the IRS spectra. The IRAC point, along with previously published secondary eclipse photometry for HD 189733b, are in good agreement with a one-dimensional model of HD 189733b that clearly shows absorption due to water vapor in the emergent spectrum. We are not able to draw firm conclusions regarding the IRS data for HD 209458b, but spectra predicted by 1D and 3D atmosphere models fit the data adequately, without adjustment of the water abundance or reliance on cloud opacity. We argue that the generally good agreement between model spectra and IRS spectra of brown dwarfs with atmospheric temperatures similar to these highly irradiated planets lends confidence in the modeling procedure. ", "machine_text": " We present the results of an analysis of Spitzer spectra of irradiated planets, including an analysis of the relative concentrations of water vapor and other atmospheric constituents, such as carbon dioxide, as a function of planet age. We found that the older planets have higher concentrations of water vapor than younger planets, which we attribute to the longer exposure to the Poynting- peaked radiation field. The difference is large enough to change the chemical makeup of the atmosphere. We found that the difference in the water vapor concentrations is more significant than the difference between the concentration of carbon dioxide in younger and older planets. We also found that the difference in the optical depth of water vapor between older and younger planets is smaller than the difference in the optical depth of carbon dioxide. We attribute this to the difference in the molecular weight of the two gases. This has important implications for the photochemistry and thermal structure of the atmospheres of these planets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Close Look at Star Formation around Active Galactic Nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1374, "human_text": "  We analyse star formation in the nuclei of 9 Seyfert galaxies at spatial resolutions down to 0.085arcsec, corresponding to length scales of less than 10pc in some objects. Our data were taken mostly with the near infrared adaptive optics integral field spectrograph SINFONI. The stellar light profiles typically have size scales of a few tens of parsecs. In two cases there is unambiguous kinematic evidence for stellar disks on these scales. In the nuclear regions there appear to have been recent - but no longer active - starbursts in the last 10-300Myr. The stellar luminosity is less than a few percent of the AGN in the central 10pc, whereas on kiloparsec scales the luminosities are comparable. The surface stellar luminosity density follows a similar trend in all the objects, increasing steadily at smaller radii up to 10^{13}L_sun/kpc^2 in the central few parsecs, where the mass surface density exceeds 10^4M_sun/pc^2. The intense starbursts were probably Eddington limited and hence inevitably short-lived, implying that the starbursts occur in multiple short bursts. The data hint at a delay of 50--100Myr between the onset of star formation and subsequent fuelling of the black hole. We discuss whether this may be a consequence of the role that stellar ejecta could play in fuelling the black hole. While a significant mass is ejected by OB winds and supernovae, their high velocity means that very little of it can be accreted. On the other hand winds from AGB stars ultimately dominate the total mass loss, and they can also be accreted very efficiently because of their slow speeds. ", "machine_text": "  We present a systematic study of star formation around active galactic nuclei (AGN) in nearby galaxies, based on an analysis of the optical images obtained with the Hubble Space Telescope. Our main aim is to investigate the relation between the activity of the central AGN and the star formation rate (SFR) in the surrounding regions. We find that the SFRs in the regions close to AGN (within 50 arcsec) are, on average, higher than in the rest of the galaxy. We show this by using the color-magnitude diagrams of the galaxies, in which the SFR is traced by the absolute magnitude of the main star-forming region. This result is in agreement with previous work based on the analysis of the H\u03b1 images, and it indicates that the AGN activity is somehow promoting star formation in the nearby regions. We also show that the SFR is higher in regions with low metallicity, confirming the results of previous studies based on H\u03b1 images. We discuss several physical mechanisms that may be responsible for the triggering of star formation by the AGN activity, and we suggest that the low metallicity in the regions close to the AGN is due to the photoevaporation of the gas by the AGN's radiation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Daemons and DAMA: Their Celestial-Mechanics Interrelations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0982, "human_text": "  The assumption of the capture by the Solar System of the electrically charged Planckian DM objects (daemons) from the galactic disk is confirmed not only by the St.Petersburg (SPb) experiments detecting particles with V<30 km/s. Here the daemon approach is analyzed considering the positive model independent result of the DAMA/NaI experiment. We explain the maximum in DAMA signals observed in the May-June period to be associated with the formation behind the Sun of a trail of daemons that the Sun captures into elongated orbits as it moves to the apex. The range of significant 2-6-keV DAMA signals fits well the iodine nuclei elastically knocked out of the NaI(Tl) scintillator by particles falling on the Earth with V=30-50 km/s from strongly elongated heliocentric orbits. The half-year periodicity of the slower daemons observed in SPb originates from the transfer of particles that are deflected through ~90 deg into near-Earth orbits each time the particles cross the outer reaches of the Sun which had captured them. Their multi-loop (cross-like) trajectories traverse many times the Earth's orbit in March and September, which increases the probability for the particles to enter near-Earth orbits during this time. Corroboration of celestial mechanics calculations with observations yields ~1e-19 cm2 for the cross section of daemon interaction with the solar matter. ", "machine_text": " We present here an interdisciplinary study in which the tools of celestial mechanics are used to examine some of the issues raised by the DAMA/NIM-wide-area-survey/ asap experiments. We show that an appropriately simple model can describe the motion of both the DAMA/NIM and asap detectors. This model is based on the relative motion of the Earth and a point-mass \"Planet X\" in a guess-range spherical potential well, the deepest part of which is located at the orbit of the Kuiper belt. In this model the amplitudes of the DAMA/NIM and asap signals are determined by the Earth's velocity as it moves in and out of the well, while the phase of the signal depends on the exact location of the Earth within the well. We show that the combination of a suitable choice of the well's location and the Earth's entry and exit velocities can explain both the observed DAMA/NIM and asap data, without the need to introduce any other relativistic effects. Within this model the simplest explanation for the observed data is that the well is centered at the orbit of the Kuiper belt, and that the Earth's entry and exit velocities from the well are the same, in which case the Earth's orbit is a closed, unchanging, ellipse. We show that the data can also be explained if the well is slightly offset from the Kuiper belt, in which case the Earth's orbit slowly converges to a closed, unchanging, ellipse. We also show that the data can be explained if the well is centered very far from the Sun, in which case the Earth's orbit slowly diverges from a closed, unchanging, ellipse. We discuss several ways in which the \"Planet X\" model can be tested, and we point out that the motion of the Earth can be used to determine the location of the well, provided that the well's potential is known.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Minimum Expected Distortion in Gaussian Layered Broadcast Coding with   Successive Refinement. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2659, "human_text": "  A transmitter without channel state information (CSI) wishes to send a delay-limited Gaussian source over a slowly fading channel. The source is coded in superimposed layers, with each layer successively refining the description in the previous one. The receiver decodes the layers that are supported by the channel realization and reconstructs the source up to a distortion. In the limit of a continuum of infinite layers, the optimal power distribution that minimizes the expected distortion is given by the solution to a set of linear differential equations in terms of the density of the fading distribution. In the optimal power distribution, as SNR increases, the allocation over the higher layers remains unchanged; rather the extra power is allocated towards the lower layers. On the other hand, as the bandwidth ratio b (channel uses per source symbol) tends to zero, the power distribution that minimizes expected distortion converges to the power distribution that maximizes expected capacity. While expected distortion can be improved by acquiring CSI at the transmitter (CSIT) or by increasing diversity from the realization of independent fading paths, at high SNR the performance benefit from diversity exceeds that from CSIT, especially when b is large. ", "machine_text": "  Minimum Expected Distortion in Gaussian Layered Broadcast Coding with Successive Refinement  We consider the problem of Gaussian layered broadcast coding with successive refinement (BLBCSR), which is the problem of communicating over a broadcast channel with a finite number of identical receivers, while minimizing the expected distortion per receiver. We show that, in contrast to the case with a Gaussian layered channel, for which there exists a universal layering scheme that achieves the minimum possible distortion, in the case of BLBCSR the minimum expected distortion can only be achieved by using a scheme in which the number of layers is not greater than the number of receivers. We show that the number of layers is a strict inequality, rather than an equality, by deriving a new, tractable upper bound on the minimum expected distortion. The bound is achieved by using a successive-refinement technique, in which one sends the first few layers at the highest rate possible, and then gradually increases the number of layers while decreasing the rate on each layer.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Infrared Cloud Monitor for the MAGNUM Robotic Telescope at Haleakala. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.227, "human_text": "  We present the most successful infrared cloud monitor for a robotic telescope. This system was originally developed for the MAGNUM 2-m telescope, which has been achieving unmanned and automated monitoring observation of active galactic nuclei at Haleakala on the Hawaiian island of Maui since 2001. Using a thermal imager and two aspherical mirrors, it at once sees almost the whole sky at a wavelength of $\\lambda\\sim 10\\mu{\\rm m}$. Its outdoor part is weather-proof and is totally maintenance-free. The images obtained every one or two minutes are analysed immediately into several ranks of weather condition, from which our automated observing system not only decides to open or close the dome, but also selects what types of observations should be done. The whole-sky data accumulated over four years show that 50$-$60 % of all nights are photometric, and about 75 % are observable with respect to cloud condition at Haleakala. Many copies of this system are now used all over the world such as Mauna Kea in Hawaii, Atacama in Chile, and Okayama and Kiso in Japan. ", "machine_text": "  The Infrared Cloud Monitor for the MAGNUM Robotic Telescope at Haleakala  We describe a new instrument, the Infrared Cloud Monitor (ICM), an automated cloud cover monitor operating in the near-infrared. The ICM is designed to operate with the MAGNUM Robotic Telescope (MRT) at Haleakal\u0101, Hawaii. The ICM measures the amount of cloud cover between the telescope and the sky by detecting the glow from the earth's atmosphere. We describe the motivation for the ICM, the instrument's design, implementation, and operation, and the analysis of the data from the first year of operation. We find that the ICM is capable of monitoring the cloud cover at a high temporal resolution, at a level of sensitivity suitable for triggering the measurement of the optical depth of the atmosphere when cloud-free conditions are present. The ICM is an indispensable tool for the optimal operation of the MRT because it enables weather forecasts for the telescope. We also find that the ICM can be used to study the cloud properties by analyzing the non-common mode components of the ICM data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bit-Interleaved Coded Multiple Beamforming with Imperfect CSIT. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2009, "human_text": "  This paper addresses the performance of bit-interleaved coded multiple beamforming (BICMB) [1], [2] with imperfect knowledge of beamforming vectors. Most studies for limited-rate channel state information at the transmitter (CSIT) assume that the precoding matrix has an invariance property under an arbitrary unitary transform. In BICMB, this property does not hold. On the other hand, the optimum precoder and detector for BICMB are invariant under a diagonal unitary transform. In order to design a limited-rate CSIT system for BICMB, we propose a new distortion measure optimum under this invariance. Based on this new distortion measure, we introduce a new set of centroids and employ the generalized Lloyd algorithm for codebook design. We provide simulation results demonstrating the performance improvement achieved with the proposed distortion measure and the codebook design for various receivers with linear detectors. We show that although these receivers have the same performance for perfect CSIT, their performance varies under imperfect CSIT. ", "machine_text": "  Bit-Interleaved Coded Multiple Beamforming with Imperfect CSIT  We propose a novel technique for the downlink of a Multi-User Multiple-Input Multiple-Output (MU-MIMO) system that incorporates beamforming and Bit-Interleaved Coded Modulation (BICM) to combat channel uncertainty in the Channel State Information at Transmitter (CSIT). Our proposed technique, which we dub Bit-Interleaved Coded Multiple Beamforming (BICMB), extends the single-user BICM scheme to a MU-MIMO system. In our proposed scheme, the receiver is aware of the bit-interleaved codebook used by the transmitter, and hence, it is able to perform Chase Combining (CC) of the multiple copies of its own codeword. Since the channel may not be perfectly known at the transmitter, the proposed scheme employs a codeword adaptation algorithm that varies the number of bits allocated to the different transmit beams in order to maximize the throughput. The proposed scheme is particularly well-suited for a system where the transmitter has a large number of transmit antennas, and therefore, a large number of possible beams, but only a coarse estimate of the channel at the transmitter. In such a system, the proposed scheme may achieve close to the same performance as a system where the channel is perfectly known at the transmitter, while requiring much less channel feedback. The proposed scheme is analyzed and compared to other related schemes in the downlink of a MU-MIMO system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New scaling relations in cluster radio halos and the re-acceleration   model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.349, "human_text": "  In this paper we derive new expected scaling relations for clusters with giant radio halos in the framework of the re-acceleration scenario in a simplified, but physically motivated, form, namely: radio power (P_R) vs size of the radio emitting region (R_H), and P_R vs total cluster mass (M_H) contained in the emitting region and cluster velocity dispersion (sigma_H) in this region.   We search for these correlations by analyzing the most recent radio and X-ray data available in the literature for a well known sample of clusters with giant radio halos. In particular we find a good correlation between P_R and R_H and a very tight ``geometrical'' scaling between M_H and R_H. From these correlations P_R is also expected to scale with M_H and sigma_H and this is confirmed by our analysis. We show that all the observed trends can be well reconciled with expectations in the case of a slight variation of the mean magnetic field strength in the radio halo volume with M_H. A byproduct correlation between R_H and sigma_H is also found, and can be further tested by optical studies. In addition, we find that observationally R_H scales non-linearly with the virial radius of the host cluster, and this immediately means that the fraction of the cluster volume which is radio emitting increases with cluster mass and thus that the non-thermal component in clusters is not self-similar. ", "machine_text": " We present scaling relations for the intensity distribution of radio halos in cluster galaxies, based on the analysis of a sample of 52 clusters with galaxies in the range 8 < log(Mpc/h) < 11. We find that the correlation between the radio halo intensity and the cluster mass is described by a power law with a correlation coefficient of 0.71. The power law index is 1.25 +0.19 and is consistent with the index predicted by the re-acceleration model. We also find that the radio halo intensity distribution is well described by a log-normal distribution with a standard deviation of 1.25, implying that the radio halos in clusters have a scale-free intensity distribution. We discuss these results in the context of the re-acceleration model, which predicts that the power law index is 1.0 and that the distribution is scale-free. We also present a comparison between our results and the predictions of the first-order gradient instability model. We find that the scaling relations we observe are consistent with a model in which the radio halo intensity distribution is determined by the superposition of a small number of discrete, localised sources, and that the correlation between the radio halo intensity and the cluster mass can be described by a simple first-order differential equation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: What are the Best Hierarchical Descriptors for Complex Networks?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4251, "human_text": "  This work reviews several hierarchical measurements of the topology of complex networks and then applies feature selection concepts and methods in order to quantify the relative importance of each measurement with respect to the discrimination between four representative theoretical network models, namely Erd\\\"{o}s-R\\'enyi, Barab\\'asi-Albert, Watts-Strogatz as well as a geographical type of network. The obtained results confirmed that the four models can be well-separated by using a combination of measurements. In addition, the relative contribution of each considered feature for the overall discrimination of the models was quantified in terms of the respective weights in the canonical projection into two dimensions, with the traditional clustering coefficient, hierarchical clustering coefficient and neighborhood clustering coefficient resulting particularly effective. Interestingly, the average shortest path length and hierarchical node degrees contributed little for the separation of the four network models. ", "machine_text": "  We introduce a new family of algorithms for extracting topological structure from large complex networks that are believed to be scale-free or small-world in their connectivity distribution. Our approach is based on finding the smallest subgraph that is a good approximation of the original network in terms of several well-defined graph properties. We show that for a large class of networks, the size of this approximation subgraph is proportional to the logarithm of the number of nodes in the network. Furthermore, the number of edges in this subgraph is guaranteed to be at most twice the number of edges in the largest clique in the network. We implement our algorithm in a computer program called Quasyclique, and evaluate its efficiency on several real-world networks. In terms of the quality of the extracted subgraph, we show that our algorithm is guaranteed to extract the clique that contains the largest number of nodes, and that this clique contains at most one edge per node, on average. We also show that our algorithm extracts the clique that is the best approximation to the network in terms of the number of cliques it contains. Our algorithm runs in time proportional to the square of the number of nodes in the network.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: BEC-BCS Crossover of a Trapped Two-Component Fermi Gas with Unequal   Masses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0671, "human_text": "  We determine the energetically lowest lying states in the BEC-BCS crossover regime of s-wave interacting two-component Fermi gases under harmonic confinement by solving the many-body Schrodinger equation using two distinct approaches. Essentially exact basis set expansion techniques are applied to determine the energy spectrum of systems with N=4 fermions. Fixed-node diffusion Monte Carlo methods are applied to systems with up to N=20 fermions, and a discussion of different guiding functions used in the Monte Carlo approach to impose the proper symmetry of the fermionic system is presented. The energies are calculated as a function of the s-wave scattering length a_s for N=2-20 fermions and different mass ratios \\kappa of the two species. On the BEC and BCS sides, our energies agree with analytically-determined first-order correction terms. We extract the scattering length and the effective range of the dimer-dimer system up to \\kappa = 20. Our energies for the strongly-interacting trapped system in the unitarity regime show no shell structure, and are well described by a simple expression, whose functional form can be derived using the local density approximation, with one or two parameters. The universal parameter \\xi for the trapped system for various \\kappa is determined, and comparisons with results for the homogeneous system are presented. ", "machine_text": " We study a trapped two-component Fermi gas with unequal masses. The system is exactly solved in the limit of large masses. We obtain a general formula for the density-of-states (DOS) as a function of the mass ratio. It is shown that a crossover from a pure BCS state to a BEC state as the mass ratio is varied. The crossover temperature is obtained as a function of the mass ratio. Our result is consistent with the recent experimental observation of a crossover temperature for a gas of magnetic atoms.  We study a trapped two-component Fermi gas with unequal masses. The system is exactly solved in the limit of large masses. We obtain a general formula for the density-of-states (DOS) as a function of the mass ratio. It is shown that a crossover from a pure BCS state to a BEC state as the mass ratio is varied. The crossover temperature is obtained as a function of the mass ratio. Our result is consistent with the recent experimental observation of a crossover temperature for a gas of magnetic atoms.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Panchromatic Study of the Globular Cluster NGC 1904. I: The Blue   Straggler Population. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1393, "human_text": "  By combining high-resolution (HST-WFPC2) and wide-field ground based (2.2m ESO-WFI) and space (GALEX) observations, we have collected a multi-wavelength photometric data base (ranging from the far UV to the near infrared) of the galactic globular cluster NGC1904 (M79). The sample covers the entire cluster extension, from the very central regions up to the tidal radius. In the present paper such a data set is used to study the BSS population and its radial distribution. A total number of 39 bright ($m_{218}\\le 19.5$) BSS has been detected, and they have been found to be highly segregated in the cluster core. No significant upturn in the BSS frequency has been observed in the outskirts of NGC 1904, in contrast to other clusters (M 3, 47 Tuc, NGC 6752, M 5) studied with the same technique. Such evidences, coupled with the large radius of avoidance estimated for NGC 1904 ($r_{avoid}\\sim 30$ core radii), indicate that the vast majority of the cluster heavy stars (binaries) has already sunk to the core. Accordingly, extensive dynamical simulations suggest that BSS formed by mass transfer activity in primordial binaries evolving in isolation in the cluster outskirts represent only a negligible (0--10%) fraction of the overall population. ", "machine_text": " We present a study of the blue straggler (BS) population in the globular cluster NGC 1904, based on high-resolution spectroscopy and photometry of more than 500 BS candidates in the cluster. Our analysis reveals a tight correlation between the photometric and spectroscopic properties of the BSs, with the stragglers displaying a strong preference for mid- to late-type stars. We show that this preference can be understood in terms of a simple model in which the BSs are formed by the fusion of two stars of different types, with the more massive star being polluted by the lighter one. We determine the mean mass of the BSs, and find that it lies between 1.0 and 1.6 times the mass of the Sun, with a significant fraction ( possibly up to 50%) of the BSs being less massive than the Sun. The distribution of the BSs is highly non-uniform, with a strong preference for the cluster's core region. Our analysis of the BSs' orbital properties reveals a large number of close encounters between stragglers and other cluster members, suggesting that dynamical friction is probably responsible for the removal of the lighter objects from the BS population. We conclude that the observed properties of the BS population are consistent with the hypothesis that the BSs are formed by the fusion of two stars of different types, and that dynamical friction is probably responsible for the removal of the lighter objects from the population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black Hole Motion as Catalyst of Orbital Resonances. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2756, "human_text": "  The motion of a black hole about the centre of gravity of its host galaxy induces a strong response from the surrounding stellar population. We treat the case of a harmonic potential analytically and show that half of the stars on circular orbits in that potential shift to an orbit of lower energy, while the other half receive a positive boost and recede to a larger radius. The black hole itself remains on an orbit of fixed amplitude and merely acts as a catalyst for the evolution of the stellar energy distribution function f(E). We show that this effect is operative out to a radius of approx 3 to 4 times the hole's influence radius, R_bh. We use numerical integration to explore more fully the response of a stellar distribution to black hole motion. We consider orbits in a logarithmic potential and compare the response of stars on circular orbits, to the situation of a `warm' and `hot' (isotropic) stellar velocity field. While features seen in density maps are now wiped out, the kinematic signature of black hole motion still imprints the stellar line-of-sight mean velocity to a magnitude ~18% the local root mean-square velocity dispersion sigma. ", "machine_text": "  We investigate the role of black hole (BH) motion on the dynamical evolution of stellar orbits in galactic nuclei. We consider a simple model of a galactic nucleus consisting of a central massive black hole, a disc of orbiting matter and a assumed cylindrical distribution of dark matter (DM). We study the dynamics of this system by means of a two-dimensional (2D) general relativistic hydrodynamical model and show that the black hole motion can excite an instability in the disc, which in turn leads to the development of orbital resonances. Our analysis shows that these resonances are associated with the three characteristic orbital frequencies of the galactic nucleus, which can be excited by the regular motion of the black hole. In this way, the black hole motion acts as a catalyst of the orbital resonance. We discuss the role of the assumption of a cylindrical distribution of DM in the developed resonance structure and the effect of the relaxation of the DM density profile. We show that the resulting resonance structure is in agreement with the observed dynamics of the stellar orbits in the galactic nuclei.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geodesics for Efficient Creation and Propagation of Order along Ising   Spin Chains. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0378, "human_text": "  Experiments in coherent nuclear and electron magnetic resonance, and optical spectroscopy correspond to control of quantum mechanical ensembles, guiding them from initial to final target states by unitary transformations. The control inputs (pulse sequences) that accomplish these unitary transformations should take as little time as possible so as to minimize the effects of relaxation and decoherence and to optimize the sensitivity of the experiments. Here we give efficient syntheses of various unitary transformations on Ising spin chains of arbitrary length. The efficient realization of the unitary transformations presented here is obtained by computing geodesics on a sphere under a special metric. We show that contrary to the conventional belief, it is possible to propagate a spin order along an Ising spin chain with coupling strength J (in units of Hz), significantly faster than 1/(2J) per step. The methods presented here are expected to be useful for immediate and future applications involving control of spin dynamics in coherent spectroscopy and quantum information processing. ", "machine_text": "  We consider a one-dimensional Ising model with a periodically modulated non-Ising interaction $J$ in a magnetic field $H$. For a large number $N$ of spins, the system is shown to be mapped into an effective Ising model with a non-collinear $J$ field along the spins. The only states with $J>0$ are those with $N$ up spins in a row, and the only states with $J<0$ are those with $N$ down spins in a row. For a small number $N$ of spins, a more detailed analysis shows that the system is mapped into an effective Ising model with a collinear $J$ field along the spins. However, a finite number of non-Ising states with $J>0$ or $J<0$ can still be achieved by a careful choice of the field $H$. By using a golden section method, we obtain the criterion for the Ising model to be mapped into an effective model with the non-collinear $J$ field, which is shown to be equivalent to the golden section of the spins. Our results show that the Ising model is especially efficient in creating and propagating order along spin chains.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: How to Compile Some NAND Formula Evaluators. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0479, "human_text": "  We say a unitary operator acting on a set of qubits has been compiled if it has been expressed as a SEO (sequence of elementary operations, like CNOTs and single-qubit operations). SEO's are often represented as quantum circuits. arXiv:quant-ph/0702144 by Farhi-Goldstone-Gutmann has inspired a recent flurry of papers, that propose quantum algorithms for evaluating NAND formulas via quantum walks over tree graphs. These algorithms use two types of unitary evolution: oracle and non-oracle. Non-oracle evolutions are independent of the NAND formula input, whereas oracle evolutions depend on this input. In this paper we compile (i.e., give explicit SEOs and their associated quantum circuits for) the oracle and non-oracle evolution operators used in some of these NAND formula evaluators. We consider here only the case of balanced binary NAND trees. Our compilation methods are based on the CSD (Cosine Sine Decomposition), a matrix decomposition from Linear Algebra. The CS decomposition has been used very successfully in the past to compile unstructured unitary matrices exactly. ", "machine_text": "  We present a detailed design and implementation of a system for evaluating NAND expressions on flashed-based computers. Our system is based on a new two-level intermediate representation that is tailored to the specificities of flashed-based computers. It uses a very simple stack machine as a low-level intermediate representation that is compiled into a unique high-level intermediate representation that can be further compiled into different final architectures. Our system is the first that is both efficient in terms of execution time and memory usage, while being able to evaluate any NAND expression on a broad range of flashed-based computers. It is at least one order of magnitude faster than previous solutions in all tested configurations, while using at most one order of magnitude more memory. It therefore opens the route to efficient compilation chains that are able to take advantage of all the specificities of different flashed-based computers, something that was not possible with previous solutions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Zero-temperature phase of the XY spin glass in two dimensions: Genetic   embedded matching heuristic. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0227, "human_text": "  For many real spin-glass materials, the Edwards-Anderson model with continuous-symmetry spins is more realistic than the rather better understood Ising variant. In principle, the nature of an occurring spin-glass phase in such systems might be inferred from an analysis of the zero-temperature properties. Unfortunately, with few exceptions, the problem of finding ground-state configurations is a non-polynomial problem computationally, such that efficient approximation algorithms are called for. Here, we employ the recently developed genetic embedded matching (GEM) heuristic to investigate the nature of the zero-temperature phase of the bimodal XY spin glass in two dimensions. We analyze bulk properties such as the asymptotic ground-state energy and the phase diagram of disorder strength vs. disorder concentration. For the case of a symmetric distribution of ferromagnetic and antiferromagnetic bonds, we find that the ground state of the model is unique up to a global O(2) rotation of the spins. In particular, there are no extensive degeneracies in this model. The main focus of this work is on an investigation of the excitation spectrum as probed by changing the boundary conditions. Using appropriate finite-size scaling techniques, we consistently determine the stiffness of spin and chiral domain walls and the corresponding fractal dimensions. Most noteworthy, we find that the spin and chiral channels are characterized by two distinct stiffness exponents and, consequently, the system displays spin-chirality decoupling at large length scales. Results for the overlap distribution do not support the possibility of a multitude of thermodynamic pure states. ", "machine_text": " We study the zero-temperature phase of the XY spin glass in two dimensions, using a genetic algorithm to find an embedded matching heuristic. This is the first successful application of a genetic algorithm to the glass problem. The motivation for this work is that the matching heuristic has been proven to be very efficient in finding spin glass ground states, but the conventional wisdom is that this method would not be applicable in two dimensions. We show that the matching heuristic can be made to work in two dimensions, by using a genetic algorithm to evolve a heuristic that is locally very simple, but globally able to find the spin glass ground state. We find the zero-temperature phase in a class of 2D spin glasses that includes the most famous examples, such as the Harris spin glass and the ropes spin glass. Our method is based on the simple idea that we can use a genetic algorithm to learn a heuristic that is locally \"smart\" enough to avoid getting trapped in local minima, while being globally \"dumb\" enough to eventually find the global minimum. We describe our algorithm and the parameter settings used, and present results for several 2D spin glasses.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetorotational collapse of very massive stars to black holes in full   general relativity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.236, "human_text": "  We perform axisymmetric simulations of the magnetorotational collapse of very massive stars in full general relativity. Our simulations are applicable to the collapse of supermassive stars (M > 10^3M_sun) and to very massive Pop III stars. We model our initial configurations by n=3 polytropes. The ratio of magnetic to rotational kinetic energy in these configurations is chosen to be small (1% and 10%). We find that such magnetic fields do not affect the initial collapse significantly. The core collapses to a black hole, after which black hole excision is employed to continue the evolution long enough for the hole to reach a quasi-stationary state. We find that the black hole mass is M_h = 0.95M and its spin parameter is J_h/M_h^2 = 0.7, with the remaining matter forming a torus around the black hole. We freeze the spacetime metric (\"Cowling approximation\") and continue to follow the evolution of the torus after the black hole has relaxed to quasi-stationary equilibrium. In the absence of magnetic fields, the torus settles down following ejection of a small amount of matter due to shock heating. When magnetic fields are present, the field lines gradually collimate along the hole's rotation axis. MHD shocks and the MRI generate MHD turbulence in the torus and stochastic accretion onto the central black hole. When the magnetic field is strong, a wind is generated in the torus, and the torus undergoes radial oscillations that drive episodic accretion onto the hole. These oscillations produce long-wavelength gravitational waves potentially detectable by LISA. The final state of the magnetorotational collapse always consists of a central black hole surrounded by a collimated magnetic field and a hot, thick accretion torus. This system is a viable candidate for the central engine of a long-soft gamma-ray burst. ", "machine_text": " We investigate the formation of black holes in very massive stars in full general relativity. We consider a model in which the stellar mass is distributed homogeneously, and the star is rotating and axially symmetric. We find that for stars with a mass $M\\sim10^{32}$ kg, the gravitational instability against an axisymmetric perturbation (which we consider in a first approximation as adelta-pinch) is not stable against a rotation frequency $\\Omega_{\\rm crit} \\sim 2.2 \\cdot 10^{29}$ Hz. Thus, for these stars the magnetorotational instability will not be the relevant mechanism for the formation of black holes, but other mechanisms such as the direct collapse of the star to a black hole or the formation of a accretion disc around the collapsed object, that can be eventually accreted by a black hole. In addition, we find that the evolutionary track of the stellar collapse is very sensitive to the value of the adiabatic index $\\gamma$ of the gas, which must be known with a good accuracy. In particular, we find that the tidal gravity waves generated during the collapse can produce a significant increase of the gravitational radius of the object, in spite of the fact that the total mass is decreasing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observational Constraints on Interstellar Grain Alignment. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1306, "human_text": "  We present new multicolor photo-polarimetry of stars behind the Southern Coalsack. Analyzed together with multiband polarization data from the literature, probing the Chamaeleon I, Musca, rho Opiuchus, R CrA and Taurus clouds, we show that the wavelength of maximum polarization (lambda_max) is linearly correlated with the radiation environment of the grains. Using Far-Infrared emission data, we show that the large scatter seen in previous studies of lambda_max as a function of A_V is primarily due to line of sight effects causing some A_V measurements to not be a good tracer of the extinction (radiation field strength) seen by the grains being probed. The derived slopes in lambda_max vs. A_V, for the individual clouds, are consistent with a common value, while the zero intercepts scale with the average values of the ratios of total-to-selective extinction (R_V) for the individual clouds. Within each cloud we do not find direct correlations between lambda_max and R_V. The positive slope in consistent with recent developments in theory and indicating alignment driven by the radiation field. The present data cannot conclusively differentiate between direct radiative torques and alignment driven by H_2 formation. However, the small values of lambda_max(A_V=0), seen in several clouds, suggest a role for the latter, at least at the cloud surfaces. The scatter in the lambda_max vs. A_V relation is found to be associated with the characteristics of the embedded Young Stellar Objects (YSO) in the clouds. We propose that this is partially due to locally increased plasma damping of the grain rotation caused by X-rays from the YSOs. ", "machine_text": "  We present a set of guidelines for the interpretation of observations of aligned interstellar grains in a fiducial model that consists of a known initial alignment distribution, a known boundary condition at the ISM-ellar medium interface, and a known grain growth and alignment distribution function. We show that due to projection effects the observed alignment distribution will depend on the observational direction relative to the alignment distribution in the bulk, on the grain boundary condition, and on the grain growth rate. We evaluate the uncertainties in the derived alignment parameters and discuss the prospects of detecting deviations from a fiducial model. Our results indicate that a statistically significant detection of a significant deviation from a fiducial model is only possible if the observed grain boundary condition deviates significantly from a 'perfect' boundary condition, or if the growth rate is significantly different from the fiducial growth rate. We also derive a formula for the limiting error in the derived alignment parameters as a function of the observation duration, and we discuss the prospects of using observations of grain alignment for probing the properties of the interstellar medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Millennium Galaxy Catalogue: The connection between close pairs and   asymmetry; implications for the galaxy merger rate. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2528, "human_text": "  We compare the use of galaxy asymmetry and pair proximity for measuring galaxy merger fractions and rates for a volume limited sample of 3184 galaxies with -21 < M(B) -5 log h < -18 mag. and 0.010 < z < 0.123 drawn from the Millennium Galaxy Catalogue. Our findings are that:   (i) Galaxies in close pairs are generally more asymmetric than isolated galaxies and the degree of asymmetry increases for closer pairs. At least 35% of close pairs (with projected separation of less than 20 h^{-1} kpc and velocity difference of less than 500 km s^{-1}) show significant asymmetry and are therefore likely to be physically bound.   (ii) Among asymmetric galaxies, we find that at least 80% are either interacting systems or merger remnants. However, a significant fraction of galaxies initially identified as asymmetric are contaminated by nearby stars or are fragmented by the source extraction algorithm. Merger rates calculated via asymmetry indices need careful attention in order to remove the above sources of contamination, but are very reliable once this is carried out.   (iii) Close pairs and asymmetries represent two complementary methods of measuring the merger rate. Galaxies in close pairs identify future mergers, occurring within the dynamical friction timescale, while asymmetries are sensitive to the immediate pre-merger phase and identify remnants.   (iv) The merger fraction derived via the close pair fraction and asymmetries is about 2% for a merger rate of (5.2 +- 1.0) 10^{-4} h^3 Mpc^{-3} Gyr^{-1}. These results are marginally consistent with theoretical simulations (depending on the merger time-scale), but imply a flat evolution of the merger rate with redshift up to z ~1. ", "machine_text": "  We present the Millennium Galaxy Catalogue, a catalogue of galaxy pairs with projected separations of <= 50 Mpc, drawn from the Millennium Survey. We find a strong correlation between the total observed galaxy number in a pair and the asymmetry of the pair, with an excess of galaxies in the trailing half of the pair. We show this correlation to be consistent with a model in which the merger rate of a pair is proportional to the product of the number of galaxies in the pair and the asymmetry of the pair, where the asymmetry is a measure of the probability that a galaxy in the leading half of the pair is closer to the nearest galaxy in the pair than a galaxy in the trailing half. We determine the merger rate of the Millennium Galaxy Catalogue using this model, and show that it is consistent with the rate estimated from the Hamiltonian of a simple model of the formation and evolution of galaxy pairs. We find that the estimated merger rate is higher than previously estimated, but still consistent with a merge rate of <= 10 perrably per Gpc3 per year.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lattice Boltzmann Approach to High-Speed Compressible Flows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0405, "human_text": "  We present an improved lattice Boltzmann model for high-speed compressible flows. The model is composed of a discrete-velocity model by Kataoka and Tsutahara [Phys. Rev. E \\textbf{69}, 056702 (2004)] and an appropriate finite-difference scheme combined with an additional dissipation term. With the dissipation term parameters in the model can be flexibly chosen so that the von Neumann stability condition is satisfied. The influence of the various model parameters on the numerical stability is analyzed and some reference values of parameter are suggested. The new scheme works for both subsonic and supersonic flows with a Mach number up to 30 (or higher), which is validated by well-known benchmark tests. Simulations on Riemann problems with very high ratios ($1000:1$) of pressure and density also show good accuracy and stability. Successful recovering of regular and double Mach shock reflections shows the potential application of the lattice Boltzmann model to fluid systems where non-equilibrium processes are intrinsic. The new scheme for stability can be easily extended to other lattice Boltzmann models. ", "machine_text": "  We propose and analyze a lattice Boltzmann scheme for the solution of the compressible Euler equations in a simple geometrically periodic domain. The method is based on the solution of the Boltzmann equation with a stochastic cancellation procedure, which is exact in the limit of a large number of lattice sites. We show that this scheme is unconditionally stable and that it preserves the speed of sound, both of which are important and difficult to achieve in lattice Boltzmann methods for incompressible flows. To achieve these results we develop a new interpretation of the lattice Boltzmann method as a stochastic process with a reservation of the total kinetic energy. This interpretation is different from the standard one based on the Kolmogorov equation, but is more suitable for the analysis of the method and for the understanding of its limitations. This approach also enables us to study the statistical properties of the solution, which are different in the presence of compression. We show that the standard lattice Boltzmann method is not appropriate for high-speed compressible flows, due to the effect of the grid spacing on the speed of sound. Our method is shown to be accurate and stable for a large range of Knudsen numbers, including the limit in which the grid does not affect the solution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Universal spectrum for DNA base CG frequency distribution in Takifugu   rubripes (Puffer fish) genome. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2114, "human_text": "  The frequency distribution of DNA bases A, C, G, T exhibit fractal fluctuations ubiquitous to dynamical systems in nature. The power spectra of fractal fluctuations exhibit inverse power law form signifying long-range correlations between local (small-scale) and global (large-scale) perturbations. The author has developed a general systems theory based on classical statistical physics for fractal fluctuations which predicts that the probability distribution of eddy amplitudes and the variance (square of eddy amplitude)spectrum of fractal fluctuations follow the universal Boltzmann inverse power law expressed as a function of the golden mean. The model predicted distribution is very close to statistical normal distribution for fluctuations within two standard deviations from the mean and exhibits a fat long tail. In this paper it is shown that DNA base CG frequency distribution in Takifugu rubripes (Puffer fish) Genome Release 4 exhibit universal inverse power law form consistent with model prediction. The observed long-range correlations in the DNA bases implies that the non-coding 'junk' or 'selfish' DNA which appear to be redundant, may also contribute to the efficient functioning of the protein coding DNA, a result supported by recent studies. ", "machine_text": "  We have developed a new method to obtain the base (A, C, G, T) composition of DNA for each position along a nucleotide sequence. Our method is based on the generation of a library of sequences containing all possible dinucleotides in a given sequence length. We then measured the frequency of each dinucleotide in the library to obtain the base composition. We used this method to obtain the base composition along the genome of Takifugu rubripes (puffer fish) for sequence lengths of 50, 100, and 200 nucleotides. We found that the distribution of CG dinucleotides along the genome follows a universal spectrum, characterized by a parameter a, which may be close to a value of 1. We also found that the distribution of TG dinucleotides along the genome also follows a universal spectrum, characterized by a parameter b, which is significantly different from a. In contrast, the distribution of AT dinucleotides along the genome did not follow a universal spectrum. Our results suggested that the variation in the dinucleotide composition along the T. rubripes genome is driven by the variation in the frequency of CG and TG dinucleotides, while the frequency of AT dinucleotides is relatively constant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mode stability in delta Scuti stars: linear analysis versus observations   in open clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3626, "human_text": "  A comparison between linear stability analysis and observations of pulsation modes in five delta Scuti stars, belonging to the same cluster, is presented. The study is based on the work by Michel et al. (1999), in which such a comparison was performed for a representative set of model solutions obtained independently for each individual star considered. In this paper we revisit the work by Michel et al. (1999) following, however, a new approach which consists in the search for a single, complete, and coherent solution for all the selected stars, in order to constrain and test the assumed physics describing these objects. To do so, refined descriptions for the effects of rotation on the determination of the global stellar parameters and on the adiabatic oscillation frequency computations are used. In addition, a crude attempt is made to study the role of rotation on the prediction of mode instabilities.The present results are found to be comparable with those reported by Michel et al. (1999). Within the temperature range log T_eff = 3.87-3.88 agreement between observations and model computations of unstable modes is restricted to values for the mixing-length parameter alpha_nl less or equal to 1.50. This indicates that for these stars a smaller value for alpha_nl is required than suggested from a calibrated solar model. We stress the point that the linear stability analysis used in this work still assumes stellar models without rotation and that further developments are required for a proper description of the interaction between rotation and pulsation dynamics. ", "machine_text": " We present a systematic study of mode stability in delta Scuti stars, based on a comparison of numerical results from a linear analysis of the problem with observations of mode stability in open clusters. We derive a simple empirical criterion that is in good agreement with the observations, and we show that the commonly used parameter b/R, which measures the mode stability, is not a good indicator of the evolutionary status of these stars. We find that the evolutionary state of a delta Scuti star, in particular the rotation period, is the main determining factor of mode stability. Our results indicate that slow rotators are very stable, while fast rotators are not. The observations are consistent with a simple model in which the mode stability is quenched when the rotation period is shorter than a critical value, which we derive. We also show that the mode stability is inversely proportional to the delta Scuti star's frequency discrepancy, that is, the difference between the frequencies of the oscillations in the star's atmosphere and the rotation. This is consistent with the idea that the mode instability is triggered by the frequency discrepancy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Characterization of open cluster remnants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1159, "human_text": "  Despite progress in the theoretical knowledge of open cluster remnants and the growing search for observational identifications in recent years, open questions still remain. The methods used to analyze open cluster remnants and criteria to define them as physical systems are not homogeneous. In this work we present a systematic method for studying these objects that provides a view of their properties and allows their characterization. Eighteen remnant candidates are analyzed by means of photometric and proper motion data. These data provide information on objects and their fields. We establish criteria for characterizing open cluster remnants, taking observational uncertainties into account. 2MASS J and H photometry is employed (i) to study structural properties of the objects by means of radial stellar density profiles, (ii) to test for any similarity between objects and fields with a statistical comparison method applied to the distributions of stars in the CMDs, and (iii) to obtain ages, reddening values, and distances from the CMD, taking an index of isochrone fit into account. The UCAC2 proper motions allowed an objective comparison between objects and large solid angle offset fields. The objective analysis based on the present methods indicates 13 open-cluster remnants in the sample. Evidence of the presence of binary stars is found, as expected for dynamically evolved systems. Finally, we infer possible evolutionary stages among remnants from the structure, proper motion, and CMD distributions. The low stellar statistics for individual objects is overcome by means of the construction of composite proper motion and CMD diagrams. The distributions of remnants in the composite diagrams resemble the single-star and unresolved binary star distributions of open clusters. ", "machine_text": " We present an analysis of the properties of a sample of 22 intermediate-mass open clusters that retain some remains of their original gas-rich condition, as diagnosed by the presence of He-rich Wolf-Rayet stars. We found that the clusters in our sample are, on average, more distant, more metal-poor, and have lower gas fractions than a sample of 22 gas-rich clusters from the same region. We also found that the gas fractions of the clusters in our sample are inversely correlated with the total mass of the cluster, whereas no correlation was found between the gas fraction and the total number of cluster members. We conclude that the remains of gas-rich open clusters are the fossils of a large-scale evolutionary process that was first proposed by 1996ApJ...511..77S, in which the gas-rich clusters are expected to have evolved towards massive, gas-poor clusters. Our results suggest that this process is more efficient in removing gas from the clusters than the simple infall onto the clusters of the ambient matter, and that the mass of the infalling matter is only of the same order of magnitude as the mass of the gas that the clusters are able to retain. We discuss our results in the framework of the existing models for the evolution of gas-rich clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The standard model on a domain-wall brane?. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1584, "human_text": "  We propose a 4+1-dimensional action that is a candidate for realising a standard-model-like effective theory for fields dynamically localised to a domain-wall brane. Our construction is based in part on the conjecture that the Dvali-Shifman mechanism for dynamically localising gauge bosons works correctly in 4+1-d. Assuming this to be so, we require the gauge symmetry to be SU(5)in the bulk, spontaneously breaking to SU(3)xSU(2)xU(1) inside the domain wall, thus dynamically localising the standard model gauge bosons provided that the SU(5) theory in the bulk exhibits confinement. The wall is created jointly by a real singlet-Higgs field eta configured as a kink, and an SU(5) adjoint-Higgs field chi that takes nonzero values inside the wall. Chiral 3+1-dimensional quarks and leptons are confined and split along the bulk direction via their Yukawa couplings to eta and chi. The Higgs doublet and its colour triplet SU(5) partner are similarly localised and split. The splittings suppress coloured-Higgs-induced proton decay and, because of the different localisation profiles, the usual SU(5) mass relation m_e = m_d does not arise. Localised gravity is generated via the Randall-Sundrum alternative to compactification. ", "machine_text": " We study the problem of putting a generic standard model on a domain wall brane. The standard model is a set of equations that describe the behavior of fundamental particles and their interactions. It is a very well-studied and well-developed theory, and it is used to make very accurate predictions about the behavior of particles. The standard model is a theory that is very difficult to test directly, but it has been tested to a very high degree by making very precise predictions that can be tested in experiments. We show that the standard model can be put on a domain wall brane, and we show that this domain wall brane is very well-suited for studying the standard model. We show that the domain wall brane is very well-suited for making very precise predictions that can be tested in experiments. We show that the domain wall brane is very well-suited for being tested in very high energy experiments. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of particles. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of dimensions. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of colors. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of generations. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of families. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of generations. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of families. We show that the domain wall brane is very well-suited for being tested in experiments that have a very large number of colors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlinear Perturbations and Conservation Laws on Curved Backgrounds in   GR and Other Metric Theories. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0019, "human_text": "  The field-theoretical approach is reviewed. Perturbations in general relativity as well as in an arbitrary $D$-dimensional metric theory are studied on a background, which is a solution (arbitrary) of the theory. Lagrangian for perturbations is defined, and field equations for perturbations are derived from the variational principle. These equations are exact and equivalent to the equations in the standard formulation, but can be approximate also. The field-theoretical description is invariant under gauge (inner) transformations, which can be presented both in exact and approximate forms. Following the usual field-theoretical prescription, conserved quantities for perturbations are constructed. Conserved currents are expressed through divergences of superpotentials -- antisymmetric tensor densities. This form allows to relate a necessity to consider local properties of perturbations with a theoretical representation of the quasi-local nature of conserved quantities in metric theories. Applications of the formalism in general relativity are discussed. Generalized formulae for an arbitrary metric $D$-dimensional theory are tested in the Einstein-Gauss-Bonnet gravity. ", "machine_text": " We investigate conservation laws in metric theories with nonlinear perturbations on curved backgrounds. We consider a large class of such theories which includes general relativity, Carterian gravity, Einstein- Maxwell theory and Newtonian theory as special cases. The theories are described by a metric tensor $g$ and a symmetric conservation tensor $T^{\\mu\\nu}$, with $\\mu$ and $\\nu$ being spacetime indices. The metric tensor is allowed to have a nonlinear structure and can be written in a background curved in a Riemannian or Finsler space. The symmetric conservation tensor has a conventional linear structure and is constructed from a tracefree tensorial decomposition of the metric tensor. In this way, we show that the conventional structure of the conservation tensor is invariant under an arbitrary nonlinear perturbation of the metric tensor in a background curved in a Riemannian or Finsler space. As a by-product, we show that the usual tracefree tensorial decomposition of the metric tensor is invariant under an arbitrary nonlinear perturbation in a background curved in a Riemannian or Finsler space. This holds true also for a tracefree tensorial decomposition of a nonlinear conservation tensor in a background curved in a Riemannian or Finsler space. We show further that an arbitrary nonlinear perturbation of the conservation tensor is invariant under a background change from a Riemannian to a Finsler space and vice versa. In our final section we discuss the general meaning of these results for an arbitrary symmetric tensor and an arbitrary metric tensor on a Riemannian or Finsler space.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Analysis of the Shapes of Interstellar Extinction Curves. V. The   IR-Through-UV Curve Morphology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0154, "human_text": "  We study the IR-through-UV interstellar extinction curves towards 328 Galactic B and late-O stars. We use a new technique which employs stellar atmosphere models in lieu of unreddened \"standard\" stars. This technique is capable of virtually eliminating spectral mismatch errors in the curves. It also allows a quantitative assessment of the errors and enables a rigorous testing of the significance of relationships between various curve parameters, regardless of whether their uncertainties are correlated. Analysis of the curves gives the following results: (1) In accord with our previous findings, the central position of the 2175 A extinction bump is mildly variable, its width is highly variable, and the two variations are unrelated. (2) Strong correlations are found among some extinction properties within the UV region, and within the IR region. (3) With the exception of a few curves with extreme (i.e., large) values of R(V), the UV and IR portions of Galactic extinction curves are not correlated with each other. (4) The large sightline-to-sightline variation seen in our sample implies that any average Galactic extinction curve will always reflect the biases of its parent sample. (5) The use of an average curve to deredden a spectral energy distribution (SED) will result in significant errors, and a realistic error budget for the dereddened SED must include the observed variance of Galactic curves. While the observed large sightline-to-sightline variations, and the lack of correlation among the various features of the curves, make it difficult to meaningfully characterize average extinction properties, they demonstrate that extinction curves respond sensitively to local conditions. Thus, each curve contains potentially unique information about the grains along its sightline. ", "machine_text": " We present an analysis of the shapes of interstellar extinction curves, based on a statistical study of their morphology. We find that the majority of extinction curves are S-shaped, with the strength of the S-increasing with increasing extinction. We show this to be consistent with a model in which the extinction curve is formed by the sum of a constant through-uve contribution plus a positive power-law contribution that increases with increasing extinction. We find that this model can quantitatively reproduce the shapes of extinction curves, both for stars of known spectral type and for those with unknown spectral type. The power law contribution has a scaling exponent that depends only on the extinction and not on the spectral type of the star. We show that this model can be used to derive the exponent of the power law contribution and the through-UV excess for a given extinction curve, and that these quantities are related in a simple way to the underlying physical properties of the absorbing clouds. We find that the shapes of the extinction curves are consistent with the clouds consisting of a large number of small grains that produce the bulk of the extinction in the UV, and a small number of large grains that produce the bulk of the extinction in the IR. We discuss the implications of this finding for theories of cloud structure and for our understanding of the physics and chemistry of the interstellar medium.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The geometrical quantity in damped wave equations on a square. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0172, "human_text": "  The energy in a square membrane $\\Omega$ subject to constant viscous damping on a subset $\\omega\\subset \\Omega$ decays exponentially in time as soon as $\\omega$ satisfies a geometrical condition known as the \"Bardos-Lebeau-Rauch\" condition. The rate $\\tau(\\omega)$ of this decay satisfies $\\tau(\\omega)= 2 \\min(-\\mu(\\omega), g(\\omega))$ (see Lebeau [Math. Phys. Stud. 19 (1996) 73-109]). Here $\\mu(\\omega)$ denotes the spectral abscissa of the damped wave equation operator and $g(\\omega)$ is a number called the geometrical quantity of $\\omega$ and defined as follows. A ray in $\\Omega$ is the trajectory generated by the free motion of a mass-point in $\\Omega$ subject to elastic reflections on the boundary. These reflections obey the law of geometrical optics. The geometrical quantity $g(\\omega)$ is then defined as the upper limit (large time asymptotics) of the average trajectory length. We give here an algorithm to compute explicitly $g(\\omega)$ when $\\omega$ is a finite union of squares. ", "machine_text": " We consider the geometrical quantity in damped wave equations on a square. Let $\\Delta\\subset\\mathbb R^2$ be a square. We study the damped wave equation $$\\begin{aligned} \\label{eq} \\ddift \\varphi & \\in\\mathcal C^\\infty(\\Delta)& \\nonumber \\\\ &\\big|_{t=0}& \\nonumber \\\\ &\\dot\\varphi &=-i\\varphi&\\nonumber \\\\ &\\dot \\dot \\varphi & + \\dot \\varphi &+b\\dot\\varphi &=-ab\\varphi &\\nonumber \\\\ & \\dot \\dot \\dot \\varphi & - \\dot \\dot \\dot \\varphi &+c\\dot \\dot \\dot \\varphi &=-bc\\dot \\dot \\dot \\varphi &\\nonumber \\\\ & \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot & + \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot &+d\\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot &=-ed\\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot \\dot &\\nonumber \\end{aligned}$$ on $\\Delta$. For any $\\lambda\\in\\mathbb R$, define the solution of equation (\\[eq\\]) by $$\\label{sol} \\Phi_\\lambda(x)= \\begin{cases}  \\left|\\frac{x}{\\Delta}\\right|^{-2\\lambda}& x\\in\\Delta \\\\ 0 & x\\in\\mathbb R^2\\setminus\\Delta \\\\  \\end{cases}$$ We prove the following properties of the solution $\\Phi_\\lambda$ of (\\[eq\\]). (i) For $\\lambda\\in\\mathbb R$, $\\Phi_\\lambda$ is a solution of (\\[eq\\]) if and only if $\\lambda\\in(-\\frac{1}{2},\\frac{1}{2})$. (ii) If $\\lambda\\in(-\\frac{1}{2},\\frac{1}{2})$, $\\Phi_\\lambda$ is the only solution of (\\[eq\\]) on $\\Delta$. (iii) For $\\lambda\\in(-\\frac{1}{2},\\frac{1}{2})$, $\\Phi_\\lambda$ is continuous on $\\mathbb R^2$. (iv) For $\\lambda\\in(-\\frac{1}{2},\\frac{1}{2})$, $\\Phi_\\lambda$ is differentiable on $\\mathbb R^2$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A successive sub-grouping method for multiple sequence alignments   analysis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4429, "human_text": "  A novel approach to protein multiple sequence alignment is discussed: substantially this method counterparts with substitution matrix based methods (like Blosum or PAM based methods), and implies a more deterministic approach to chemical/physical sub-grouping of amino acids . Amino acids (aa) are divided into sub-groups with successive derivations, that result in a clustering based on the considered property. The properties can be user defined or chosen between default schemes, like those used in the analysis described here. Starting from an initial set of the 20 naturally occurring amino acids, they are successively divided on the basis of their polarity/hydrophobic index, with increasing resolution up to four level of subdivision. Other schemes of subdivision are possible: in this thesis work it was employed also a scheme based on physical/structural properties (solvent exposure, lateral chain mobility and secondary structure tendency), that have been compared to the chemical scheme with testing purposes. In the method described in this chapter, the total score for each position in the alignment accounts for different degree of similarity between amino acids. The scoring value result form the contribution of each level of selectivity for every individual property considered. Simply the method (called M_Al) analyse the n sequence alignment position per position and assigns a score which have contributes by aa identity plus a composed valuation of the chemical or of the structural affinity between the n aligned amino acids. This method has been implemented in a series of programs written in python language; these programs have been tested in some biological cases, with benchmark purposes. ", "machine_text": "  We present a new method for constructing summarizes of multiple sequence alignments that is based on successive sub-groupings of the aligned sequences. We show that our method is broadly applicable to many of the summarization methods that have been proposed in the literature. Our method has several advantages over existing methods. First, our method is guaranteed to produce a summary that is consistent with the multiple alignment when it is applied to any set of multiple alignment summaries that are themselves consistent. Second, our method is simple and efficient, being an entirely deterministic process of simpleminded filtering and clustering. Third, our method is general and can be applied to a variety of alignment summary methods, while previous methods have typically been specific to a single summary method. We demonstrate the effectiveness of our method on a standard benchmark set of proteins, and show that it produces summaries that are more highly consistent with the multiple alignment than do previous methods.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Discrete Choices under Social Influence: Generic Properties. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2333, "human_text": "  We consider a model of socially interacting individuals that make a binary choice in a context of positive additive endogenous externalities. It encompasses as particular cases several models from the sociology and economics literature. We extend previous results to the case of a general distribution of idiosyncratic preferences, called here Idiosyncratic Willingnesses to Pay (IWP). Positive additive externalities yield a family of inverse demand curves that include the classical downward sloping ones but also new ones with non constant convexity. When j, the ratio of the social influence strength to the standard deviation of the IWP distribution, is small enough, the inverse demand is a classical monotonic (decreasing) function of the adoption rate. Even if the IWP distribution is mono-modal, there is a critical value of j above which the inverse demand is non monotonic, decreasing for small and high adoption rates, but increasing within some intermediate range. Depending on the price there are thus either one or two equilibria. Beyond this first result, we exhibit the generic properties of the boundaries limiting the regions where the system presents different types of equilibria (unique or multiple). These properties are shown to depend only on qualitative features of the IWP distribution: modality (number of maxima), smoothness and type of support (compact or infinite). The main results are summarized as phase diagrams in the space of the model parameters, on which the regions of multiple equilibria are precisely delimited. ", "machine_text": "  We study generic properties of discrete choices under social influence. We consider a setting where individuals make choices among a finite number of alternatives, where the set of alternatives is divided into two subsets, and where individuals are influenced by the choices of others. We first show that the number of individuals who choose from each subset will be equal if and only if the influence process is symmetric, that is, if and only if the effect of choosing each alternative on the choice probability of each other alternative is the same. We then consider the case where the number of alternatives is a constant, and show that the fraction of individuals who choose from each subset converges to the generic proportion of alternatives in each subset as the number of individuals increases, provided that the influence process is symmetric and that the initial conditions are chosen in a symmetric way. We also show that in a more general setting, the fraction of individuals who choose from each subset converges to the generic proportion of alternatives in each subset, provided that the influence process is symmetric. We show that our results generalize previous results in this area, and that they provide a useful abstraction of several settings where choices are influenced by the choices of others.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The role of elastic stresses on leaf venation morphogenesis. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0902, "human_text": "  We explore the possible role of elastic mismatch between epidermis and mesophyll as a driving force for the development of leaf venation. The current prevalent 'canalization' hypothesis for the formation of veins claims that the transport of the hormone auxin out of the leaves triggers cell differentiation to form veins. Although there is evidence that auxin plays a fundamental role in vein formation, the simple canalization mechanism may not be enough to explain some features observed in the vascular system of leaves, in particular, the abundance of vein loops. We present a model based on the existence of mechanical instabilities that leads very naturally to hierarchical patterns with a large number of closed loops. When applied to the structure of high order veins, the numerical results show the same qualitative features as actual venation patterns and, furthermore, have the same statistical properties. We argue that the agreement between actual and simulated patterns provides strong evidence for the role of mechanical effects on venation development. ", "machine_text": "  We present a theory of elastic stresses and their role in leaf venation morphogenesis. We consider a thin, elastic, and anisotropic sheet which is incompressible in the thickness direction. The sheet is assumed to be in a state of plane-strain with elastic constants which vary in the plane. In the limit of small thickness, the sheet energy is shown to minimize the total elastic stress. This leads to the system of elastic equations which govern the evolution of the elastic stresses. We solve these equations for a variety of forms of the elastic constants. The solutions show several different patterns of elastic stresses which are possible. We also relate our theory to the observation that the elastic constants often have a gradient in the direction of the leaf margin. The elastic stress patterns we find have a variety of possible relationships to the arrangement of the primary and secondary veins. We also discuss the possible physical mechanisms which may cause the elastic constants to take on the values we find in our theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Single Top Results from CDF. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0282, "human_text": "  The CDF Collaboration has analyzed 955/pb of CDF II data to search for electroweak single top quark production at the Tevatron. We employ three different analysis techniques to search for a single top signal: multivariate likelihood functions; neural networks; the matrix element analysis technique. The sensitivities to a single top signal at the rate predicted by the Standard Model are 2.1 - 2.6 sigma. The first two analyses observe a deficit of single top-like events and set upper limits on the production cross section. The matrix element analysis observes a 2.3 sigma single top excess and measures a combined t-channel and s-channel cross section of 2.7 +1.5-1.3 pb. Using the same dataset, we have searched for non-Standard Model production of single top quarks through a heavy W' boson resonance. No evidence for a signal is observed. We exclude at the 95 % C.L. W' boson production with masses of 760 GeV/c^2 (790 GeV/c^2) in case the right handed neutrino is smaller (larger) than the mass of the W' boson. ", "machine_text": "  We present the first search results from the CDF experiment that can be interpreted as the direct observation of a new elementary particle, the top quark. We report a significance of 4.9 standard deviations (sigma) in the search for a single top quark produced in association with a bottom quark, and/******/sigma for the search for a single top quark produced in association with a charm quark. We observe 2.9sigma evidence for the production of a single top quark in association with a bottom quark and a significance of 1.3sigma for the production of a single top quark in association with a charm quark. The observed single top quark production cross sections are consistent with the Standard Model prediction for a 100 GeV top quark, as is the observed ratio of top quarks produced in association with bottom quarks to top quarks produced in association with charm quarks. We observe a 3sigma excess of events with a charged lepton and an missing energy larger than 20 GeV, which could be due to the production of a top quark and an additional heavy quark. The results are based on an integrated luminosity of 1.96 inverse picobarns of collisions at a center of mass energy of 1.96 TeV.<PAD>", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Finite Element framework for computation of protein normal modes and   mechanical response. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0634, "human_text": "  A coarse-grained computational procedure based on the Finite Element Method is proposed to calculate the normal modes and mechanical response of proteins and their supramolecular assemblies. Motivated by the elastic network model, proteins are modeled as homogeneous isotropic elastic solids with volume defined by their solvent-excluded surface. The discretized Finite Element representation is obtained using a surface simplification algorithm that facilitates the generation of models of arbitrary prescribed spatial resolution. The procedure is applied to compute the normal modes of a mutant of T4 phage lysozyme and of filamentous actin, as well as the critical Euler buckling load of the latter when subject to axial compression. Results compare favorably with all-atom normal mode analysis, the Rotation Translation Blocks procedure, and experiment. The proposed methodology establishes a computational framework for the calculation of protein mechanical response that facilitates the incorporation of specific atomic-level interactions into the model, including aqueous-electrolyte-mediated electrostatic effects. The procedure is equally applicable to proteins with known atomic coordinates as it is to electron density maps of proteins, protein complexes, and supramolecular assemblies of unknown atomic structure. ", "machine_text": " A Finite Element framework for computation of protein normal modes and mechanical response.  We present a Finite Element framework for computation of protein normal modes and mechanical response. The method is based on a novel combination of three elements: (i) A streamlined implementation of the FEM, (ii) A new method for the computation of the underlying atomistic system stiffness matrix, and (iii) An efficient procedure for the identification of the lowest eigenvalues and eigenvectors of the stiffness matrix. We demonstrate the performance of the method on a number of benchmark systems, and show that the method is both robust and accurate. The method has a number of attractive features, including (i) the possibility to deal with large systems, (ii) the use of a minimal number of parameters, (iii) a straightforward interpretation of the results, (iv) a simple implementation, (v) the possibility of using any kind of boundary conditions, and (vi) a natural way to deal with heterogeneity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Spitzer c2d Survey of Large, Nearby, Insterstellar Clouds. IX. The   Serpens YSO Population As Observed With IRAC and MIPS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0009, "human_text": "  We discuss the results from the combined IRAC and MIPS c2d Spitzer Legacy observations of the Serpens star-forming region. In particular we present a set of criteria for isolating bona fide young stellar objects, YSO's, from the extensive background contamination by extra-galactic objects. We then discuss the properties of the resulting high confidence set of YSO's. We find 235 such objects in the 0.85 deg^2 field that was covered with both IRAC and MIPS. An additional set of 51 lower confidence YSO's outside this area is identified from the MIPS data combined with 2MASS photometry. We describe two sets of results, color-color diagrams to compare our observed source properties with those of theoretical models for star/disk/envelope systems and our own modeling of the subset of our objects that appear to be star+disks. These objects exhibit a very wide range of disk properties, from many that can be fit with actively accreting disks to some with both passive disks and even possibly debris disks. We find that the luminosity function of YSO's in Serpens extends down to at least a few x .001 Lsun or lower for an assumed distance of 260 pc. The lower limit may be set by our inability to distinguish YSO's from extra-galactic sources more than by the lack of YSO's at very low luminosities. A spatial clustering analysis shows that the nominally less-evolved YSO's are more highly clustered than the later stages and that the background extra-galactic population can be fit by the same two-point correlation function as seen in other extra-galactic studies. We also present a table of matches between several previous infrared and X-ray studies of the Serpens YSO population and our Spitzer data set. ", "machine_text": "  We present a catalog of 66 YSOs in the Serpens cloud, as observed with IRAC and MIPS, and discuss their properties in the context of the cloud as a whole. We show that the distribution of the YSOs is well described by a simple model in which the cloud is treated as a uniform one-dimensional structure. We derive a total mass for the cloud of 4 x 10^4 solar masses, with an age of 1-2 Gyr. We discuss the evolution of the cloud and show that a significant fraction of the cloud's gas has been lost through interaction with the Galactic potential. We find that the cloud is both massive and dense enough to have retained its identity as a discrete cloud for several billion years, in spite of these interactions. We show that the observed distribution of YSOs in the cloud is consistent with a model in which the YSOs are born in a narrow, punctuated shell and are distributed according to the primordial distribution function. We discuss the cloud's three-dimensional structure and show that a simple model in which the cloud is treated as a uniform one-dimensional structure provides a good description of the cloud's major properties. We briefly discuss the possible mechanisms for the formation of the cloud and the subsequent evolution of its YSO population.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The largest eigenvalues of finite rank deformation of large Wigner   matrices: convergence and nonuniversality of the fluctuations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0136, "human_text": "  In this paper, we investigate the asymptotic spectrum of complex or real Deformed Wigner matrices $(M_N)_N$ defined by $M_N=W_N/\\sqrt{N}+A_N$ where $W_N$ is an $N\\times N$ Hermitian (resp., symmetric) Wigner matrix whose entries have a symmetric law satisfying a Poincar\\'{e} inequality. The matrix $A_N$ is Hermitian (resp., symmetric) and deterministic with all but finitely many eigenvalues equal to zero. We first show that, as soon as the first largest or last smallest eigenvalues of $A_N$ are sufficiently far from zero, the corresponding eigenvalues of $M_N$ almost surely exit the limiting semicircle compact support as the size $N$ becomes large. The corresponding limits are universal in the sense that they only involve the variance of the entries of $W_N$. On the other hand, when $A_N$ is diagonal with a sole simple nonnull eigenvalue large enough, we prove that the fluctuations of the largest eigenvalue are not universal and vary with the particular distribution of the entries of $W_N$. ", "machine_text": "  We consider the problem of the largest eigenvalues of finite rank deformation of large Wigner matrices. We show that the fluctuations of the largest eigenvalue of such a matrix are not universal, in the sense that the distribution of the largest eigenvalue of a large random Wigner matrix is not the same as the distribution of the largest eigenvalue of a large random deformation of a Wigner matrix. We show that the distribution of the largest eigenvalue of a large random deformation of a Wigner matrix depends on the underlying matrix. In particular, we show that the distribution of the largest eigenvalue of a large random deformation of a Wigner matrix converges to the largest eigenvalue distribution of a large random symmetric Toeplitz matrix, as the size of the matrix grows large. We show that this convergence is very slow, in the sense that the largest eigenvalue distribution of a large random deformation of a Wigner matrix converges to the largest eigenvalue distribution of a large random symmetric Toeplitz matrix in an algebraically slow way as the size of the matrix grows large.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A unified model for AGN feedback in cosmological simulations of   structure formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2238, "human_text": "  We discuss a numerical model for black hole growth and its associated feedback processes that for the first time allows cosmological simulations of structure formation to self-consistently follow the build up of the cosmic population of galaxies and active galactic nuclei. Our model assumes that seed black holes are present at early cosmic epochs at the centres of forming halos. We then track their growth from gas accretion and mergers with other black holes in the course of cosmic time. For black holes that are active, we distinguish between two distinct modes of feedback, depending on the black hole accretion rate itself. Black holes that accrete at high rates are assumed to be in a `quasar regime', where we model their feedback by thermally coupling a small fraction of their bolometric luminosity to the surrounding gas. For black holes with low accretion rates, we conjecture that most of their feedback occurs in mechanical form, where AGN-driven bubbles are injected into a gaseous environment. Using our new model, we carry out TreeSPH cosmological simulations on the scales of individual galaxies to those of massive galaxy clusters, both for isolated systems and for cosmological boxes. We demonstrate that our model produces results for the black hole and stellar mass densities in broad agreement with observational constraints. We find that the black holes significantly influence the evolution of their host galaxies, changing their star formation history, their amount of cold gas, and their colours. Also, the properties of intracluster gas are affected strongly by the presence of massive black holes in the cores of galaxy clusters, leading to shallower metallicity and entropy profiles, and to a suppression of strong cooling flows. [Abridged] ", "machine_text": " We present a unified model for active galactic nucleus (AGN) feedback in cosmological hydrodynamical simulations of structure formation. We solve the hydrodynamics in a companion paper and here focus on the feedback from the galaxies. We consider a simple model in which galaxies are treated as passive particle systems with a single time parameterization, and solve the feedback in a cosmological hydrodynamical simulation with a coupled code. We include both feedback from star formation and from active galactic nuclei, and allow for the possibility of a feedback cycle where the mass distribution in the galaxies affects the feedback. We find that this feedback cycle has a strong effect on the resulting mass distribution, and can produce either very efficient feedback, or strongly depressed feedback. The strength of the feedback cycle depends on the mass of the galaxies, and the probability of having an active galactic nucleus. We find that a simple feedback prescription, where the feedback is a fixed fraction of the total galaxy mass, is not capable of producing the wide range of feedback strengths seen in observations, but a feedback model where the feedback is proportional to the star formation rate is able to produce the full range of observations. We discuss possible physical mechanisms for this feedback cycle.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Spectral Index Distribution of EGRET Blazars: Prospects for GLAST. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2417, "human_text": "  The intrinsic distribution of spectral indices in GeV energies of gamma-ray--loud blazars is a critical input in determining the spectral shape of the unresolved blazar contribution to the diffuse extragalactic gamma-ray background, as well as an important test of blazar emission theories. We present a maximum-likelihood method of determining the intrinsic spectral index distribution (ISID) of a population of gamma-ray emitters which accounts for error in measurement of individual spectral indices, and we apply it to EGRET blazars. We find that the most likely Gaussian ISID for EGRET blazars has a mean of 2.27 and a standard deviation of 0.20. We additionally find some indication that FSRQs and BL Lacs may have different ISIDs (with BL Lacs being harder). We also test for spectral index hardening associated with blazar variability for which we find no evidence. Finally, we produce simulated GLAST spectral index datasets and perform the same analyses. With improved statistics due to the much larger number of resolvable blazars, GLAST data will help us determine the ISIDs with much improved accuracy. Should any difference exist between the ISIDs of BL Lacs and FSRQs or between the ISIDs of blazars in the quiescent and flaring states, GLAST data will be adequate to separate these ISIDs at a significance better than 3 sigma. ", "machine_text": " We present here the results of a systematic and quantitative analysis of the spectral index distribution of EGRET blazars. A total of 252 EGRET blazars are considered, all of them with measured redshifts and taken from the second version of the EGRET blazar database. We find that the distribution of their spectral indices is significantly different from a Gaussian distribution. The most significant departure is found in the high-frequency part of the distribution, where the majority of the blazars present indices smaller than -1. We discuss this non-Gaussianity in the framework of a simple model in which the production of the UV and X-ray emission in blazars is related to the accretion disc instability. Within this framework, we show that the non-Gaussianity can be naturally explained by the large-scale distribution of the accretion disc matter, if the disc is subject to violent kinematic instabilities. We also show that the distribution of the accretion disc matter has to be very close to a Gaussian one, in order to reproduce the observed distribution of the spectral indices. The quality of the fit is better if we allow the index to be dependent on the redshift, in a way consistent with the change in the properties of the accretion disc with redshift. We discuss the prospects of using this distribution to test the disc instability model and to select blazars with extreme accretion disc instabilities for further study with GLAST.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New systematics in charmless strange $B^+ \\to VP$ decays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2557, "human_text": "  Latest data on charmless strange vector-pseudoscalar $B^+$ decays now including $B^+\\to \\rho^+ K^o$ confirm a simple penguin model in which the gluon $G$ in an initial $\\bar s u G$ state fragments equally into $u \\bar u$, $d \\bar d$ and $s \\bar s$ and all form factors are equal. A search for possible additional contributions shows only a few signals not obscured by experimental errors whose implications are discussed. The experimental value of $0.25 \\pm 0.11$ for the ratio of the branching ratios $BR(B^+ \\to K^{*+}\\eta)$ to $BR(B^+\\to K^{*+}\\eta')$ confirms the parity selection rule prediction 0.32. Large violations arise in a new sum rule for the sum of these branching ratios, analogous to the similar pseudoscalar sum rule including $K^+\\eta$ and $K^+\\eta'$. Indications for either an electroweak penguin contribution or additional admixtures like instrinsic charm in the $\\eta-\\eta'$ system remain to be clarified. An alternative symmetry description with new predictive power clarifies the simple penguin approximation and presents new predictions which can be tested experimentally. The fragmentation of the $\\bar s u G$ state into two mesons is described by a strong interaction S-matrix dominated by nonexotic hadron resonances in multiparticle intermediate states. ", "machine_text": " We present a new systematics in charmless strange $B^+ \\to VP$ decays, based on the idea that the $B^+$ meson is a quantum mechanically-delocalized particle. The main ingredients of our approach are (i) the introduction of a new quantum number, the \"strangeness lifetime\", (ii) the assumption that the dynamics of $B^+$ production and decay is largely unaffected by the local density of states, and (iii) the calculation of the branching ratio of $B^+$ to $VP$ as a function of the strangeness lifetime and the relative velocity between the $B^+$ and $V$ particles. We show that our predictions for the $B^+$ branching ratio to $VP$ are in excellent agreement with the latest experimental data, and that the \"Standard Model\" (SM) explanation for the $B^+$ branching ratio to $V\\ell^+$ is not consistent with the data. The main problem the SM has to face is the strong dependence of the $B^+$ branching ratio on the relative velocity between the $B^+$ and $V\\ell^+$ particles. We also make predictions for the $B^+$ branching ratio to $K^*$ and $\\ell^*$, and for the $\\ell^+$ branching ratio to $K^*$, which can be tested at the LHC.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Chemical Compositions of the Type II Cepheids -- The BL Her and W   Vir Variables. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2029, "human_text": "  Abundance analyses from high-resolution optical spectra are presented for 19 Type II Cepheids in the Galactic field. The sample includes both short-period (BL Her) and long-period (W Vir) stars. This is the first extensive abundance analysis of these variables. The C, N, and O abundances with similar spreads for the BL Her and W Vir show evidence for an atmosphere contaminated with $3\\alpha$-process and CN-cycling products. A notable anomaly of the BL Her stars is an overabundance of Na by a factor of about five relative to their presumed initial abundances. This overabundance is not seen in the W Vir stars. The abundance anomalies running from mild to extreme in W Vir stars but not seen in the BL Her stars are attributed to dust-gas separation that provides an atmosphere deficient in elements of high condensation temperature, notably Al, Ca, Sc, Ti, and $s$-process elements. Such anomalies have previously been seen among RV Tau stars which represent a long-period extension of the variability enjoyed by the Type II Cepheids. Comments are offered on how the contrasting abundance anomalies of BL Her and W Vir stars may be explained in terms of the stars' evolution from the blue horizontal branch. ", "machine_text": "  The Chemical Compositions of the Type II Cepheids -- The BL Her and W Vir Variables  The chemical compositions of 31 type II Cepheids (14 BL Her and 17 W Vir variables) are presented. These data are used to discuss the relation between chemical composition and the period-color magnitude diagram. It is shown that the classical P-M diagram can be used to estimate the metallicities of type II Cepheids. The mean metallicity of the BL Her variables is found to be very close to solar, a result which is consistent with their very low peculiar-velocity orbits. The average metallicities of the W Vir variables are also close to solar, indicating that these stars have relatively low-metal winds. However, the properties of some of these stars are inconsistent with the assumption that all W Vir variables have low-metal winds. It is suggested that the W Vir variables form a chemically heterogeneous group. The membership in the different chemical groups defined here is consistent with the available evolutionary theory. The relatively low metallicities of the type II Cepheids imply that these stars have had a relatively low-metal accretion history. The results are consistent with the relatively high metallicities found for the type I Cepheids, indicating a different chemical history for these two populations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The multiplicity of planet host stars - New low-mass companions to   planet host stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1767, "human_text": "  We present new results from our ongoing multiplicity study of exoplanet host stars, carried out with the infrared camera SofI at ESO-NTT. We have identified new low mass companions to the planet host stars HD101930 and HD65216. HD101930AB is a wide binary systems composed of the planet host star HD101930A and its companion HD101930B which is a M0 to M1 dwarf with a mass of about 0.7Msun separated from the primary by ~73arcsec (2200AU projected separation). HD65216 forms a hierarchical triple system, with a projected separation of 253AU (angular separation of about 7arcsec) between the planet host star HD65216A and its close binary companion HD65216BC, whose two components are separated by only ~0.17arcsec (6AU of projected separation). Two VLT-NACO images separated by 3 years confirm that this system is co-moving to the planet host star. The infrared photometry of HD65216B and C is consistent with a M7 to M8 (0.089Msun), and a L2 to L3 dwarf (0.078Msun), respectively, both close to the sub-stellar limit. An infrared spectrum with VLT-ISAAC of the pair HD65216BC, even though not resolved spatially, confirms this late spectral type. Furthermore, we present H- and K-band ISAAC infrared spectra of HD16141B, the recently detected co-moving companion of the planet host star HD16141A. The infrared spectroscopy as well as the apparent infrared photometry of HD16141B are both fully consistent with a M2 to M3 dwarf located at the distance of the planet host star. ", "machine_text": "  We present a large sample of low-mass companions to planet host stars. These stars have one or more giant planets, and the companions are gas giants as well, in wide orbits. We use the NASA Transiting Exoplanet Survey Satellite, which has a large field of view and exquisite photometric precision, to detect these low-mass companions. We estimate the companion masses from radial velocity measurements. We show that the probability distribution of the companion masses is strongly skewed to higher masses. The mean mass is close to the minimum mass for a gas giant, but a large fraction of the population has a mass above this threshold. These companions are not gravitationally bound, and are likely to have formed through the fragmentation of a larger planet. Our results suggest that giant planets are more likely to be formed by the accretion of smaller bodies, rather than by the collapse of a giant molecular cloud.  We present a sample of low-mass companions to giant planet host stars. These stars have one or more giant planets, and the companions are gas giants as well, in wide orbits. We use the NASA Transiting Exoplanet Survey Satellite, which has a large field of view and exquisite photometric precision, to detect these low-mass companions. We estimate the companion masses from radial velocity measurements. We show that the probability distribution of the companion masses is strongly skewed to higher masses. The mean mass is close to the minimum mass for a gas giant, but a large fraction of the population has a mass above this threshold. These companions are not gravitationally bound, and are likely to have formed through the fragmentation of a larger planet. Our results suggest that giant planets are more likely to be formed by the accretion of smaller bodies, rather than by the collapse of a giant molecular cloud.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geometrical properties of local dynamics in Hamiltonian systems: the   Generalized Alignment Index (GALI) method. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3155, "human_text": "  We investigate the detailed dynamics of multidimensional Hamiltonian systems by studying the evolution of volume elements formed by unit deviation vectors about their orbits. The behavior of these volumes is strongly influenced by the regular or chaotic nature of the motion, the number of deviation vectors, their linear (in)dependence and the spectrum of Lyapunov exponents. The different time evolution of these volumes can be used to identify rapidly and efficiently the nature of the dynamics, leading to the introduction of quantities that clearly distinguish between chaotic behavior and quasiperiodic motion on $N$-dimensional tori. More specifically we introduce the Generalized Alignment Index of order $k$ (GALI$_k$) as the volume of a generalized parallelepiped, whose edges are $k$ initially linearly independent unit deviation vectors from the studied orbit whose magnitude is normalized to unity at every time step. The GALI$_k$ is a generalization of the Smaller Alignment Index (SALI) (GALI$_2$ $\\propto$ SALI). However, GALI$_k$ provides significantly more detailed information on the local dynamics, allows for a faster and clearer distinction between order and chaos than SALI and works even in cases where the SALI method is inconclusive. ", "machine_text": " We introduce a geometrical method, based on the symplectic structure of the equations of motion, for computing and analyzing the local dynamics in Hamiltonian systems. The method is based on the computation of the so-called Generalized Alignment Index (GALI), which provides a measure of the similarities between the directions of the local dynamics at different points in the phase space. By properly interpreting the GALI, we are able to extract the qualitative features of the local dynamics, including the existence of different types of invariant manifolds (e.g., symmetry, quasi-symmetry, and anti-symmetry manifolds) as well as the local stability of the various tori. We show that the GALI is closely related to the so-called Topological Alignment Index (TAI), recently introduced in the field of image analysis to extract the topological structure of geometrically transformed images. As an application, we present an analysis of the local dynamics in a simple model of glass transition, and show how the method can be used to compute the various local relaxation times.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ages for illustrative field stars using gyrochronology: viability,   limitations and errors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3068, "human_text": "  We here develop an improved way of using a rotating star as a clock, set it using the Sun, and demonstrate that it keeps time well. This technique, called gyrochronology, permits the derivation of ages for solar- and late-type main sequence stars using only their rotation periods and colors. The technique is clarified and developed here, and used to derive ages for illustrative groups of nearby, late-type field stars with measured rotation periods. We first demonstrate the reality of the interface sequence, the unifying feature of the rotational observations of cluster and field stars that makes the technique possible, and extends it beyond the proposal of Skumanich by specifying the mass dependence of rotation for these stars. We delineate which stars it cannot currently be used on. We then calibrate the age dependence using the Sun. The errors are propagated to understand their dependence on color and period. Representative age errors associated with the technique are estimated at ~15% (plus possible systematic errors) for late-F, G, K, & early-M stars. Ages derived via gyrochronology for the Mt. Wilson stars are shown to be in good agreement with chromospheric ages for all but the bluest stars, and probably superior. Gyro ages are then calculated for each of the active main sequence field stars studied by Strassmeier and collaborators where other ages are not available. These are shown to be mostly younger than 1Gyr, with a median age of 365Myr. The sample of single, late-type main sequence field stars assembled by Pizzolato and collaborators is then assessed, and shown to have gyro ages ranging from under 100Myr to several Gyr, and a median age of 1.2Gyr. Finally, we demonstrate that the individual components of the three wide binaries XiBooAB, 61CygAB, & AlphaCenAB yield substantially the same gyro ages. ", "machine_text": "  We present an evaluation of the viability of gyrochronology for dating field stars in terms of the precision that can be achieved, the limitations of the method, and the sources of error. We pay particular attention to the underlying assumptions and the propagation of errors through the various steps of the process. We find that the precision that can be achieved with this method is in the range of 10\u201320%, depending on the accuracy with which the disk orbital elements can be measured. The main limitation is the assumption of a constant orbital decay rate, which can be relaxed only if the disk's inner edge is sufficiently sharp. This is not likely to be the case for low-mass disks such as those around T Tauri stars. In any case, the sources of error are not negligible. In particular, we show that a poorly constrained orbital model can produce a date for a given field star that is in disagreement with the true age by as much as several hundred million years. We also show that, unless the orbital elements of a given disk can be constrained to high accuracy early in the process, the obtained age is likely to be very uncertain. Therefore, this method is not likely to provide reliable absolute ages for field stars, but it may be useful for dating young stellar objects if a sufficient number of independent data sets can be obtained to constrain the orbital model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Planck Scale Unification in a Supersymmetric Standard Model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0301, "human_text": "  We show how gauge coupling unification near the Planck scale $M_P\\sim 10^{19}$ GeV can be achieved in the framework of supersymmetry, facilitating a full unification of all forces with gravity. Below the conventional GUT scale $M_{GUT}\\sim 10^{16}$ GeV physics is described by a Supersymmetric Standard Model whose particle content is that of three complete $\\mathbf{27}$ representations of the gauge group $E_6$. Above the conventional GUT scale the gauge group corresponds to a left-right symmetric Supersymmetric Pati-Salam model, which may be regarded as a ``surrogate SUSY GUT'' with all the nice features of SO(10) but without proton decay or doublet-triplet splitting problems. At the TeV scale the extra exotic states may be discovered at the LHC, providing an observable footprint of an underlying $E_6$ gauge group broken at the Planck scale. Assuming an additional low energy $U(1)_X$ gauge group, identified as a non-trivial combination of diagonal $E_6$ generators, the $\\mu$ problem of the MSSM can be resolved. ", "machine_text": "  We propose a model that unifies the Planck scale in a supersymmetric standard model. Our model has a minimal number of supersymmetric excitations and contains gravity in its low-energy limit. We show that the model is invariant under a certain subgroup $\\Gamma$ of the standard model $\\mathrm{SM}$, and that the representations of the $\\Gamma$-invariant fermionic generators in the excited states of the model form a sequence of interlocked supersymmetric pairs, with the first pair being the gravitino-axion and the last pair being the light fermion-light antifermion. We show that the parameters of the model can be fixed by requiring that the representation of the Higgs boson in the highest excitation is the same as the standard model Higgs boson. We analyze the mass spectrum of the model and show that the only scalar mass that is smaller than the Planck scale is the axion mass, which may be as small as the smallest supersymmetric mass scale $m_{Pl}$. We show that the standard model may be considered as a subset of our model, and that the only necessary modification of the standard model is to include a second Higgs sector with a Yukawa coupling to the fermionic generators that is proportional to the inverse of the Higgs mass. We discuss the problem of integrating out the Dirac fermionic generators in the low-energy limit, and suggest that this may be done in a manner analogous to the integration of the Dirac mass in the standard model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: PSR J1453+1902 and the radio luminosities of solitary versus binary   millisecond pulsars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0685, "human_text": "  We present 3 yr of timing observations for PSR J1453+1902, a 5.79-ms pulsar discovered during a 430-MHz drift-scan survey with the Arecibo telescope. Our observations show that PSR J1453+1902 is solitary and has a proper motion of 8(2) mas/yr. At the nominal distance of 1.2 kpc estimated from the pulsar's dispersion measure, this corresponds to a transverse speed of 46(11) km/s, typical of the millisecond pulsar population. We analyse the current sample of 55 millisecond pulsars in the Galactic disk and revisit the question of whether the luminosities of isolated millisecond pulsars are different from their binary counterparts. We demonstrate that the apparent differences in the luminosity distributions seen in samples selected from 430-MHz surveys can be explained by small-number statistics and observational selection biases. An examination of the sample from 1400-MHz surveys shows no differences in the distributions. The simplest conclusion from the current data is that the spin, kinematic, spatial and luminosity distributions of isolated and binary millisecond pulsars are consistent with a single homogeneous population. ", "machine_text": "  We present new radio luminosity measurements for the millisecond pulsars (MSPs) PSR J1453+1902 and PSR J1650-erts. These radio luminosity measurements are derived from observations made with the Very Large Array (VLA) as part of the North American Nanohertz Observatory for Networked Grids (NANOGrav) project. We find that the radio luminosity of PSR J1453+1902 is 6.3 kpc$^{-1}$, which is one of the highest radio luminosities measured for a solitary MSP. We also find that the radio luminosity of PSR J1650-erts has a startlingly low value of 2.6 kpc$^{-1}$, which is similar to the radio luminosity measured for the MSP- companion star binaries such as PSR J1141-6545 and PSR J1708-1458. Our results raise the question of whether a large fraction of MSPs are actually members of wide binary systems that are simply not detected because of the limitations of current observing techniques. We discuss the implications of this hypothesis on the current theories of the evolution of MSPs and their companions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Straggler Identification in Round-Trip Data Streams via Newton's   Identities and Invertible Bloom Filters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3313, "human_text": "  We introduce the straggler identification problem, in which an algorithm must determine the identities of the remaining members of a set after it has had a large number of insertion and deletion operations performed on it, and now has relatively few remaining members. The goal is to do this in o(n) space, where n is the total number of identities. The straggler identification problem has applications, for example, in determining the set of unacknowledged packets in a high-bandwidth multicast data stream. We provide a deterministic solution to the straggler identification problem that uses only O(d log n) bits and is based on a novel application of Newton's identities for symmetric polynomials. This solution can identify any subset of d stragglers from a set of n O(log n)-bit identifiers, assuming that there are no false deletions of identities not already in the set. Indeed, we give a lower bound argument that shows that any small-space deterministic solution to the straggler identification problem cannot be guaranteed to handle false deletions. Nevertheless, we show that there is a simple randomized solution using O(d log n log(1/epsilon)) bits that can maintain a multiset and solve the straggler identification problem, tolerating false deletions, where epsilon>0 is a user-defined parameter bounding the probability of an incorrect response. This randomized solution is based on a new type of Bloom filter, which we call the invertible Bloom filter. ", "machine_text": "  We present a new method for identifying stragglers in round-trip data streams based on Newton's identities and invertible Bloom filters. The method is motivated by the observation that when a message is delayed due to a straggler, the resulting sequence of messages forms a linear dependence over the original field. By using this linear dependence to extract the straggler, we are able to identify the straggler in the presence of any field- independent probabilistic adversary that can create (unidirectional) data dependencies. We show that the key idea of our method is to use a \"straggler-oriented\" Newton identity that does not preserve the field-independent structure induced by the straggler. Our technique is robust to stragglers that act as a combination of a field-dependent and field-independent adversary. We also show that our method is more efficient than existing techniques that use only field-independent Newton identities. Finally, we show that our method can be used to identify stragglers in the context of application-level protocols, where the data is opaque.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The impact of radio feedback from active galactic nuclei in cosmological   simulations: Formation of disk galaxies. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1218, "human_text": "  In this paper, we present a new implementation of feedback due to active galactic nuclei (AGN) in cosmological simulations of galaxy formation. We assume that a fraction of jet energy, which is generated by an AGN, is transferred to the surrounding gas as thermal energy. Combining a theoretical model of mass accretion onto black holes with a multiphase description of star-forming gas, we self-consistently follow evolution of both galaxies and their central black holes. The novelty in our model is that we consider two distinct accretion modes: standard radiatively efficient thin accretion disks and radiatively inefficient accretion flows which we will generically refer to as RIAFs; motivated by theoretical models for jet production in accretion disks, we assume that only the RIAF is responsible for the AGN feedback. We find that, after an initial episode of bursting star formation, the accretion rate onto the central black hole drops so that the accretion disk switches to a RIAF structure. At this point, the feedback from the AGN becomes efficient and slightly suppresses star formation in the galactic disk and almost completely halts star formation in the bulge. As a result, the nucleus becomes a stochastically fuelled low-luminosity AGN (Seyfert galaxy) with recurrent short-lived episodes of activity after the star bursts. Our model predicts several properties of the low-luminosity AGN including the bolometric luminosity, jet powers, the effect on kpc-scale of the radio jet and the AGN lifetime, which are in broad agreement with observations of Seyfert galaxies and their radio activity. We also find that the mass ratios between the central black hole and the the host spheroid at z = 0 are ~10^{-3} regardless of the strength of either supernova feedback or AGN feedback. (abridged) ", "machine_text": " We present a numerical study of the impact of feedback from active galactic nuclei (AGN) in the formation of disk galaxies in cosmological hydrodynamical simulations. We find that the ionized gas in the outer parts of the disks is able to sustain an AGN feedback that is able to regulate the gas supply to the inner parts of the disk and thus affect the formation and evolution of the galaxies. We observe that the feedback from a single AGN is able to prevent the accretion of gas and thus the growth of a single galaxy, while it has no effect on the evolution of the large scale structure in the form of a galaxy cluster. We also find that the feedback from a number of AGN that are distributed on the same scale as the galaxies is able to affect the evolution of the large scale structure. Our results suggest that the feedback from the AGN is able to form a large scale structure in the form of chains of disk galaxies, and thus it has an impact on the evolution of the structure on the largest scales that can be described by a single simulation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Planetary System Around HD 155358: The Lowest Metallicity Planet Host   Star. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3228, "human_text": "  We report the detection of two planetary mass companions to the solar-type star HD 155358. The two planets have orbital periods of 195.0 and 530.3 days, with eccentricities of 0.11 and 0.18. The minimum masses for these planets are 0.89 and 0.50 Jupiter masses respectively. The orbits are close enough to each other, and the planets are sufficiently massive, that the planets are gravitationally interacting with each other, with their eccentricities and arguments of periastron varying with periods of 2300--2700 years. While large uncertainties remain in the orbital eccentricities, our orbital integration calculations indicate that our derived orbits would be dynamically stable for at least 10^8 years. With a metallicity [Fe/H] of -0.68, HD 155358 is tied with the K1III giant planet host star HD 47536 for the lowest metallicity of any planet host star yet found. Thus, a star with only 21% of the heavy-element content of our Sun was still able to form a system of at least two Jovian-mass planets and have their orbits evolve to semi-major axes of 0.6-1.2 AU. ", "machine_text": "  A Planetary System Around HD 155358: The Lowest Metallicity Planet Host Star  We present photometric detections of three confirmed and one unconfirmed planets around the metal-poor solar twin HD 155358. The innermost planet, b, is a typical hot Jupiter with a period of 3.3 days. The middle planet, c, has a period of 8.3 days and is a low-mass object in a close orbit. The outermost planet, d, has a period of 16.3 days and is a high-mass object in a distant orbit. We estimate the mass of c using the radial velocity method, and find it to be 0.31 Jupiter masses. We determine the metallicity of the star to be [Fe/H] = +0.00 \u00b1 0.02, which is 1/3 of the metallicity of the Sun. The probability of this system being formed by the accretion of interstellar gas and dust onto the gaseous protoplanetary disk is 1.6%. This probability increases to 5% if the system is formed by the accretion of a rocky planetesimal belt. We estimate that the accretion timescale for a protoplanetary disk is 4.2 Gyr, and the accretion timescale for a rocky planetesimal belt is 1.1 Gyr. Therefore, the accretion timescale is too long to produce this system through the accretion of a protoplanetary disk, but is within the range of the accretion timescale for a rocky planetesimal belt. The metallicity of the star is too low to be explained by the accretion of a protoplanetary disk, but is consistent with the accretion of a rocky planetesimal belt. We discuss the possibility that this planetary system could have formed through the accretion of a giant planetesimal, rather than a protoplanetary disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Testing and selection of cosmological models with $(1+z)^6$ corrections. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0283, "human_text": "  In the paper we check whether the contribution of $(-)(1+z)^6$ type in the Friedmann equation can be tested. We consider some astronomical tests to constrain the density parameters in such models. We describe different interpretations of such an additional term: geometric effects of Loop Quantum Cosmology, effects of braneworld cosmological models, non-standard cosmological models in metric-affine gravity, and models with spinning fluid. Kinematical (or geometrical) tests based on null geodesics are insufficient to separate individual matter components when they behave like perfect fluid and scale in the same way. Still, it is possible to measure their overall effect. We use recent measurements of the coordinate distances from the Fanaroff-Riley type IIb (FRIIb) radio galaxy (RG) data, supernovae type Ia (SNIa) data, baryon oscillation peak and cosmic microwave background radiation (CMBR) observations to obtain stronger bounds for the contribution of the type considered. We demonstrate that, while $\\rho^2$ corrections are very small, they can be tested by astronomical observations -- at least in principle. Bayesian criteria of model selection (the Bayesian factor, AIC, and BIC) are used to check if additional parameters are detectable in the present epoch. As it turns out, the $\\Lambda$CDM model is favoured over the bouncing model driven by loop quantum effects. Or, in other words, the bounds obtained from cosmography are very weak, and from the point of view of the present data this model is indistinguishable from the $\\Lambda$CDM one. ", "machine_text": " We consider a general class of cosmological models in the presence of corrections proportional to $(1+z)^6$, where $z$ is the scale factor. We show that these corrections are linear combinations of higher-order derivatives of the scale factor. This generalizes the results of previous works in the case $z\\equiv1$. We find that the selection of models with six corrections is much more restrictive than the selection of models with two corrections only. We show that this is due to the fact that the higher-order derivatives become less important as the scale factor grows larger. The model selection problem is therefore much easier in the large-$z$ limit. In this limit, the model selection problem is equivalent to the problem of selecting the Lagrangian density $\\rho=\\rho_{\\rm matter}+\\rho_{\\rm gravity}+\\rho_{\\rm cosmological constant}$. We show that the allowed values of $\\rho$ are much more restrictive in the case with six corrections than in the case with two corrections. We find that the allowed range of the matter density is $\\rho_{\\rm matter} \\in [0.5,1.5]$, while the allowed range of the cosmological constant is $\\rho_{\\rm cosmological constant} \\in [-1,1]$. In the limit $z\\to\\infty$, the allowed range of the matter density is $\\rho_{\\rm matter} \\in [0.5,1.0]$, while the allowed range of the cosmological constant is $\\rho_{\\rm cosmological constant} \\in [-0.5,0.5]$. We discuss the physical implications of our results.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Displacement of the Sun from the Galactic Plane. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.095, "human_text": "  We have carried out a comparative statistical study for the displacement of the Sun from the Galactic plane (z_\\odot) following three different methods. The study has been done using a sample of 537 young open clusters (YOCs) with log(Age) < 8.5 lying within a heliocentric distance of 4 kpc and 2030 OB stars observed up to a distance of 1200 pc, all of them have distance information. We decompose the Gould Belt's member in a statistical sense before investigating the variation in the z_\\odot estimation with different upper cut-off limits in the heliocentric distance and distance perpendicular to the Galactic plane. We found z_\\odot varies in a range of ~ 13 - 20 pc from the analys is of YOCs and ~ 6 - 18 pc from the OB stars. A significant scatter in the z_\\odot obtained due to different cut-off values is noticed for the OB stars although no such deviation is seen for the YOCs. We also determined scale heights of 56.9(+3.8)(-3.4} and 61.4(+2.7)(-2.4) pc for the distribution of YOCs and OB stars respectively. ", "machine_text": "  We have developed a new method for investigating the three-dimensional distribution of solar-like stars in the Milky Way and applied this method to the recent Hipparchus and Gaia data. We show that the Sun is displaced by about 2.5 kpc from the plane in which the majority of stars in the Galactic disk lie, and that this displacement increases with distance from the Sun. We estimate that the Sun is about 50pc above the plane and that this 'ecliptic plane' is inclined by about 60\u00b0 to the Galactic plane. We find that the distribution of solar-like stars in the three-dimensional volume defined by the Galactic plane and the ecliptic plane is consistent with a flat distribution on the ecliptic plane, with a gentle outward trend in density away from the Sun. The properties of this 3D stellar distribution are consistent with it being due to a combination of the orbital motions of stars in the Galactic disk and the propagation of the two-dimensional stellar density distribution in the Galactic plane, which is known to be highly non-uniform. We show that this 3D stellar distribution can be explained in terms of the properties of the local Galactic neighborhood, without requiring a hypothesis of large-scale structure in the Galactic disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Expressing Combinatorial Optimization Problems by Systems of Polynomial   Equations and the Nullstellensatz. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0578, "human_text": "  Systems of polynomial equations over the complex or real numbers can be used to model combinatorial problems. In this way, a combinatorial problem is feasible (e.g. a graph is 3-colorable, hamiltonian, etc.) if and only if a related system of polynomial equations has a solution. In the first part of this paper, we construct new polynomial encodings for the problems of finding in a graph its longest cycle, the largest planar subgraph, the edge-chromatic number, or the largest k-colorable subgraph.   For an infeasible polynomial system, the (complex) Hilbert Nullstellensatz gives a certificate that the associated combinatorial problem is infeasible. Thus, unless P = NP, there must exist an infinite sequence of infeasible instances of each hard combinatorial problem for which the minimum degree of a Hilbert Nullstellensatz certificate of the associated polynomial system grows.   We show that the minimum-degree of a Nullstellensatz certificate for the non-existence of a stable set of size greater than the stability number of the graph is the stability number of the graph. Moreover, such a certificate contains at least one term per stable set of G. In contrast, for non-3- colorability, we found only graphs with Nullstellensatz certificates of degree four. ", "machine_text": " We show how to express combinatorial optimization problems by systems of polynomial equations and how to use the Nullstellensatz to solve them. As an application, we consider the problem of finding an arrangement of n identical objects in n boxes with at most k objects per box, with the objective of minimizing the number of empty boxes. We show that this problem can be expressed as a system of polynomial equations, and that the solutions to this system correspond to arrangements of minimum total number of empty boxes. Furthermore, we show that this system has a solution if and only if n \u2265 2k+1, and that this solution is unique if and only if n \u2265 3k+1. We derive a lower bound for the number of empty boxes in any arrangement of n objects in n boxes with at most k objects per box, and show that this bound is tight for n = 2k+1. Finally, we consider the special case of the problem where each box can hold at most two objects, and show that the number of empty boxes is equal to the number of non-zero terms in the unique solution to the corresponding system of polynomial equations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Isolated horizons in higher-dimensional Einstein-Gauss-Bonnet gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1371, "human_text": "  The isolated horizon framework was introduced in order to provide a local description of black holes that are in equilibrium with their (possibly dynamic) environment. Over the past several years, the framework has been extended to include matter fields (dilaton, Yang-Mills etc) in D=4 dimensions and cosmological constant in $D\\geq3$ dimensions. In this article we present a further extension of the framework that includes black holes in higher-dimensional Einstein-Gauss-Bonnet (EGB) gravity. In particular, we construct a covariant phase space for EGB gravity in arbitrary dimensions which allows us to derive the first law. We find that the entropy of a weakly isolated and non-rotating horizon is given by $\\mathcal{S}=(1/4G_{D})\\oint_{S^{D-2}}\\bm{\\tilde{\\epsilon}}(1+2\\alpha\\mathcal{R})$. In this expression $S^{D-2}$ is the $(D-2)$-dimensional cross section of the horizon with area form $\\bm{\\tilde{\\epsilon}}$ and Ricci scalar $\\mathcal{R}$, $G_{D}$ is the $D$-dimensional Newton constant and $\\alpha$ is the Gauss-Bonnet parameter. This expression for the horizon entropy is in agreement with those predicted by the Euclidean and Noether charge methods. Thus we extend the isolated horizon framework beyond Einstein gravity. ", "machine_text": "  We consider the question of whether a bound state solution can be isolated from a single horizon in higher-dimensional Einstein-Gauss-Bonnet gravity. This question is motivated by a recent suggestion that a similar scenario may occur in higher-dimensional general relativity. To answer this question, we first show that such isolation is not possible in five dimensions, using a horizonic bulk solution with an everywhere regular horizon. In higher dimensions, however, the bulk solution can be regular only on a subset of the bulk. We show that for any such bulk solution, there exist vector fields which are divergently extensive on the bulk but whose flux through the horizon is always zero. These vector fields prevent the formation of a bound state. We also consider a variant of Einstein-Gauss-Bonnet gravity in which the Ricci scalar is replaced by a \"curvature scalar\" which is defined on the bulk but not on the horizon. In this case, we show that the bulk solution is not necessarily regular on the bulk, but that an isolated bound state solution can nonetheless be formed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A WENO Algorithm for the Growth of Ionized Regions at the Reionization   Epoch. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0326, "human_text": "  We investigate the volume growth of ionized regions around UV photon sources with the WENO algorithm, which is an effective solver of photon kinetics in the phase space described by the radiative transfer equation. We show that the volume growth rate, either of isolated ionized regions or of clustered regions in merging, generally consists of three phases: fast or relativistic growth phase at the early stage, slow growth phase at the later stage, and a transition phase between the fast and slow phases. We also show that the volume growth of ionized regions around clustered sources with intensity $\\dot{E}_i$ ($i=1, 2, ...$) would have the same behavior as a single source with intensity $\\dot{E}=\\sum_i\\dot{E}_i$, if all the distances between nearest neighbor sources $i$ and $j$ are smaller than $c(t^i_c+t^j_c)$, $t^i_c$ being the time scale $t_c$ of source $i$. Therefore, a tightly clustered UV photon sources would lead to a slow growth of ionized volume. This effect would be important for studying the redshift-dependence of 21cm signals from the reionization epoch. ", "machine_text": " We have developed a high-order accurate WENO scheme for the simulation of large-scale structure formation in the IGM, capable of capturing the statistical features of the small-scale fluctuations in a fully self-consistently way. Our algorithm is based on the solution of the moment equations for the growth rates of the ionized regions, obtained by a kinetic description of the reionization process in terms of a probability distribution function. We find that a simple generalized Wolf criterion for the triggering of new ionized regions is sufficient to reproduce the large-scale structures observed in the inner IGM, provided that the small-scale fluctuations are included in a self-consistent way. Our scheme is robust and efficient, and has a high degree of accuracy. The small-scale fluctuations have a strong impact on the large-scale structure formation, and they induce a significant statistical inhomogeneity in the large-scale distribution of ionized regions. We show that this inhomogeneity can be described in terms of a simple power law, which we use to analyze the large-scale structure in the IGM, and to evaluate the statistical significance of the small-scale fluctuations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probing non-standard decoherence effects with solar and KamLAND   neutrinos. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2568, "human_text": "  It has been speculated that quantum gravity might induce a \"foamy\" space-time structure at small scales, randomly perturbing the propagation phases of free-streaming particles (such as kaons, neutrons, or neutrinos). Particle interferometry might then reveal non-standard decoherence effects, in addition to standard ones (due to, e.g., finite source size and detector resolution.) In this work we discuss the phenomenology of such non-standard effects in the propagation of electron neutrinos in the Sun and in the long-baseline reactor experiment KamLAND, which jointly provide us with the best available probes of decoherence at neutrino energies E ~ few MeV. In the solar neutrino case, by means of a perturbative approach, decoherence is shown to modify the standard (adiabatic) propagation in matter through a calculable damping factor. By assuming a power-law dependence of decoherence effects in the energy domain (E^n with n = 0,+/-1,+/-2), theoretical predictions for two-family neutrino mixing are compared with the data and discussed. We find that neither solar nor KamLAND data show evidence in favor of non-standard decoherence effects, whose characteristic parameter gamma_0 can thus be significantly constrained. In the \"Lorentz-invariant\" case n=-1, we obtain the upper limit gamma_0<0.78 x 10^-26 GeV at 95% C.L. In the specific case n=-2, the constraints can also be interpreted as bounds on possible matter density fluctuations in the Sun, which we improve by a factor of ~ 2 with respect to previous analyses. ", "machine_text": " We present a semi-quantitative interpretation of recent results from two experiments which probe non-standard decoherence effects in large-scale neutrino detectors. The first is a search for the elastic neutron-neutrino-nucleon scattering in the sun, which was reported by the Borexino experiment to be at most 0.17% of the Standard Model prediction, but could be as large as 4.4% in a model with an additional singlet quark-flavor quark-flavor-locked (QFL) neutrinos. We show that this could be probed more sensitively by a dedicated solar neutrino experiment with a small-scale detector in the near future, if the non-standard neutrinos are QFL and the detector has sufficient energy resolution to separate theStandard Model and QFL neutrinos. The second is a search for a non-standard decoherence effect in the large-scale KamLAND experiment, in which the assumption of a Markovian uncertainty model is shown to be violated by a surprise component in the $pp\\to e^+ e^-$ asymmetry. We discuss a possible physical origin of this non-standard effect, involving a mechanism which could also lead to a large suppression of the standard elastic $pp$ scattering in the sun.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Wide Field Surveys and Astronomical Discovery Space. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0809, "human_text": "  I review the status of science with wide field surveys. For many decades surveys have been the backbone of astronomy, and the main engine of discovery, as we have mapped the sky at every possible wavelength. Surveys are an efficient use of resources. They are important as a fundamental resource; to map intrinsically large structures; to gain the necessary statistics to address some problems; and to find very rare objects. I summarise major recent wide field surveys - 2MASS, SDSS, 2dfGRS, and UKIDSS - and look at examples of the exciting science they have produced, covering the structure of the Milky Way, the measurement of cosmological parameters, the creation of a new field studying substellar objects, and the ionisation history of the Universe. I then look briefly at upcoming projects in the optical-IR survey arena - VISTA, PanSTARRS, WISE, and LSST. Finally I ask, now we have opened up essentially all wavelength windows, whether the exploration of survey discovery space is ended. I examine other possible axes of discovery space, and find them mostly to be too expensive to explore or otherwise unfruitful, with two exceptions : the first is the time axis, which we have only just begun to explore properly; and the second is the possibility of neutrino astrophysics. ", "machine_text": "  Wide Field Surveys and Astronomical Discovery Space We present a new algorithm for astronomical surveys that combines a wide field of view with a high resolution, both in the spatial and the spectral domains. Such a combination is very efficient for astronomical discoveries, as it allows a large area of the sky to be surveyed at high spectral resolution, making it possible to find very faint objects that would otherwise be drowned in the noise. We demonstrate the effectiveness of the method on a real survey of the Galactic Globular Cluster M13, in which we find a previously undiscovered dwarf galaxy that had been hiding in the noise. We show that the new galaxy has a very high abundance of rare elements, suggesting that it is a pristine member of the Galactic halo. The high resolution also reveals that the galaxy is actually composed of two sub-populations of stars, with different radii, metallicities and ages. We discuss the implications of this discovery for the dynamics of the Galactic halo, and in particular for the rough orbits hypothesis. We also show that our method is very efficient in terms of data acquisition, as it requires only a single exposure to achieve the desired sensitivity. We discuss the possibility of applying our method to other types of astronomical surveys, such as extrasolar planet searches.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological Simulations of the Preheating Scenario for Galaxy Cluster   Formation: Comparison to Analytic Models and Observations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3465, "human_text": "  We perform a set of non--radiative cosmological simulations of a preheated intracluster medium in which the entropy of the gas was uniformly boosted at high redshift. The results of these simulations are used first to test the current analytic techniques of preheating via entropy input in the smooth accretion limit. When the unmodified profile is taken directly from simulations, we find that this model is in excellent agreement with the results of our simulations. This suggests that preheated efficiently smoothes the accreted gas, and therefore a shift in the unmodified profile is a good approximation even with a realistic accretion history. When we examine the simulation results in detail, we do not find strong evidence for entropy amplification, at least for the high-redshift preheating model adopted here. In the second section of the paper, we compare the results of the preheating simulations to recent observations. We show -- in agreement with previous work -- that for a reasonable amount of preheating, a satisfactory match can be found to the mass-temperature and luminosity-temperature relations. However -- as noted by previous authors -- we find that the entropy profiles of the simulated groups are much too flat compared to observations. In particular, while rich clusters converge on the adiabatic self--similar scaling at large radius, no single value of the entropy input during preheating can simultaneously reproduce both the core and outer entropy levels. As a result, we confirm that the simple preheating scenario for galaxy cluster formation, in which entropy is injected universally at high redshift, is inconsistent with observations. ", "machine_text": " We present a systematic study of the formation of galaxy clusters within a suite of state-of-the-art cosmological hydrodynamical simulations, with special focus on the preheating scenario. We compare the cluster formation in the simulations with an analytic model of cluster formation and find that the model and the simulation results are in a good agreement, in the sense that the model explains the simulation results and the simulation results are consistent with the model. The clusters in the simulations are found to be smaller on average than the clusters in the analytic model. We show that this is likely due to the cooling of the intergalactic gas in the clusters, which in turn is due to the injection of the massive amounts of energy in the early universe by the inflationary cosmology. We then compare the cluster formation in the simulations with the observations of the large scale structure and find that the clusters in the simulations are much more massive, on average, than the clusters observed in the large scale structure. We show that this is likely due to the fact that the simulations include the cooling of the gas while the observations do not. We also show that this difference is likely due to the fact that the clusters in the simulations are younger, on average, than the clusters in the large scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mass spectrum of diquarks and mesons in the color--flavor locked phase   of dense quark matter. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2666, "human_text": "  The spectrum of meson and diquark excitations of dense quark matter is considered in the framework of the Nambu -- Jona-Lasinio model with three types of massless quarks in the presense of a quark number chemical potential $\\mu$. We investigate the effective action of meson- and diquark fields both at sufficiently large values of $\\mu>\\mu_c\\approx 330$ MeV, where the color--flavor locked (CFL) phase is realized, and in the chirally broken phase of quark matter ($\\mu<\\mu_c$). In the last case all nine pseudoscalar mesons are Nambu -- Goldstone (NG) bosons, whereas the mass of the scalar meson nonet is twice the dynamical quark mass. In the chirally broken phase the pseudoscalar diquarks are not allowed to exist as stable particles, but the scalar diquarks might be stable only at a rather strong interaction in the diquark channel. In the case of the CFL phase, all NG bosons of the model are realized as scalar and pseudoscalar diquarks. Moreover, it turns out that massive diquark excitations are unstable for this phase. In particular, for the scalar and pseudoscalar octets of diquark resonances a mass value around 230 MeV was found numerically. In contrast, mesons are stable particles in the CFL phase. Their masses lie in the interval 400$\\div$500 MeV for not too large values of $\\mu>\\mu_c$. ", "machine_text": " We calculate the mass spectra of quarkonia in the color--flavor locked (CFL) phase of dense quark matter and of the corresponding diquarks and mesons in the normal hadron phase. The quarkonia mass spectra in the CFL phase can be obtained by using the exact replica of the hadron spectrum with the only difference that the quarkonia are produced from quark-antiquark pairs instead of quarks and antiquarks. We find that the quarkonia mass spectra in the CFL phase is very different from the hadron spectrum: in particular, the masses of quarkonia are always smaller than the masses of the corresponding hadrons even when the quarkonia are produced from the lightest quark-antiquark pairs. The smallness of the quarkonia masses can be explained by the strong quark-antiquark correlation in the CFL phase. On the other hand, the diquark and meson mass spectra in the normal hadron phase can be obtained by using thecounty basis trick with the Jordan--Wigner transformation. We find that the mass spectra of diquarks and mesons are different in the two phases: in particular, some very heavy mesons which do not exist in the hadron phase can be produced in the CFL phase. We also find that the diquark and meson mass spectra in the normal hadron phase can be obtained by using the exact replica of the quarkonia mass spectrum with the only difference that the quarkonia are produced from quark-antiquark pairs instead of quarks and antiquarks. Our results can be used to test the quarkonia production in the CFL phase and to probe the structure of quarkonia in the hadron phase.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Long time existence of smooth solutions for the rapidly rotating   shallow-water and Euler equations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0758, "human_text": "  We study the stabilizing effect of rotational forcing in the nonlinear setting of two-dimensional shallow-water and more general models of compressible Euler equations. In [H. Liu and E. Tadmor, Phys. D 188 (2004), no. 3-4, 262-276] we have shown that the pressureless version of these equations admit global smooth solution for a large set of sub-critical initial configurations. In the present work we prove that when rotational force dominates the pressure, it \\emph{prolongs} the life-span of smooth solutions for t < ln(1/d); here d << 1 is the ratio of the pressure gradient measured by the inverse squared Froude number, relative to the dominant rotational forces measured by the inverse Rossby number. Our study reveals a ``nearby'' periodic-in-time approximate solution in the small d-regime, upon which hinges the long time existence of the exact smooth solution. These results are in agreement with the close-to periodic dynamics observed in the ``near inertial oscillation'' (NIO) regime which follows oceanic storms. Indeed, our results indicate the existence of smooth, ``approximate periodic'' solution for a time period of \\emph{days}, which is the relevant time period found in NIO obesrvations. ", "machine_text": "  We show existence of smooth solutions for the rapidly rotating shallow-water and Euler equations. The solutions are given in the form of conservation laws for a certain class of functions. The solutions exist in a neighborhood of the origin and are regular in a neighborhood of the core. We show that the solutions are stable with respect to the small parameter $\\dot \\omega \\ll 1$. This allows us to regularize the solution by a Taylor expansion in this small parameter. In the limit $\\dot \\omega \\to 0$ the solution can be recovered from the conservation laws and the initial conditions. The solutions can be thought of as a generalization of the lazy-wave solution to the case of rapidly rotating flow. The solutions have a variety of interesting physical applications. In particular we show that they can be used to describe the flow in a rotating cylindrical tank with an insoluble contaminant, the flow in a rotating shallow water of constant depth with an impurity, the motion of a flexible membrane in a rotating frame, the dynamics of rotating bodies in a viscous fluid, and the evolution of vorticity in a rotating fluid.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An invariance principle for semimartingale reflecting Brownian motions   in domains with piecewise smooth boundaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0405, "human_text": "  Semimartingale reflecting Brownian motions (SRBMs) living in the closures of domains with piecewise smooth boundaries are of interest in applied probability because of their role as heavy traffic approximations for some stochastic networks. In this paper, assuming certain conditions on the domains and directions of reflection, a perturbation result, or invariance principle, for SRBMs is proved. This provides sufficient conditions for a process that satisfies the definition of an SRBM, except for small random perturbations in the defining conditions, to be close in distribution to an SRBM. A crucial ingredient in the proof of this result is an oscillation inequality for solutions of a perturbed Skorokhod problem. We use the invariance principle to show weak existence of SRBMs under mild conditions. We also use the invariance principle, in conjunction with known uniqueness results for SRBMs, to give some sufficient conditions for validating approximations involving (i) SRBMs in convex polyhedrons with a constant reflection vector field on each face of the polyhedron, and (ii) SRBMs in bounded domains with piecewise smooth boundaries and possibly nonconstant reflection vector fields on the boundary surfaces. ", "machine_text": " We establish an invariance principle for semimartingale reflecting Brownian motions in domains with piecewise smooth boundaries. The motivation for this research is the fact that in the study of the dynamics of quantum particles in a many-body system, the description of the evolution of the system is often done by considering the motion of a certain semimartingale, called the disturbance, reflecting at the boundary of the system. We show that such a disturbance evolving according to a certain invariance principle gives rise to a class of semimartingale reflecting Brownian motions in domains with piecewise smooth boundaries, generalizing results in the literature on invariance principles for Brownian motions in similar situations. The key ideas in the proof of the main results are the use of a stochastic counterpart of the Hamilton-Jacobi equation, the invariance of the generating functionals of the reflecting integrals and a boundary conditions for the evolution operator of the semimartingale. As an application, we show that our results can be used to establish an invariance principle for certain families of Brownian semimartingales.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of Newtonian fluid slip using a torsional ultrasonic   oscillator. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3498, "human_text": "  The composite torsional ultrasonic oscillator, a versatile experimental system, can be used to investigate slip of Newtonian fluid at a smooth surface. A rigorous analysis of slip-dependent damping for the oscillator is presented. Initially, the phenomenon of finite surface slip and the slip length are considered for a half-space of Newtonian fluid in contact with a smooth, oscillating solid surface. Definitions are revisited and clarified in light of inconsistencies in the literature. We point out that, in general oscillating flows, Navier's slip length b is a complex number. An intuitive velocity discontinuity parameter of unrestricted phase is used to describe the effect of slip on measurement of viscous shear damping. The analysis is applied to the composite oscillator and preliminary experimental work for a 40 kHz oscillator is presented. The Non-Slip Boundary Condition (NSBC) has been verified for a hydrophobic surface in water to within ~60 nm of |b|=0 nm. Experiments were carried out at shear rate amplitudes between 230 and 6800 /s, corresponding to linear displacement amplitudes between 3.2 and 96 nm. ", "machine_text": "  We have developed a new technique to measure the slip length in a Newtonian fluid using a torsional ultrasonic oscillator. The technique is based on the fact that the back and forth motion of a torsional resonator in a fluid results in a superposition of the torsional and extensional components in the fluid. By driving the resonator at a frequency at or near one of its eigenmodes, the energy transfer from the resonator to the fluid can be highly efficient. We use this effect to measure the slip length by comparing the energy consumption required to drive the resonator at different frequencies. We show that this technique is independent of the detailed shape of the resonator, the energy transfer efficiency, the amplitude of the resonator's motion, and the inertial and frictional forces in the fluid. We demonstrate a slip length measurement sensitivity of better than 10% with a standard deviation of 2.5% in a Taylor flow. The proposed technique has the potential for measuring the slip length with high sensitivity and precision in any Newtonian fluid, including liquids and gases, in a variety of flow geometries, and with a range of resonator shapes and driving frequencies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Central Kiloparsec of Seyfert and Inactive Host Galaxies: a   Comparison of Two-Dimensional Stellar and Gaseous Kinematics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4162, "human_text": "  We investigate the properties of the two-dimensional distribution and kinematics of ionised gas and stars in the central kiloparsecs of a matched sample of nearby active (Seyfert) and inactive galaxies, using the SAURON Integral Field Unit on the William Herschel Telescope. The ionised gas distributions show a range of low excitation regions such as star formation rings in Seyferts and inactive galaxies, and high excitation regions related to photoionisation by the AGN. The stellar kinematics of all galaxies in the sample show regular rotation patterns typical of disc-like systems, with kinematic axes which are well aligned with those derived from the outer photometry and which provide a reliable representation of the galactic line of nodes. After removal of the non-gravitational components due to e.g. AGN-driven outflows, the ionised gas kinematics in both the Seyfert and inactive galaxies are also dominated by rotation with global alignment between stars and gas in most galaxies. This result is consistent with previous findings from photometric studies that the large-scale light distribution of Seyfert hosts are similar to inactive hosts. However, fully exploiting the two-dimensional nature of our spectroscopic data, deviations from axisymmetric rotation in the gaseous velocity fields are identified that suggest the gaseous kinematics are more disturbed at small radii in the Seyfert galaxies compared with the inactive galaxies, providing a tentative link between nuclear gaseous streaming and nuclear activity. ", "machine_text": "  We present an analysis of the kinematics of stars and gas in the central kiloparsec of Seyfert and inactive host galaxies. We use high-resolution two-dimensional (2D) velocity fields obtained from spectral-image cubes of the 2MASS and SDSS surveys. We find that in both active and inactive galaxies the stellar velocity fields are well described by a single axisymmetric component, and that the gaseous velocity fields are well described by a single component in the active galaxies, but are more complex in the inactive galaxies. In both the stellar and gaseous velocity fields of the active galaxies, the component along the minor axis of the 2D velocity field is typically larger than the component along the major axis. We show that this is consistent with the physical scenario in which the gas is flowing towards the center along the minor axis, and is less efficiently driven out of the system along the major axis. The velocity fields of the inactive galaxies show a more complex structure, and do not display a clear preference for the minor axis. We show this is consistent with the physical scenario in which the gas is likely to be flowing along the major axis, while the stellar component is flowing along the minor axis. We find that the relative velocity dispersion of the gas and stars is systematically higher in the active galaxies, which may indicate a difference in the properties of the gas and stars in the two types of galaxies. Our results suggest that the 2D velocity fields can provide important information on the properties of the gas and stars, and on the mechanisms that drive the dynamical processes in the central region of galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Symplectic Test of the L-Functions Ratios Conjecture. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0927, "human_text": "  Recently Conrey, Farmer and Zirnbauer conjectured formulas for the averages over a family of ratios of products of shifted L-functions. Their L-functions Ratios Conjecture predicts both the main and lower order terms for many problems, ranging from n-level correlations and densities to mollifiers and moments to vanishing at the central point. There are now many results showing agreement between the main terms of number theory and random matrix theory; however, there are very few families where the lower order terms are known. These terms often depend on subtle arithmetic properties of the family, and provide a way to break the universality of behavior. The L-functions Ratios Conjecture provides a powerful and tractable way to predict these terms. We test a specific case here, that of the 1-level density for the symplectic family of quadratic Dirichlet characters arising from even fundamental discriminants d \\le X. For test functions supported in (-1/3, 1/3) we calculate all the lower order terms up to size O(X^{-1/2+epsilon}) and observe perfect agreement with the conjecture (for test functions supported in (-1, 1) we show agreement up to errors of size O(X^{-epsilon}) for any epsilon). Thus for this family and suitably restricted test functions, we completely verify the Ratios Conjecture's prediction for the 1-level density. ", "machine_text": "  We show that the L-functions ratios conjecture can be tested by examining the symplectic ratio of certain representations of the Absolute ElsevierMeasure, in a way that avoids the need to compute the L-functions of certain elliptic curves. We show that the symplectic ratio of these representations is bounded from below by a constant, which is a consequence of the Ratios Conjecture if it is true. This provides a way to test the Ratios Conjecture using only symplectic methods.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Strange Nucleon Form Factors from $ep$ and $\\nu p$ Elastic Scattering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1115, "human_text": "  The recent parity-violating $ep$ forward-scattering elastic asymmetry data from Jefferson Lab (HAPPEx and G0), when combined with the $\\nu p$ elastic cross section data from Brookhaven (E734), permit an extraction of the strangeness contribution to the vector and axial nucleon form factors for momentum transfers in the range $0.45 < Q^2 < 1.0$ GeV$^2$. These results, combined with the recent determination of the strange vector form factors at $Q^2 = 0.1$ GeV$^2$ (SAMPLE, HAPPEx, PVA4, G0) have been interpreted in terms of $uuds\\bar{s}$ configurations very different from the kaon-loop configurations usually associated with strangeness in the nucleon. New experiments are being proposed to improve the state of our knowledge of the $\\nu p$ elastic cross section -- these new experiments will push the range of $Q^2$ to much lower values, and greatly increase the precision of the $\\nu p$ elastic data. One outcome of this can be a measurement of the strangeness contribution to the nucleon spin, $\\Delta s$. Nuclear targets (e.g. C or Ar) are to be used in these neutrino experiments, and so a deep understanding of the nuclear physics, particularly in regard to final state effects, is needed before the potential of these precision experiments can be fully realized. ", "machine_text": " We present a comprehensive study of nucleon form factors in $ep$ and $\\nu p$ elastic scattering at high energy. Our aim is to search for structure beyond the Standard Model (SM) in the near-threshold region. We find that the $\\ep$-scattering cross section shows a clear structure at an energy slightly above the threshold, and the $\\nu p$-scattering cross section shows a structure in a large energy region slightly above the threshold. We show that these structures can be well described by a unified model in which the nucleon is bound to a new (heavy) neutral scalar particle (SP) with a mass around 1.5 GeV/c^2. This SP has only one SP-nucleon bound state with a width slightly smaller than the $\\ep$-scattering threshold, and the SP-nucleon system has an excited state with a width slightly larger than the $\\nu p$-scattering threshold. The model we propose can be used to explain many previous results in the literature which appeared to be inconsistent with the Standard Model. The only previous result which is not explained by our model is the $\\ep$-scattering result byColors et al. which shows a structure at an energy much higher than the threshold. We show that this result can be explained by a second order correction to the SM which we propose.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Generation of different Bell states within the SPDC phase-matching   bandwidth. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0848, "human_text": "  We study the frequency-angular lineshape for a phase-matched nonlinear process producing entangled states and show that there is a continuous variety of maximally-entangled states generated for different mismatch values within the natural bandwidth. Detailed considerations are made for two specific methods of polarization entanglement preparation, based on type-II spontaneous parametric down-conversion (SPDC) and on SPDC in two subsequent type-I crystals producing orthogonally polarized photon pairs. It turns out that different Bell states are produced at the center of the SPDC line and on its slopes, corresponding to about half-maximum intensity level. These Bell states can be filtered out by either frequency selection or angular selection, or both. Our theoretical calculations are confirmed by a series of experiments, performed for the two above-mentioned schemes of producing polarization-entangled photon pairs and with two kinds of measurements: frequency-selective and angular-selective. ", "machine_text": "  We present a simple and efficient scheme to generate different Bell states within the SPDC phase-matching bandwidth. The scheme is based on a narrow-band interferometer that is adjusted by a bulk electro-optic phase modulator. The interferometric structure is designed so that a large fraction of the output power is directed into one arm of the interferometer, leading to efficient conversion of the input light into a particular Bell state. The scheme is demonstrated experimentally and theoretically in the limit of small electro-optic phase modulation. We also propose a simple extension of the scheme that allows one to generate any Bell state.  We demonstrate theoretically and experimentally that this scheme can be used to generate different Bell states within the phase-matching bandwidth of the SPDC process. The scheme is based on a narrow-band interferometer that is adjusted by a bulk electro-optic phase modulator. The interferometric structure is designed so that a large fraction of the output power is directed into one arm of the interferometer, leading to efficient conversion of the input light into a particular Bell state. The scheme is demonstrated experimentally and theoretically in the limit of small electro-optic phase modulation. We also propose a simple extension of the scheme that allows one to generate any Bell state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Determination of intrinsic switching field distributions in   perpendicular recording media: numerical study of the $\\Delta H(M, \\Delta M)$   method. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1118, "human_text": "  We present a numerical study of the $\\Delta H(M,\\Delta M)$ method and its ability to accurately determine intrinsic switching field distributions in interacting granular magnetic materials such as perpendicular recording media. In particular, we study how this methodology fails for large ferromagnetic inter-granular interactions, at which point the associated strongly correlated magnetization reversal cannot be properly represented by the mean-field approximation, upon which the $\\Delta H(M,\\Delta M)$ method is based. In this study, we use a 2-dimensional array of symmetric hysterons that have an intrinsic switching field distribution of standard deviation $\\sigma$ and ferromagnetic nearest-neighbor interactions $J$. We find the $\\Delta H(M,\\Delta M)$ method to be very accurate for small $J/\\sigma$ values, while substantial errors develop once the effective exchange field becomes comparable with $\\sigma$, corroborating earlier results from micromagnetic simulations. We furthermore demonstrate that this failure is correlated with deviations from data set redundancy, which is a key property of the mean-field approximation. Thus, the $\\Delta H(M,\\Delta M)$ method fails in a well defined and quantifiable manner that can be easily assessed from the data sets alone. ", "machine_text": "  Determination of intrinsic switching field distributions in perpendicular recording media: numerical study of the $\\Delta H(M, \\Delta M)$ method  The demand for higher areal density and faster data transfer rate in hard disk drives has resulted in the development of new magnetic recording methods, such as perpendicular recording. In contrast to the conventional longitudinal recording, the magnetization in perpendicular recording is perpendicular to the disk surface, which allows for a much higher linear bit density. The practical consequence of this is that the magnetization of the recording media, in general, does not strictly follow the superposition principle. The superposition principle states that the magnetization in a ferromagnetic material is the vectorial sum of all previous magnetizations. In longitudinal recording, this is strictly true, in perpendicular recording, it is not. Therefore, the interpretation of magnetic measurements on perpendicular recording media requires a model that describes the statistics of the intrinsic, unwanted magnetization of the media. We have developed such a model, which we call the $\\Delta H(M, \\Delta M)$ method. The basic idea of the $\\Delta H(M, \\Delta M)$ method is to determine the switching field distribution from the statistics of the first and second order derivatives of the magnetic field with respect to the magnetic field. We have verified the $\\Delta H(M, \\Delta M)$ method by comparing the results of our numerical calculations with experimental results obtained by our colleagues. We have also performed a detailed study of the effect of the anisotropy constant on the statistics of the intrinsic magnetization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Finite temperature corrections and embedded strings in noncommutative   geometry and the standard model with neutrino mixing. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0613, "human_text": "  The recent extension of the standard model to include massive neutrinos in the framework of noncommutative geometry and the spectral action principle involves new scalar fields and their interactions with the usual complex scalar doublet. After ensuring that they bring no unphysical consequences, we address the question of how these fields affect the physics predicted in Weinberg-Salam theory, particularly in the context of the Electroweak phase transition. Applying the Dolan-Jackiw procedure, we calculate the finite temperature corrections, and find that the phase transition is first order. The new scalar interactions significantly improve the stability of the Electroweak Z string, through the ``bag'' phenomenon described by Watkins and Vachaspati. (Recently cosmic strings have climbed back into interest due to new evidence). Sourced by static embedded strings, an internal space analogy of Cartan's torsion is drawn, and a possible Higgs-force-like `gravitational' effect of this non-propagating torsion on the fermion masses is described. We also check that the field generating the Majorana mass for the $\\nu_R$ is non-zero in the physical vacuum. ", "machine_text": " We study finite temperature corrections to the leading noncommutative contributions to the effective action for a class of D-branes in noncommutative geometry. We find that the leading noncommutative correction can be generated by a change of variables which is a finite temperature correction to the original variables. We then consider the noncommutative effective action for D-branes at singularities and show that the effective action for the noncommutative geometry can be obtained as a finite temperature correction to the effective action for the standard geometry. This provides a geometrically intrinsic way to generate the noncommutative effective action from the standard effective action. We then consider the noncommutative effective action for the standard model with neutrino mixing and find that the noncommutative model can be obtained by a finite temperature correction to the standard model with neutrino mixing. We show that this correction is induced by an internal symmetry of the standard model with neutrino mixing. We consider the problem of constructing a manifestly noncommutative theory from a commutative theory and find that this is in general not possible. However, we show that a theory with an internal symmetry can be constructed from a theory without internal symmetry by a finite temperature correction which induces the internal symmetry.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Improved Quantum Hard-Sphere Ground-State Equations of State. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1191, "human_text": "  The London ground-state energy formula as a function of number density for a system of identical boson hard spheres, corrected for the reduced mass of a pair of particles in a sphere-of-influence picture, and generalized to fermion hard-sphere systems with two and four intrinsic degrees of freedom, has a double-pole at the ultimate \\textit{regular} (or periodic, e.g., face-centered-cubic) close-packing density usually associated with a crystalline branch. Improved fluid branches are contructed based upon exact, field-theoretic perturbation-theory low-density expansions for many-boson and many-fermion systems, appropriately extrapolated to intermediate densities, but whose ultimate density is irregular or \\textit{random} closest close-packing as suggested in studies of a classical system of hard spheres. Results show substantially improved agreement with the best available Green-function Monte Carlo and diffusion Monte Carlo simulations for bosons, as well as with ladder, variational Fermi hypernetted chain, and so-called L-expansion data for two-component fermions. ", "machine_text": " We consider the problem of constructing improved hard-sphere ground-state equations of state (GSEs) for use in computer simulations of hard-disk systems. We review the basic method for constructing such equations, which consists of (i) an exact determination of the low-energy structure and (ii) a subsequent fitting of a simple functional form to the computed pair potentials. We show that this method has several limitations, and we propose two general strategies for overcoming them. The first strategy involves fitting to the exact energy per particle, rather than to the simpler pair potential. The second strategy is to use a large number of reference systems, which are diverse in the details of their low-energy structure, in order to extract a generic form of the GSE that is relatively insensitive to the specific details of the low-energy structure. We illustrate these general strategies by considering several specific examples, and we provide a quantitative assessment of the improvements that are obtained.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Boutroux curves with external field: equilibrium measures without a   minimization problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3062, "human_text": "  The nonlinear steepest descent method for rank-two systems relies on the notion of g-function. The applicability of the method ranges from orthogonal polynomials (and generalizations) to Painleve transcendents, and integrable wave equations (KdV, NonLinear Schroedinger, etc.).   For the case of asymptotics of generalized orthogonal polynomials with respect to varying complex weights we can recast the requirements for the Cauchy-transform of the equilibrium measure into a problem of algebraic geometry and harmonic analysis and completely solve the existence and uniqueness issue without relying on the minimization of a functional. This addresses and solves also the issue of the ``free boundary problem'', determining implicitly the curves where the zeroes of the orthogonal polynomials accumulate in the limit of large degrees and the support of the measure. The relevance to the quasi--linear Stokes phenomenon for Painleve equations is indicated. A numerical algorithm to find these curves in some cases is also explained.   Technical note: the animations included in the file can be viewed using Acrobat Reader 7 or higher. Mac users should also install a QuickTime plugin called Flip4Mac. Linux users can extract the embedded animations and play them with an external program like VLC or MPlayer. All trademarks are owned by the respective companies. ", "machine_text": "  We study the problem of minimizing the energy of a minimizing self-map $\\phi$ of a Riemannian manifold $(M, g)$ under the assumption that for each $x\\in M$, there exists a unique positive real number $c_x$, such that $\\phi(x)=\\frac{1}{c_x}$. This problem was first considered by Boutroux, and the case of a flat metric was solved by Lawson. We show that the general case has no non-trivial solution.  Our primary motivation for this work is to understand the solution to the following problem, which appears in the literature on Lorentzian manifolds:  For a positive real number $\\epsilon$, find a minimizing self-map $\\phi$ of a Lorentzian manifold $(M, g)$, such that for each $x\\in M$, there exists a unique positive real number $c_x$, such that $\\phi(x)=\\epsilon/c_x$.  We show that in the presence of a non-trivial solution to this problem, the ambient space-time symmetry is broken in a very specific way. We then show that this symmetry breaking cannot occur in the presence of a symplectic form on the underlying space-time. In other words, we show that the solution to the problem is entirely controlled by the symplectic structure of the space-time.  This problem is closely related to the isoperimetric problem, and our techniques draw heavily on the theory of the isoperimetric constant. We show that in the presence of a solution to the isoperimetric problem, the symmetry of the space-time is broken in a way that is controlled by the isoperimetric constant. We also show that this breaking cannot occur in the presence of a symplectic form on the underlying space-time.  Finally, we show that a minimizing self-map $\\phi$ of a Riemannian manifold $(M, g)$, such that for each $x\\in M$, there exists a unique positive real number $c_x$, such that $\\phi(x)=\\frac{1}{c_x}$, is necessarily a solution to the Dirichlet problem for the Laplace equation on the space-time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Three Particle Correlations from STAR. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.022, "human_text": "  Two-particle correlations have shown modification to the away-side shape in central Au+Au collisions relative to $pp$, d+Au and peripheral Au+Au collisions. Different scenarios can explain this modification including: large angle gluon radiation, jets deflected by transverse flow, path length dependent energy loss, Cerenkov gluon radiation of fast moving particles, and conical flow generated by hydrodynamic Mach-cone shock-waves. Three-particle correlations have the power to distinguish the scenarios with conical emission, conical flow and Cerenkov radiation, from other scenarios. In addition, the dependence of the observed shapes on the $p_T$ of the associated particles can be used to distinguish conical emission from a sonic boom (Mach-cone) and from QCD-Cerenkov radiation. We present results from STAR on 3-particle azimuthal correlations for a high $p_T$ trigger particle with two softer particles. Results are shown for $pp$, d+Au and high statistics Au+Au collisions at $\\sqrt{s_{NN}}$=200 GeV. An important aspect of the analysis is the subtraction of combinatorial backgrounds. Systematic uncertainties due to this subtraction and the flow harmonics v2 and v4 are investigated in detail. The implications of the results for the presence or absence of conical flow from Mach-cones are discussed. ", "machine_text": " We present a measurement of the three-particle correlation function in heavy ion collisions from the STAR experiment. The data sample used for this analysis contains 468 million particle pairs collected in 2005 and 2006 with the SELEX detector at the Relativistic Heavy Ion Collider (RHIC), in which the incident beam was stopped in a nuclear salt-water target. The three-particle correlation is found to be independent of the pair-cross section and the event activity, two parameters that describe the conditions of the collision. The correlation function C(r) is found to have a power law tail with a negative power of \uf062 < 1. We find that the correlation length decreases with the pair-cross section, and there is no significant difference between the correlations for events with and without associated jet production. We show that the measured correlation functions can be well described by a model in which the particles are born in a small region of space, and then their momenta are thermalized according to a Boltzmann distribution with a temperature that decreases with time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An Autonomous Distributed Admission Control Scheme for IEEE 802.11 DCF. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2819, "human_text": "  Admission control as a mechanism for providing QoS requires an accurate description of the requested flow as well as already admitted flows. Since 802.11 WLAN capacity is shared between flows belonging to all stations, admission control requires knowledge of all flows in the WLAN. Further, estimation of the load-dependent WLAN capacity through analytical model requires inputs about channel data rate, payload size and the number of stations. These factors combined point to a centralized admission control whereas for 802.11 DCF it is ideally performed in a distributed manner. The use of measurements from the channel avoids explicit inputs about the state of the channel described above. BUFFET, a model based measurement-assisted distributed admission control scheme for DCF proposed in this paper relies on measurements to derive model inputs and predict WLAN saturation, thereby maintaining average delay within acceptable limits. Being measurement based, it adapts to a combination of data rates and payload sizes, making it completely autonomous and distributed. Performance analysis using OPNET simulations suggests that BUFFET is able to ensure average delay under 7ms at a near-optimal throughput. ", "machine_text": "  We propose and evaluate an autonomous distributed admission control (AC) scheme for IEEE 802.11 DCF ( Distributed Coordination Function). Our scheme improves the performance of DCF in terms of throughput, fairness, and delay, without the need of changing the physical layer or the MAC layer protocol. Our solution takes advantage of the routing mechanisms available in the network layer to achieve our objectives. In particular, our scheme uses the gossip protocol to disseminate the information about the queues in the access points (APs) throughout the network. Then, each AP makes its own admission decision based on the information it has collected and the local policy it follows. We evaluate our scheme through simulations, and the results show that our scheme achieves a throughput very close to the optimal one, a fairness level similar to the one achieved by the IEEE 802.11e EDCA (Enhanced Distributed Coordination Access) protocol, and a delay lower than the one achieved by the 802.11e EDCA protocol.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The local stellar velocity field via vector spherical harmonics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3267, "human_text": "  We analyze the local field of stellar tangential velocities for a sample of $42 339$ non-binary Hipparcos stars with accurate parallaxes, using a vector spherical harmonic formalism. We derive simple relations between the parameters of the classical linear model (Ogorodnikov-Milne) of the local systemic field and low-degree terms of the general vector harmonic decomposition. Taking advantage of these relationships we determine the solar velocity with respect to the local stars of $(V_X,V_Y,V_Z)=(10.5, 18.5, 7.3)\\pm 0.1$ \\kms. The Oort's parameters determined by a straightforward least-squares adjustment in vector spherical harmonics, are $A=14.0\\pm 1.4$, $B=-13.1\\pm 1.2$, $K=1.1\\pm 1.8$, and $C=-2.9\\pm 1.4$ \\kmspc. We find a few statistically significant higher degree harmonic terms, which do not correspond to any parameters in the classical linear model. One of them, a third-degree electric harmonic, is tentatively explained as the response to a negative linear gradient of rotation velocity with distance from the Galactic plane, which we estimate at $\\sim -20$ \\kmspc. The most unexpected and unexplained term within the Ogorodnikov-Milne model is the first-degree magnetic harmonic representing a rigid rotation of the stellar field about the axis $-Y$ pointing opposite to the direction of rotation. This harmonic comes out with a statistically robust coefficient $6.2 \\pm 0.9$ \\kmspc, and is also present in the velocity field of more distant stars. The ensuing upward vertical motion of stars in the general direction of the Galactic center and the downward motion in the anticenter direction are opposite to the vector field expected from the stationary Galactic warp model. ", "machine_text": "  We present an analysis of the local stellar velocity field of the solar neighbourhood, based on high-resolution proper motion data from the Hipparchus catalogue and an adaptation of the vector spherical harmonics method. Our aim is twofold: first, to investigate the quality of the empirical galaxy distances that enter the method, and second, to map the large-scale structure of the local velocity field. We find that the galaxy distances can be improved by combining proper motion data with galaxy photometry in a linear estimator, and that this has only a small impact on the large-scale velocity field. We map the local velocity field in the galaxy number density plane, and find that the field is well described by a few modes of a simple power law model. The best-fitting model modes are in good agreement with the large-scale structure revealed by the three-dimensional velocity field. We have also investigated the effect of uncertain galaxy distances on the power law index of the velocity field, and found that the uncertainty has only a small impact on the index. This suggests that the power law description of the local velocity field is robust to the distance uncertainty.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: In search of dying radio sources in the local universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3209, "human_text": "  Up till now very few dying sources were known, presumably because the dying phase is short at centimeter wavelengths. We therefore have tried to improve the statistics on sources that have ceased to be active, or are intermittently active. The latter sources would partly consist of a fossil radio plasma left over from an earlier phase of activity, plus a recently restarted core and radio jets. Improving the statistics of dying sources will give us a better handle on the evolution of radio sources, in particular the frequency and time scales of radio activity. We have used the WENSS and NVSS surveys, in order to find sources with steep spectral indices, associated with nearby elliptical galaxies. In the cross correlation we presently used only unresolved sources, with flux densities at 1.4 GHz larger than 10 mJy. The eleven candidates thus obtained were observed with the VLA in various configurations, in order to confirm the steepness of the spectra, and to check whether active structures like flat-spectrum cores and jets are present, perhaps at low levels. We estimated the duration of the active and relic phases by modelling the integrated radio spectra using the standard models of spectral evolution. We have found six dying sources and three restarted sources, while the remaining two candidates remain unresolved also with the new VLA data and may be Compact Steep Spectrum sources, with an unusually steep spectrum. The typical age of the active phase, as derived by spectral fits, is in the range 10^7 - 10^8 years. For our sample of dying sources, the age of the relic phase is on average shorter by an order of magnitude than the active phase. ", "machine_text": "  We present a search for dying radio sources in the local universe. We have selected eight galaxies within 80 Mpc that are known to contain an active galactic nucleus (AGN) which is currently in the process of shutting down, and for which there exists a reference radio source, in most cases the currently-active nucleus. We have observed these galaxies in the 1.4 GHz and 6 GHz bands, and have compared the observed radio source properties with those of the reference source when possible. We find that in most cases the dying source is either weaker than the reference source, or it is not detected at all, providing evidence that the radio sources in these galaxies are shutting down. In three galaxies the comparison is inconclusive, due either to insufficient sensitivity, or to the presence of a strong torus that is obscuring the dying source. We have also observed the sources in the 1.4 GHz band in order to search for any new sources that may be brightenning, and have found no evidence for such a source in any of the galaxies. These results provide further evidence that galaxies shut down their radio sources on timescales of several million years. We have also compared the observed 1.4 GHz and 6 GHz properties of the dying sources in order to derive the radio spectral index of each source, and have found that the index is flat in most cases. The one exception is the source in IC 469, for which we find that the index is slightly positive. These results suggest that the simple model of a constant index for all sources is incorrect, and that the index may in fact be slightly negative for most sources, and positive for some sources.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Molecular Line Emission from Massive Protostellar Disks: Predictions for   ALMA and the EVLA. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0536, "human_text": "  We compute the molecular line emission of massive protostellar disks by solving the equation of radiative transfer through the cores and disks produced by the recent radiation-hydrodynamic simulations of Krumholz, Klein, & McKee. We find that in several representative lines the disks show brightness temperatures of hundreds of Kelvin over velocity channels ~10 km s^-1 wide, extending over regions hundreds of AU in size. We process the computed intensities to model the performance of next-generation radio and submillimeter telescopes. Our calculations show that observations using facilities such as the EVLA and ALMA should be able to detect massive protostellar disks and measure their rotation curves, at least in the nearest massive star-forming regions. They should also detect significant sub-structure and non-axisymmetry in the disks, and in some cases may be able to detect star-disk velocity offsets of a few km s^-1, both of which are the result of strong gravitational instability in massive disks. We use our simulations to explore the strengths and weaknesses of different observational techniques, and we also discuss how observations of massive protostellar disks may be used to distinguish between alternative models of massive star formation. ", "machine_text": " We present predictions, derived from simple models, for the molecular line emission from massive protostellar disks. We consider the impact of various physical ingredients, such as the disk temperature, the fraction of gas that is CO, the grain surface chemistry, and the relative spatial distribution of the grain and gas regions. We show that a simple recipe for computing the molecular line luminosity can be derived from first principles, and we use this recipe to derive the molecular line luminosity function in a parameter space that is relevant for the ALMA Band 4 and Band 5. We also consider the case of a disk with a given temperature and gas-to-grain ratio, and we derive the molecular line luminosity function as a function of the fraction of gas that is CO. We show that this function has a minimum, which is reached for a gas mixture that is approximately one-half CO and one-half H2. We also derive a simple expression for the molecular line luminosity function for an optically thick disk, and we use this expression to derive the molecular line luminosity function for a subset of the disks in our parameter space. We compare our predictions with observations of massive protostellar disks, and we conclude that observations of the CO J=1-0 and J=2-1 lines with ALMA will be able to discriminate between disks with different physical ingredients. We also discuss observations of the CO J=3-2 line with the EVLA, and we derive a recipe for computing the EVLA sensitivity to disks with different physical ingredients. We show that the CO J=3-2 line has the potential to discriminate between disks with different physical ingredients, provided that the disk temperature is high enough.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum Quenches in Extended Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.188, "human_text": "  We study in general the time-evolution of correlation functions in a extended quantum system after the quench of a parameter in the hamiltonian. We show that correlation functions in d dimensions can be extracted using methods of boundary critical phenomena in d+1 dimensions. For d=1 this allows to use the powerful tools of conformal field theory in the case of critical evolution. Several results are obtained in generic dimension in the gaussian (mean-field) approximation. These predictions are checked against the real-time evolution of some solvable models that allows also to understand which features are valid beyond the critical evolution.   All our findings may be explained in terms of a picture generally valid, whereby quasiparticles, entangled over regions of the order of the correlation length in the initial state, then propagate with a finite speed through the system. Furthermore we show that the long-time results can be interpreted in terms of a generalized Gibbs ensemble. We discuss some open questions and possible future developments. ", "machine_text": "  We study various aspects of the dynamics of quantum systems after a quench in extended systems. We consider a class ofonic-Remote-Canada-eld- supplemented with additional drive fields-which can be used to investigate the role of spatial symmetry in the dynamics of the system after a quench. We show that the dynamics after a slow or fast quench has different regimes, depending on the symmetry of the initial state. In particular, we show that in one-dimensional systems a fast quench can drive the system to a new state, while in higher-dimensional systems it cannot. In one-dimensional systems, the new state is a superposition of all symmetry states, while in higher-dimensional systems it is the unique ground state of the corresponding thermodynamic system. We also consider the case of a fast quench in a one-dimensional model which has a continuously tunable symmetry. In this case we show that the dynamics after a quench is given by a sequence of governed by the quenching rate, the initial state, and the symmetry of the model. We also derive a simple formula which describes the evolution after a slow quench in a one-dimensional model with a discrete symmetry. In the last part of the paper we consider a class of systems which are being investigated in quantum optics, namely systems with one-dimensional scalar fields and a drive which is a combination of a scalar field and a vector field. We show that in such systems the dynamics after a slow or fast quench has different regimes, depending on the symmetry of the initial state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The distance and neutral environment of the massive stellar cluster   Westerlund 1. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3073, "human_text": "  The goal of this study is to determine a distance to Westerlund 1 independent of the characteristics of the stellar population and to study its neutral environment, using observations of atomic hydrogen. The HI observations are taken from the Southern Galactic Plane Survey to study HI absorption in the direction of the HII region created by the members of Westerlund 1 and to investigate its environment as observed in the HI line emission. A Galactic rotation curve was derived using the recently revised values for the Galactic centre distance of $R_\\odot = 7.6$ kpc, and the velocity of the Sun around the Galactic centre of $\\Theta_\\odot = 214$ km s$^{-1}$. The newly determined rotation model leads us to derive a distance of $3.9\\pm 0.7$ kpc to Westerlund 1, consistent with a location in the Scutum-Crux Arm. Included in this estimate is a very careful investigation of possible sources of error for the Galactic rotation curve. We also report on small expanding HI features around the cluster with a maximum dynamic age of 600,000 years and a larger bubble which has a minimum dynamic age of 2.5 million years. Additionally we re-calculated the kinematic distances to nearby HII regions and supernova remnants based on our new Galaxic rotation curve. We propose that in the early stages of the development of Wd 1 a large interstellar bubble of diameter about 50 pc was created by the cluster members. This bubble has a dynamic age similar to the age of the cluster. Small expanding bubbles, with dynamical ages $\\sim 0.6$ Myr are found around Wd 1, which we suggest consist of recombined material lost by cluster members through their winds. ", "machine_text": " We present photometric detections of 31 members of the massive stellar cluster Westerlund 1, and a membership probability assessment for a further 21 candidates, using deep imaging of the cluster field obtained with the Hubble Space Telescope. We determine the distance to the cluster, using the luminosities and temperatures of the detected members, to be 1.004 \u00b1 0.009 kpc. We use the distances and the locations of the members in the sky to search for evidence of the presence of a three-body resonance, and find that the data are consistent with the cluster being in a pure stage II $4:1$ resonance. We determine the mass of the cluster to be $M \\sim 2.3 x 10^5 M_{\\odot}$. We find that the kinematic properties of the cluster, its age, and its chemical composition are consistent with it having formed in a single burst of star formation. We conclude that the high concentration of massive stars in such a small volume of space implies that a similar mechanism may have been responsible for the formation of the most massive stars and clusters in other galaxies.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Black Hole Evaporation in an Expanding Universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4012, "human_text": "  We calculate the quantum radiation power of black holes which are asymptotic to the Einstein-de Sitter universe at spatial and null infinities. We consider two limiting mass accretion scenarios, no accretion and significant accretion. We find that the radiation power strongly depends on not only the asymptotic condition but also the mass accretion scenario. For the no accretion case, we consider the Einstein-Straus solution, where a black hole of constant mass resides in the dust Friedmann universe. We find negative cosmological correction besides the expected redshift factor. This is given in terms of the cubic root of ratio in size of the black hole to the cosmological horizon, so that it is currently of order $10^{-5} (M/10^{6}M_{\\odot})^{1/3} (t/14 {Gyr})^{-1/3}$ but could have been significant at the formation epoch of primordial black holes. Due to the cosmological effects, this black hole has not settled down to an equilibrium state. This cosmological correction may be interpreted in an analogy with the radiation from a moving mirror in a flat spacetime. For the significant accretion case, we consider the Sultana-Dyer solution, where a black hole tends to increase its mass in proportion to the cosmological scale factor. In this model, we find that the radiation power is apparently the same as the Hawking radiation from the Schwarzschild black hole of which mass is that of the growing mass at each moment. Hence, the energy loss rate decreases and tends to vanish as time proceeds. Consequently, the energy loss due to evaporation is insignificant compared to huge mass accretion onto the black hole. Based on this model, we propose a definition of quasi-equilibrium temperature for general conformal stationary black holes. ", "machine_text": "  Black Hole Evaporation in an Expanding Universe  We investigate the effects of the expansion of the Universe on the evolution of a black hole. We find that the cosmological constant $\\Lambda$ can be treated as a background energy source, and thus, the black hole evaporation rate is proportional to $\\Lambda$. In other words, the black hole evaporation can be completely stopped by a large enough $\\Lambda$. This is in sharp contrast to the situation in a contracting Universe, where the black hole evaporation rate is in general enhanced by the gravitational collapse. We also show that the black hole information paradox is not affected by the expansion of the Universe.  We consider the evolution of a black hole in an expanding Universe. We find that the black hole evaporation rate is proportional to the cosmological constant $\\Lambda$. Thus, a black hole can be completely evaporated by a large enough $\\Lambda$. This is in sharp contrast to the situation in a contracting Universe, where the black hole evaporation rate is in general enhanced by the gravitational collapse. The black hole information paradox is not affected by the expansion of the Universe. We also discuss the physical meaning of the evaporated black hole entropy in an expanding Universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Mid-infrared laser light nulling experiment using single-mode conductive   waveguides. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0146, "human_text": "  Aims: In the context of space interferometry missions devoted to the search of exo-Earths, this paper investigates the capabilities of new single mode conductive waveguides at providing modal filtering in an infrared and monochromatic nulling experiment; Methods: A Michelson laser interferometer with a co-axial beam combination scheme at 10.6 microns is used. After introducing a Pi phase shift using a translating mirror, dynamic and static measurements of the nulling ratio are performed in the two cases where modal filtering is implemented and suppressed. No additional active control of the wavefront errors is involved. Results: We achieve on average a statistical nulling ratio of 2.5e-4 with a 1-sigma upper limit of 6e-4, while a best null of 5.6e-5 is obtained in static mode. At the moment, the impact of external vibrations limits our ability to maintain the null to 10 to 20 seconds.; Conclusions: A positive effect of SM conductive waveguide on modal filtering has been observed in this study. Further improvement of the null should be possible with proper mechanical isolation of the setup. ", "machine_text": "  Mid-infrared laser light nulling experiment using single-mode conductive waveguides  A nulling experiment was performed to investigate the formation of a single-mode conductive waveguide. The experiment was conducted in the mid-infrared spectral region, where a semiconductor laser was butt-coupled to a single-mode optical fiber. A spatial filter was used to obtain a single-mode light input to the fiber. The fiber was made of a Tellurite-based glass and had a circular core of 3 micrometers in diameter. The fiber was drawn with a velocity of 6 m/s and had a length of 1.4 km. The temperature of the fiber was maintained at 20 degrees Celsius. A total of 11 thermo-mechanical cycles were applied to the fiber. Each cycle consisted of heating the fiber for 1 hour and then cooling it for 1 hour. The output power of the laser was monitored during each cycle. The laser was operated in continuous wave mode. The results showed that the power at the fiber output decreased after each thermo-mechanical cycle. The power was completely nulled after the 11th cycle. The temporal profile of the output power during the nulling process was analyzed. It was found that the power decreased exponentially with time. The relaxation time of the output power was estimated to be 7 minutes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Halo-model signatures from 380,000 SDSS Luminous Red Galaxies with   photometric redshifts. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3377, "human_text": "  We analyze the small-scale clustering in \"MegaZ-LRG\", a large photometric-redshift catalogue of Luminous Red Galaxies extracted from the imaging dataset of the Sloan Digital Sky Survey. MegaZ-LRG, presented in a companion paper, spans the redshift range 0.4 < z < 0.7 with an r.m.s. redshift error dz ~ 0.03(1+z), covering 5,914 deg^2 to map out a total cosmic volume 2.5 h^-3 Gpc^3. In this study we use 380,000 photometric redshifts to measure significant deviations from the canonical power-law fit to the angular correlation function in a series of narrow redshift slices, in which we construct volume-limited samples. These deviations are direct signatures of the manner in which these galaxies populate the underlying network of dark matter haloes. We cleanly delineate the separate contributions of the \"1-halo\" and \"2-halo\" clustering terms and fit our measurements by parameterizing the halo occupation distribution N(M) of the galaxies. Our results are successfully fit by a \"central\" galaxy contribution with a \"soft\" transition from zero to one galaxies, combined with a power-law \"satellite\" galaxy component, the slope of which is a strong function of galaxy luminosity. The large majority of galaxies are classified as central objects of their host dark matter haloes rather than satellites in more massive systems. The effective halo mass of MegaZ-LRG galaxies lies in the range log_10 (M_eff / h^-1 M_sol) = 13.61 - 13.8 (increasing with redshift, assuming large-scale normalization sigma_8 = 0.8) for corresponding number densities in the range n_g = 5.03 - 0.56 x 10^-4 h^3 Mpc^-3. Our results confirm the usefulness of the halo model for gaining physical insight into the patterns of galaxy clustering. ", "machine_text": "  We present here the first study of the large-scale structure of the red galaxy (RG) halo population in the SDSS using the halo model. We identified 27,351 galaxies with photometric redshifts in the SDSS DR7 catalog of luminous RGs with Mrk > -18.5, a selected group which has the same properties as the optically-selected halo RGs but with a significantly higher number of galaxies, enabling a more robust analysis of the large-scale structure. We find that the galaxies in this sample follow the halo model very well, with the projected density distribution in very good agreement with the predictions of the model, and the corresponding spherical halo profiles are consistent with those obtained in previous studies of optically-selected RGs. We find no evidence of a core in the projected density distribution, in agreement with previous results for optically-selected RGs, and we obtain a scaling length of $h \\sim 250$ kpc. The number density profile follows the halo model with a core, and we find that the Virial Theorem is satisfied with a Virial ratio of $\\sim 2.1$. We find that the bulk of the population is comprised of galaxies in groups, and that only a small fraction of the population is comprised of galaxies in the large voids; this fraction is consistent with the predictions of the model. We also present a catalog of 9,302 optically-selected RGs with Mrk > -18.5 in the same redshift range as the photometric RGs, and find that the photometric and optically-selected samples have very similar properties, in agreement with the predictions of the halo model. We conclude that the halo model successfully describes the large-scale structure of the SDSS luminous RGs in this redshift range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Deformed Wigner crystal in a one-dimensional quantum dot. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1445, "human_text": "  The spatial Fourier spectrum of the electron density distribution in a finite 1D system and the distribution function of electrons over single-particle states are studied in detail to show that there are two universal features in their behavior, which characterize the electron ordering and the deformation of Wigner crystal by boundaries. The distribution function has a $\\delta$-like singularity at the Fermi momentum $k_F$. The Fourier spectrum of the density has a step-like form at the wavevector $2k_F$, with the harmonics being absent or vanishing above this threshold. These features are found by calculations using exact diagonalization method. They are shown to be caused by Wigner ordering of electrons, affected by the boundaries. However the common Luttinger liquid model with open boundaries fails to capture these features, because it overestimates the deformation of the Wigner crystal. An improvement of the Luttinger liquid model is proposed which allows one to describe the above features correctly. It is based on the corrected form of the density operator conserving the particle number. ", "machine_text": "  We investigate a system composed of a one-dimensional quantum dot embedded in a reservoir and weakly coupled to it, which is in a state with many particle-hole excitations. We show that the system can be well described by a Deformed Wigner crystal, a generalization of a Wigner crystal to a system with an infinite number of degrees of freedom. The stability of the Deformed Wigner crystal is ensured by a strict conservation of the symmetry of the elementary excitations. We show that such a conservation is guaranteed by the interatomic Hamiltonian in a certain range of values of the parameters of the system. Within this range, the Deformed Wigner crystal is stable against a deformation, i.e. a change of the elementary excitations. We analyze the mechanism of the formation of the Deformed Wigner crystal and find that it is based on the competition between an extended Kondo and singlet phases. The transition to the Deformed Wigner crystal is associated with a sharp drop in the thermal conductance, and therefore, it can be detected by a thermal Aharonov-Bohm signature. Our results suggest that in a large class of systems the elementary excitations are necessarily symmetric, which has important consequences for the physics of finite systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: CIV 1549 as an Eigenvector 1 Parameter for Active Galactic Nuclei. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1895, "human_text": "  [Abridged] We have been exploring a spectroscopic unification for all known types of broad line emitting AGN. The 4D Eigenvector 1 (4DE1) parameter space shows promise as a unification capable of organizing quasar diversity on a sequence primarily governed by Eddington ratio. This paper considers the role of CIV 1549 measures with special emphasis on the CIV 1549 line shift as a principal 4DE1 diagnostic. We use HST archival spectra for 130 sources with S/N high enough to permit reliable CIV 1549 broad component (BC) measures. We find a CIV 1549 BC profile blueshift that is strongly concentrated among (largely radio-quiet: RQ) sources with FWHM(H beta BC) < 4000 km/s (which we call Population A). Narrow line Seyfert 1 (NLSy1, with FWHM H beta < 2000 km/s) sources belong to this population but do not emerge as a distinct class. The systematic blueshift, widely interpreted as arising in a disk wind/outflow, is not observed in broader lined AGN which we call Population B. We find new correlations between FWHM(CIV 1549 BC) and CIV 1549 line shift as well as the equivalent width of CIV 1549. They are seen only in Pop. A sources. CIV 1549 measures enhance the apparent dichotomy at FWHM(Hbeta BC) approx. 4000 \\kms\\ (Sulentic et al. 2000) suggesting that it has more significance in the context of Broad Line Region structure than the more commonly discussed RL vs. RQ dichotomy. Black hole masses computed from FWHM CIV 1549 BC for about 80 AGN indicate that the CIV 1549 width is a poor virial estimator. Comparison of mass estimates derived from Hbeta BC and CIV 1549 reveals that the latter show different and nonlinear offsets for population A and B sources. A significant number of sources also show narrow line CIV 1549 emission. We present a recipe for CIV 1549 narrow component extraction. ", "machine_text": " We present a new method for measuring the relative strength of the torus and jet in active galactic nuclei (AGN) based on the analysis of the Taup\u014d supernova remnant. We find that the torus contribution to the supernova (SN) is anisotropic with a bias in the direction of the galactic plane, possibly related to the large-scale structure in the galaxy. We show that the strength of the torus is correlated with the mass of the central engine, but not with the accretion rate, the age of the system or the nuclear activity level. Our results suggest that the torus is driven by a feedback mechanism related to the SN, and that the torus and jet are approximately equally strong. We find that the strength of the torus can be used to reliably differentiate between AGN and galaxies, based on the assumption that the torus is less strong in AGN than in galaxies. The torus strength can also be used to estimate the accretion rate, the central mass, and the age of the system. We find that the strength of the torus increases with the age of the system, possibly due to the increasing effect of feedback from the SN. Our results suggest that the torus plays a fundamental role in the evolution of AGN and that its strength is an important parameter that can be used to probe the nature of AGN.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Critical edge behavior in unitary random matrix ensembles and the thirty   fourth Painleve transcendent. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1972, "human_text": "  We describe a new universality class for unitary invariant random matrix ensembles. It arises in the double scaling limit of ensembles of random $n \\times n$ Hermitian matrices $Z_{n,N}^{-1} |\\det M|^{2\\alpha} e^{-N \\Tr V(M)} dM$ with $\\alpha > -1/2$, where the factor $|\\det M|^{2\\alpha}$ induces critical eigenvalue behavior near the origin. Under the assumption that the limiting mean eigenvalue density associated with $V$ is regular, and that the origin is a right endpoint of its support, we compute the limiting eigenvalue correlation kernel in the double scaling limit as $n, N \\to \\infty$ such that $n^{2/3}(n/N-1) = O(1)$. We use the Deift-Zhou steepest descent method for the Riemann-Hilbert problem for polynomials on the line orthogonal with respect to the weight $|x|^{2\\alpha} e^{-NV(x)}$. Our main attention is on the construction of a local parametrix near the origin by means of the $\\psi$-functions associated with a distinguished solution of the Painleve XXXIV equation. This solution is related to a particular solution of the Painleve II equation, which however is different from the usual Hastings-McLeod solution. ", "machine_text": " We investigate the critical behavior of unitary random matrix ensembles in the thermodynamic limit. We show that the eigenvalues of these ensembles are Poisson distributed with the magnitude of the expected value equal to the thermodynamic equilibrium value of the root-mean-square (RMS) conductivity. We derive an expression for the probability distribution of the number of local maxima in the steady-state RMS conductivities, and use this result to show that the occurrence of a single local maximum in the RMS conductivity is an indication of a transition to a metallic phase. In the case of a model system with anharmonic interactions we show that the dynamic critical behavior is described by an anti-catastrophic type of criticality. In the case of a system with harmonic interactions we show that the critical behavior is described by a noisy catastrophe type of criticality. We also show that the evolution to a state with a large number of local maxima in the steady-state RMS conductivity is a slow process that can be described by a random walk. In addition we show that a finite size effect can significantly affect the critical behavior. We also investigate the critical behavior of the thirty fourth Painlev\u00e9 transcendent and show that this behavior is described by a noisy catastrophe type of criticality.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On constraining a transiting exoplanet's rotation rate with its transit   spectrum. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0004, "human_text": "  We investigate the effect of planetary rotation on the transit spectrum of an extrasolar giant planet. During ingress and egress, absorption features arising from the planet's atmosphere are Doppler shifted by of order the planet's rotational velocity (~1-2 km/s) relative to where they would be if the planet were not rotating. We focus in particular on the case of HD209458b, which ought to be at least as good a target as any other known transiting planet. For HD209458b, this shift should give rise to a small net centroid shift of ~60 cm/s on the stellar absorption lines. Using a detailed model of the transmission spectrum due to a rotating star transited by a rotating planet with an isothermal atmosphere, we simulate the effect of the planet's rotation on the shape of the spectral lines, and in particular on the magnitude of their width and centroid shift. We then use this simulation to determine the expected signal-to-noise ratio for distinguishing a rotating from a non-rotating planet, and assess how this S/N scales with various parameters of HD209458b. We find that with a 6 m telescope, an equatorial rotational velocity of ~2 km/s could be detected with a S/N~5 by accumulating the signal over many transits over the course of several years. With a 30 m telescope, the time required to make such a detection reduces to less than 2 months. ", "machine_text": "  We present a new method for constraining the rotation rate of transiting exoplanets by combining high-resolution transit data with observations of the planetary atmosphere during transits. We show that a rotation rate can be constrained provided that the atmosphere does not contain strong winds. We demonstrate the method by applying it to the exoplanet HD209458b, for which we show that the rotation rate must be higher than 6.5 hours. This constraint is consistent with the rotation rate being between 8 and 16 hours. We also show that the rotation rate of HD209458b cannot be as low as 4 hours, as claimed by earlier observations. We discuss how this method can be applied to other exoplanets.  We present a new method for constraining the rotation rate of transiting exoplanets by combining high-resolution transit data with observations of the planetary atmosphere during transits. We show that a rotation rate can be constrained provided that the atmosphere does not contain strong winds. We demonstrate the method by applying it to the exoplanet HD209458b, for which we show that the rotation rate must be higher than 6.5 hours. This constraint is consistent with the rotation rate being between 8 and 16 hours. We also show that the rotation rate of HD209458b cannot be as low as 4 hours, as claimed by earlier observations. We discuss how this method can be applied to other exoplanets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Relativistic Tennis with Photons: Demonstration of Frequency Upshifting   by a Relativistic Flying Mirror through Two Colliding Laser Pulses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0872, "human_text": "  Since the advent of chirped pulse amplification1 the peak power of lasers has grown dramatically and opened the new branch of high field science, delivering the focused irradiance, electric fields of which drive electrons into the relativistic regime. In a plasma wake wave generated by such a laser, modulations of the electron density naturally and robustly take the shape of paraboloidal dense shells, separated by evacuated regions, moving almost at the speed of light. When we inject another counter-propagating laser pulse, it is partially reflected from the shells, acting as relativistic flying (semi-transparent) mirrors, producing an extremely time-compressed frequency-multiplied pulse which may be focused tightly to the diffraction limit. This is as if the counterstreaming laser pulse bounces off a relativistically swung tennis racket, turning the ball of the laser photons into another ball of coherent X-ray photons but with a form extremely relativistically compressed to attosecond and zeptosecond levels. Here we report the first demonstration of the frequency multiplication detected from the reflection of a weak laser pulse in the region of the wake wave generated by the driver pulse in helium plasma. This leads to the possibility of very strong pulse compression and extreme coherent light intensification. This Relativistic Tennis with photon beams is demonstrated leading to the possibility toward reaching enormous electromagnetic field intensification and finally approaching the Schwinger field, toward which the vacuum nonlinearly warps and eventually breaks, producing electron-positron pairs. ", "machine_text": "  We propose and demonstrate a novel technique to generate intense ultrashort laser pulses with a frequency upshifted by one or more optical phonons with a relativistic flying mirror in the context of tennis-like laser cavity. Two or more laser pulses are injected into a laser cavity with a frequency difference of the order of an optical phonon energy. The generated pulses exhibit a bandwidth up to three times larger than the injected ones, and a duration up to two times shorter. The maximum upshifted frequency is determined by the pulse energy and the reflectivity of the flying mirror. We also show that the conversion efficiency can be significantly enhanced by implementing a multi-pass configuration. The method is demonstrated experimentally with a 10-fold increase in the frequency for ultrashort laser pulses, and a four-fold increase for nanosecond pulses, which is limited by the longitudinal optical phonon energy of the titanium:sapphire (Ti:Sa) crystal. Our work paves the way for the generation of intense ultrashort laser pulses with a frequency different from that of the pump laser. It could be useful in the context of optical frequency conversion, for the generation of ultraviolet or infrared light, or in the field of high-energy lasers for beam combination purposes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Mean and Scatter of the Velocity Dispersion-Optical Richness   Relation for maxBCG Galaxy Clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3614, "human_text": "  The distribution of galaxies in position and velocity around the centers of galaxy clusters encodes important information about cluster mass and structure. Using the maxBCG galaxy cluster catalog identified from imaging data obtained in the Sloan Digital Sky Survey, we study the BCG-galaxy velocity correlation function. By modeling its non-Gaussianity, we measure the mean and scatter in velocity dispersion at fixed richness. The mean velocity dispersion increases from 202+/-10 km/s for small groups to more than 854+/-102 km/s for large clusters. We show the scatter to be at most 40.5+/-3.5%, declining to 14.9+/-9.4% in the richest bins. We test our methods in the C4 cluster catalog, a spectroscopic cluster catalog produced from the Sloan Digital Sky Survey DR2 spectroscopic sample, and in mock galaxy catalogs constructed from N-body simulations. Our methods are robust, measuring the scatter to well within one-sigma of the true value, and the mean to within 10%, in the mock catalogs. By convolving the scatter in velocity dispersion at fixed richness with the observed richness space density function, we measure the velocity dispersion function of the maxBCG galaxy clusters. Although velocity dispersion and richness do not form a true mass-observable relation, the relationship between velocity dispersion and mass is theoretically well characterized and has low scatter. Thus our results provide a key link between theory and observations up to the velocity bias between dark matter and galaxies. ", "machine_text": " We present a detailed statistical analysis of the relation between the velocity dispersion and optical richness (or age) of the galaxy clusters belonging to the SDSS BCG catalogue, a sample of which contains many of the most massive and luminous galaxy clusters in the local volume. We find a significant correlation between the two properties, and show that this correlation is well described by a power law with an exponential cutoff. The power law index and the cutoff scale are found to be in good agreement with the theoretical predictions of an arrested $\\Gamma$-class cluster model. Our result implies that the velocity dispersion of a cluster is largely controlled by its optical richness. We show that this conclusion can be understood in the framework of a simple model in which the mean cluster velocity is proportional to the square root of the optical richness. We discuss the implication of this relation for the dynamics of galaxy clusters, and in particular for the problem of cluster tending.  We also present a detailed study of the scatter of the velocity dispersion-optical richness relation. We show that this scatter follows a power law with an exponential cutoff. The power law index and the cutoff scale are in good agreement with the theoretical predictions of a model in which the scatter is described by a finite number of non-overlapping $\\Gamma$-class clusters moving in a linear potential. The model also predicts that the number density of these clusters should be proportional to the optical richness, a relation that is in good agreement with the data. We discuss the implications of our results for the dynamics of galaxy clusters, and in particular for the problem of cluster tending.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dynamics of Localization Phenomena for Hardcore Bosons in Optical   Lattices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0823, "human_text": "  We investigate the behavior of ultracold bosons in optical lattices with a disorder potential generated via a secondary species frozen in random configurations. The statistics of disorder is associated with the physical state in which the secondary species is prepared. The resulting random potential, albeit displaying algebraic correlations, is found to lead to localization of all single-particle states. We then investigate the real-time dynamics of localization for a hardcore gas of mobile bosons which are brought into sudden interaction with the random potential. Regardless of their initial state and for any disorder strength, the mobile particles are found to reach a steady state characterized by exponentially decaying off-diagonal correlations and by the absence of quasi-condensation; when the mobile particles are initially confined in a tight trap and then released in the disorder potential, their expansion is stopped and the steady state is exponentially localized in real space, clearly revealing Anderson localization. ", "machine_text": "  We study the dynamics of localization phenomena for hardcore bosons in optical lattices. We consider a system of many ultracold bosons at absolute zero temperature, hosted in an optical lattice, and subject to a weak avoided crossing between different orbital states. We find that such a system is stable against thermal fluctuations, in the sense that the fraction of atoms that are localized in the lattice, instead of being uniformly distributed, does not decay with time. We analyze the dependence of the fraction of localized atoms on the parameters of the system, in particular on the boson mass m, the lattice spacing a, and the avoided crossing strength \u0394. Our results are consistent with the idea that the system is in a state of arrested development: the fraction of localized atoms does not increase with time, it does not decrease either, and it is very sensitive to the parameters of the system. We show that this fraction displays power law statistics, with an exponent that depends on the parameters of the system, and we discuss the possibility of a critical behavior for some values of the parameters. Our results suggest that there is a range of parameters for which the dynamics of localization phenomena is driven by a delicate balance between different interactions, and for which small perturbations can have a strong effect on the statistical properties of the system.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Feynman-Weinberg Quantum Gravity and the Extended Standard Model as a   Theory of Everything. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3276, "human_text": "  I argue that the (extended) Standard Model (SM) of particle physics and the renormalizable Feynman-Weinberg theory of quantum gravity comprise a theory of everything. I show that imposing the appropriate cosmological boundary conditions make the theory finite. The infinities that are normally renormalized away and the series divergence infinities are both eliminated by the same mechanism. Furthermore, this theory can resolve the horizon, flatness, and isotropy problems of cosmology. Joint mathematical consistency naturally yields a scale-free, Gaussian, adiabatic perturbation spectrum, and more matter than antimatter. I show that mathematical consistency of the theory requires the universe to begin at an initial singularity with a pure $SU(2)_L$ gauge field. I show that quantum mechanics requires this field to have a Planckian spectrum whatever its temperature. If this field has managed to survive thermalization to the present day, then it would be the CMBR. If so, then we would have a natural explanation for the dark matter and the dark energy. I show that isotropic ultrahigh energy (UHE) cosmic rays are explained if the CMBR is a pure $SU(2)_L$ gauge field. The $SU(2)_L$ nature of the CMBR may have been seen in the Sunyaev-Zel'dovich effect. I propose several simple experiments to test the hypothesis. ", "machine_text": " We propose a scheme of Feynman-Weinberg quantum gravity with the Extended Standard Model as a theory of everything, in which the fermionic generators are treated as a particular case of the general approach of the symmetric and antisymmetric components of a gravity field. In our scheme the symmetric part of the gravity field is responsible for the geometry of the spacetime, while the antisymmetric part is responsible for the structure of the matter fields. The spacetime is described by a dynamic triangular decomposition in the 3D-dimensional space, while the matter fields are described by a quadratic form in the 3D-dimensional space. We show that our scheme is equivalent to the well-known approach of the Ashtekar-Barlev-Corichi gravity model, in which the antisymmetric part of the gravity field is associated with the Standard Model. We discuss the relation to the other approaches to quantum gravity and the Extended Standard Model, and the question of the quantization of the bulk fields is discussed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Third-order cosmological perturbations of zero-pressure multi-component   fluids: Pure general relativistic nonlinear effects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2086, "human_text": "  Present expansion stage of the universe is believed to be mainly governed by the cosmological constant, collisionless dark matter and baryonic matter. The latter two components are often modeled as zero-pressure fluids. In our previous work we have shown that to the second-order cosmological perturbations, the relativistic equations of the zero-pressure, irrotational, multi-component fluids in a spatially near flat background effectively coincide with the Newtonian equations. As the Newtonian equations only have quadratic order nonlinearity, it is practically interesting to derive the potential third-order perturbation terms in general relativistic treatment which correspond to pure general relativistic corrections. Here, we present pure general relativistic correction terms appearing in the third-order perturbations of the multi-component zero-pressure fluids. We show that, as in a single component situation, the third-order correction terms are quite small (~ 5 x10^{-5} smaller compared with the relativistic/Newtonian second-order terms) due to the weak level anisotropy of the cosmic microwave background radiation. Still, there do exist pure general relativistic correction terms in third-order perturbations which could potentially become important in future development of precision cosmology. We include the cosmological constant in all our analyses. ", "machine_text": " We consider third-order cosmological perturbations of zero-pressure multi-component fluids. The general relativistic nonlinear effects are pure and are equivalent to a general relativistic correction to the bulk viscosity. They are shown to be a general relativistic correction to the hydrodynamic stress $T_{ij}$, related to the bulk viscosity $\\dot \\Phi$ by $T_{ij} \\equiv \\dot \\Phi \\epsilon_{ij}$ with $\\epsilon_{ij}$ the strain tensor. We show that these effects are small in the limit $\\dot \\Phi \\ll 1$ and that they can be expanded in a Taylor series in powers of $\\dot \\Phi$. This series has as few terms as there are components in the stress $T$ or the strain tensor $\\epsilon$. The third-order effects are evaluated exactly in the simple case of a fluid with two components, and approximately in the case of a fluid with an arbitrary number of components. We show that in both cases the third-order effects are small when compared to the second-order effects, and that they are not relevant for most of the physical applications of general relativity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Diversity of MIMO Multihop Relay Channels - Part I: Amplify-and-Forward. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3969, "human_text": "  In this two-part paper, we consider the multiantenna multihop relay channels in which the source signal arrives at the destination through N independent relaying hops in series. The main concern of this work is to design relaying strategies that utilize efficiently the relays in such a way that the diversity is maximized. In part I, we focus on the amplify-and-forward (AF) strategy with which the relays simply scale the received signal and retransmit it. More specifically, we characterize the diversity-multiplexing tradeoff (DMT) of the AF scheme in a general multihop channel with arbitrary number of antennas and arbitrary number of hops. The DMT is in closed-form expression as a function of the number of antennas at each node. First, we provide some basic results on the DMT of the general Rayleigh product channels. It turns out that these results have very simple and intuitive interpretation. Then, the results are applied to the AF multihop channels which is shown to be equivalent to the Rayleigh product channel, in the DMT sense. Finally, the project-and-forward (PF) scheme, a variant of the AF scheme, is proposed. We show that the PF scheme has the same DMT as the AF scheme, while the PF can have significant power gain over the AF scheme in some cases. In part II, we will derive the upper bound on the diversity of the multihop channels and show that it can be achieved by partitioning the multihop channel into AF subchannels. ", "machine_text": " We investigate the diversity of MIMO multihop relay channels. We consider the amplify-and-forward relay channel where a source wants to communicate with a destination via a relay. We allow the source to send independent messages to the relay and the destination in each time slot. We also allow the relay to use both its antennas to forward the message to the destination, after having received it on one of its antennas. We study the performance of this channel in terms of the outage probability and the rate region. We compare the diversity order of the channel with that of other channels. We show that the diversity order of the relay channel is strictly increasing in the number of relay antennas and that it equals the diversity order of the direct channel if the relay uses its second antenna only to obtain a better estimate of the source message. We also derive a general expression of the diversity order for the relay channel, which is shown to have a simple closed form in the case of practical interest.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A deeper search for the progenitor of the Type Ic Supernova 2002ap. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.05, "human_text": "  (Abridged) We present a search for the progenitor star of the Type Ic Supernova 2002ap in deep, high quality pre-explosion observations taken with the Canada-France-Hawaii Telescope (CFHT). Aligning high-resolution Hubble Space Telescope (HST) observations of the supernova itself with the archival CFHT images allowed us to pinpoint the location of the progenitor site on the ground based observations. We find that a source visible in the B and R band pre-explosion images close to the position of the SN is (1) not coincident with the SN position within the uncertainties of our relative astrometry, and (2) is still visible ~ 4.7 yrs post-explosion in late-time observations taken with the William Herschel Telescope. We therefore conclude that it is not the progenitor of SN 2002ap. Comparing our luminosity limits with stellar models of single stars at appropriate metallicity (Z=0.008) we conclude that any single star progenitor must have experienced at least twice the standard mass loss rates during pre-Wolf-Rayet evolution, been initially > 30-40M(Sun) and exploded as a Wolf-Rayet star of final mass 10-12M(Sun). Alternatively an initially less massive progenitor may have evolved in an interacting binary system. We constrain any possible binary companion to a main sequence star of < 20M(Sun), a neutron star or a black hole. By combining the pre-explosion limits with the ejecta mass estimates and constraints from X-ray and radio observations we conclude that any binary interaction most likely occurred as Case B mass transfer, either with or without a subsequent common envelope evolution phase. ", "machine_text": " We present photometric and spectroscopic observations of the Type Ic supernova (SN 2002ap), made since its discovery in 2002. Our high-resolution, high signal-to-noise ratio spectra show a strong stellar emission line, indicating that the progenitor star is still present. The observations needed to independently verify this interpretation, however, have been made only recently. We show that the observations are consistent with a free-free absorption model with an expansion velocity of 6,000 km s$^{-1}$, and that this model explains the changes in the SN 2002ap spectrum as observed between 2002 and 2014. We show that the un modelling the evolution of the supernova. If the observed progenitor star is a member of the stripped-down stellarator (a stripped-down Wolf-Rayet star), then its initial mass must have been at least $25M_{\\odot}$. If, instead, the progenitor was a massive convective envelope around a neutron star (or black hole), then its initial mass must have been at least $50M_{\\odot}$. We discuss the properties of the stripped-down stellarator, and compare the properties of SNe 2002ap and 2008ha.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of the Spatial Dispersion on the Shape of a Light Pulse in a   Quantum Well. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1697, "human_text": "  Reflectance, transmittance and absorbance of a symmetric light pulse, the carrying frequency of which is close to the frequency of interband transitions in a quantum well, are calculated. Energy levels of the quantum well are assumed discrete, and two closely located excited levels are taken into account. A wide quantum well (the width of which is comparable to the length of the light wave, corresponding to the pulse carrying frequency) is considered, and the dependance of the interband matrix element of the momentum operator on the light wave vector is taken into account. Refractive indices of barriers and quantum well are assumed equal each other. The problem is solved for an arbitrary ratio of radiative and nonradiative lifetimes of electronic excitations. It is shown that the spatial dispersion essentially affects the shapes of reflected and transmitted pulses. The largest changes occur when the radiative broadening is close to the difference of frequencies of interband transitions taken into account. ", "machine_text": " We investigate the effect of spatial dispersion on the shape of a light pulse in a quantum well. We consider a model of a quantum well with a delta-doped region. The spatial dispersion of the optical field in the quantum well is modeled by a convolution of the field with a function that describes the spatial variation of the refractive index. The resulting equation is solved using the principles of analytic continuation and residue theory. The solution is found to be a linear combination of two Airy functions, which depends on the width of the delta-doped region and the strength of the spatial dispersion. We show that the shape of the light pulse is significantly affected by the spatial dispersion, and that the width of the pulse can be controlled by adjusting the parameters of the quantum well. The practical application of our results is in the design of semiconductor lasers, where spatial dispersion can be used to stabilize the transverse mode and to narrow the emission spectrum.  The effect of spatial dispersion on the shape of a light pulse in a quantum well is investigated. A model of a quantum well with a delta-doped region is considered, and the spatial dispersion of the optical field in the quantum well is modeled by a convolution of the field with a function that describes the spatial variation of the refractive index. The resulting equation is solved using the principles of analytic continuation and residue theory, and the solution is found to be a linear combination of two Airy functions. The shape of the light pulse is significantly affected by the spatial dispersion, and the width of the pulse can be controlled by adjusting the parameters of the quantum well. The practical application of our results is in the design of semiconductor lasers, where spatial dispersion can be used to stabilize the transverse mode and to narrow the emission spectrum.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Large Attractive Depletion Interactions in Soft Repulsive-Sphere Binary   Mixtures. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1633, "human_text": "  We consider binary mixtures of soft repulsive spherical particles and calculate the depletion interaction between two big spheres mediated by the fluid of small spheres, using different theoretical and simulation methods. The validity of the theoretical approach, a virial expansion in terms of the density of the small spheres, is checked against simulation results. Attention is given to the approach toward the hard-sphere limit, and to the effect of density and temperature on the strength of the depletion potential. Our results indicate, surprisingly, that even a modest degree of softness in the pair potential governing the direct interactions between the particles may lead to a significantly more attractive total effective potential for the big spheres than in the hard-sphere case. This might lead to significant differences in phase behavior, structure and dynamics of a binary mixture of soft repulsive spheres. In particular, a perturbative scheme is applied to predict the phase diagram of an effective system of big spheres interacting via depletion forces for a size ratio of small and big spheres of 0.2; this diagram includes the usual fluid-solid transition but, in the soft-sphere case, the metastable fluid-fluid transition, which is probably absent in hard-sphere mixtures, is close to being stable with respect to direct fluid-solid coexistence. From these results the interesting possibility arises that, for sufficiently soft repulsive particles, this phase transition could become stable. Possible implications for the phase behavior of real colloidal dispersions are discussed. ", "machine_text": " We investigate the large attractive depletion interaction in a model system consisting of hard repulsive spheres embedded in a soft attractive matrix. We show that the strength of the depletion interaction is dependent on the diameter of the hard spheres, the volume fraction of the hard spheres, and the ratio of the hard and soft sphere radii, and we obtain a general formula for the interaction in terms of these parameters. Our analytical model is verified by comparison with numerical solutions for several realistic mixtures. Our results show that large attractive depletion interactions can be obtained in mixtures of hard and soft spheres, even in the absence of large inter-sphere distances, provided that the soft sphere radius is sufficiently large compared to the hard sphere radius. Our results have implications for the design of functional particle mixtures for applications in tissue engineering and drug delivery, and they suggest new ways to engineer the spatial organization of particles in mixtures.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Emergence of spatiotemporal chaos driven by far-field breakup of spiral   waves in the plankton ecological systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0322, "human_text": "  Alexander B. Medvinsky \\emph{et al} [A. B. Medvinsky, I. A. Tikhonova, R. R. Aliev, B.-L. Li, Z.-S. Lin, and H. Malchow, Phys. Rev. E \\textbf{64}, 021915 (2001)] and Marcus R. Garvie \\emph{et al} [M. R. Garvie and C. Trenchea, SIAM J. Control. Optim. \\textbf{46}, 775-791 (2007)] shown that the minimal spatially extended reaction-diffusion model of phytoplankton-zooplankton can exhibit both regular, chaotic behavior, and spatiotemporal patterns in a patchy environment. Based on that, the spatial plankton model is furtherly investigated by means of computer simulations and theoretical analysis in the present paper when its parameters would be expected in the case of mixed Turing-Hopf bifurcation region. Our results show that the spiral waves exist in that region and the spatiotemporal chaos emerge, which arise from the far-field breakup of the spiral waves over large ranges of diffusion coefficients of phytoplankton and zooplankton. Moreover, the spatiotemporal chaos arising from the far-field breakup of spiral waves does not gradually involve the whole space within that region. Our results are confirmed by means of computation spectra and nonlinear bifurcation of wave trains. Finally, we give some explanations about the spatially structured patterns from the community level. ", "machine_text": "  We study the emergence of spatiotemporal chaos in a system of couplewise competitors. Our approach is based on the well-established theory of ecological slots. A system of n species is described by a set of differential equations, where the coefficients are functions of n variables, corresponding to the relative populations of the species. The coefficients are assumed to be smooth and symmetric with respect to a diagonal of the coefficient matrix. The model predicts a transition from a steady state to a state of spatiotemporal chaos, that is, a state in which the species densities show a chaotic evolution in space and time. Our theoretical analysis is based on the assumption that the species move according to a L\u00e9vy walk. We show that a generic form of the coefficient matrix, that captures the main statistical features of ecological systems, implies a transition to spatiotemporal chaos. The parameters of the model are adjusted to match the theoretical predictions with the dynamics observed in an ecological system. In particular, the parameters are chosen so that the model predicts a transition to spatiotemporal chaos, that is, a regime in which the populations of the species show a chaotic evolution in space and time.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Direct calculation of interfacial tensions from computer simulation:   Results for freely jointed tangent hard sphere chains. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.123, "human_text": "  We develop a methodology for the calculation of surface free energies based on the probability distribution of a wandering interface. Using a simple extension of the NpT sampling, we allow the interface area to randomly probe the available space and evaluate the surface free energy from histogram analysis and the corresponding average. The method is suitable for studying systems with either continuous or discontinuous potentials, as it does not require explicit evaluation of the virial. The proposed algorithm is compared with known results for the surface tension of Lennard--Jones and Square Well fluid, as well as for the interface tension of a bead--spring polymer model and good agreement is found. We also calculate interfacial tensions of freely jointed tangent hard sphere chains on athermal walls for a wide range of chain lengths and densities. The results are compared with three different theoretical approaches, Scaled Particle Theory, the Yu and Wu density functional theory and an analytical approximation based on the latter approach. Whereas SPT only yields qualitative results, the last two approaches are found to yield very good agreement with simulations. ", "machine_text": " We present a direct and general method to calculate the interfacial tension between two liquids from a computer simulation. Our method is based on the measurement of the bending energy of freely jointed chains of hard spheres placed at the interface. The accuracy of the method is assessed by comparing the results with those obtained from extensively validated molecular dynamics (MD) simulations of several systems of interest, such as the surfactant sodium dodecyl sulfate (SDS) in water and the protein bovine serum albumin (BSA) in water and in the presence of SDS. We show that, in good agreement with previous theoretical and experimental results, our method correctly predicts the variation of the interfacial tension with the molecular weight of the proteins or the chain length of the surfactants. We also analyze the effect of the pH in the case of the protein BSA in water, and we find that our results are consistent with the trend expected from the protonation state of the protein, in qualitative agreement with experimental data. Finally, we present a simple model that relates the interfacial tension with the concentration of the species in the mixture in a good agreement with the results obtained with our method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spin-polarized transport in II-VI magnetic resonant tunneling devices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0237, "human_text": "  We investigate electronic transport through II-VI semiconductor resonant tunneling structures containing diluted magnetic impurities. Due to the exchange interaction between the conduction electrons and the impurities, there arises a giant Zeeman splitting in the presence of a moderately low magnetic field. As a consequence, when the quantum well is magnetically doped the current-voltage characteristics shows two peaks corresponding to transport for each spin channel. This behavior is experimentally observed and can be reproduced with a simple tunneling model. The model thus allows to analyze other configurations. First, we further increase the magnetic field, which leads to a spin polarization of the electronic current injected from the leads, thus giving rise to a relative change in the current amplitude. We demonstrate that the spin polarization in the emitter can be determined from such a change. Furthermore, in the case of a magnetically doped injector our model shows a large increase in peak amplitude and a shift of the resonance to higher voltages as the external field increases. We find that this effect arises from a combination of giant Zeeman splitting, 3-D incident distribution and broad resonance linewidth. ", "machine_text": "  We report on the transport properties of single-walled carbon nanotube (SWNT) interconnects in a magnetic resonant tunneling device, where the tunnel barrier is a II-VI semiconductor with a perpendicular magnetic anisotropy. The anisotropy is derived from the spin-orbit coupling and is controlled by a perpendicular magnetic field. We show that a transport current in such a device is sensitive to the SWNT's spin-polarization, and can be used to manipulate the SWNT's magnetic state. The SWNT's transport behavior is characterized by a positive or negative spin-dependent charge transfer, depending on the relative orientation of the SWNT's and barrier's magnetic moments. We demonstrate a fabrication process for a device, where the SWNT is embedded in the barrier, resulting in a high efficiency of the spin-dependent charge transfer. Our results suggest that such a device can be used as a spin-valve, where the charge transfer is controlled by a gate voltage and depends on the SWNT's spin-polarization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Accurate QCD predictions for heavy-quark jets at the Tevatron and LHC. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2999, "human_text": "  Heavy-quark jets are important in many of today's collider studies and searches, yet predictions for them are subject to much larger uncertainties than for light jets. This is because of strong enhancements in higher orders from large logarithms, ln(p_t/m_Q). We propose a new definition of heavy-quark jets, which is free of final-state logarithms to all orders and such that all initial-state collinear logarithms can be resummed into the heavy-quark parton distributions. Heavy-jet spectra can then be calculated in the massless approximation, which is simpler than a massive calculation and reduces the theoretical uncertainties by a factor of three. This provides the first ever accurate predictions for inclusive b- and c-jets, and the latter have significant discriminatory power for the intrinsic charm content of the proton. The techniques introduced here could be used to obtain heavy-flavour jet results from existing massless next-to-leading order calculations for a wide range of processes. We also discuss the experimental applicability of our flavoured jet definition. ", "machine_text": " Accurate QCD predictions for heavy-quark jets at the Tevatron and LHC  We present the first set of predictions, based on a next-to-leading order QCD calculation, for the heavy-quark jet cross section at the Tevatron and LHC. We consider the cross sections for heavy quarkonia (H), charmonia (D), and bottomonia (B) production in association with a jet, and for the direct production of heavy quarks (H, Z, W). We find that the heavy-quark jet cross section is small compared to the standard jet cross section, but has a large component of intermediate-pT jets with H and D production, and a small but non-zero contribution to the high-pT tail with H, D, and B production. We evaluate the production cross section of a heavy-quark jet in the context of QCD, and compare it to the latest theoretical and experimental results. We find good agreement with the available data, and an improvement over the next-to-leading order prediction of Ref. [hep-ph/0609105]. We also evaluate the heavy-quark jet cross section in the forward region, and find a large forward-boost factor which is in agreement with the data. We predict a small though non-zero heavy-quark jet cross section at the LHC, and evaluate its contribution to the total jet cross section.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Young massive star clusters in the era of the Hubble Space Telescope. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1865, "human_text": "  The Hubble Space Telescope (HST) has been instrumental in the discovery of large numbers of extragalactic young massive star clusters (YMCs), often assumed to be proto-globular clusters (GCs). As a consequence, the field of YMC formation and evolution is thriving, generating major breakthroughs as well as controversies on annual (or shorter) time-scales. Here, I review the long-term survival chances of YMCs, hallmarks of intense starburst episodes often associated with violent galaxy interactions. In the absence of significant external perturbations, the key factor determining a cluster's long-term survival chances is the shape of its stellar initial mass function (IMF). It is, however, not straightforward to assess the IMF shape in unresolved extragalactic YMCs. I also discuss the latest progress in worldwide efforts to better understand the evolution of entire cluster populations, predominantly based on HST observations, and conclude that there is an increasing body of evidence that GC formation appears to be continuing until today; their long-term evolution crucially depends on their environmental conditions, however. ", "machine_text": "  Young Massive Star Clusters in the Era of the Hubble Space Telescope  We present a census of young massive star clusters (MSCs) in the era of the Hubble Space Telescope. Using the Hubble images, we select objects in the solar neighborhood (within 50 pc) that are potentially gravitationally-bound clusters containing massive stars (with B-band absolute magnitude Mbol> -1.5 mag), and determine the cluster membership with high-resolution near-infrared imaging with the W2 bridge camera on the Keck Observatory 10-m telescope. We determine the cluster parameters (the number of massive stars, their mass, and the cluster's total mass) for the member stars in the 13 candidate clusters found. Four of the clusters (including the closest one, at 2.6 pc) are newly discovered. The number of massive stars in these clusters ranges between 2 and 99, with a total cluster mass of $1-3 \\times 10^{4} M_{\\odot}$. The highest mass cluster, Mensa, contains the largest number of massive stars. The cluster ages are estimated to be $5-10^{6}$ years, based on the age of the stellar population in the neighborhood and the clusters' dynamical states. We discuss the implications of these clusters for massive star formation, the galactic fountain, and the relation between massive stars and their clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Failure mechanisms and surface roughness statistics of fractured   Fontainebleau sandstone. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2925, "human_text": "  In an effort to investigate the link between failure mechanisms and the geometry of fractures of compacted grains materials, a detailed statistical analysis of the surfaces of fractured Fontainebleau sandstones has been achieved. The roughness of samples of different widths W is shown to be self affine with an exponent zeta=0.46 +- 0.05 over a range of length scales ranging from the grain size d up to an upper cut-off length \\xi = 0.15 W. This low zeta value is in agreement with measurements on other sandstones and on sintered materials. The probability distributions P(delta z,delta h) of the variations of height over different distances delta z > d can be collapsed onto a single Gaussian distribution with a suitable normalisation and do not display multifractal features. The roughness amplitude, as characterized by the height-height correlation over fixed distances delta z, does not depend on the sample width, implying that no anomalous scaling of the type reported for other materials is present. It is suggested, in agreement with recent theoretical work, to explain these results by the occurence of brittle fracture (instead of damage failure in materials displaying a higher value of zeta = 0.8). ", "machine_text": "  Failure mechanisms and surface roughness statistics of fractured Fontainebleau sandstone  The Fontainebleau sandstone is a key formation for the evaluation of mechanical properties of granular media. In this work, we investigate the failure mechanisms and surface roughness statistics of fractured Fontainebleau sandstone. We first present results of an experimental program conducted to investigate the effects of different loading modes and rates on the failure mechanisms. We then focus on the characterization of the surface of the failed samples. We analyze the spatial distribution of the roughness, in relation with the crack network. We show that the roughness is mainly concentrated in the proximity of the main cracks, and especially at the crack tips. We also quantify the spatial distribution of the roughness power law parameter and demonstrate that it follows a log-normal distribution, with a clear peak at the value typical of the failure roughness. Finally, we analyze the anisotropy of the roughness and show that it is mainly due to the anisotropy of the crack network, with the longest cracks having the highest roughness. This study contributes to better understanding the role of surface roughness on the behavior of fractured rocks, and particularly on the problem of loose rock slippage.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: An array of low-background $^3$He proportional counters for the Sudbury   Neutrino Observatory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3665, "human_text": "  An array of Neutral-Current Detectors (NCDs) has been built in order to make a unique measurement of the total active flux of solar neutrinos in the Sudbury Neutrino Observatory (SNO). Data in the third phase of the SNO experiment were collected between November 2004 and November 2006, after the NCD array was added to improve the neutral-current sensitivity of the SNO detector. This array consisted of 36 strings of proportional counters filled with a mixture of $^3$He and CF$_4$ gas capable of detecting the neutrons liberated by the neutrino-deuteron neutral current reaction in the D$_2$O, and four strings filled with a mixture of $^4$He and CF$_4$ gas for background measurements. The proportional counter diameter is 5 cm. The total deployed array length was 398 m. The SNO NCD array is the lowest-radioactivity large array of proportional counters ever produced. This article describes the design, construction, deployment, and characterization of the NCD array, discusses the electronics and data acquisition system, and considers event signatures and backgrounds. ", "machine_text": " We describe an array of low-background $^3$He proportional counters for the Sudbury Neutrino Observatory. The array consists of eight $^3$He counters embedded in a $^4$He-saturated acrylic sphere of radius 55 cm. The counters are located at the nodes of a symmetrical eight-fold spherical octant division. Each counter is a $^3$He diffusion chamber with a volume of $\\sim 2.4$ litres. The chamber gas is contained in a cylindrical inner vessel made of glass or quartz, which is inserted into an outer vessel of PVC. The counters are instrumented with longitudinal and transverse resistive anode wires, and the number of pulses observed during a 3-minute sampling interval is recorded by a multichannel scaler. Each counter is surrounded by a thick layer of polyethylene foam to reduce the rate of $^3$He diffusion from the chamber. The array was designed to have good sensitivity to a point source anywhere in the sphere, while maintaining a small dead zone. We report on the construction, operation, and performance of the array.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Building Portable Thread Schedulers for Hierarchical Multiprocessors:   the BubbleSched Framework. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2069, "human_text": "  Exploiting full computational power of current more and more hierarchical multiprocessor machines requires a very careful distribution of threads and data among the underlying non-uniform architecture. Unfortunately, most operating systems only provide a poor scheduling API that does not allow applications to transmit valuable scheduling hints to the system. In a previous paper, we showed that using a bubble-based thread scheduler can significantly improve applications' performance in a portable way. However, since multithreaded applications have various scheduling requirements, there is no universal scheduler that could meet all these needs. In this paper, we present a framework that allows scheduling experts to implement and experiment with customized thread schedulers. It provides a powerful API for dynamically distributing bubbles among the machine in a high-level, portable, and efficient way. Several examples show how experts can then develop, debug and tune their own portable bubble schedulers. ", "machine_text": " We present BubbleSched, a portable framework for building thread schedulers for hierarchical multiprocessors. It comprises a hardware abstraction layer and a reusable library of software components that can be combined in different ways to create different thread schedulers. BubbleSched is based on a hierarchical scheduling architecture that maps threads to a hierarchy of execution bubbles. A bubble is a container for a group of threads and is the basic unit of execution. The hierarchy of bubbles is mapped to the hierarchy of processors in the system. Threads within a bubble can be executed concurrently, but execution bubbles themselves are scheduled serially. A thread is executed using a sequence of execution bubbles that share the thread's resource requirements and memory state. The key idea is that different scheduling policies can be implemented by dynamically associating threads to bubbles, and by configuring the manner in which bubbles are scheduled. We demonstrate the effectiveness of this approach by implementing several example schedulers, including a conventional multiprocessor OS thread scheduler, a task-based thread scheduler, and an event-driven concurrent programming model. Our results show that by exploiting the hierarchy of processors, BubbleSched can effectively reduce the overheads associated with scheduling threads and managing their resource requirements.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Evidence for Pre-SN Mass Loss in the Galactic SNR 3C 58. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.278, "human_text": "  We discuss the findings of a comprehensive imaging and spectroscopic survey of the optical emission associated with the supernova remnant 3C 58 (Fesen et al. 2007) as they relate to the topic of pre-SN mass loss. Spectroscopically measured radial velocities of ~450 emission knots within the remnant show two distinct kinematic populations of optical knots: a high-velocity group with radial velocities in the range of 700 - 1100 km/s and a lower velocity group exhibiting radial expansion velocities below ~250 km/s. We interpret the high-velocity knots as ejecta from the SN explosion and the low-velocity knots as shocked circumstellar material likely resulting from pre-SN mass loss. The chemical signatures of the two populations also show marked differences. The high velocity group includes a substantial number of knots with notably higher [N II]/H-alpha ratios not seen in the lower velocity population, suggesting greater nitrogen enrichment in the SN ejecta than in the CSM. These results are compared with evidence for pre-SN mass loss in the Crab Nebula, perhaps the SNR most similar to 3C 58. These SNRs may comprise two case studies of pre-SN mass loss in relatively low mass (~8 - 10 solar masses) core-collapse SN progenitors. ", "machine_text": "  We present observations of the supernova (SN) 1987A shock wave as it passes through the old supernova remnant 3C 58. We find a large, well-defined peak in the shocked gas at the same distance from the SN 1987A as the peak in the sound wave, but six times farther away than the peak in the temperature distribution. This shock-wave peak contains 0.4 kpc^2 of the total 1.4 kpc^2 of gas that is shocked by the passage of the supernova blast wave. We interpret this shock structure as a bubble, with the gas inside the bubble being excited by the shock wave and the gas outside the bubble being depressed by the shock wave. We show that such a bubble configuration is consistent with the observed density and temperature distribution. We estimate that the mass of the gas inside the bubble is M_{gas} \u223c 2 \u00d7 10^{33} M\u2299, which is \u223c 1% of the total SN 1987A mass. The mass of gas in the bubble is much less than the total mass of gas in the remnant, which is M_{gas} \u223c 7 \u00d7 10^{33} M\u2299. We conclude that most of the gas in the 3C 58 remnant was lost before the SN 1987A shock wave reached the remnant.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measurement of the production of charged pions by protons on a tantalum   target. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.16, "human_text": "  A measurement of the double-differential cross-section for the production of charged pions in proton--tantalum collisions emitted at large angles from the incoming beam direction is presented. The data were taken in 2002 with the HARP detector in the T9 beam line of the CERN PS. The pions were produced by proton beams in a momentum range from 3 \\GeVc to 12 \\GeVc hitting a tantalum target with a thickness of 5% of a nuclear interaction length. The angular and momentum range covered by the experiment ($100 \\MeVc \\le p < 800 \\MeVc$ and $0.35 \\rad \\le \\theta <2.15 \\rad$) is of particular importance for the design of a neutrino factory. The produced particles were detected using a small-radius cylindrical time projection chamber (TPC) placed in a solenoidal magnet. Track recognition, momentum determination and particle identification were all performed based on the measurements made with the TPC. An elaborate system of detectors in the beam line ensured the identification of the incident particles. Results are shown for the double-differential cross-sections ${{\\mathrm{d}^2 \\sigma}} / {{\\mathrm{d}p\\mathrm{d}\\theta}}$ at four incident proton beam momenta (3 \\GeVc, 5 \\GeVc, 8 \\GeVc and 12 \\GeVc). In addition, the pion yields within the acceptance of typical neutrino factory designs are shown as a function of beam momentum. The measurement of these yields within a single experiment eliminates most systematic errors in the comparison between rates at different beam momenta and between positive and negative pion production. ", "machine_text": "  We have measured the production of charged pions by protons on a tantalum target. Our aim was to investigate the longitudinal development of the scattered proton as a function of its energy. The longitudinal development was measured by detecting the scattered protons in the forward direction, in the plane of the target. We used a magnetic spectrometer to detect the charged pions; it was found that the detection efficiency as a function of the pion's momentum was well described by a curve which was obtained from a simulation of the longitudinal development of the scattered proton. The data were compared with the results of a theoretical model which includes the stopping power as a function of the proton's energy. A reasonable agreement was obtained, except that the theory predicts a larger contribution from higher energy protons than we observed. The model also predicts a correlation between the stopping power and the ionization density as a function of the proton's energy, and we observed such a correlation in our data.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: STBCs from Representation of Extended Clifford Algebras. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2507, "human_text": "  A set of sufficient conditions to construct $\\lambda$-real symbol Maximum Likelihood (ML) decodable STBCs have recently been provided by Karmakar et al. STBCs satisfying these sufficient conditions were named as Clifford Unitary Weight (CUW) codes. In this paper, the maximal rate (as measured in complex symbols per channel use) of CUW codes for $\\lambda=2^a,a\\in\\mathbb{N}$ is obtained using tools from representation theory. Two algebraic constructions of codes achieving this maximal rate are also provided. One of the constructions is obtained using linear representation of finite groups whereas the other construction is based on the concept of right module algebra over non-commutative rings. To the knowledge of the authors, this is the first paper in which matrices over non-commutative rings is used to construct STBCs. An algebraic explanation is provided for the 'ABBA' construction first proposed by Tirkkonen et al and the tensor product construction proposed by Karmakar et al. Furthermore, it is established that the 4 transmit antenna STBC originally proposed by Tirkkonen et al based on the ABBA construction is actually a single complex symbol ML decodable code if the design variables are permuted and signal sets of appropriate dimensions are chosen. ", "machine_text": "  We consider the problem of constructing or characterizing (symmetric informationally stable) time-frequency based communication (STBC) codes from a representation of extended Clifford algebras. The motivation for the research is that a rich theory of time-frequency based communication (TFC) codes has been developed in the context of time-frequency analysis and synthesis, but relatively little is known about the connection between TFC codes and algebraic structures. In this work, we consider the problem of constructing or characterizing STBC codes from a representation of extended Clifford algebras. The main results show that the orthogonal and symplectic Clifford algebras over $\\mathbb C$ and the symmetric informationally stable orthogonal and symplectic Clifford algebras over $\\mathbb R$ correspond to the set of all STBC codes. As a by-product, we give a description of the symmetric informationally stable time-frequency based communication codes in terms of the modulation theory of quaternions.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Deaconstructing Functions on Quadratic Surfaces into Multipoles. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1174, "human_text": "  Any homogeneous polynomial $P(x, y, z)$ of degree $d$, being restricted to a unit sphere $S^2$, admits essentially a unique representation of the form $\\lambda + \\sum_{k = 1}^d [\\prod_{j = 1}^k L_{kj}]$, where $L_{kj}$'s are linear forms in $x, y$ and $z$ and $\\lambda$ is a real number. The coefficients of these linear forms, viewed as 3D vectors, are called \\emph{multipole} vectors of $P$. In this paper we consider similar multipole representations of polynomial and analytic functions on other quadratic surfaces $Q(x, y, z) = c$, real and complex. Over the complex numbers, the above representation is not unique, although the ambiguity is essentially finite. We investigate the combinatorics that depicts this ambiguity. We link these results with some classical theorems of harmonic analysis, theorems that describe decompositions of functions into sums of spherical harmonics. We extend these classical theorems (which rely on our understanding of the Laplace operator $\\Delta_{S^2}$) to more general differential operators $\\Delta_Q$ that are constructed with the help of the quadratic form $Q(x, y, z)$. Then we introduce modular spaces of multipoles. We study their intricate geometry and topology using methods of algebraic geometry and singularity theory. The multipole spaces are ramified over vector or projective spaces, and the compliments to the ramification sets give rise to a rich family of $K(\\pi, 1)$-spaces, where $\\pi$ runs over a variety of modified braid groups. ", "machine_text": "  Deaconstructing Functions on Quadratic Surfaces into Multipoles  We consider the problem of decomposing a function on a quadratic surface in a projective space into a superposition of multipoles, that is, linear combinations of Dirac $\\delta$-functionals. We show that this is possible in the case of quadrics that are symmetric with respect to the projective plane. We describe the minimal basis of Dirac $\\delta$-functionals on the symmetric quadrics. Our approach is via the geometric structure of the symmetric quadrics in the projective space, which enables us to give a description of the resulting multipoles in terms of the geometry of the projective space. In particular, we show that the multipoles can be extracted from the restriction of the function to certain lines in the projective space. Our approach does not rely on the classification of quadratic surfaces, but rather uses a geometric description of the symmetric part of the quadric. As such, it provides a geometrically intuitive approach to decomposing functions on quadrics into multipoles.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Arc-like distribution of high CO(J=3-2)/CO(J=1-0) ratio gas surrounding   the central star cluster of the supergiant HII region NGC 604. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.143, "human_text": "  We report the discovery of a high CO(J=3-2)/CO(J=1-0) ratio gas with an arc-like distribution (``high-ratio gas arc'') surrounding the central star cluster of the supergiant HII region NGC 604 in the nearby spiral galaxy M 33, based on multi-J CO observations of a 5' $\\times$ 5' region of NGC 604 conducted using the ASTE 10-m and NRO 45-m telescopes. The discovered ``high-ratio gas arc'' extends to the south-east to north-west direction with a size of $\\sim$ 200 pc. The western part of the high-ratio gas arc closely coincides well with the shells of the HII regions traced by H$\\alpha$ and radio continuum peaks. The CO(J=3-2)/CO(J=1-0) ratio, R_{3-2/1-0}, ranges between 0.3 and 1.2 in the observed region, and the R_{3-2/1-0} values of the high-ratio gas arc are around or higher than unity, indicating very warm (T_kin > 60 K) and dense (n(H_2) > 10^{3-4} cm^{-3}) conditions of the high-ratio gas arc. We suggest that the dense gas formation and second-generation star formation occur in the surrounding gas compressed by the stellar wind and/or supernova of the first-generation stars of NGC 604, i.e., the central star cluster of NGC 604. ", "machine_text": "  We present a spatially resolved spectroscopic study of the gas distribution in the supergiant HII region NGC 604, based on a new catalogue of 30 single-dish detections of the CO(J=3-2) line in the region. The catalogue also contains 21 detections of the CO(J=1-0) line, allowing a determination of the ratio of line intensities CO(J=3-2)/CO(J=1-0) for each detection. The resulting map of the CO(J=3-2)/CO(J=1-0) ratio shows an almost exponential decline with distance from the central star cluster, with an exponential coefficient of -1.5+/-0.1. The same pattern is also seen when the catalogue is divided in two according to the visual classification of the stars in the region, resulting in a 'compact' part with a ratio of typically 1.5 and a more 'halo-like' part with a ratio of typically 1.9. We conclude that a significant fraction (up to 50%) of the CO(J=3-2)-emitting gas in the outer parts of NGC 604 has a velocity too low to be able to escape from the region, even at the low density (typical log(column density) = 7.5) measured in these regions. We discuss this low-velocity gas in the context of a simple model in which the gas is treated as a perfect gas and the stellar velocity distribution is used to prescribe the gas velocity distribution. In such a model, the gas distribution is capable of producing the arc-like distribution of high CO(J=3-2)/CO(J=1-0) ratio gas surrounding the central star cluster, provided that the gas fraction is at least 10% of the total (gas plus stars) density. The minimum gas fraction required is found to be slightly higher (by a factor of about 1.5) for the 'compact' part of the region than for the 'halo-like' part. We discuss the problem of low-resolution spectra of gas in regions with very large scale molecular clouds and the problem of continuum-level data analysis in the case of highly non-linearly broadened spectra.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The design of a very high-Q superconductor electromechanical clock. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2842, "human_text": "  We discuss theoretically the properties of an electromechanical oscillator whose operation is based upon the cyclic, quasi-conservative conversion between gravitational potential, kinetic, and magnetic energies. The system consists of a strong-pinning type-II superconductor square loop subjected to a constant external force and to magnetic fields. The loop oscillates in the upright position at a frequency that can be tuned in the range 10-1000 Hz, and has induced in it a rectified electrical current. The emphasis of this paper is on the evaluation of the major remaining source of losses in the oscillations. We argue that such losses should be associated with the viscous vibration of pinned flux lines in the superconductor Nb-Ti wire, provided the oscillator is kept close to zero Kelvin, under high-vacuum, and the magnetic field is sufficiently uniform. We discuss how other different sources of loss would become negligible for such operational conditions, so that a very high quality factor Q exceeding 10^(10) might in principle be reached by the oscillator. The prospective utilization of such oscillator as a low-frequency high-Q clock is analyzed.Since publication the ideas in this paper have been explored both by the author and elsewhere, in applications covering Metrology, quantum systems, and gravimetry. ", "machine_text": " We report on a superconductor electromechanical clock with a quality factor of << 10^6. The device consists of a superconducting loop with a single-turn secondary coil. The primary coil is used to generate a magnetic field over a Josephson junction which is located in the loop. The supercurrent through the junction is induced by the magnetic field and is opposed by the critical current of the junction. The critical current is modulated by a DC current bias and the supercurrent is reset by a thermo-mechanical mechanism. The dynamic behavior of the supercurrent is found to be in good agreement with the analytical model presented in this paper. The mechanism of the device is such that the energy losses due to the finite thermal and mechanical relaxation time are negligible. This makes it possible to reach very high quality factors. The current-voltage characteristics of the Josephson junction and the frequency of the induced supercurrent are stable over a wide range of temperature, bias current, and external magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Dahlberg's bilinear estimate for solutions of divergence form complex   elliptic equations. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0839, "human_text": "  We consider divergence form elliptic operators $L=-\\dv A(x)\\nabla$, defined in $\\mathbb{R}^{n+1}=\\{(x,t)\\in\\mathbb{R}^{n}\\times\\mathbb{R}\\}, n \\geq 2$, where the $L^{\\infty}$ coefficient matrix $A$ is $(n+1)\\times(n+1)$, uniformly elliptic, complex and $t$-independent. Using recently obtained results concerning the boundedness and invertibility of layer potentials associated to such operators, we show that if $Lu=0$ in $\\mathbb{R}^{n+1}_+$, then for any vector-valued ${\\bf v} \\in W^{1,2}_{loc},$ we have the bilinear estimate $$|\\iint_{\\mathbb{R}^{n+1}_+} \\nabla u \\cdot \\bar{{\\bf v}} dx dt |\\leq C\\sup_{t>0} \\|u(\\cdot,t)\\|_{L^2(\\mathbb{R}^n)}(\\||t \\nabla {\\bf v}\\|| + \\|N_*{\\bf v}\\|_{L^2(\\mathbb{R}^n)}),$$ where $\\||F\\|| \\equiv (\\iint_{\\mathbb{R}^{n+1}_+} |F(x,t)|^2 t^{-1} dx dt)^{1/2},$ and where $N_*$ is the usual non-tangential maximal operator. The result is new even in the case of real symmetric coefficients, and generalizes the analogous result of Dahlberg for harmonic functions on Lipschitz graph domains. ", "machine_text": "  We show that Dahlberg's bilinear estimate for solutions of divergence form complex elliptic equations. Let $\\alpha\\in\\mathbb{R}$ and $u$ be a function of two independent variables $x$ and $y$. Consider the elliptic PDE $$\\label{eq1} \\dot\\bigl(u(x,y)\\bigr)=\\bigl(u(x,y)\\bigr)\\dot x+\\dot y\\bigl(u(x,y)\\bigr)$$ on the infinite strip $\\{x,x+iy\\in\\mathbb{R}^2\\,|\\,x,y\\ge 0\\}$. Here the nonlinear term is given by the so-called divergence form $$\\dot y\\bigl(u(x,y)\\bigr)=\\bigl(u(x,y)\\bigr)\\dot y-\\dot x\\bigl(u(x,y)\\bigr).$$ It is known that solutions of $(1)$ with initial conditions in $C^\\infty\\bigl(\\mathbb{R}^2\\bigr)$ are uniquely determined on each component of the following mixed space $$C^\\infty\\bigl(M\\bigr)=\\bigcup_{\\substack{x,y\\ge 0\\\\ x+y\\in\\mathbb{R}^2}}C^\\infty\\bigl(\\{x,y\\}\\bigr).$$ Here $M$ is the two-dimensional torus $$M=\\bigl\\{(x,y)\\in\\mathbb{R}^2\\,|\\,x,y\\ge 0\\,\\text{ and }x+y\\in\\mathbb{R}^2\\bigr).$$ In this paper, we present an estimate for solutions of $(1)$ with initial conditions in $C^\\infty\\bigl(\\mathbb{R}^2\\bigr)$ in the following form: $$\\label{ estimates } \\label{eq2} \\dot \\bigl(u(x,y)\\bigr)=\\bigl(u(x,y)\\bigr)\\dot x+\\dot y\\bigl(u(x,y)\\bigr)$$ on the torus $M$; with initial condition in $C^\\infty\\bigl(\\mathbb{R}^2\\bigr)$; and where $$\\dot x\\bigl(u(x,y)\\bigr)=\\bigl(u(x,y)\\bigr)\\dot x-\\dot y\\bigl(u(x,y)\\bigr)$$ on the strip $\\{x,x+iy\\in\\mathbb{R}^2\\,|\\,x,y\\ge 0\\}$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spectral analysis of Swift long GRBs with known redshift. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0791, "human_text": "  We study the spectral and energetics properties of 47 long-duration gamma-ray bursts (GRBs) with known redshift, all of them detected by the Swift satellite. Due to the narrow energy range (15-150 keV) of the Swift-BAT detector, the spectral fitting is reliable only for fitting models with 2 or 3 parameters. As high uncertainty and correlation among the errors is expected, a careful analysis of the errors is necessary. We fit both the power law (PL, 2 parameters) and cut--off power law (CPL, 3 parameters) models to the time-integrated spectra of the 47 bursts, and present the corresponding parameters, their uncertainties, and the correlations among the uncertainties. The CPL model is reliable only for 29 bursts for which we estimate the nuf_nu peak energy Epk. For these GRBs, we calculate the energy fluence and the rest- frame isotropic-equivalent radiated energy, Eiso, as well as the propagated uncertainties and correlations among them. We explore the distribution of our homogeneous sample of GRBs on the rest-frame diagram E'pk vs Eiso. We confirm a significant correlation between these two quantities (the \"Amati\" relation) and we verify that, within the uncertainty limits, no outliers are present. We also fit the spectra to a Band model with the high energy power law index frozen to -2.3, obtaining a rather good agreement with the \"Amati\" relation of non-Swift GRBs. ", "machine_text": "  Spectral analysis of Swift long GRBs with known redshift  We present spectral analysis of all Swift long gamma-ray bursts (GRBs) with known redshift in order to study the evolution of their spectral and energetics properties as a function of redshift. We find a clear segregation of the samples in two distinct groups according to their redshift, with the high-redshift bursts (z > 1) presenting harder and more energetic spectra than the low-redshift bursts (z < 1). We show this difference cannot be explained by a simple evolution of the burst parameters (energy fluence, peak energy and isotropic-equivalent radiated energy) as a function of redshift, suggesting an additional, poorly understood, evolution of the spectral properties. We find a good agreement of our results with a model in which the high-redshift bursts are produced in an extra-galactic medium, with the low-redshift bursts produced in a galactic medium. This model is in good agreement with the observed distribution of burst redshift, with the known extragalactic burst population, and with the galactic observations of the burst birth-sites. We discuss our results in the framework of the current theories of GRB production and evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: New interpretation for energy gap $\\Delta$ of the cut-off approximation   in the BCS theory of superconductivity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2392, "human_text": "  This paper concerns the solution of the self-consistency equation for energy gap parameter $\\Delta_{\\bf k}$ in the BCS theory of superconductivity. We show that there exists a well-defined relation between the solution for energy gap parameter amplitude $|\\Delta_{\\bf k}|$ for a general interaction $V_{{\\bf k},{\\bf k}'}$ and energy gap $\\Delta$ obtained by using the cut-off approximation. The relation between $|\\Delta_{\\bf k}|$ and $\\Delta$ indicates that $\\Delta$ is a weighted average over $|\\Delta_{\\bf k}|$ of electronic states within cut-off energy $\\xi_c$ around the Fermi surface. In this interpretation for $\\Delta$, $\\xi_c$ is not a property of $V_{{\\bf k},{\\bf k}'}$, but a parameter specifying the energy range within which the weighted average over $|\\Delta_{\\bf k}|$ is taken. We show that the proper choice for the value of $\\xi_c$ is only a few $k_BT_c$ (i.e., $\\xi_c/k_BT_c$ is about 3 or 4). We also show that the cut-off approximation, even with $\\xi_c/k_BT_c=\\infty$, is a good approximation when it is used to calculate quantities such as the condensation energy and the specific heat, but it leads to significant overestimation for the Josephson critical current density of a Josephson junction if $\\xi_c/k_BT_c \\gg 1$ is assumed. ", "machine_text": " We re-examine the energy gap $\\Delta$ of the cut-off approximation in the theory of superconductivity in cuprates, and point out that an overlooked translation symmetry in the mathematical derivation of the energy gap $\\Delta$ of the paired impurity model on the square lattice $L\\otimes L$ results in an incorrect formula for $\\Delta$. After a correct derivation of the energy gap $\\Delta$ of the cut-off approximation, we show that the usual $\\Delta$ is not the minimal energy gap in the full paired impurity model on $L\\otimes L$. In fact, the minimal energy gap is achieved by the so-called $L\\times L$-term, which describes the long range entanglement of the order parameter, and is related to the $L\\times L$- grassland in the problem of statistical mechanics. We show that the energy gap $\\Delta$ of the cut-off approximation is related to the spectrum of the Laplace operator on the $L\\times L$-term. In particular, the energy gap $\\Delta$ of the cut-off approximation is related to the Casimir energy of the Laplace operator. We show that the energy gap $\\Delta$ of the cut-off approximation exhibits a strong difference between the $L\\otimes L$- and $L\\times L$-terms, which may be related to the difference between the long range entanglement and the short range entanglement in the paired impurity model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Constrained simulations of the local universe: I. Mass and motion in the   Local Volume. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3385, "human_text": "  It has been recently claimed that there is no correlation between the distribution of galaxies and their peculiar velocities within the Local Volume (LV), namely a sphere of R=7/h Mpc around the Local Group (LG). It has been then stated that this implies that either locally dark matter is not distributed in the same way as luminous matter, or peculiar velocities are not due to fluctuations in mass. To test that statement a set of constrained N-body cosmological simulations, designed to reproduce the main observed large scale structure, have been analyzed. The simulations were performed within the flat-Lambda, open and flat matter only CDM cosmogonies. Two unconstrained simulations of the flat-Lambda and open CDM models were performed for comparison. LG-like objects have been selected so as to mimic the real LG environment. The local gravitational field due to all halos found within each LV is compared with the exact gravitational field induced by all matter in the simulation. We conclude that there is no correlation between the exact and the local gravitational field obtained by pairwise newtonian forces between halos. Moreover, the local gravitational field is uncorrelated with the peculiar velocities of halos. The exact gravitational field has a linear correlation with peculiar velocities but the proportionality constant relating the velocity with gravitational field falls below the prediction of the linear theory. Upon considering all matter inside the LVs, the exact and local gravitational accelerations show a much better correlation, but with a considerable scatter independent on the cosmological models. The main conclusion is that the lack of correlation between the local gravitation and the peculiar velocity fields around LG-like objects is naturally expected in the CDM cosmologies. ", "machine_text": "  We present the first results from a systematic study of the evolution of matter and motion in the Local Volume, based on constrained simulations with the Taaffe simulation code, on a set of ~40 million CPU hours on TeraGrid resources. We consider the evolution of the mass and motion in the Local Volume, focusing on the growth of structure on small scales (comoving scales less than 5 h$^{-1}$ Mpc) and the correlation between matter and motion. We find that the large-scale structure in the Local Volume has many of the same statistical properties as the large-scale structure in the universe at large, such as the power law decline in the correlation function and the increasingly exponential decline with scale. We also find that the correlation between matter and motion is very tight on large scales, but breaks down on small scales, with a correlation length that decreases with radius in a way consistent with the sound-wave approximation. We discuss these results in the context of the current theories of structure formation in the Local Volume, and find that our results are consistent with the idea that large-scale structure forms through a gravitational instability that is largely insensitive to the detailed distribution of matter, and that small-scale structure forms through a process of resonance that depends sensitively on the detailed distribution of matter.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gaussian-Basis Monte Carlo Method for Numerical Study on Ground States   of Itinerant and Strongly Correlated Electron Systems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3792, "human_text": "  We examine Gaussian-basis Monte Carlo method (GBMC) introduced by Corney and Drummond. This method is based on an expansion of the density-matrix operator rho by means of the coherent Gaussian-type operator basis Lambda and does not suffer from the minus sign problem. The original method, however, often fails in reproducing the true ground state and causes systematic errors of calculated physical quantities because the samples are often trapped in some metastable or symmetry broken states. To overcome this difficulty, we combine the quantum-number projection scheme proposed by Assaad, Werner, Corboz, Gull and Troyer in conjunction with the importance sampling of the original GBMC method. This improvement allows us to carry out the importance sampling in the quantum-number-projected phase-space. Some comparisons with the previous quantum-number projection scheme indicate that, in our method, the convergence with the ground state is accelerated, which makes it possible to extend the applicability and widen the range of tractable parameters in the GBMC method. The present scheme offers an efficient practical way of computation for strongly correlated electron systems beyond the range of system sizes, interaction strengths and lattice structures tractable by other computational methods such as the quantum Monte Carlo method. ", "machine_text": "  We present a Gaussian-basis Monte Carlo method for numerical study on ground states of itinerant and strongly correlated electron systems. The method is based on the use of Gaussian random numbers, which enables an exact evaluation of the mean-square violation of the various conservation laws. We show that this method is exact and free from any systematic errors. We apply the method to the study of the ground state of the 1d Mott insulator LiCoO2, for which an exact solution is known. The results show that the method is very efficient and accurate.  The method can be used to study systems for which an exact solution is not known. As an example we consider the three-dimensional (3d) Mott insulator CeCoIn5. The results show that the method is able to give a good description of the ground state, in spite of the strong spin-orbit coupling and the large number of spin-orbital states, which causes a strong symmetry breaking of the ground state.  The method can also be used to study more complex systems, such as the 3d Ising antiferromagnet NiO. In this case the method is not exact, but it gives a very good approximation of the ground state. The method is also applied to the study of the spectral functions of the states, which are found to be in very good agreement with the results obtained by using the mean-field theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Zeta-Function of a p-Adic Manifold, Dwork Theory for Physicists. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2056, "human_text": "  In this article we review the observation, due originally to Dwork, that the zeta-function of an arithmetic variety, defined originally over the field with p elements, is a superdeterminant. We review this observation in the context of a one parameter family of quintic threefolds, and study the zeta-function as a function of the parameter \\phi. Owing to cancellations, the superdeterminant of an infinite matrix reduces to the (ordinary) determinant of a finite matrix, U(\\phi), corresponding to the action of the Frobenius map on certain cohomology groups. The parameter-dependence of U(\\phi) is given by a relation U(\\phi)=E^{-1}(\\phi^p)U(0)E(\\phi) with E(\\phi) a Wronskian matrix formed from the periods of the manifold. The periods are defined by series that converge for $|\\phi|_p < 1$. The values of \\phi that are of interest are those for which \\phi^p = \\phi so, for nonzero \\phi, we have |\\vph|_p=1. We explain how the process of p-adic analytic continuation applies to this case. The matrix U(\\phi) breaks up into submatrices of rank 4 and rank 2 and we are able from this perspective to explain some of the observations that have been made previously by numerical calculation. ", "machine_text": " We review recent progress in the field of analysis of infinite-dimensional structures in physics, initiated by A.D.W. Stone with the study of infinite-dimensional algebras in quantum theory, and the construction of a formalism of brushed algebras and Stone's970 Fuglede-Putnam index theorem for these. This is followed by the construction of the chased structure for locally constant sections of vector bundles generalizing the Frielandsyzetafunctionfor Chainsaw algebras, and the application of this theory to the study of n-Calabi-Yau spaces and their moduli. We then sketch the basic results of the Dwork theory for physicists developed by S.D. Nozick, and his proof of the non-existence of a permanent objects in a class of linear operators on the space of vector fields on a non-compact complex manifold, and the relation of this to the weakepermitivity of the global sections of certain vector bundles on these manifolds. We then review the extension of the Dwork theory to the setting of sheaves on a p-adic manifold, and the results on the Zeta-function of a p-adic manifold in this setting. We finally discuss the relation of these results to the question of the existence of a favorite Isaacs triple product for a general p-adic manifold, and the application of these results to the problem of constructing an Isaacs triple product on a non-compact p-adic manifold.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Kinematics of the Ultra-Faint Milky Way Satellites: Solving the   Missing Satellite Problem. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0516, "human_text": "  We present Keck/DEIMOS spectroscopy of stars in 8 of the newly discovered ultra-faint dwarf galaxies around the Milky Way. We measure the velocity dispersions of Canes Venatici I and II, Ursa Major I and II, Coma Berenices, Hercules, Leo IV and Leo T from the velocities of 18 - 214 stars in each galaxy and find dispersions ranging from 3.3 to 7.6 km/s. The 6 galaxies with absolute magnitudes M_V < -4 are highly dark matter-dominated, with mass-to-light ratios approaching 1000. The measured velocity dispersions are inversely correlated with their luminosities, indicating that a minimum mass for luminous galactic systems may not yet have been reached. We also measure the metallicities of the observed stars and find that the 6 brightest of the ultra-faint dwarfs extend the luminosity-metallicity relationship followed by brighter dwarfs by 2 orders of magnitude in luminosity; several of these objects have mean metallicities as low as [Fe/H] = -2.3 and therefore represent some of the most metal-poor known stellar systems. We detect metallicity spreads of up to 0.5 dex in several objects, suggesting multiple star formation epochs. Having established the masses of the ultra-faint dwarfs, we re-examine the missing satellite problem. After correcting for the sky coverage of the SDSS, we find that the ultra-faint dwarfs substantially alleviate the discrepancy between the predicted and observed numbers of satellites around the Milky Way, but there are still a factor of ~4 too few dwarf galaxies over a significant range of masses. We show that if galaxy formation in low-mass dark matter halos is strongly suppressed after reionization, the simulated circular velocity function of CDM subhalos can be brought into approximate agreement with the observed circular velocity function of Milky Way satellite galaxies. [slightly abridged] ", "machine_text": "  We present a kinematic analysis of 19 ultra-faint Milky Way satellites (galaxies <= 10^5 Lodded), representing the largest sample of satellites observed with high signal-to-noise ratio (SNR) data. Our analysis comprises four different galactic orbits, four different galaxy-galaxy separation metrics, and both absolute and relative photometric and kinematic measurements. We find that the satellites are (i) distributed in orbits that are slightly more eccentric than those of the Galactic globular clusters; (ii) more numerous in their pericentric regions than their apocenter; (iii) less likely to have large relative velocities than the globular clusters; and (iv) significantly more likely to be member of a bound system than the globular clusters. The results are consistent with the globular clusters and the ultra-faint satellites belonging to a dynamically driven galactic ecosystem, with the globular clusters corresponding to the most massive and least frequent population. The ultra-faint satellites are more numerous, but also less massive, than the globular clusters, which reflects the fact that they are likely to be the least evolved objects of the galactic globular/halo system. We also find a strong correlation between the orbital eccentricity and the galaxy-galaxy separation, which implies that the satellites are more likely to be involved in dynamical interactions than the globular clusters. We discuss the implications of our results for the formation and evolution of the Milky Way globular cluster system, as well as for the dynamical structure of the galactic halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chaos and Symmetry in String Cosmology. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1457, "human_text": "  We review the recently discovered interplay between chaos and symmetry in the general inhomogeneous solution of many string-related Einstein-matter systems in the vicinity of a cosmological singularity. The Belinsky-Khalatnikov-Lifshitz-type chaotic behaviour is found, for many Einstein-matter models (notably those related to the low-energy limit of superstring theory and M-theory), to be connected with certain (infinite-dimensional) hyperbolic Kac-Moody algebras. In particular, the billiard chambers describing the asymptotic cosmological behaviour of pure Einstein gravity in spacetime dimension d+1, or the metric-three-form system of 11-dimensional supergravity, are found to be identical to the Weyl chambers of the Lorentzian Kac-Moody algebras AE_d, or E_{10}, respectively. This suggests that these Kac-Moody algebras are hidden symmetries of the corresponding models. There even exists some evidence of a hidden equivalence between the general solution of the Einstein-three-form system and a null geodesic in the infinite dimensional coset space E_{10} / K(E_{10}), where K(E_{10}) is the maximal compact subgroup of E_{10}. ", "machine_text": "  We investigate the role of chaos and symmetry in string cosmology. We show that a slight break down of thesymmetry of the stringy dynamics can have a major impact on the evolution of the universe. In particular we consider the case of a spontaneously broken Symplectic group, which corresponds to a non-trivial Cosmological constant, and show that in this case the evolution is generically chaotic. We find that the level of chaos can be related to the string scale, and thus is very large in the early universe. We also find that the structure of the string dynamics has a strong influence on the shape of the probability distribution function, and thus on the structure of the matter power spectrum. In particular we find that a random choice of the stringy dynamics typically produces a scale invariant power spectrum, while a more structured dynamics produces a power law one. We also discuss the role of chaos and symmetry in the stringy description of the early universe, and the relation between the string dynamics and the effective dynamics of the early universe.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Space-time percolation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0506, "human_text": "  The contact model for the spread of disease may be viewed as a directed percolation model on $\\ZZ \\times \\RR$ in which the continuum axis is oriented in the direction of increasing time. Techniques from percolation have enabled a fairly complete analysis of the contact model at and near its critical point. The corresponding process when the time-axis is unoriented is an undirected percolation model to which now standard techniques may be applied. One may construct in similar vein a random-cluster model on $\\ZZ \\times \\RR$, with associated continuum Ising and Potts models. These models are of independent interest, in addition to providing a path-integral representation of the quantum Ising model with transverse field. This representation may be used to obtain a bound on the entanglement of a finite set of spins in the quantum Ising model on $\\ZZ$, where this entanglement is measured via the entropy of the reduced density matrix. The mean-field version of the quantum Ising model gives rise to a random-cluster model on $K_n \\times \\RR$, thereby extending the Erdos-Renyi random graph on the complete graph $K_n$. ", "machine_text": "  We consider a space-time percolation process on a lattice, in which the evolution of a site is governed by the local update rule proposed by Edelsbrunner and Gel'fand: the site changes state only if all its neighbors are in the same state. We show that this process is critical in all dimensions greater than or equal to three, and derive an explicit expression for the probability that a site is in the critical state. In two dimensions, we show that the percolation process is mean-field critical and derive an expression for the probability that a site is in the critical state, which, in the case of a large system size, has a simple intuitive meaning. We also show that the critical state is resilient against changes in the update rule: a slight modification of the update rule, in which the order in which the neighbors are checked is changed, can lead to a different critical state. However, for large system sizes, this different critical state is obtained by first percolating in space and then percolating in time, which suggests that the critical state is robust against changes in the update rule and has a simple intuitive meaning.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Metal Cooling in Simulations of Cosmic Structure Formation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0754, "human_text": "  The addition of metals to any gas can significantly alter its evolution by increasing the rate of radiative cooling. In star-forming environments, enhanced cooling can potentially lead to fragmentation and the formation of low-mass stars, where metal-free gas-clouds have been shown not to fragment. Adding metal cooling to numerical simulations has traditionally required a choice between speed and accuracy. We introduce a method that uses the sophisticated chemical network of the photoionization software, Cloudy, to include radiative cooling from a complete set of metals up to atomic number 30 (Zn) that can be used with large-scale three-dimensional hydrodynamic simulations. Our method is valid over an extremely large temperature range (10 K < T < 10^8 K), up to hydrogen number densities of 10^12 cm^-3. At this density, a sphere of 1 Msun has a radius of roughly 40 AU. We implement our method in the adaptive mesh refinement (AMR) hydrodynamic/N-body code, Enzo. Using cooling rates generated with this method, we study the physical conditions that led to the transition from Population III to Population II star formation. While C, O, Fe, and Si have been previously shown to make the strongest contribution to the cooling in low-metallicity gas, we find that up to 40% of the metal cooling comes from fine-structure emission by S, when solar abundance patterns are present. At metallicities, Z > 10^-4 Zsun, regions of density and temperature exist where gas is both thermally unstable and has a cooling time less than its dynamical time. We identify these doubly unstable regions as the most inducive to fragmentation. At high redshifts, the CMB inhibits efficient cooling at low temperatures and, thus, reduces the size of the doubly unstable regions, making fragmentation more difficult. ", "machine_text": "  We present a new set of N-body simulations of structure formation in the Universe, in which we study the effects of various cooling functions on the evolution of the matter density field. We have chosen the case of an expanding Universe with a negative spatial curvature, which corresponds to a model in which the scale factor increases over time. We employ a cooling function which is very general and contains as special cases the power law cooling and the two-zone cooling functions used previously in N-body simulations. We find that the main difference between the various cooling functions is the different initial conditions that they generate. For all cooling functions the evolution is always a slow descent towards a power law density field. The power of the density field is, however, different in general. The only case in which the power law index is not modified during the evolution is the case of the power law cooling function. For this special case we can also investigate the variation of the power law index as a function of the total matter content of the Universe. Our numerical results show that the evolution of the density field is very sensitive to the choice of the initial conditions. We find that the choice of the cooling function has only a very small effect on the final structure of the Universe. The results are in agreement with the conclusion that the evolution is governed by the slow descent towards a power law density field, and that the initial conditions have a far more important role in the evolution than the cooling function.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Catalog of Star Cluster Candidates in M33. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1576, "human_text": "  We present a new catalog of star cluster candidates in the nearby spiral galaxy M33. It is based on eight existing catalogs wherein we have cross-referenced identifications and endeavored to resolve inconsistencies between them. Our catalog contains 451 candidates of which 255 are confirmed clusters based on HST and high resolution ground-based imaging. The catalog contains precise cluster positions (RA and Dec), magnitudes and colors in the UBVRIJHKs filters, metallicities, radial velocities, masses and ages, where available, and galactocentric distances for each cluster. The color distribution of the M33 clusters appears to be similar to those in the Large Magellanic Cloud with major peaks at (B-V)o~0.15, and (B-V)o~0.65. The intrinsic colors are correlated with cluster ages, which range from 10^{7.5} to 10^{10.3} years. The age distribution of the star clusters supports the notion of rapid cluster disruption with a slope of alpha=-1.09 +/- 0.07 in the dN_{cluster}/dt ~ t^{alpha} relation. In addition, comparison to theoretical single stellar population models suggests the presence of an age-metallicity relation among these clusters with younger clusters being more metal-rich. Analysis of the radial distribution of the clusters yields some evidence that younger clusters (age <~ 1 Gyr) may be more concentrated toward the center of M33 than older ones. A similar comparison with the radial profile of the M33 field stars shows the clusters to be more centrally concentrated at the greater than 99.9% confidence level. Possible reasons for this are presented and discussed; however, the overwhelming conclusion seems to be that a more complete and thorough cluster search is needed covering at least 4 square degrees centered on M33. ", "machine_text": "  We present a catalog of 1,722 star cluster candidates in M33, based on an analysis of two sets of images obtained with the Hubble Space Telescope. The first set of images was obtained with the Wide Field and Planetary Camera (WFPC) in 1998, and the second with the Advanced Camera for Surveys (ACS) in 2004. The catalog contains 898 new cluster candidates, which more than doubles the number of known star clusters in M33. We describe a statistical method for identifying star clusters in color-magnitude diagrams. The method makes use of the fact that clusters are composed of stars that are approximately the same age, and therefore have similar colors and magnitudes. We apply this method to the two sets of HST images, and combine the results to produce our catalog of star cluster candidates. The new catalog shows a preference for clusters with intermediate ages, between 3 and 10 billion years. We also present a new algorithm for estimating the star formation rate in M33, based on the star cluster candidates and an updated estimate of the stellar mass of the galaxy. The estimated star formation rate is 11 \u00b1 3 per cent per year, with a total current mass of 1.5 \u00b1 0.5 x 1011  M\u2299. This represents a major increase over previous estimates, and suggests that M33 is still a site of active star formation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nature of phase transition in magnetic thin films. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4044, "human_text": "  We study the critical behavior of magnetic thin films as a function of the film thickness. We use the ferromagnetic Ising model with the high-resolution multiple histogram Monte Carlo (MC) simulation. We show that though the 2D behavior remains dominant at small thicknesses, there is a systematic continuous deviation of the critical exponents from their 2D values. We observe that in the same range of varying thickness the deviation of the exponent $\\nu$ is very small from its 2D value, while exponent $\\beta$ suffers a larger deviation. Moreover, as long as the film thickness is fixed, i. e. no finite size scaling is done in the $z$ direction perpendicular to the film, the 3D values of the critical exponents cannot be attained even with very large (but fixed) thickness. The crossover to 3D universality class cannot therefore take place without finite size scaling applied in the $z$ direction, in the limit of numerically accessible thicknesses. From values of exponent $\\alpha$ obtained by MC, we estimate the effective dimension of the system. We conclude that with regard to the critical behavior, thin films behave as systems with effective dimension between 2 and 3. ", "machine_text": " We present an analytical model that reveals the nature of phase transition in magnetic thin films, especially in those with a perpendicular magnetic anisotropy. Our approach is based on a systematic variation of the ratio of the in-plane and out-of-plane magnetic permeabilities in the thermodynamic equilibrium state of the nanoscale magnetic films. We show that the resulting phase diagram has a unique meta-stable phase, in which the magnetization is entirely oriented out of the film plane, and a stable phase, in which the magnetization is either entirely in-plane or has a component in-plane. Our model makes quantitative predictions for the magnetic properties of the nanoscale films in the meta-stable phase, which can be tested with existing experimental data. In particular, our model predicts a non-monotonic behavior of the in-plane magnetization as a function of the thickness of the magnetic thin film, in contrast to the monotonically increasing in-plane magnetization as a function of the film thickness predicted by the standard theory. Our model also predicts the existence of a critical thickness of the magnetic film, below which the out-of-plane magnetization becomes completely impossible.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonequilibrium quantum-impurities: from entropy production to   information theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4479, "human_text": "  Nonequilibrium steady-state currents, unlike their equilibrium counterparts, continuously dissipate energy into their physical surroundings leading to entropy production and time-reversal symmetry breaking. This letter discusses these issues in the context of quantum impurity models driven out of equilibrium by attaching the impurity to leads at different chemical potentials and temperatures. We start by pointing out that entropy production is often hidden in traditional treatments of quantum-impurity models. We then use simple thermodynamic arguments to define the rate of entropy production. Using the scattering framework recently developed by the authors we show that the rate of entropy production has a simple information theoretic interpretation in terms of the Shannon entropy and Kullback-Leibler divergence of nonequilibrium distribution function. This allows us to show that the entropy production is strictly positive for any nonequilibrium steady-state. We conclude by applying these ideas to the Resonance Level Model and the Kondo model. ", "machine_text": "  We investigate the nonequilibrium dynamics of a general class of quantum impurities whose symmetry is broken by an external drive. We show that such systems exhibit rich non-equilibrium physics, including non-Equilibrium Phase Transitions (NEPTs), nonequilibrium criticality, and memory-like dynamics, which can be understood by studying the relation between the rate of entropy production and the information theory developed for these systems. In particular, we show that the excess of entropy production over the equilibrium value is related to the violation of the Second Law of Thermodynamics for a general class of quantum systems, and that it is equal to the information produced by an observer performing a nonequilibrium measurement on the system. We also show that an analogue of the Jarzynski equality holds for nonequilibrium systems, relating the rate of entropy production to the probability distribution of the states visited by the system. We discuss the relation between our results and the recently introduced concept of Griffiths phases, and the role of the detection process in the interpretation of nonequilibrium information.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Optimal Occulter Design for Finding Extrasolar Planets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3488, "human_text": "  One proposed method for finding terrestrial planets around nearby stars is to use two spacecraft--a telescope and a specially shaped occulter that is specifically designed to prevent all but a tiny fraction of the starlight from diffracting into the telescope. As the cost and observing cadence for such a mission will be driven largely by the separation between the two spacecraft, it is critically important to design an occulter that can meet the observing goals while flying as close to the telescope as possible. In this paper, we explore this tradeoff between separation and occulter diameter. More specifically, we present a method for designing the shape of the outer edge of an occulter that is as small as possible and gives a shadow that is deep enough and large enough for a 4m telescope to survey the habitable zones of many stars for Earth-like planets. In particular, we show that in order for a 4m telescope to detect in broadband visible light a planet 0.06 arcseconds from a star shining $10^{10}$ times brighter than the planet requires a specially-shaped occulter 50m in diameter positioned about $72,000$ km in front of the telescope. ", "machine_text": "  We present an optimal occulter design strategy for finding extrasolar planets. Our method is based on the use of a thin circular occulter, placed at the optimal distance from the target star to maximize the contrast between the star and the sky background. Our analysis includes the effect of diffraction around the occulter, and we evaluate the optimal diameter for a given distance. We also take into account the required precision in the radial direction, as well as the effect of proper motion of the star, in order to derive the optimal observing strategy. The method is evaluated using a model of the region around the solar system, and applying different criteria in terms of probability of detection and number of planets to be detected. We also derive a simple formula for the optimal occulter area, which depends only on the stellar radius and the distance to the star. Our analysis indicates that a rather large occulter is required to achieve a high probability of detection, and that a distance in the range of 10-100 pc is optimal to find small extrasolar planets around solar-type stars.  We also present a design for a thin occulter which can be used for the optimal occulter strategy, and which can be built using current technology. The occulter design consists of a thin foil which is deformed by a set of internal pressure gradients, so that the desired shape is obtained without the need of any internal structure. We analyze the required pressure, and the optimal pressure distribution to obtain a good approximation to a thin occulter, and we evaluate the effect of different foil materials. Our analysis shows that a foil with a thickness in the range of 10-100 microns is sufficient to withstand the required pressure. We also analyze the effect of the occulter color on the detection probability, and we derive a simple relation between the color and the optimal occulter area.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Measuring the Decoherence of a Quantronium Qubit with the Cavity   Bifurcation Amplifier. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0765, "human_text": "  Dispersive readouts for superconducting qubits have the advantage of speed and minimal invasiveness. We have developed such an amplifier, the Cavity Bifurcation Amplifier (CBA) [10], and applied it to the readout of the quantronium qubit [2]. It consists of a Josephson junction embedded in a microwave on-chip resonator. In contrast with the Josephson bifurcation amplifier [17], which has an on-chip capacitor shunting a junction, the resonator is based on a simple coplanar waveguide imposing a pre-determined frequency and whose other RF characteristics like the quality factor are easily controlled and optimized. Under proper microwave irradiation conditions, the CBA has two metastable states. Which state is adopted by the CBA depends on the state of a quantronium qubit coupled to the CBA's junction. Due to the MHz repetition rate and large signal to noise ratio we can show directly that the coherence is limited by 1/f gate charge noise when biased at the sweet spot - a point insensitive to first order gate charge fluctuations. This architecture lends itself to scalable quantum computing using a multi-resonator chip with multiplexed readouts. ", "machine_text": " We propose and analyze a novel scheme for measuring the decoherence time of a quirked quantum bit, or quantonium, embedded in a quantum computer. Our scheme is based on a cavity- squeezed-state generation and relies on the quirked bit being embedded in a superconducting quantum computer. We show that our scheme is applicable to a variety of quantum computers and, in particular, it is more suitable for qubit registers in which the qubit coherence time is relatively long. We derive a simple formula for the probability of success of our scheme, which depends on the structure of the quantum computer, the details of the measurement protocol, and the level of squeezing. Our scheme is robust with respect to thermal noise and detector inefficiencies, provided that the qubit coherence time is long enough. We analyze the experimental challenges of our scheme and propose several possible realizations. Our scheme is in principle independent of the particular physical system used to realize the qubit, and thus it can be applied to a variety of systems, including superconducting qubits, ion traps, and solid-state qubits.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The 3D soft X-ray cluster-AGN cross-correlation function in the ROSAT   NEP survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2285, "human_text": "  X-ray surveys facilitate investigations of the environment of AGNs. Deep Chandra observations revealed that the AGNs source surface density rises near clusters of galaxies. The natural extension of these works is the measurement of spatial clustering of AGNs around clusters and the investigation of relative biasing between active galactic nuclei and galaxies near clusters.The major aims of this work are to obtain a measurement of the correlation length of AGNs around clusters and a measure of the averaged clustering properties of a complete sample of AGNs in dense environments. We present the first measurement of the soft X-ray cluster-AGN cross-correlation function in redshift space using the data of the ROSAT-NEP survey. The survey covers 9x9 deg^2 around the North Ecliptic Pole where 442 X-ray sources were detected and almost completely spectroscopically identified. We detected a >3sigma significant clustering signal on scales s<50 h70^-1 Mpc. We performed a classical maximum-likelihood power-law fit to the data and obtained a correlation length s_0=8.7+1.2-0.3 h_70-1 Mpc and a slope gamma=1.7$^+0.2_-0.7 (1sigma errors). This is a strong evidence that AGNs are good tracers of the large scale structure of the Universe. Our data were compared to the results obtained by cross-correlating X-ray clusters and galaxies. We observe, with a large uncertainty, that the bias factor of AGN is similar to that of galaxies. ", "machine_text": " We present the 3D soft X-ray cluster-AGN cross-correlation function in the ROSAT NEP survey. We have searched the complete survey with a significance level of $3 \\sigma$ for point sources within 40 $\\mathrm{kpc}$ of a cluster, and found 703 cluster-point source pairs. We have observed a strong correlation between clusters and point sources in the same pointing, supporting the hypothesis that clusters are the dominant merger mechanism for supersymmetric black holes. The cross-correlation function was consistent with a model in which clusters and point sources are completely uncorrelated except when they are very close, where a power law Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice. relation between the cluster magnetic field and the point source radio luminosity is a good fit. We also present a search for clusters within 40 $\\mathrm{kpc}$ of an active galactic nucleus (AGN), and find that clusters are significantly correlated with radio-loud AGN (at the 2$\\sigma$ level), but not with quiet AGN. We discuss the implications of our results for the role of clusters in the formation and evolution of supersymmetric black holes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A twisted FZZ-like dual for the two-dimensional black hole. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0036, "human_text": "  We review and study the duality between string theory formulated on a curved exact background (the two dimensional black hole) and string theory in flat space with a tachyon-like potential. We generalize previous results in this subject by discussing a twisted version of the Fateev-Zamolodchikov-Zamolodchikov conjecture. This duality is shown to hold at the level of N-point correlation functions on the sphere topology, and connects tree-level string amplitudes in the Euclidean version of the 2D black hole (x time) to correlation functions in a non-linear sigma-model in flat space but in presence of a tachyon wall potential and a linear dilaton. The dual CFT corresponds to the perturbed 2D quantum gravity coupled to c<1 matter (x time), where the operator that describes the tachyon-like potential can be seen as a n=2 momentum mode perturbation, while the usual sine-Liouville operator would correspond to the vortex sector n =1. We show how the sine-Liouville interaction term arises through a twisting of the marginal deformation introduced here, and discuss such 'twisting' as a non-trivial realization of the symmetries of the theory. After briefly reviewing the computation of correlation functions in sine-Liouville CFT, we give a precise prescription for computing correlation functions in the twisted model. To show the new version of the correspondence we make use of a formula recently proven by S. Ribault and J. Teschner, which connects the correlation functions in the Wess-Zumino-Witten theory to correlation functions in the Liouville theory. Conversely, the duality discussed here can be thought of as a free field realization of such remarkable formula. ", "machine_text": "  We consider the duality between the two-dimensional black hole and the electromagnetic field in a strong magnetic field, which is a generalization of the well-known Fock-Zakota-Zurek (FZZ) duality to the case of a cylindrical black hole. The duality is related to the analog of the Euler-Heisenberg pendant group in the presence of a non-Abelian group symmetry. The motivation for the research is to explore the boundaries of the original FZZ-duality in the framework of the current theory, in the case of a non-rotating black hole with a mirror symmetry in the axial direction. We show that the structure of the resulting duality is similar to that of the original FZZ-duality in some aspects, but different in others. In particular, we find that the two-dimensional black hole has a twisted FZZ-like dual, which consists of a pair of surface modes living on the boundary of the two-dimensional black hole, and the bulk structure of this dual is related to the \"twisted\" bulk of the original FZZ-duality. We show that the twist angle of this dual is proportional to the golden angle. The problem this work attempts to solve is to find a generalization of the FZZ-duality to the case of a cylindrical black hole, which is motivated by the recent progress in the study of black holes with a non-Abelian group symmetry. The practical application of this work is in the field of quantum information theory, where the FZZ-duality is used to study the complexity of quantum computation with black holes. The theoretical application of this work is in the field of quantum gravity, where the FZZ-duality is used to study the relationship between the two-dimensional black hole and the electromagnetic field in a strong magnetic field.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Flame Evolution During Type Ia Supernovae and the Deflagration Phase in   the Gravitationally Confined Detonation Scenario. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1094, "human_text": "  We develop an improved method for tracking the nuclear flame during the deflagration phase of a Type Ia supernova, and apply it to study the variation in outcomes expected from the gravitationally confined detonation (GCD) paradigm. A simplified 3-stage burning model and a non-static ash state are integrated with an artificially thickened advection-diffusion-reaction (ADR) flame front in order to provide an accurate but highly efficient representation of the energy release and electron capture in and after the unresolvable flame. We demonstrate that both our ADR and energy release methods do not generate significant acoustic noise, as has been a problem with previous ADR-based schemes. We proceed to model aspects of the deflagration, particularly the role of buoyancy of the hot ash, and find that our methods are reasonably well-behaved with respect to numerical resolution. We show that if a detonation occurs in material swept up by the material ejected by the first rising bubble but gravitationally confined to the white dwarf (WD) surface (the GCD paradigm), the density structure of the WD at detonation is systematically correlated with the distance of the deflagration ignition point from the center of the star. Coupled to a suitably stochastic ignition process, this correlation may provide a plausible explanation for the variety of nickel masses seen in Type Ia Supernovae. ", "machine_text": " We present a systematic study of the temporal evolution of the photospheric flames in 37 Type Ia supernovae (SNe) observed by the Hubble Space Telescope, in an attempt to understand the physical mechanisms that drive the different observed flame morphologies. We find that a large fraction (72%) of SNe display a flame structure characterized by a rapid initial expansion followed by a slow expansion or quiescence, which is often associated with the ejection of matter in the form of a jet. The properties of the quiescent phase, such as the flame size and temperature, are consistent with the burning of the Si-burning shell, and suggest that the energy injection from the radioactive decay of 44Ti is not sufficient to drive the flame, at least in the cases we consider. We argue that the rapid expansion of the flame observed in many SNe is likely to be driven by the combustion of hydrogen in an inner layer, and that this combustion stops once the hydrogen is exhausted. The ejection of matter that is often associated with the quiescence of the flame probably results from the violent mixing that takes place in the immediate surroundings of the burnt-out Si shell. We also present detailed numerical simulations of the flame evolution in the gravitationally confined detonation scenario, and show that the agreement with observations is poor. We conclude that this scenario is unable to explain the wide range of observations, and that the true nature of the Type Ia SN mechanism remains unknown.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modelling diffusional transport in the interphase cell nucleus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3551, "human_text": "  In this paper a lattice model for diffusional transport of particles in the interphase cell nucleus is proposed. Dense networks of chromatin fibers are created by three different methods: randomly distributed, non-interconnected obstacles, a random walk chain model, and a self avoiding random walk chain model with persistence length. By comparing a discrete and a continuous version of the random walk chain model, we demonstrate that lattice discretization does not alter particle diffusion. The influence of the 3D geometry of the fiber network on the particle diffusion is investigated in detail, while varying occupation volume, chain length, persistence length and walker size. It is shown that adjacency of the monomers, the excluded volume effect incorporated in the self avoiding random walk model, and, to a lesser extent, the persistence length, affect particle diffusion. It is demonstrated how the introduction of the effective chain occupancy, which is a convolution of the geometric chain volume with the walker size, eliminates the conformational effects of the network on the diffusion, i.e., when plotting the diffusion coefficient as a function of the effective chain volume, the data fall onto a master curve. ", "machine_text": "  We present a new finite element model for simulating diffusion in the interphase cell nucleus. Our motivation is to provide a better understanding of the role of intranuclear organization in the regulation of gene expression. We consider a simplified model in which the nucleus is described as a periodic structure of chromatin fiber bundles, which are assumed to be idealized as cylinders. We model the diffusion within the cylinders by a Fick-like equation, and account for the anisotropy of the inter-cylinder space by a relationship that ensures the conservation of flux. We investigate the effect of the porosity and the thickness of the fiber bundles on the effective diffusion coefficients, and study the behavior of the model in the limit of small bundle thickness. We find that the model is capable of describing several features of interphase nuclei, including the observed dependence of the effective diffusion coefficient on the volume fraction of the fiber bundles and the presence of a clear-up regime for the mean intensity of the gene expression signal above a characteristic concentration.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Improving Stellar and Planetary Parameters of Transiting Planet Systems:   The Case of TrES-2. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2938, "human_text": "  We report on a spectroscopic determination of the atmospheric parameters and chemical abundance of the parent star of the recently discovered transiting planet {TrES-2}. A detailed LTE analysis of a set of \\ion{Fe}{1} and \\ion{Fe}{2} lines from our Keck spectra yields $T_\\mathrm{eff} = 5850\\pm 50$ K, $\\log g = 4.4\\pm 0.1$, and [Fe/H] $= -0.15\\pm 0.10$. Several independent checks (e.g., additional spectroscopy, line-depth ratios) confirm the reliability of our spectroscopic $T_\\mathrm{eff}$ estimate. The mass and radius of the star, needed to determine the properties of the planet, are traditionally inferred by comparison with stellar evolution models using $T_\\mathrm{eff}$ and some measure of the stellar luminosity, such as the spectroscopic surface gravity (when a trigonometric parallax is unavailable, as in this case). We apply here a new method in which we use instead of $\\log g$ the normalized separation $a/R_\\star$ (related to the stellar density), which can be determined directly from the light curves of transiting planets with much greater precision. With the $a/R_\\star$ value from the light curve analysis of Holman et al. \\citeyearpar{holman07b} and our $T_\\mathrm{eff}$ estimate we obtain $M_\\star = 0.980\\pm0.062 M_\\odot$ and $R_\\star = 1.000_{-0.033}^{+0.036} R_\\odot$, and an evolutionary age of $5.1^{+2.7}_{-2.3}$ Gyr, in good agreement with other constraints based on the strength of the emission in the \\ion{Ca}{2} H & K line cores, the Lithium abundance, and rotation. The new stellar parameters yield improved values for the planetary mass and radius of $M_p = 1.198 \\pm 0.053 M_\\mathrm{Jup}$ and $R_p = 1.220^{+0.045}_{-0.042} R_\\mathrm{Jup}$, confirming that {TrES-2} is the most massive among the currently known nearby ($d\\lesssim 300$ pc) transiting hot Jupiters. [Abridged] ", "machine_text": " We present an analysis of high-precision photometric and spectroscopic observations of the transiting extrasolar planet system TrES-2. We find that the system contains two giant planets with radii R \u22c5 m, and m. We also determine the density of both planets to be \u03c1 \u22c5 kg m\u22123. These parameters are consistent with a pure hydrogen atmosphere for both planets, which implies a significant improvement in the atmospheric model compared to previous estimates. We find that the giant planet with the longer orbital period also has a higher density, suggesting that it is composed of a higher fraction of rocky material. We show that both giant planets have significant atmospheric temperature differences between the lit and unlit sides, which implies a large heat capacity. This could be indicative of a significant magnetic field, although this would be in conflict with the low magnetic field strength measured for the host star. Alternatively, this could be due to the giants' large heat capacity, which may be a result of their high density and thus a significant fraction of rocky material. We discuss this system in the context of known transiting giant planets, and the implications for the measurement of the atmospheric and radiative properties of these systems.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Orbital-Free Density Functional Theory: Kinetic Potentials and Ab-Initio   Local Pseudopotentials. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1878, "human_text": "  In the density functional (DF) theory of Kohn and Sham, the kinetic energy of the ground state of a system of noninteracting electrons in a general external field is calculated using a set of orbitals. Orbital free methods attempt to calculate this directly from the electron density by approximating the universal but unknown kinetic energy density functional. However simple local approximations are inaccurate and it has proved very difficult to devise generally accurate nonlocal approximations. We focus instead on the kinetic potential, the functional derivative of the kinetic energy DF, which appears in the Euler equation for the electron density. We argue that the kinetic potential is more local and more amenable to simple physically motivated approximations in many relevant cases, and describe two pathways by which the value of the kinetic energy can be efficiently calculated. We propose two nonlocal orbital free kinetic potentials that reduce to known exact forms for both slowly varying and rapidly varying perturbations and also reproduce exact results for the linear response of the density of the homogeneous system to small perturbations. A simple and systematic approach for generating accurate and weak ab-initio local pseudopotentials which produce a smooth slowly varying valence component of the electron density is proposed for use in orbital free DF calculations of molecules and solids. The use of these local pseudopotentials further minimizes the possible errors from the kinetic potentials. Our theory yields results for the total energies and ionization energies of atoms, and for the shell structure in the atomic radial density profiles that are in very good agreement with calculations using the full Kohn-Sham theory. ", "machine_text": " We present orbital-free density functional theory (OFDFT) methods that combine exact kinetic energies with local pseudopotential orbitals to accurately and efficiently describe the electronic structure of transition metal complexes. The kinetic energies are constructed from a parameterization of the Overbach-Gessner-Mehl-Deisenroth (OGMD) functional that is fitted to ab initio data for a large number of benchmark complexes. This parameterization is then used to calculate the kinetic energy for any complex that can be described by a small number of local pseudoatoms. The methods are applied to the calculation of excited states and other properties of several benchmark complexes, and the results are compared to those obtained with the corresponding exact ab initio methods. We also describe a strategy for including correlated orbitals in OFDFT calculations, by means of a mapping of theOGMDfunctional into a series of basis functions that can be evaluated rapidly. This approach is tested on the benchmark systems Morokite and Florescence, and the results are in good agreement with those obtained from full ab initio calculations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ratios of star cluster core and half-mass radii: a cautionary note on   intermediate-mass black holes in star clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0748, "human_text": "  There is currently much interest in the possible presence of intermediate-mass black holes in the cores of globular clusters. Based on theoretical arguments and simulation results it has previously been suggested that a large core radius -- or particularly a large ratio of the core radius to half-mass radius -- is a promising indicator for finding such a black hole in a star cluster. In this study N-body models of 100000 stars with and without primordial binaries are used to investigate the long-term structural evolution of star clusters. Importantly, the simulation data is analysed using the same processes by which structural parameters are extracted from observed star clusters. This gives a ratio of the core and half-mass (or half-light) radii that is directly comparable to the Galactic globular cluster sample. As a result, it is shown that the ratios observed for the bulk of this sample can be explained without the need for an intermediate-mass black hole. Furthermore, it is possible that clusters with large core to half-light radius ratios harbour a black-hole binary (comprised of stellar mass black holes) rather than a single massive black hole. This work does not rule out the existence of intermediate-mass black holes in the cores of at least some star clusters. ", "machine_text": "  We consider the problem of an intermediate-mass black hole (IMBH) in a star cluster. We derive a simple expression for the core radius of the cluster as a function of the IMBH mass, which can be used to constrain the IMBH mass if the core radius is known. We show that this constraint is not tight for clusters with a low mass, and can be significantly relaxed if the IMBH is accompanied by a significant baryonic mass, for example in the form of a companion. We then consider the special case of a system with a low-mass IMBH (MIMBH  \u223c 1\u201310 M\u2299) and a companion with a mass of order unity, and show that the core radius is then approximately proportional to MIMBH 2 /3. This result is independent of the nature of the companion, and holds even if the companion is a black hole. We discuss this result in the context of the recently proposed mechanism of IMBH formation in star clusters. We then consider the problem of the half-mass radius of the cluster, and show that this is not well-constrained by the mass of the IMBH if the IMBH is less massive than the baryonic mass of the cluster. We also show that the half-mass radius is not well-constrained if the IMBH is more massive than the baryonic mass of the cluster. We discuss these results in the context of the proposed mechanism for IMBH formation, and suggest that they cast significant doubt on the suggestion that IMBHs are likely to be found in star clusters.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Principal Component Analysis and Automatic Relevance Determination in   Damage Identification. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1672, "human_text": "  This paper compares two neural network input selection schemes, the Principal Component Analysis (PCA) and the Automatic Relevance Determination (ARD) based on Mac-Kay's evidence framework. The PCA takes all the input data and projects it onto a lower dimension space, thereby reduc-ing the dimension of the input space. This input reduction method often results with parameters that have significant influence on the dynamics of the data being diluted by those that do not influence the dynamics of the data. The ARD selects the most relevant input parameters and discards those that do not contribute significantly to the dynamics of the data being modelled. The ARD sometimes results with important input parameters being discarded thereby compromising the dynamics of the data. The PCA and ARD methods are implemented together with a Multi-Layer-Perceptron (MLP) network for fault identification in structures and the performance of the two methods is as-sessed. It is observed that ARD and PCA give similar accu-racy levels when used as input-selection schemes. There-fore, the choice of input-selection scheme is dependent on the nature of the data being processed. ", "machine_text": "  Damage identification is the process of determining the onset and progression of damage in engineered structures. This paper presents a data-driven damage identification approach that is based on Principal Component Analysis (PCA) and Automatic Relevance Determination (ARD). The motivation for the research is that the current approaches to damage identification are largely model-based and rely on the a priori knowledge of the damage modes. The key idea is to use the PCA to extract the features of the damage signal and ARD to identify the damage modes. The methodology is demonstrated on a simulated damage data obtained from the execution of a 3-D Finite Element Analysis. The obtained results show that the proposed approach is capable of identifying the multiple damage modes and their evolution with the number of cycles. The results also show that the use of ARD is crucial to achieve the damage identification from the PCA features. The problem that the work attempts to solve is that the conventional damage identification approaches rely on the a priori knowledge of the damage modes. The practical application of the research is that the proposed approach can be used for the health monitoring and remaining useful life prediction of the engineered structures. The theoretical application of the research is that the proposed approach extends the data-driven damage identification to the case of the multiple damage modes and it provides a theoretical basis for the design of the damage detection algorithms.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Monoid generalizations of the Richard Thompson groups. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0189, "human_text": "  The groups G_{k,1} of Richard Thompson and Graham Higman can be generalized in a natural way to monoids, that we call M_{k,1}, and to inverse monoids, called Inv_{k,1}; this is done by simply generalizing bijections to partial functions or partial injective functions. The monoids M_{k,1} have connections with circuit complexity (studied in another paper). Here we prove that M_{k,1} and Inv_{k,1} are congruence-simple for all k. Their Green relations J and D are characterized: M_{k,1} and Inv_{k,1} are J-0-simple, and they have k-1 non-zero D-classes. They are submonoids of the multiplicative part of the Cuntz algebra O_k. They are finitely generated, and their word problem over any finite generating set is in P. Their word problem is coNP-complete over certain infinite generating sets.   Changes in this version: Section 4 has been thoroughly revised, and errors have been corrected; however, the main results of Section 4 do not change. Sections 1, 2, and 3 are unchanged, except for the proof of Theorem 2.3, which was incomplete; a complete proof was published in the Appendix of reference [6], and is also given here. ", "machine_text": "  We consider monoid generalizations of the Richard Thompson groups, that is, groups $G$ with a set of generators $\\mathcal S$ and a map $\\alpha$ of the set $\\mathcal S$ to itself such that for all $s$, $t$, and $u$ in $\\mathcal S$, the following properties hold: (1) $\\alpha(s)$ and $\\alpha(t)$ commute with $u$; (2) $\\alpha(st)$ and $\\alpha(ts)$ are equal to $\\alpha(s)$ and $\\alpha(t)$, respectively; and (3) $\\alpha(s^m)$ is equal to $\\alpha(s)^m$ for all $m$ and all $s$ in $\\mathcal S$. We show that if $\\mathcal S$ is any monoid, the map $\\alpha$ is a homomorphism if and only if $\\mathcal S$ is a group. We then consider the case in which $\\mathcal S$ is the set of all monomials in $\\mathbb C[x]$ of degree $\\leqslant n$ and $\\alpha$ is the map that takes $s$ to $xs$. This leads to the concept of a monoid polytope, a generalization of the polytope associated with a finite semigroups. We show that a monoid polytope is the convex hull of a set of points in $\\mathbb C^n$ and that it is always a simplicial complex. We also show that every simplicial complex is the convex hull of a set of points in $\\mathbb C^n$, and hence that every simplicial complex is a monoid polytope.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Interplay between thermal percolation and jamming upon dimer adsorption   on binary alloys. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0562, "human_text": "  Using Monte Carlo simulations we study jamming and percolation processes upon the random sequential adsorption of dimers on binary alloys with different degrees of structural order. We obtain the equimolar mixtures used as substrates by applying the isomorphism between an alloy and the Ising model (conserved order parameter). The annealing temperature $T$ of the mixture then is a continuous parameter that characterizes the different sets of substrates, shaping the deposition process. As the alloy undergoes an order-disorder phase transition at the Onsager critical temperature ($T_{c}$), the jamming and percolating properties of the dimers deposited over the substrate are subjected to non-trivial changes. These are reflected in a density-temperature phase diagram with three well-defined regions. We find that for $T < T^* = 1.22 T_{c}$ the occurrence of jamming prevents the onset of percolating clusters, while percolation is possible for $T > T^{*}$. Particular attention is focused close to $T^{*}$, where the interplay between jamming and percolation restricts fluctuations, forcing exponents seemingly different from the standard percolation universality class. By analogy with a thermal transition, we study the onset of percolation by using the {\\it temperature} (in this case, the substrate annealing temperature) as a control parameter. By proposing thermal scaling Ansatzes we analyze the behavior of the percolation threshold and its thermally induced fluctuations. Also, the fractal dimension of the percolating cluster is determined. Based on these measurements and the excellent data collapsing, we conclude that the universality class of standard percolation is preserved for all temperatures. ", "machine_text": " We study the interplay between thermal percolation and jamming upon dimer adsorption on binary alloys. We consider a two-dimensional (2D) suspension of hard disk-shaped particles with a small attractive interaction between the adsorbates and the substrate. We find that the coverage-dependent transition temperature between the disordered liquid-like and the ordered solid-like phases is modified by the shape of the adsorbates. For a dimer with a strong preference for a particular orientation, the transition temperature is increased by a strong surface roughness, but it is decreased by a weak one. For a dimer with a weak preference for a particular orientation, the transition temperature is increased by both strong and weak surface roughness. We explain the results by a careful analysis of the corresponding percolation models. Our work suggests that the preference of a given adsorbate for a particular orientation is important in determining the nature of the disordered phase below the glass transition temperature.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Link concordance, homology cobordism, and Hirzebruch-type defects from   iterated p-covers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0088, "human_text": "  We obtain new invariants of topological link concordance and homology cobordism of 3-manifolds from Hirzebruch-type intersection form defects of towers of iterated p-covers. Our invariants can extract geometric information from an arbitrary depth of the derived series of the fundamental group, and can detect torsion which is invisible via signature invariants. Applications illustrating these features include the following: (1) There are infinitely many homology equivalent rational 3-spheres which are indistinguishable via multisignatures, eta-invariants, and L2-signatures but have distinct homology cobordism types. (2) There is an infinite family of 2-torsion (amphichiral) knots, including the figure eight knot, with non-slice iterated Bing doubles; as a special case, we give the first proof of the conjecture that the Bing double of the figure eight knot is not slice. (3) There exist infinitely many torsion elements at any depth of the Cochran-Orr-Teichner filtration of link concordance. ", "machine_text": " We establish a relationship between iterated p-covers, link concordance, homology cobordism, and Hirzebruch-type defects on 3- and 4-dimensional spheres. We show that a link L is concordant with a link M if and only if there exists an iterated p-cover of M which is isomorphic to the quotient of an iterated p-cover of L by the action of a subgroup of the fundamental group of M. We use this relationship to give a description of the concordance class of certain links in terms of iterated p-covers. We show that a link L is contained in the boundary of a writhe two disc if and only if there exists an iterated p-cover of the 3-sphere which is isomorphic to the quotient of an iterated p-cover of the link L by the action of a subgroup of the fundamental group of the 3-sphere. We show that a link L is contained in the boundary of an open writhe two disc if and only if there exists an iterated p-cover of the 4-sphere which is isomorphic to the quotient of an iterated p-cover of the link L by the action of a subgroup of the fundamental group of the 4-sphere. We show that a link L is contained in the boundary of a closed writhe two disc if and only if there exists an iterated p-cover of the 3-sphere which is isomorphic to the quotient of an iterated p-cover of the link L by the action of a subgroup of the fundamental group of the 3-sphere. We show that a link L is contained in the boundary of a closed writhe three disc if and only if there exists an iterated p-cover of the 4-sphere which is isomorphic to the quotient of an iterated p-cover of the link L by the action of a subgroup of the fundamental group of the 4-sphere.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Studies of Cosmic Rays with GeV Gamma Rays. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1524, "human_text": "  We describe the role of GeV gamma-ray observations with GLAST-LAT (Gamma-ray Large Area Space Telescope - Large Area Telescope) in identifying interaction sites of cosmic-ray proton (or hadrons) with interstellar medium (ISM). We expect to detect gamma rays from neutral pion decays in high-density ISM regions in the Galaxy, Large Magellanic Cloud, and other satellite galaxies. These gamma-ray sources have been detected already with EGRET (Energetic Gamma Ray Experiment Telescope) as extended sources (eg. LMC and Orion clouds) and GLAST-LAT will detect many more with a higher spatial resolution and in a wider spectral range. We have developed a novel image restoration technique based on the Richardson-Lucy algorithm optimized for GLAST-LAT observation of extended sources. Our algorithm calculates PSF (point spread function) for each event. This step is very important for GLAST-LAT and EGRET image analysis since PSF varies more than one order of magnitude from one gamma ray to another depending on its energy as well as its impact point and angle in the instrument. The GLAST-LAT and EGRET image analysis has to cope with Poisson fluctuation due to low number of detected photons for most sources. Our technique incorporates wavelet filtering to minimize effects due to the fluctuation. Preliminary studies on some EGRET sources are presented, which shows potential of this novel image restoration technique for the identification and characterisation of extended gamma-ray sources. ", "machine_text": " We present here results of a systematic study of the correlation between cosmic rays and gamma rays in the energy range above 100 GeV. We have developed a new method which enables us to measure with a high statistical significance the correlation between the cosmic ray and gamma ray fluences on a spatial scale of several tens of degrees. Our method is based on the measurement of the spectral distribution of the scattered gamma rays from the terrestrial atmosphere, which allows us to obtain the fluxes of cosmic rays and gamma rays on the ground. We found that the correlation function between the cosmic ray and gamma ray fluences has a positive peak at a correlation coefficient of about 0.6, indicating a significant correlation between these two quantities in the energy range above 100 GeV. The correlation function changes sign at a cosmic ray fluence of about 10\udbff\udc05\u00b7cm\udbff\udc05\u2079 \u00a7 6 , which corresponds to a gamma ray fluence of about 5\udbff\udc05\u00b7cm\udbff\udc05\u2079 \u00a7 2 . We explain this behavior by a simple model in which the production of secondary cosmic rays is described by a single power law with a linear dependence on the primary cosmic ray fluence. Our results suggest that the correlation between cosmic rays and gamma rays in the energy range above 100 GeV is due to a common production mechanism, i.e., hadronization of the primary cosmic rays and subsequent decays of the hadrons.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bandstructure and optical properties of $\\alpha-LiIO_{3}$ crystal. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2323, "human_text": "  The bandstructure was calculated by the full-potential linearized augmented plane wave method. The result reveals two important insights to the novel second harmonic generation (SHG) of alpha-phase lithium iodate ($\\alpha-LiIO_{3}$) crystal: the existence of finite intra-band momentum matrix elements due to the non-inversion symmetry of the crystal illuminating the potential of the intra-band transition, and the strong covalent bonding between the $I$-atoms and the ligand $O$-atoms resulting the condition of the double-resonance. An inter-band transition scenario in SHG as $\\alpha-LiIO_{3}$ in nano-structure is proposed. The optical properties were calculated within the theoretical framework of the time-dependent perturbation of the independent-particle model. The dielectric tensors and the refractive index were evaluated. Comparisons between the predictions and the results were made: the x-ray near edge absorption spectra; the refractive index at the static limit, and at finite frequencies. Possible factors attributing the calculation errors is discussed. ", "machine_text": " We have investigated the bandstructure and optical properties of $\\alpha-LiIO_{3}$ crystal. The bandstructure was calculated by using the first-principles method based on the density functional theory (DFT). We found that the $\\alpha-LiIO_{3}$ has a direct bandgap of 3.8 eV at the $J=1-0$ point in the $\\mathrm{ABAC}$ (face centered cubic) structure. The electronic structure analysis showed that the bandgap is originated from the hybridization between the $\\mathrm{O}$ and $\\mathrm{Li}$ atoms. The bandedges are slightly shifted to the $\\mathrm{Li}$ sublattice from the $\\mathrm{O}$ sublattice, which can be explained by the larger atomic number of $\\mathrm{Li}$ and the smaller atomic size compared with $\\mathrm{O}$. In addition, we found two types of dumbbell-like hole states located at the $\\mathrm{Li}$ sublattice. The optical absorption spectrum was also calculated by using the DFT method. The results showed that the absorption edge was red-shifted with respect to the bandedge, and the absorption coefficient was higher in the visible region compared with the UV region. The $\\alpha-LiIO_{3}$ crystal was found to be a promising material for photonic device applications.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The lower mass function of the young open cluster Blanco 1: from 30 Mjup   to 3 Mo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2102, "human_text": "  We performed a deep wide field optical survey of the young (~100-150 Myr) open cluster Blanco1 to study its low mass population well down into the brown dwarf regime and estimate its mass function over the whole cluster mass range.The survey covers 2.3 square degrees in the I and z-bands down to I ~ z ~ 24 with the CFH12K camera. Considering two different cluster ages (100 and 150 Myr), we selected cluster member candidates on the basis of their location in the (I,I-z) CMD relative to the isochrones, and estimated the contamination by foreground late-type field dwarfs using statistical arguments, infrared photometry and low-resolution optical spectroscopy. We find that our survey should contain about 57% of the cluster members in the 0.03-0.6 Mo mass range, including 30-40 brown dwarfs. The candidate's radial distribution presents evidence that mass segregation has already occured in the cluster. We took it into account to estimate the cluster mass function across the stellar/substellar boundary. We find that, between 0.03Mo and 0.6Mo, the cluster mass distribution does not depend much on its exact age, and is well represented by a single power-law, with an index alpha=0.69 +/- 0.15. Over the whole mass domain, from 0.03Mo to 3Mo, the mass function is better fitted by a log-normal function with m0=0.36 +/- 0.07Mo and sigma=0.58 +/- 0.06. Comparison between the Blanco1 mass function, other young open clusters' MF, and the galactic disc MF suggests that the IMF, from the substellar domain to the higher mass part, does not depend much on initial conditions. We discuss the implications of this result on theories developed to date to explain the origin of the mass distribution. ", "machine_text": "  The Lower Mass Function of the Young Open Cluster Blanco 1: from 30 Mjup to 3 Mo  We present photometric observations of the young open cluster Blanco 1 made with the Hubble Space Telescope to study the cluster's lower mass function in the mass range from 30 Mjup to 3 Mo. Our analysis shows a significant under-abundance of massive stars in Blanco 1 compared to the predictions of the linear metallicity-mass relation for star formation, particularly for stars in the range 30 < log(M/M\u2299) < 1.5. The under-abundance is even more pronounced if the corrected mass function of the solar neighbourhood is used as the benchmark, which suggests that massive stars in Blanco 1 are less massive than their main sequence turn-off mass. We also find a clear over-abundance of low-mass stars in the cluster compared to the local mass function, but this may be due to contamination from field stars. The ratio of massive stars to low-mass stars in Blanco 1 is consistent with the predictions of theinitial mass function for a cluster born with a turn-off mass of 1.4\u20131.5 M\u2299. We therefore suggest that the main mechanism responsible for the formation of massive stars in clusters is the accretion of gas onto the most massive seeds, provided that these seeds are massive enough, rather than the competitive accretion of many small seeds. The study of the low mass function of clusters is important for understanding the process of star formation in general, and particularly for testing the theory of competitive accretion.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Prospects for precision measurements of atomic helium using direct   frequency comb spectroscopy. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.343, "human_text": "  We analyze several possibilities for precisely measuring electronic transitions in atomic helium by the direct use of phase-stabilized femtosecond frequency combs. Because the comb is self-calibrating and can be shifted into the ultraviolet spectral region via harmonic generation, it offers the prospect of greatly improved accuracy for UV and far-UV transitions. To take advantage of this accuracy an ultracold helium sample is needed. For measurements of the triplet spectrum a magneto-optical trap (MOT) can be used to cool and trap metastable 2^3S state atoms. We analyze schemes for measuring the two-photon $2^3S \\to 4^3S$ interval, and for resonant two-photon excitation to high Rydberg states, $2^3S \\to 3^3P \\to n^3S,D$. We also analyze experiments on the singlet-state spectrum. To accomplish this we propose schemes for producing and trapping ultracold helium in the 1^1S or 2^1S state via intercombination transitions. A particularly intriguing scenario is the possibility of measuring the $1^1S \\to 2^1S$ transition with extremely high accuracy by use of two-photon excitation in a magic wavelength trap that operates identically for both states. We predict a ``triple magic wavelength'' at 412 nm that could facilitate numerous experiments on trapped helium atoms, because here the polarizabilities of the 1^1S, 2^1S and 2^3S states are all similar, small, and positive. ", "machine_text": " We propose and analyze a new method for precision measurements of atomic helium based on direct frequency comb spectroscopy. The method does not require the atoms to be slowed down or the light to be pulsed, and therefore it has the potential for much higher precision than the conventional methods based on optical molasses or frequency-modulated spectroscopy. We evaluate the feasibility of the method by comparing it with the conventional methods, and we analyze the influence of the various parameters on the precision that can be achieved. We show that with current technology it is possible to reach a few parts in 1011 already, and that with technology that is expected to be available in the near future a precision of a few parts in 1012 should be achievable. We also show that by using a cavity to accumulate the atoms it is possible to increase the number of atoms in the measurement by a factor of several thousand, which will bring the precision to the level of the conventional methods.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A remarkable moduli space of rank 6 vector bundles related to cubic   surfaces. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2184, "human_text": "  We study the moduli space $\\fM^s(6;3,6,4)$ of simple rank 6 vector bundles $\\E$ on $\\PP^3$ with Chern polynomial $1+3t+6t^2+4t^3$ and properties of these bundles, especially we prove some partial results concerning their stability. We first recall how these bundles are related to the construction of sextic nodal surfaces in $\\PP^3$ having an even set of 56 nodes (cf. \\cite{CaTo}). We prove that there is an open set, corresponding to the simple bundles with minimal cohomology, which is irreducible of dimension 19 and bimeromorphic to an open set $\\fA^0$ of the G.I.T. quotient space of the projective space $\\fB:=\\{B\\in \\PP(U^\\vee\\otimes W\\otimes V^\\vee)\\}$ of triple tensors of type $(3,3,4)$ by the natural action of $SL(W)\\times SL(U)$. We give several constructions for these bundles, which relate them to cubic surfaces in 3-space $\\PP^3$ and to cubic surfaces in the dual space $(\\PP^3)^{\\vee}$. One of these constructions, suggested by Igor Dolgachev, generalizes to other types of tensors. Moreover, we relate the socalled {\\em cross-product involution} for $(3,3,4)$-tensors, introduced in \\cite{CaTo}, with the Schur quadric associated to a cubic surface in $\\PP^3$ and study further properties of this involution. ", "machine_text": "  We show that the space of rank 6 vector bundles over a smooth cubic surface in $\\mathbb C^3$ is a remarkable moduli space with many special geometric and topological properties. It is shown that this moduli space is  connected, and that every line bundle is the pullback of a vector bundle. We give an algebraic description of this moduli space in terms of the perverse bilinear form on the symmetric algebra of the third fundamental group. We show that the Jacobean of the standard cubic surface over $\\mathbb C^3$ is an ample vector bundle on this moduli space, and use this to show that the symmetric algebra of the third fundamental group of this cubic surface is isomorphic to the symmetric algebra of the third fundamental group of the affine plane. We show that this is an analogue of the Casson-Bleiler algebras for cubic surfaces. We show that the geometric class field theory of this moduli space is isomorphic to the topological class field theory of the symmetric algebra of the fundamental group of this cubic surface. We show that this geometric class field theory is an analogue of the Casson-Bleiler theory of cubic surfaces. We show that the cohomology of this moduli space is related to the Casson-Bleiler cohomology of cubic surfaces.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hybrid inflation followed by modular inflation. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1436, "human_text": "  Inflationary models with a superheavy scale F-term hybrid inflation followed by an intermediate scale modular inflation are considered. The restrictions on the power spectrum P_R of curvature perturbation and the spectral index n_s from the recent data within the power-law cosmological model with cold dark matter and a cosmological constant can be met provided that the number of e-foldings N_HI* suffered by the pivot scale k_*=0.002/Mpc during hybrid inflation is suitably restricted. The additional e-foldings needed for solving the horizon and flatness problems are generated by modular inflation with a string axion as inflaton. For central values of P_R and n_s, the grand unification scale comes out, in the case of standard hybrid inflation, close to its supersymmetric value M_GUT=2.86 x 10^16 GeV, the relevant coupling constant is relatively large (0.005-0.14), and N_HI* is between 10 and 21.7. In the shifted [smooth] hybrid inflation case, the grand unification scale can be identified with M_GUT for N_HI*=21 [N_HI*=18]. ", "machine_text": " We study a hybrid inflation model with both a non-standard and a standard component. The non-standard component is a flexible geometric series, whereas the standard component is an elegant modular inflation model which allows for a simple qualitative explanation of the origin of the universal Gerbera SIMA plot. The model can be used to generate an infinite number of inflationary epochs with different growth rates and duration. This can be used to generate data for statistical analysis of inflationary periods. We generate random data and analyze the resulting inflationary periods in terms of the average duration and the total amount of inflation. We show that the data is consistent with the existence of a unique threshold value for the non-standard component which separates periods of high inflation from periods of low inflation. We analyze the data in terms of a simple functional relationship between the inflation rate and the duration of the inflationary period. The resulting functional form is consistent with a threshold value for the inflation rate which separates high inflation from low inflation. We also show that the standard component can be used to explain the origin of the universal Gerbera SIMA plot.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Synergistic Effects of MoDTC and ZDTP on Frictional Behaviour of   Tribofilms at the Nanometer Scale. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0338, "human_text": "  The layered structure and the rheological properties of anti-wear films, generated in a rolling/sliding contact from lubricants containing zinc dialkyldithiophosphate (ZDTP) and/or molybdenum dialkyldithiocarbamate (MoDTC) additives, have been studied by dynamic nanoindentation experiments coupled with a simple modelling of the stiffness measurements. Local nano-friction experiments were conducted with the same device in order to determine the evolution of the friction coefficient as a function of the applied pressure for the different lubricant formulations. For the MoDTC film, the applied pressure in the friction test remains low (<0.5 GPa) and the apparent friction coefficient is high ($\\mu$ > 0.4). For the tribofilms containing MoDTC together with ZDTP, which permits the applied pressure to increase up to a few GPa through some accommodation process, a very low friction domain appears (0.01 < $\\mu$ < 0.05), located a few nanometers below the surface of the tribofilm. This low friction coefficient is attributed to the presence of MoS2 planes sliding over each other in a favourable configuration obtained when the pressure is sufficiently high, which is made possible by the presence of ZDTP. ", "machine_text": "  We have investigated the effect of MoDTC and ZDDP additives on the tribofilm formation and friction behaviour of fully dense ZrO2-based ceramics. The results show that the friction coefficient decreases with the increase of the number of sliding cycles for all the additives, but the magnitude of the friction coefficient varies with the type of additive. The friction coefficient values for MoDTC- and ZDDP-added ZrO2-based ceramics are 0.07 and 0.11, respectively, after one million sliding cycles. The images of the worn surfaces after one million sliding cycles show that the tribofilm formed with MoDTC is composed of spherical particles, while the tribofilm formed with ZDDP is a layer of amorphous material. The thicknesses of the tribofilms formed with MoDTC and ZDDP are 100 and 400 nm, respectively. The results reveal that the synergistic effects of MoDTC and ZDDP additives on the tribofilm formation and friction behaviour of ZrO2-based ceramics are mainly attributed to the formation of MoS2 and ZrS2 particles, respectively.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmic Evolution of Black Holes and Spheroids. II: Scaling Relations at   z=0.36. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0519, "human_text": "  We combine Hubble Space Telescope images of a sample of 20 Seyfert galaxies at z=0.36 with spectroscopic information from the Keck Telescope to determine the black hole mass - spheroid luminosity relation (M-L), the Fundamental Plane (FP) of the host galaxies and the M-sigma relation. Assuming pure luminosity evolution, we find that the host spheroids had smaller luminosity and stellar velocity dispersion than today for a fixed M. The offsets correspond to Delta log L_B,0=0.40+-0.11+-0.15 (Delta log M = 0.51+-0.14+-0.19) and Delta log sigma = 0.13+-0.03+-0.05 (Delta log M = 0.54+-0.12+-0.21), respectively for the M-L and M-sigma relation. A detailed analysis of known systematic errors and selection effects shows that they cannot account for the observed offset. The data are inconsistent with pure luminosity evolution and the existence of universal and tight scaling relations. To obey the three local scaling relations by z=0 the distant spheroids have to grow their stellar mass by approximately 60% (\\Delta log M_sph=0.20+-0.14) in the next 4 billion years. The measured evolution can be expressed as M/ M_sph ~ (1+z)^{1.5+-1.0}. Based on the disturbed morphologies of a fraction of the sample (6/20) we suggest collisional mergers with disk-dominated systems as evolutionary mechanism. ", "machine_text": " We have carried out a scaling analysis of the distribution of black holes and spheroids in the Cosmic Evolution Survey (CES) at z=0.36, using the Automatically Generated Cosmological Traverse (AGCT) method. We show that the masses of black holes and spheroids are in good agreement with a cosmological model in which the galaxies are taken to evolve from a state of small scale structure at high redshift to a state of large scale structure at low redshift, with a gradual increase of scale in between. We have investigated two different assumptions for the evolution of the number density of black holes and spheroids, and found that the shape of the distribution is consistent with a single power law increasing from high to low redshift, with a small but non-zero value of the power law index. The analysis of the correlation functions shows that the large scale structure in the black hole and spheroid distribution is described by a single power law correlation function, with a value of the power law index that is consistent with the one obtained in the analysis of the mass function. We have also found that the correlation functions of black holes and spheroids are consistent with a simple model in which galaxies evolve from small scale structure to large scale structure, while the distribution of black holes and spheroids in the intergalactic medium remains approximately constant. We discuss the implications of our results for the evolution of the structure of the Universe, and in particular for the problem of the formation of large scale structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Covariant Holographic Entanglement Entropy Proposal. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0016, "human_text": "  With an aim towards understanding the time-dependence of entanglement entropy in generic quantum field theories, we propose a covariant generalization of the holographic entanglement entropy proposal of hep-th/0603001. Apart from providing several examples of possible covariant generalizations, we study a particular construction based on light-sheets, motivated in similar spirit to the covariant entropy bound underlying the holographic principle. In particular, we argue that the entanglement entropy associated with a specified region on the boundary in the context of the AdS/CFT correspondence is given by the area of a co-dimension two bulk surface with vanishing expansions of null geodesics. We demonstrate our construction with several examples to illustrate its reduction to the holographic entanglement entropy proposal in static spacetimes. We further show how this proposal may be used to understand the time evolution of entanglement entropy in a time varying QFT state dual to a collapsing black hole background. Finally, we use our proposal to argue that the Euclidean wormhole geometries with multiple boundaries should be regarded as states in a non-interacting but entangled set of QFTs, one associated to each boundary. ", "machine_text": " We propose a covariant holographic entanglement entropy proposal for a general framework of holography with one space-like dimension and one time-like dimension, which are the prerequisites to achieve the notion of the contingency of quantum theory and the Gibson-Ma particle-like nature of quantum information. We show that this proposal circumvents the three well-known paradoxes of quantum information (the EPSR, PBR, and multi-particle paradoxes), thereby providing a solution to the well-posed problem of how the information about a quantum state can be cloned without entanglement. The proposed general framework of holography also provides a solution to the non-well-posed problem of how to create an exact replica of a quantum state by entanglement, without the need to consider a particular basis of the quantum state. We show that the proposed framework of holography is consistent with the general framework of de Broglie-Bohm theory. We also show that it predicts the possibility of faster-than-light communication and the possibility of using entanglement to create an exact replica of a quantum state.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Virtual Photon Emission from Quark-Gluon Plasma. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3676, "human_text": "  We recently proposed an empirical approach for the Landau-Pomeranchuk-Migdal (LPM) effects in photon emission from the quark gluon plasma as a function of photon mass. This approach was based on Generalized Emission Functions (GEF) for photon emission, derived at a fixed temperature and strong coupling constant. In the present work, we have extended the LPM calculations for several temperatures and strong coupling strengths. The integral equations for (${\\bf \\tilde{f}(\\tilde{p}_\\perp)}$) and ($\\tilde{g}({\\bf \\tilde{p}_\\perp})$) are solved by the iterations method for the variable set \\{$p_0,q_0,Q^2,T,\\alpha_s$\\}, considering bremsstrahlung and $\\bf aws$ processes. We generalize the dynamical scaling variables, $x_T$, $x_L$, for bremsstrahlung and {\\bf aws} processes which are now functions of variables $p_0,q_0,Q^2,T,\\alpha_s$. The GEF introduced earlier, $g^b_T$, $g^a_T$, $g^b_L$, $g^a_L$, are also generalized for any temperatures and coupling strengths. From this, the imaginary part of the photon polarization tensor as a function of photon mass and energy can be calculated as a one dimensional integral over these GEF and parton distribution functions in the plasma. However, for phenomenological studies of experimental data, one needs a simple empirical formula without involving parton momentum integrations. Therefore, we present a phenomenological formula for imaginary photon polarization tensor as a function of \\{$q_0,Q^2,T,\\alpha_s$\\} that includes bremsstrahlung and $\\bf aws$ mechanisms along with LPM effects. ", "machine_text": " We study the emission of virtual photons from a relativistic quark-gluon plasma (QGP) and investigate the energy distribution and the production rate of these photons. We calculate the QGP photon energy distribution in the case of a perturbative QGP and find that it is wider than the one observed in heavy ion collisions. The difference is due to the larger energy spread of the virtual photon distribution in the perturbative case. The probability distribution function of the virtual photon emission process is also calculated, and a clear signature of a boost in the probability distribution is found close to the unity contribution from the virtual photon pair production. The high temperature of the QGP and the large density make the QGP photon production rate larger than the one from a hot gas by several orders of magnitude. We also study the coherent radiation of the QGP virtual photons and find that it is possible to produce a coherent radiation with the wavelength of the order of the QGP size.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Chromohydrodynamical instabilities induced by relativistic jets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1047, "human_text": "  We study the properties of the chromohydrodynamical instabilities induced by a relativistic jet that crosses the quark-gluon plasma. Assuming that the jet of particles and the plasma can be described using a hydrodynamical approach, we derive and discuss the dispersion laws for the unstable collective modes. In our analysis the chromohydrodynamical equations for the collective modes are tackled in the linear response approximation. Such an approximation, valid for short time scales, allows to study in a straightforward way the dependence of the dispersion laws of the collective modes on the velocity of the jet, on the magnitude of the momentum of the collective mode and on the angle between these two quantities. We find that unstable modes arise for velocity of the jet larger than the speed of the sound of the plasma and only modes with momenta smaller than a certain values are unstable. Moreover, for ultrarelativistic velocities of the jet the longitudinal mode becomes stable and the most unstable modes correspond to relative angles between the velocity of the jet and momentum of the collective mode larger than $\\sim \\pi/8$. Our results suggest an alternative mechanism for the description of the jet quenching phenomenon, where the jet crossing the plasma loses energy exciting colored unstable modes. ", "machine_text": " We consider the problem of stationary relativistic jets in a homogeneous and isotropic hydrogenous intergalactic medium, with no infall or outflows in the vicinity of the jet. We find that a relativistic jet can give rise to various types of chromohydrodynamic instabilities, provided that the bulk velocity of the jet is large enough. The most interesting of these is the so-called Alfv\u00e9n rotor, which is a limit cycle instability that leads to the evolution of the jet into a supersonic tornado-like structure. This instability is driven by a feedback between the bulk velocity of the jet and the bulk velocity of the ionized gas that surrounds the jet. We show that this feedback process is self-limited, and that the growth rate of the instability is inversely proportional to the thickness of the shear layer between the relativistic jet and the bulk medium. We also show that the rotor is a spherically symmetric solution, and that it therefore is axisymmetric with respect to the jet. This has important implications for the stability of the rotor, as well as for its physical interpretation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Novel phase in the phase structure of the $(g\\phi^4 + h\\phi^6)_{1+1}$   field theoretic model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1923, "human_text": "  In view of the newly discovered and physically acceptable $PT$ symmetric and non-Hermitian models, we reinvestigated the phase structure of the ($g\\phi^{4}+h\\phi^{6}$)$_{1+1}$ Hermitian model. The reinvestigation concerns the possibility of a phase transition from the original Hermitian and $PT$ symmetric phase to a non-Hermitian and $PT$ symmetric one. This kind of phase transition, if verified experimentally, will lead to the first proof that non-Hermitian and $PT$ symmetric models are not just a mathematical research framework but are a nature desire. To do the investigation, we calculated the effective potential up to second order in the couplings and found a Hermitian to Non-Hermitian phase transition. This leads us to introduce, for the first time, hermiticity as a symmetry which can be broken due to quantum corrections, \\textit{i.e.}, when starting with a model which is Hermitian in the classical level, quantum corrections can break hermiticity while the theory stays physically acceptable. In fact, ignoring this phase will lead to violation of universality when comparing this model predictions with other models in the same class of universality. For instance, in a previous work we obtained a second order phase transition for the $PT$ symmetric and non-Hermitian $(-g\\phi^{4})$ and according to universality, this phase should exist in the phase structure of the ($g\\phi^{4}+h\\phi^{6}$) model for negative $g$. Finally, among the novelties in this letter, in our calculation for the effective potential, we introduced a new renormalization group equation which describes the invariance of the bare vacuum energy under the change of the scale. We showed that without this invariance, the original theory and the effective one are inequivalent. ", "machine_text": " We study a field theoretic model which can be thought of as an expansion of the Standard Model by a sector $g\\phi^4 + h\\phi^6$ with $g,h$ real and $\\phi$ a fundamental scalar. We show that this model in the 1+1d Euclidean space has a novel phase structure which includes a distinctive naked singularity. The model has an explicit supersymmetric quantum deformation theory with a certain 1d grand canonical group $G$. We show that the model has a particularity which relates to the real structure of $G$. This relates to the recent discussion in the literature on the relationship between the real and the imaginary parts of the field theoretic model. We show that the real part of the model is invariant under a special kind of external symmetry group $G^{\\rm ext}$ which turns on in a certain range of the moduli. We show further that this real part has a special relation to the dynamics of the model and in particular to the appearance of the naked singularity. We show finally that the imaginary part of the model is related to the internal symmetry group $G^{\\rm int}$ of the model and that this internal symmetry group is related to the breaking of the external symmetry group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Network tomography based on 1-D projections. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4476, "human_text": "  Network tomography has been regarded as one of the most promising methodologies for performance evaluation and diagnosis of the massive and decentralized Internet. This paper proposes a new estimation approach for solving a class of inverse problems in network tomography, based on marginal distributions of a sequence of one-dimensional linear projections of the observed data. We give a general identifiability result for the proposed method and study the design issue of these one dimensional projections in terms of statistical efficiency. We show that for a simple Gaussian tomography model, there is an optimal set of one-dimensional projections such that the estimator obtained from these projections is asymptotically as efficient as the maximum likelihood estimator based on the joint distribution of the observed data. For practical applications, we carry out simulation studies of the proposed method for two instances of network tomography. The first is for traffic demand tomography using a Gaussian Origin-Destination traffic model with a power relation between its mean and variance, and the second is for network delay tomography where the link delays are to be estimated from the end-to-end path delays. We compare estimators obtained from our method and that obtained from using the joint distribution and other lower dimensional projections, and show that in both cases, the proposed method yields satisfactory results. ", "machine_text": "  Network tomography based on 1-D projections ------------------------------------------  A reliable and efficient estimation of the underlying connectivity structure of a network is a long-standing problem in network science. We present a new algorithm for estimating the connectivity of a general directed network, based on computing a 1-D projection of the network. Our algorithm is simple and fast, with a linear complexity in the number of nodes. The proposed method has several attractive properties. In particular, it is shown that the proposed algorithm is reliable in the sense that the error in the estimated connectivity structure is upper-bounded from above, as the number of samples goes to infinity. Furthermore, the proposed algorithm is shown to be relatively insensitive to the choice of the projection direction, in the sense that the choice of the projection direction has only a second order impact on the obtained connectivity estimate. The proposed method is evaluated and compared to other network tomography methods using both simulated and real-world network data sets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spatial separation of small and large grains in the transitional disk   around the young star IRS 48. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2969, "human_text": "  We present spatially resolved mid-infrared images of the disk surrounding the young star IRS 48 in the Ophiuchus cloud complex. The disk exhibits a ring-like structure at 18.7 micron, and is dominated by very strong emission from polycyclic aromatic hydrocarbons at shorter wavelengths. This allows a detailed study of the relative distributions of small and large dust grains.   Images of IRS 48 in 5 mid-infrared bands from 8.6 to 18.7 micron as well as a low resolution N-band spectrum are obtained with VLT-VISIR. Optical spectroscopy is used to determine the spectral type of the central star and to measure the strength of the Halpha line.   The 18.7 micron ring peaks at a diameter of 110 AU, with a gap of ~ 60 AU. The shape of the ring is consistent with an inclination of i = 48 +- 8 degrees. In contrast, the 7.5-13 micron PAH emission bands are centered on the source and appear to fill the gap within the ring. The measured PAH line strengths are 10-100x stronger than those typically measured for young M0 stars and can only be explained with a high PAH abundance and/or strong excess optical/UV emission. The morphology of the images, combined with the absence of a silicate emission feature, imply that the inner disk has been cleared of micron-sized dust but with a significant population of PAHs remaining. We argue that the gap can be due to grain growth and settling or to clearing by an unseen planetary or low-mass companion. IRS 48 may represent a short-lived transitional phase from a classical to a weak-line T Tauri star. ", "machine_text": "  We present photometric and structural measurements of the disk around the young star IRS 48. Our observations resolve the disk into a series of rings, the gaps between which are marked by the locations of planetesimals. We find that the inner few gaps are approximately equally spaced, indicating that the planetesimals are roughly equal in size. The sizes of the planetesimals decrease outward, and the outermost planetesimals are much smaller than the inner planetesimals. The inner large planetesimals are spatially separated from the outer small planetesimals by a gap approximately 1.5 times the size of the inner planetesimals. We propose that the disk has a transition region between the inner and outer planetesimal belts. In this region, planetesimals grow by colliding with each other and fragmenting, until they are large enough to be stable against further fragmentation. We model the evolution of the disk and find that the predicted grain size distribution is in good agreement with the observed distribution, if the disk contains a transition region between the inner and outer planetesimal belts. Our results suggest that the grain size distribution in planetesimal belts is determined by the planetesimals' growth history, and that a continuous range of grain sizes is not produced by the collisional fragmentation of planetesimals.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Electronic spin transport and spin precession in single graphene layers   at room temperature. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1948, "human_text": "  The specific band structure of graphene, with its unique valley structure and Dirac neutrality point separating hole states from electron states has led to the observation of new electronic transport phenomena such as anomalously quantized Hall effects, absence of weak localization and the existence of a minimum conductivity. In addition to dissipative transport also supercurrent transport has already been observed. It has also been suggested that graphene might be a promising material for spintronics and related applications, such as the realization of spin qubits, due to the low intrinsic spin orbit interaction, as well as the low hyperfine interaction of the electron spins with the carbon nuclei. As a first step in the direction of graphene spintronics and spin qubits we report the observation of spin transport, as well as Larmor spin precession over micrometer long distances using single graphene layer based field effect transistors. The non-local spin valve geometry was used, employing four terminal contact geometries with ferromagnetic cobalt electrodes, which make contact to the graphene sheet through a thin oxide layer. We observe clear bipolar (changing from positive to negative sign) spin signals which reflect the magnetization direction of all 4 electrodes, indicating that spin coherence extends underneath all 4 contacts. No significant changes in the spin signals occur between 4.2K, 77K and room temperature. From Hanle type spin precession measurements we extract a spin relaxation length between 1.5 and 2 micron at room temperature, only weakly dependent on charge density, which is varied from n~0 at the Dirac neutrality point to n = 3.6 10^16/m^2. The spin polarization of the ferromagnetic contacts is calculated from the measurements to be around 10%. ", "machine_text": " We report on electronic spin transport and spin precession in single graphene layers at room temperature. We show that spin transport in graphene is governed by two different processes: a thermally driven one, related to the transport of charges, and a pure spin-driven one. By using a method based on spin-dependent total variation, we are able to separate the two contributions and to evaluate the thermal spin transport. We find that it is always superdiffusive, with a characteristic length that increases with the square of the thermal energy, in agreement with the predictions of a Boltzmann transport model. By using the same method we also measure the spin precession in a gated graphene layer, and we find that it is very fast, in agreement with theoretical predictions. We also show that the spin precession depends on the type of charge transport: it is faster when the charge transport is ballistic, and much slower when the charge transport is diffusive. This finding may be relevant for spintronic applications, where one has to control the spin precession by controlling the charge transport.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Vortex in axion condensate as a dark matter halo. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3017, "human_text": "  We study the possibility of the vortices formation in axion condensate on the galactic scale. Such vortices can occur as a result of global rotation of the early universe. We study analytical models of vortices and calculate exemplary galaxy rotation curves. Depending on the setup it is possible to obtain a variety of shapes which give a good qualitative agreement with observational results. However, as we show, the extremely low velocity dispersions of the axions velocity are required to form the single vortex on the galactic scales. We find that the required velocity dispersion is of the order of $\\sigma \\approx 10^{-12} \\frac{m}{s}$. This is much smaller that predicted within the present understanding of the axion physics. The vortices in axion condensate can be however formed on the much smaller scales and give seeds to the galaxy formation and to their angular momenta. On the other hand, the vortices can be formed on the galactic scales, but only if the mass of the axion-like particles is of the order of $10^{-30}$eV. In this case, the particle de Broglie wavelength is comparable with the galactic diameter. This condition must be fulfilled in order to keep the coherence of the quantum condensate on the galactic scales. ", "machine_text": " We consider a scenario where an axion condensate is present in the early Universe and the axion fluid is able to sustain a significant vortex structure that collapses in the later Universe to form a dark matter halo. We show that the energy density of this vortex has the right scale to become a dark matter halo with the same energy density as the one observed in the Universe. We find that the growth of the vortex is governed by the mass flux through the vortex core, which in our case is driven by the anisotropic pressure. Therefore, our scenario can provide a physical explanation for the velocity distribution function of dark matter particles, which is consistent with the data from large scale structure formation. The core of the vortex is able to sustain a significant amount of mass, because the mass flow is driven by the pressure gradient and the structure is able to keep itself stable by the positive feedback from the gravitational attraction. We show that the outer regions of the halo contain much less mass, and the profile is able to fit the observations.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: TYZ expansion for the Kepler manifold. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2118, "human_text": "  The main goal of the paper is to address the issue of the existence of Kempf's distortion function and the Tian-Yau-Zelditch (TYZ) asymptotic expansion for the Kepler manifold - an important example of non compact manfold. Motivated by the recent results for compact manifolds we construct Kempf's distortion function and derive a precise TYZ asymptotic expansion for the Kepler manifold. We get an exact formula: finite asymptotic expansion of $n-1$ terms and exponentially small error terms uniformly with respect to the discrete quantization parameter $m\\to \\infty $ and $\\rho \\to \\infty$, $\\rho$ being the polar radius in $\\C^n$.   Moreover, the coefficents are calculated explicitly and they turned out to be homogeneous functions with respect to the polar radius in the Kepler manifold. We also prove and derive an asymptotic expansion of the obtstruction term with the coefficients being defined by geometrical quantities. We show that our estimates are sharp by analyzing the nonharmonic behaviour of $T_m$ and the error term of the approximation of the Fubini--Study metric by $m\\omega$ for $m\\to +\\infty$. The arguments of the proofs combine geometrical methods, quantization tools and functional analytic techniques for investigating asymptotic expansions in the framework of analytic-Gevrey spaces. ", "machine_text": "  We consider the expansion of the Tokyo IoT-oriented zones (TYZ) from the view of a large-scale urban information and communication technology (ICT) infrastructure. We found that TYZ can be viewed as a special kind of network, called a vegetation model, in which the nodes are labeled by three kinds of tags, corresponding to the three kinds of entities that make up the TYZ: Things, People, and Spaces. We show that this model is associated with a class of expansions that has a natural topological structure, called aEventually we arrived at a solution using the tools of category theory, a branch of abstract mathematics that studies the structure of mathematical objects and the morphisms between them. In this approach, we regard TYZ as a category, where the objects are the elements of the expansion and the morphisms are the inclusion maps. We show that this category has a structure called a cartesian monad. We regard this solution as a theoretical achievement, because it provides a general framework for understanding the expansion of TYZ, not only in Tokyo but in other cities as well. We also regard this solution as a practical achievement, because it provides a basis for the construction of an information and communication technology (ICT) infrastructure that can support the expansion of TYZ.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Needlet algorithms for estimation in inverse problems. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0274, "human_text": "  We provide a new algorithm for the treatment of inverse problems which combines the traditional SVD inversion with an appropriate thresholding technique in a well chosen new basis. Our goal is to devise an inversion procedure which has the advantages of localization and multiscale analysis of wavelet representations without losing the stability and computability of the SVD decompositions. To this end we utilize the construction of localized frames (termed \"needlets\") built upon the SVD bases. We consider two different situations: the \"wavelet\" scenario, where the needlets are assumed to behave similarly to true wavelets, and the \"Jacobi-type\" scenario, where we assume that the properties of the frame truly depend on the SVD basis at hand (hence on the operator). To illustrate each situation, we apply the estimation algorithm respectively to the deconvolution problem and to the Wicksell problem. In the latter case, where the SVD basis is a Jacobi polynomial basis, we show that our scheme is capable of achieving rates of convergence which are optimal in the $L_2$ case, we obtain interesting rates of convergence for other $L_p$ norms which are new (to the best of our knowledge) in the literature, and we also give a simulation study showing that the NEED-D estimator outperforms other standard algorithms in almost all situations. ", "machine_text": "  Inverse problems are encountered in many applications, such as medical imaging, earthquake detection, and astronomical imaging, where the goal is to reconstruct an unknown quantity from its known partial derivatives. In this work, we develop a new general approach to such inverse problems based on the use of needle algorithms, which are a generalization of the celebrated Grassmannian algorithm to higher dimensions. The new approach is applicable to a large class of inverse problems and enjoys several of the advantages of the Grassmannian algorithm, such as the use of low-dimensional Euclidean space and a direct method for the estimation of the solution vector. We show that in many cases the new approach results in a substantial reduction of the number of unknowns in the inverse problem and that it can be used to derive new explicit expressions for the solution vector. Furthermore, the proposed method is suitable for implementation on a computer and we present an illustrative example from the field of image processing.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Exciting the Magnetosphere of the Magnetar CXOU J164710.2-455216 in   Westerlund 1. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.163, "human_text": "  We describe XMM-Newton observations taken 4.3 days prior to and 1.5 days subsequent to two remarkable events that were detected with Swift on 2006 September 21 from the candidate magnetar CXOU J164710.2-455216: (1) a 20 ms burst with an energy of 1e37 erg (15-150 keV), and (2) a rapid spin-down (glitch) with a fractionap period change of 1e-4. We find that the luminosity of the pulsar increased by a factor of 100 in the interval between observations, from 1e33 to 1e35 erg/s (0.5-8.0 keV), and that its spectrum hardened. The pulsed count rate increased by a factor of 10 (0.5-8.0 keV), but the fractional rms amplitude of the pulses decreased from 65 to 11 per cent, and their profile changed from being single-peaked to exhibiting three peaks. Similar changes have been observed from other magnetars in response to outbursts, such as that of 1E 2259+586 in 2002 June. We suggest that a plastic deformation of the neutron star's crust induced a very slight twist in the external magnetic field, which in turn generated currents in the magnetosphere that were the direct cause of the X-ray outburst. ", "machine_text": " We present a comprehensive analysis of the four greatest X-ray flares ever observed from the magnetar CXOU J164710.2-455216 in Westerlund 1. These extraordinary flares were discovered in a one-week monitoring campaign in April 2018. The observed energy distribution in the flares is well described by an exponentially cut-off power law with a cutoff energy of 2.2 kJ. This energy distribution is consistent with the temperature distribution in the flaring magnetosphere, suggesting that the flares were produced by magnetic reconnection in the magnetosphere. We show that the energy released in the flares is much larger than the spin-down power of the magnetar, indicating that the magnetic energy in the magnetosphere is deposited by the magnetic field of the companion star. We find that the occurrence of such flares is a rare event in magnetars with a well-developed magnetosphere, and that the probability of occurrence decreases with increasing magnetic field and volume of the magnetosphere. Our results suggest that magnetic reconnection is an important process in the magnetosphere of magnetars, and can lead to the occurrence of flares with an energy content of up to 6% of the stellar mass of our Sun.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Elusive AGN in the XMM-Newton bright serendipitous survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2985, "human_text": "  AIMS: We investigate here the nature of all the sources (35 in total) in the XBS survey (which is 86% optically identified) showing an optical spectrum dominated by the light from the host galaxy with no evidence (or little evidence) for the presence of an AGN. METHODS: We use the X-ray spectral analysis to assess the presence of an AGN in these sources and to characterize its properties. RESULTS: We detect AGN activity in 33 out of 35 sources. The remaining 2 sources are the ones with the lowest X-ray luminosity in the sample (L[2-10keV]<10^41 erg s^-1) and their X-ray emission could be produced within the host galaxy. We find that the ``recognition problem'' for AGN is very critical in the low-luminosity regime (at least 60% of the AGN with L[2-10keV]<10^43 erg s^-1 are elusive) becoming negligible for high X-ray luminosities (~1.5% of elusive AGN with L[2-10keV]>10^44 erg s^-1). This problem affects mostly absorbed AGN (~40% of type~2 AGN in the survey are elusive) but also a significant fraction of unabsorbed AGN (8%). CONCLUSIONS: We find that the simplest explanations of why these 33 (or most of them) AGNs are elusive are two: at low X-ray luminosities (<10^43 erg s^-1) the most important reason is the intrinsically low AGN/galaxy contrast (optical dilution) while at high luminosities (>10^44 erg s^-1) it is due to the optical absorption (in the Compton-thin regime, i.e. NH<10^24 cm^-2). Alternative hypotheses, like the presence of Compton-thick sources, BL Lac objects or ``non-standard'' AGN (e.g. with alpha_OX<1 or with weak/absorbed Narrow Line Region) are not supported by the data although we cannot exclude the presence in the sample of a few sources of these types. ", "machine_text": "  We present the discovery of a large population of previously undetected low-mass active galactic nuclei (AGN) in the XMM-Newton bright serendipitous survey. We estimate that several thousand such sources must exist in the local volume, but they are extremely faint and hard to detect. We found the first indication of these sources in the XMM-Newton data by searching for point sources that were not detected in archival data from the 2 Micron All Sky Survey but that have a high probability of being an X-ray source (based on their optical and N-band data). Follow-up spectroscopy with the UV-optical suite on Hubble and with the DEIMOS multiobject spectrograph on KeckII confirmed that a large fraction of these sources are indeed AGN, with mid-IR colors and X-ray spectra consistent with accreting supermassive black holes. These AGN are estimated to have accretion rates of 10^(\u22121) to 10^(+3) times the accretion rate of the supermassive black hole in our own galaxy, and they are faint because they are both distant and young. We determine the masses of the host galaxies and the supermassive black holes in these galaxies, and find that a significant fraction ( approximately 50%) of these black holes are in the range 10^4 to 10^7 solar masses. These black holes are an order of magnitude less massive than the black holes in galaxies that were previously known to host an AGN, indicating that the low-mass end of the distribution of supermassive black holes is preserved in galaxies that host an AGN. We discuss the implications of this discovery for the formation history of galaxies and the relationship between supermassive black holes and galaxy evolution.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The colour selection of distant galaxies in the UKIDSS Ultra-Deep Survey   Early Data Release. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2136, "human_text": "  We investigate colour selection techniques for high redshift galaxies in the UKIDSS Ultra Deep Survey Early Data Release (UDS EDR). Combined with very deep Subaru optical photometry, the depth (K_AB = 22.5) and area (0.62 deg^2) of the UDS EDR allows us to investigate optical/near-IR selection using a large sample of over 30,000 objects. By using the B-z, z-K colour-colour diagram (the BzK technique) we identify over 7500 candidate galaxies at z > 1.4, which can be further separated into passive and starforming systems (pBzK and sBzK respectively). Our unique sample allows us to identify a new feature not previously seen in BzK diagrams, consistent with the passively evolving track of early type galaxies at z < 1.4. We also compare the BzK technique with the R-K colour selection of Extremely Red Objects (EROs) and the J-K selection of Distant Red Galaxies (DRGs), and quantify the overlap between these populations. We find that the majority of DRGs, at these relatively bright magnitudes are also EROs. Since previous studies have found that DRGs at these magnitudes have redshifts of z ~ 1 we determine that these DRG/ERO galaxies have SEDs consistent with being dusty star-forming galaxies or AGN at z < 2. Finally we observe a flattening in the number counts of pBzK galaxies, similar to other studies, which may indicate that we are sampling the luminosity function of passive z > 1 galaxies over a narrow redshift range. ", "machine_text": "  We present a study of the colour selection of distant galaxies in the UKIDSS Ultra-Deep Survey. We find that the colour selection is peaked at GAL99 centre and it is slightly blue away from the centre. This is different from the colour selection in the SDSS survey where the colour selection is more red in the centres of the fields. The difference in the colour selection is probably due to the different survey geometry. The centre of GAL99 is filled with many bright galaxies and the outskirts are dominated by faint galaxies. The colour selection is obtained from the 2-colour distribution of galaxies with respect to their local galaxy number density. The colour selection is independent of the absolute magnitude and redshift. The 2-colour distribution of galaxies in GAL99 is very different from that in the SDSS, with the main difference being that the SDSS colour selection is more red in the centres of the fields, while in GAL99 the colour selection is blue in the centres. We have compared the GAL99 colour selection with the SDSS colour selection using the Kolmogorov-Smirnov test, and found that the two colour selections are statistically different. This suggests that the colour selection in GAL99 is not the same as the SDSS colour selection. We have also compared the GAL99 colour selection with the SDSS colour selection using the same Kolmogorov-Smirnov test, and found that the two colour selections are statistically different. This suggests that the colour selection in GAL99 is not the same as the SDSS colour selection.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Mathematica script for harmonic oscillator nuclear matrix elements   arising in semileptonic electroweak interactions. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.221, "human_text": "  Semi-leptonic electroweak interactions in nuclei - such as \\beta decay, \\mu capture, charged- and neutral-current neutrino reactions, and electron scattering - are described by a set of multipole operators carrying definite parity and angular momentum, obtained by projection from the underlying nuclear charge and three-current operators. If these nuclear operators are approximated by their one-body forms and expanded in the nucleon velocity through order |\\vec{p}|/M, where \\vec{p} and M are the nucleon momentum and mass, a set of seven multipole operators is obtained. Nuclear structure calculations are often performed in a basis of Slater determinants formed from harmonic oscillator orbitals, a choice that allows translational invariance to be preserved. Harmonic-oscillator single-particle matrix elements of the multipole operators can be evaluated analytically and expressed in terms of finite polynomials in q^2, where q is the magnitude of the three-momentum transfer. While results for such matrix elements are available in tabular form, with certain restriction on quantum numbers, the task of determining the analytic form of a response function can still be quite tedious, requiring the folding of the tabulated matrix elements with the nuclear density matrix, and subsequent algebra to evaluate products of operators. Here we provide a Mathematica script for generating these matrix elements, which will allow users to carry out all such calculations by symbolic manipulation. This will eliminate the errors that may accompany hand calculations and speed the calculation of electroweak nuclear cross sections and rates. We illustrate the use of the new script by calculating the cross sections for charged- and neutral-current neutrino scattering in ^{12}C. ", "machine_text": " We present a Mathematica script which computes the non-relativistic harmonic oscillator matrix elements of the effective Lagrangian density $$\\Phi(\\epsilon)=\\epsilon^2 \\epsilon^\\ast \\Phi(\\epsilon) \\equiv \\epsilon^2 \\epsilon^\\ast \\bigl[-\\epsilon^2\\delta^2-\\epsilon^\\ast\\delta^\\ast\\delta^2-\\delta^\\ast\\epsilon^\\ast\\delta^2-\\delta^\\ast\\epsilon^2\\delta^\\ast\\delta^2+\\delta^2\\epsilon^\\ast\\epsilon^2\\delta^\\ast\\delta^2\\bigr] \\ . $$ This effective Lagrangian density arises in the framework of the standard Model of electroweak interactions when the final state includes a virtual photon in the electroweak sector, for example, in the computation of the hadrononia $J/\\Psi_{\\rm had}$ matrix elements. The script is based on the properties of the Lorentzian invariance and the non-relativistic limit of the Maxwell equations. We show that in the framework of this model the non-relativistic limit is equivalent to a decay of the Fourier-Mascheroni kernel and that this limit is related to the Dawson functions. The script computes the non-relativistic matrix elements of $\\Phi$ as well as the derivatives with respect to the polarization $\\epsilon$ and the total energy $E$. It is illustrated with the computation of the $J/\\Psi_{\\rm had}$ matrix elements of the nucleons and deuteron.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A detailed study of the enigmatic cluster M82F. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0543, "human_text": "  We present a detailed study of the stellar cluster M82F, using multi-band high resolution HST imaging and deep ground based optical slit and integral field spectroscopy. Using the imaging we create colour maps of the cluster and surrounding region in order to search for substructure. We find a large amount of substructure, which we interpret as the result of differential extinction across the projected face of the cluster. With this interpretation, we are able to construct a spatially resolved extinction map across the cluster which is used to derive the intrinsic flux distribution. Fitting cluster profiles (King and EFF) to the intrinsic images we find that the cluster is 15-30% larger than previous estimates, and that no strong evidence of mass segregation in this cluster exists. Using the optical spectra, we find that the age of M82F is 60-80 Myr and from its velocity conclude that the cluster is not physically associated with a large HII region that it is projected upon, both in agreement with previous studies. The reconstructed integral field maps show that that majority of the line emission comes from a nearby HII region. The spatial dependence of the line widths (implying the presence of multiple components)measured corresponds to the extinction map derived from photometry, indicating that the gas/dust clouds responsible for the extinction are also partially ionised. Even with the wealth of observations presented here, we do not find a conclusive solution to the problem of the high light-to-mass ratio previously found for this cluster and its possible top-heavy stellar IMF. ", "machine_text": "  We present a detailed study of the enigmatic cluster M82F using a combination of high-resolution near-infrared spectroscopy, high-resolution optical spectroscopy, and multi-object optical/NIR imaging. We find that the cluster consists of two distinct groups of galaxies, which we term the North and South components. The North component contains a small number of bright galaxies, which are member galaxies of the Local Volume Subcluster, and a much larger number of faint galaxies, which form the majority of the M82F cluster. The South component consists of a relatively small number of bright galaxies which are probably member galaxies of the Comiccio- burial Subcluster and a much larger number of faint galaxies which are a minority population in the M82F cluster. We show that the M82F cluster is a member of the Fornax-Righarthed galaxy cluster system, and we determine the redshift of the M82F cluster to be z ~ 1.225. We discuss the dynamical state of the cluster and the physical properties of the galaxies in the context of the dominant galaxy formation theory.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The shapes, orientation, and alignment of Galactic dark matter subhalos. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2037, "human_text": "  We present a study of the shapes, orientations, and alignments of Galactic dark matter subhalos in the ``Via Lactea'' simulation of a Milky Way-size LCDM host halo. Whereas isolated dark matter halos tend to be prolate, subhalos are predominantly triaxial. Overall subhalos are more spherical than the host halo, with minor to major and intermediate to major axis ratios of 0.68 and 0.83, respectively. Like isolated halos, subhalos tend to be less spherical in their central regions. The principal axis ratios are independent of subhalo mass, when the shapes are measured within a physical scale like r_Vmax, the radius of the peak of the circular velocity curve. Subhalos tend to be slightly more spherical closer to the host halo center. The spatial distribution of the subhalos traces the prolate shape of the host halo when they are selected by the largest V_max they ever had, i.e. before they experienced strong tidal mass loss. The subhalos' orientation is not random: the major axis tends to align with the direction towards the host halo center. This alignment disappears for halos beyond 3 r_200 and is more pronounced when the shapes are measured in the outer regions of the subhalos. The radial alignment is preserved during a subhalo's orbit and they become elongated during pericenter passage, indicating that the alignment is likely caused by the host halo's tidal forces. These tidal interactions with the host halo act to make subhalos rounder over time. ", "machine_text": "  We present a catalog of 2\u00d7105 randomly selected Galactic dark matter subhalos, constructed using the StructuredStreaming algorithm applied to the uncorrupted part of the DarkMarkovian galaxy (DMG) simulation. We describe the shape, orientation, and alignment of these subhalos, and find that they have well-defined oblate spheroids with the major axis pointing in the direction of the Galactic disk. We find that the alignment of the subhalos is very good, with the degree of alignment increasing with the concentration of the subhalo. We compare the results with earlier results from the Tokyo parting and find that they are consistent. We find that the alignment is slightly better for the subhalos in the DMG than for the subhalos in the Tokyo parting, which we attribute to the different techniques used to extract the subhalos. We also present the catalog of all the subhalos in the DMG with |Mpc|>5, and find that the fraction of aligned subhalos is significantly larger for these subhalos than for the |Mpc|<5 subhalos, which we attribute to the fact that large subhalos are more likely to form in the Galactic disk than in the Galactic halo. We find that the shape of the subhalos is well described by an oblate spheroid, and that the deviation from this shape is small for |Mpc|>5 subhalos but significant for |Mpc|<5 subhalos. We attribute the different shapes of the subhalos to the fact that large subhalos are more likely to form in the Galactic disk, where the dark matter is more spherical, while small subhalos are more likely to form in the Galactic halo, where the dark matter is more disk-like.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Instanton Induced Neutrino Majorana Masses in CFT Orientifolds with   MSSM-like spectra. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1079, "human_text": "  Recently it has been shown that string instanton effects may give rise to neutrino Majorana masses in certain classes of semi-realistic string compactifications. In this paper we make a systematic search for supersymmetric MSSM-like Type II Gepner orientifold constructions admitting boundary states associated with instantons giving rise to neutrino Majorana masses and other L- and/or B-violating operators. We analyze the zero mode structure of D-brane instantons on general type II orientifold compactifications, and show that only instantons with O(1) symmetry can have just the two zero modes required to contribute to the 4d superpotential. We however discuss how the addition of fluxes and/or possible non-perturbative extensions of the orientifold compactifications would allow also instantons with $Sp(2)$ and U(1) symmetries to generate such superpotentials. In the context of Gepner orientifolds with MSSM-like spectra, we find no models with O(1) instantons with just the required zero modes to generate a neutrino mass superpotential. On the other hand we find a number of models in one particular orientifold of the Gepner model $(2,4,22,22)$ with $Sp(2)$ instantons with a few extra uncharged non-chiral zero modes which could be easily lifted by the mentioned effects. A few more orientifold examples are also found under less stringent constraints on the zero modes. This class of $Sp(2)$ instantons have the interesting property that R-parity conservation is automatic and the flavour structure of the neutrino Majorana mass matrices has a simple factorized form. ", "machine_text": "  We consider the possibility of the Majorana masses of neutrinos in CFTs with MSSM-like spectra being induced by the presence of a special class of non-perturbative instabilities, which we call \"instanton induced\". We show that this is possible provided that the relevant CFT has certain special properties, which are not universal and are only shared by a small number of CFTs. As an application, we consider the case of SO(10) with the simplest MSSM-like spectrum, and show that in this case the Majorana masses of the weakly coupled neutrinos can be induced by the unique combination of a single $N=1$ axial-vector current and a single $Z_2$ weak-singlet mode. We show that the Majorana mass of the active neutrino is related to the $Z_2$ weak-singlet mass, and that the three passive neutrinos are related to the $N=1$ axial-vector current. We evaluate the mass of the $Z_2$ weak-singlet in terms of the $N=1$ axial-vector mass and the Standard Model Higgs mass, and show that the Majorana masses of the neutrinos can be large, but are not necessarily so.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The high energy emission of GRO J1655-40 as revealed with INTEGRAL   spectroscopy of the 2005 outburst. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1302, "human_text": "  We present broadband (3-500 keV) INTEGRAL X-ray spectra and X-ray/optical light curves of the luminous black hole X-ray transient and relativistic jet source GRO J1655-40. Our analysis covers four Target of Opportunity observations of the outburst that started in February 2005. We find that the high energy emission of GRO J1655-40 can be modelled well with an unbroken power-law (with photon indices of 1.72+-0.03,2.21+-0.04 for the first and the second observations, respectively). These correspond to hard and thermal dominant states, respectively. In contrast to many other black hole spectra, high energy complexity in the form of a break or cut-off is not required for the hard state, contrary to previous expectations for this state. We show for the first time that Comptonization by non-thermal electrons is the dominant process for the high energy emission in the hard state. We discuss our results in terms of models for broad-band emission and accretion flows in stellar-mass black holes. ", "machine_text": " We present INTEGRAL spectroscopy and photometry of the outburst from the LMXB companion star to GRO J1655-40, a member of the HR diagram with an extremely wide gap between the ascending and descending branches. We find that the outburst energy is at least 6 kJ, comparable to but slightly smaller than the recently observed outburst from the Galactic globular cluster M55. The accretion phase in GRO J1655-40 is much longer, however, lasting about four times as long as in M55. We discuss the accretion mechanism responsible for these outbursts and compare the properties of the accretion discs in both systems. We find that the mass of the accretion disc in GRO J1655-40 is smaller by a factor of  \u223c 3-4, which probably explains why its accretion phase is so much longer. We also present a simple model which describes the observed correlation between the accretion burst and the orbital period in terms of a constant accretion rate (or a very small number of discrete accretion events) and a single frequency modulated by the orbital period.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Equation of state of isospin-asymmetric nuclear matter in relativistic   mean-field models with chiral limits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1738, "human_text": "  Using in-medium hadron properties according to the Brown-Rho scaling due to the chiral symmetry restoration at high densities and considering naturalness of the coupling constants, we have newly constructed several relativistic mean-field Lagrangians with chiral limits. The model parameters are adjusted such that the symmetric part of the resulting equation of state at supra-normal densities is consistent with that required by the collective flow data from high energy heavy-ion reactions, while the resulting density dependence of the symmetry energy at sub-saturation densities agrees with that extracted from the recent isospin diffusion data from intermediate energy heavy-ion reactions. The resulting equations of state have the special feature of being soft at intermediate densities but stiff at high densities naturally. With these constrained equations of state, it is found that the radius of a 1.4$M_\\odot$ canonical neutron star is in the range of 11.9 km$\\leq$R$\\leq$13.1 km, and the maximum neutron star mass is around 2.0$M_\\odot$ close to the recent observations. ", "machine_text": " We study the equation of state of isospin-asymmetric nuclear matter in relativistic mean-field models with chiral limits. The isospin-asymmetry of the nuclear matter is implemented by a $3\\to 2$ symmetry transformation in the hadron sector, while the equation of state is obtained from a $2\\to 1$ hadron-antihadron symmetry transformation in the hadron-antihadron sector. We find that the relativistic mean-field models with chiral limits can well describe the isospin-asymmetric nuclear matter in a wide range of the baryon number density $\\overline{B}_{\\text{eq}}$, when the isospin-asymmetry is generated by a $3\\to 2$ symmetry transformation in the hadron sector. As the $\\overline{B}_{\\text{eq}}$ increases, the isospin-asymmetric matter approaches the pure isospin symmetric nuclear matter, and the hadron-antihadron symmetry transformation in the hadron-antihadron sector gradually becomes a pure isospin symmetry transformation. We also discuss the $\\overline{B}_{\\text{eq}}$ dependence of the isospin-asymmetric matter in the mean-field models with the Roses-uto-Young (R-U-Y) and the Gauss-Bonnet-Chern (G-B-C) limit, which are the chiral limits of the G-B-C and R-U-Y model, respectively.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A high-frequency radio continuum study of massive young stellar objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4664, "human_text": "  We present high-resolution observations made with the Very Large Array (VLA) in its A configuration at frequencies between 5 and 43 GHz of a sample of five massive young stellar objects (YSOs): LkHa101, NGC2024-IRS2, S106-IR, W75N and S140-IRS1. The resolution varied from 0.04 arcsec (at 43 GHz) to 0.5 arcsec (at 5 GHz), corresponding to a linear resolution as high as 17 AU for our nearest source. A MERLIN observation of S106-IR at 23 GHz with 0.03-arcsec resolution is also presented. S106-IR and S140-IRS1 are elongated at 43 GHz perpendicular to their large scale bipolar outflows. This confirms the equatorial wind picture for these sources seen previously in MERLIN 5 GHz observations. The other sources are marginally resolved at 43 GHz. The spectral indices we derive for the sources in our sample range from +0.2 to +0.8, generally consistent with ionized stellar winds. We have modelled our sources as uniform, isothermal spherical winds, with LkHa101 and NGC2024-IRS2 yielding the best fits. However, in all cases our fits give wind temperatures of only 2000 to 5000 K, much less than the effective temperatures of main-sequence stars of the same luminosity, a result which is likely due to the clumpy nature of the winds. ", "machine_text": "  We present here the results of a systematic study of massive young stellar objects (MYSOs) in the local molecular cloud using high-frequency radio continuum observations with the Plateau de Bureuja Observatory (PBO) low-frequency array. We aim to test the assumption that MYSOs are powerful sources of radio continuum emission, and to investigate the physical properties of the ionised gas in the immediate neighbourhood of these sources. We have imaged with milliarcsecond resolution, by means of multi-frequency synthesis, a number of MYSOs in the \u1e9e\u22c5B \u223c 1.5\u20132.5 GHz frequency range. We find that in general the radio power from these sources is below the detection limit of our observations, in spite of the fact that some of these sources are known to be extremely luminous in the optical and near-infrared domains. We have derived a detection limit of \u1e9e\u22c5B \u223c 1027 W Hz-1  Mousis et al. (1995). This is slightly above the absolute magnitude of the brightest sources in our sample. We have derived an upper limit to the radio power of the brightest sources of \u1e9e\u22c5B \u223c 1028 W Hz-1, which represents  \u223c 10% of their optical power. The only two sources which have been detected are also the two brightest in our sample. We have compared our observations with simple models in which the radio source is treated as a  point source  within a uniform ionised gas cloud. In our best-fitting model, the ionised gas is not homogeneous, but has a temperature gradient, with the gas temperature increasing with distance from the source. We discuss this result in the framework of recent theoretical models.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Unplugging the Universe: the neglected electromagnetic consequence of   decoupling. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4632, "human_text": "  This letter concentrates on the non-equilibrium evolution of magnetic field structures at the onset of recombination, when the charged particle current densities decay as neutrals are formed.   We consider the effect that a decaying magnetic flux has on the acceleration of particles via the transient induced electric field. Since the residual charged-particle number density is small as a result of decoupling, we shall consider the magnetic and electric fields essentially to be imposed, neglecting the feedback from any minority accelerated population.   We find that the electromagnetic treatment of this phase transition can produce energetic electrons scattered throughout the Universe. Such particles could have a significant effect on cosmic evolution in several ways: (i) their presence could delay the effective end of the recombination era; (ii) they could give rise to plasma concentrations that could enhance early gravitational collapse of matter by opposing cosmic expansion to a greater degree than neutral matter could; (iii) they could continue to be accelerated, and become the seed for reionisation at the later epoch $z \\approx 10$. ", "machine_text": " Unplugging the Universe: the neglected electromagnetic consequence of decoupling  We present a solution to the problem of the energy stored in the electromagnetic field surrounding a uniformly charged sphere as it is being moved through a medium with a non-zero resistivity. The solution is found by first considering the exact solution to the problem of the energy stored in the electric field surrounding a point charge as it is being moved through a medium with a non-zero resistivity. This exact solution is then used to find the energy stored in the electromagnetic field surrounding a uniformly charged sphere as it is being moved through a medium with a non-zero resistivity. The solution to the problem is obtained by using a technique called the method of images. The solution is exact, and it is independent of the size of the sphere, the radius of the sphere, and the resistivity of the medium. The solution also shows that the energy stored in the electromagnetic field surrounding a uniformly charged sphere as it is being moved through a medium with a non-zero resistivity is equal to the energy stored in the electromagnetic field surrounding a point charge as it is being moved through a medium with a non-zero resistivity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Supersymmetry versus Gauge Symmetry on the Heterotic Landscape. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.132, "human_text": "  One of the goals of the landscape program in string theory is to extract information about the space of string vacua in the form of statistical correlations between phenomenological features that are otherwise uncorrelated in field theory. Such correlations would thus represent predictions of string theory that hold independently of a vacuum-selection principle. In this paper, we study statistical correlations between two features which are likely to be central to any potential description of nature at high energy scales: gauge symmetries and spacetime supersymmetry. We analyze correlations between these two kinds of symmetry within the context of perturbative heterotic string vacua, and find a number of striking features. We find, for example, that the degree of spacetime supersymmetry is strongly correlated with the probabilities of realizing certain gauge groups, with unbroken supersymmetry at the string scale tending to favor gauge-group factors with larger rank. We also find that nearly half of the heterotic landscape is non-supersymmetric and yet tachyon-free at tree level; indeed, less than a quarter of the tree-level heterotic landscape exhibits any supersymmetry at all at the string scale. ", "machine_text": "  We study the supersymmetry versus gauge symmetry on the heterotic landscape. We find that the smallest supersymmetric model in a given representation is always much smaller than the smallest gauge model in the same representation. We show that the number of supersymmetric representations is much smaller than the number of gauge representations, and that every gauge representation can be obtained as a limit of a supersymmetric representation. We show that the Landau gauge group is the only gauge group that is semisimple, and that the Langlands dual group is the only group that is fully symmetric. We show that the heterotic action can be constructed from the representations of the Landau gauge group, the Langlands dual group, and a representation of the fundamental group. We show that the singularity at the origin of the heterotic action is due to the representations of the fundamental group. We show that the only local Lagrangian representation of the fundamental group is the trivial representation, and that the only local representation of the fundamental group is the representation given by the restriction to the identity element. We show that the representation of the fundamental group must be an irreducible representation. We show that the representation of the fundamental group is a unique representation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A quantitative study on the growth variability of tumour cell clones in   vitro. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2132, "human_text": "  Objectives: In this study, we quantify the growth variability of tumour cell clones from a human leukemia cell line. Materials and methods: We have used microplate spectrophotometry to measure the growth kinetics of hundreds of individual cell clones from the Molt3 cell line. The growth rate of each clonal population has been estimated by fitting experimental data with the logistic equation. Results: The growth rates were observed to vary among different clones. Up to six clones with a growth rate above or below the mean growth rate of the parent population were further cloned and the growth rates of their offsprings were measured. The distribution of the growth rates of the subclones did not significantly differ from that of the parent population thus suggesting that growth variability has an epigenetic origin. To explain the observed distributions of clonal growth rates we have developed a probabilistic model assuming that the fluctuations in the number of mitochondria through successive cell cycles are the leading cause of growth variability. For fitting purposes, we have estimated experimentally by flow cytometry the maximum average number of mitochondria in Molt3 cells. The model fits nicely the observed distributions of growth rates, however, cells in which the mitochondria were rendered non functional (rho-0 cells) showed only a 30% reduction in the clonal growth variability with respect to normal cells. Conclusions: A tumor cell population is a dynamic ensemble of clones with highly variable growth rate. At least part of this variability is due to fluctuations in the number of mitochondria. ", "machine_text": "  A quantitative study on the growth variability of tumour cell clones in vitro.  We have developed a new and simple method for the quantitative assessment of the growth variability of cells, which is based on the measurement of the density of cells and the determination of the corresponding doubling time. The variability of the growth rate of cells is a relevant topic because it affects many different processes, such as the synchronization of cell populations and the detection of small subpopulations of cells with different features. We applied our new method to the study of the growth variability of a large panel of cell clones derived from the same tumour, to assess whether the growth variability of these clones could be related to their genetic instability. We show that the growth variability is related to the genetic instability of the clones, as measured by the frequency of micronucleated cells and the number of chromosomal aberrations, and that it can be used as a simple and rapid predictor of the genetic instability of a given clone.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Norma Cluster (ACO 3627): I. A Dynamical Analysis of the Most   Massive Cluster in the Great Attractor. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2227, "human_text": "  A detailed dynamical analysis of the nearby rich Norma cluster (ACO 3627) is presented. From radial velocities of 296 cluster members, we find a mean velocity of 4871 +/- 54 km/s and a velocity dispersion of 925 km/s. The mean velocity of the E/S0 population (4979 +/- 85 km/s) is offset with respect to that of the S/Irr population (4812 +/- 70 km/s) by `Delta' v = 164 km/s in the cluster rest frame. This offset increases towards the core of the cluster. The E/S0 population is free of any detectable substructure and appears relaxed. Its shape is clearly elongated with a position angle that is aligned along the dominant large-scale structures in this region, the so-called Norma wall. The central cD galaxy has a very large peculiar velocity of 561 km/s which is most probably related to an ongoing merger at the core of the cluster. The spiral/irregular galaxies reveal a large amount of substructure; two dynamically distinct subgroups within the overall spiral-population have been identified, located along the Norma wall elongation. The dynamical mass of the Norma cluster within its Abell radius is 1 - 1.1 x 10^15 h^-1_73 M_Sun. One of the cluster members, the spiral galaxy WKK 6176 which recently was observed to have a 70 kpc X-ray tail, reveals numerous striking low-brightness filaments pointing away from the cluster centre suggesting strong interaction with the intracluster medium. ", "machine_text": "  We present a dynamical analysis of the Norma Cluster (ACO 3627), the most massive cluster in the Great Attractor. A large fraction of the cluster's total mass is contributed by a group of giant molecular clouds (GMCs) which are responsible for the high metallicity of the cluster. We show that the kinematics of these clouds are consistent with a massive infall from the systemic cirrus clouds of the Orion arm. We have identified a total of eight satellite clouds around the main cluster, four of which are associated with the GMCs. We show that the relative velocity of the clouds is in agreement with the cluster's radial velocity of +5 km s$^{-1}$. We have used the ages of the stars in the cluster to determine the cluster's formation history. We show that the age distribution of the cluster is consistent with a model in which the gas infall happened before the massive starburst in the central region, and we discuss the relation of this event with the origin of the short-lived radio sources in the cluster.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Alignment and signed-intensity anomalies in WMAP data. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3736, "human_text": "  Significant alignment and signed-intensity anomalies of local features of the cosmic microwave background (CMB) are detected on the three-year WMAP data, through a decomposition of the signal with steerable wavelets on the sphere. Firstly, an alignment analysis identifies two mean preferred planes in the sky, both with normal axes close to the CMB dipole axis. The first plane is defined by the directions toward which local CMB features are anomalously aligned. A mean preferred axis is also identified in this plane, located very close to the ecliptic poles axis. The second plane is defined by the directions anomalously avoided by local CMB features. This alignment anomaly provides further insight on recent results (Wiaux et al. 2006). Secondly, a signed-intensity analysis identifies three mean preferred directions in the southern galactic hemisphere with anomalously high or low temperature of local CMB features: a cold spot essentially identified with a known cold spot (Vielva et al. 2004), a second cold spot lying very close to the southern end of the CMB dipole axis, and a hot spot lying close to the southern end of the ecliptic poles axis. In both analyses, the anomalies are observed at wavelet scales corresponding to angular sizes around 10 degress on the celestial sphere, with global significance levels around 1%. Further investigation reveals that the alignment and signed-intensity anomalies are only very partially related. Instrumental noise, foreground emissions, as well as some form of other systematics, are strongly rejected as possible origins of the detections. An explanation might still be envisaged in terms of a global violation of the isotropy of the Universe, inducing an intrinsic statistical anisotropy of the CMB. ", "machine_text": "  We present a statistical study of the alignment and signed-intensity anomalies in the WMAP data. We find that the alignment anomaly can be explained by a simple model in which the dipole moment of the CMB anisotropy is oriented along the ecliptic plane. We find that this explanation is in agreement with the observed correlation between the alignment anomaly and the inclination of the orbital plane of the Earth around the Sun, and the correlation between the alignment anomaly and the average position of the Sun on the sky. We find that the signed-intensity anomaly is in good agreement with a model in which the dipole moment of the CMB anisotropy is aligned in the direction of the equatorial plane, but its intensity is modulated by a dipole moment along the ecliptic plane. We also find that the level of the signed-intensity anomaly is in good agreement with a model in which the amplitude of the dipole moment along the equatorial plane is constant, but its intensity is modulated by a sinusoidal function with a period of one year. We find that this explanation is in agreement with the observed correlation between the signed-intensity anomaly and the position of the Sun on the sky.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of magnetic field on spontaneous Fermi surface symmetry breaking. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4233, "human_text": "  We study magnetic field effects on spontaneous Fermi surface symmetry breaking with d-wave symmetry, the so-called d-wave \"Pomeranchuk instability''. We use a mean-field model of electrons with a pure forward scattering interaction on a square lattice. When either the majority or the minority spin band is tuned close to the van Hove filling by a magnetic field, the Fermi surface symmetry breaking occurs in both bands, but with a different magnitude of the order parameter. The transition is typically of second order at high temperature and changes to first order at low temperature; the end points of the second order line are tricritical points. This qualitative picture does not change even in the limit of a large magnetic field, although the magnetic field substantially suppresses the transition temperature at the van Hove filling. The field produces neither a quantum critical point nor a quantum critical end point in our model. In the weak coupling limit, typical quantities characterizing the phase diagram have a field-independent single energy scale while its dimensionless coefficient varies with the field. The field-induced Fermi surface symmetry breaking is a promising scenario for the bilayer ruthenate Sr3Ru2O7, and future issues are discussed to establish such a scenario. ", "machine_text": " We study the effect of a non-zero magnetic field on the symmetry of the spontaneous Fermi surface in a metal. We consider a system in which the underlying symmetry of the lattice is broken by an external field, and show that this breaks also the symmetry of the resulting Fermi surface. We find that the resulting Fermi surface is very sensitive to the underlying lattice symmetry, the strength of the field, and the type of thesymmetry breaking. Our results are consistent with the notion that the formation of a non-trivial Fermi surface is a consequence of the spontaneous symmetry breaking, and that the only symmetry of the Fermi surface is that of the underlying lattice. We also show that in a lattice with a non-trivial symmetry, the resulting Fermi surface is not necessarily symmetric.  Symmetry breaking is at the heart of many processes in physics, from the breaking of fundamental symmetries in the early universe to the dynamics of quantum systems. Spontaneous Fermi surface symmetry breaking is a consequence of the breaking of the symmetry of the lattice by the presence of a non-zero magnetic field. We show that in a lattice with a non-trivial symmetry, the resulting Fermi surface is not necessarily symmetric. We find that the Fermi surface is very sensitive to the underlying lattice symmetry, the strength of the field, and the type of the symmetry breaking. Our results suggest that the formation of a non-trivial Fermi surface is a consequence of the spontaneous symmetry breaking, and that the only symmetry of the Fermi surface is that of the underlying lattice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Intrinsic Origin of Spin Echoes in Dipolar Solids Generated by   Strong Pi Pulses. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.362, "human_text": "  In spectroscopy, it is conventional to treat pulses much stronger than the linewidth as delta-functions. In NMR, this assumption leads to the prediction that pi pulses do not refocus the dipolar coupling. However, NMR spin echo measurements in dipolar solids defy these conventional expectations when more than one pi pulse is used. Observed effects include a long tail in the CPMG echo train for short delays between pi pulses, an even-odd asymmetry in the echo amplitudes for long delays, an unusual fingerprint pattern for intermediate delays, and a strong sensitivity to pi-pulse phase. Experiments that set limits on possible extrinsic causes for the phenomena are reported. We find that the action of the system's internal Hamiltonian during any real pulse is sufficient to cause the effects. Exact numerical calculations, combined with average Hamiltonian theory, identify novel terms that are sensitive to parameters such as pulse phase, dipolar coupling, and system size. Visualization of the entire density matrix shows a unique flow of quantum coherence from non-observable to observable channels when applying repeated pi pulses. ", "machine_text": " We present a theory of the intrinsic generation of spin echoes in dipolar solids by strong pi pulses. The theory is based on a rigorous, fully consistent, and exact treatment of the evolution of the spin and the spin-current density in the presence of a strong pulse, in terms of the spin-current density-functional and the commutator of the spin-current density-functional with the spin-current density. We show that the intrinsic spin echoes can be explained by a simple and general mechanism, which does not require the involvement of any transient spin-current density-fluctuations, and that the theory can be exactly solved for a large class of dipolar solids. The exact solutions show that the intrinsic echo is always a broad spectrum, and that the position of the echo maximum depends on the anisotropy of the solid. The good agreement between the theory and the experiments suggests that the intrinsic spin echoes may be useful for characterizing the structural and dynamical properties of the solids.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Cosmological perturbations in Palatini modified gravity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0232, "human_text": "  Two approaches to the study of cosmological density perturbations in modified theories of Palatini gravity have recently been discussed. These utilise, respectively, a generalisation of Birkhoff's theorem and a direct linearization of the gravitational field equations. In this paper these approaches are compared and contrasted. The general form of the gravitational lagrangian for which the two frameworks yield identical results in the long-wavelength limit is derived. This class of models includes the case where the lagrangian is a power-law of the Ricci curvature scalar. The evolution of density perturbations in theories of the type $f(R)=R-c /R^ b$ is investigated numerically. It is found that the results obtained by the two methods are in good agreement on sufficiently large scales when the values of the parameters (b,c) are consistent with current observational constraints. However, this agreement becomes progressively poorer for models that differ significantly from the standard concordance model and as smaller scales are considered. ", "machine_text": " We study cosmological perturbations in Palatini modified gravity. We consider a Palatini term in the Einstein- Hilbert action, which is proportional to the first derivative of the scalar curvature with respect to the radius of the sphere, which parametrizes the Einstein- Hilbert action. We show that this term does not change the structure of the Einstein- Hilbert action, and thus the solution to the Einstein- Hilbert equation is unchanged. We also show that this term does not change the energy conservation. However, this term changes the equations for the gravitational waves, and in particular it can produce a gravitational wave which does not have a vanishing second derivative at the turning points. We analyze the structure of the solutions with this non-zero second derivative, and we show that they describe a generic mechanism of generation of a kind of gravitational waves, which are not present in the Einstein gravity. We show that this non-traditional gravitational waves can be generated by the motions of the relativistic particles, if their speeds are not too large. We also show that this kind of gravitational waves can be generated by a special kind of solutions, which are invariant under the Affine transformation. We show also that the traditional gravitational waves are generated by a particular class of solutions, which are invariant under the Projective transformation. Finally, we discuss the physical meaning of the non-traditional gravitational waves, and we suggest that they can be generated by a certain kind of quantum gravity.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Probabilistic Anonymity and Admissible Schedulers. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1019, "human_text": "  When studying safety properties of (formal) protocol models, it is customary to view the scheduler as an adversary: an entity trying to falsify the safety property. We show that in the context of security protocols, and in particular of anonymizing protocols, this gives the adversary too much power; for instance, the contents of encrypted messages and internal computations by the parties should be considered invisible to the adversary.   We restrict the class of schedulers to a class of admissible schedulers which better model adversarial behaviour. These admissible schedulers base their decision solely on the past behaviour of the system that is visible to the adversary.   Using this, we propose a definition of anonymity: for all admissible schedulers the identity of the users and the observations of the adversary are independent stochastic variables. We also develop a proof technique for typical cases that can be used to proof anonymity: a system is anonymous if it is possible to `exchange' the behaviour of two users without the adversary `noticing'. ", "machine_text": "  We consider a probabilistic model of a resource-constrained scheduled system, in which jobs arrive according to a Poisson process and have a random service demand. The scheduling policy is based on the concept of admissible scheduling, which was introduced by D.34 The system is adversarial: the scheduler wishes to minimize the variance of the sojourn time of the jobs subject to the constraint that the jobs do not wait too long. The analysis of the system reveals a connection with the probabilistic notion of anonymity, which was introduced by A.5 An anonymous process is one for which the distribution of the number of distinct elements in a sample is the same as the distribution of the number of distinct elements in the whole process. We show that a scheduler is admissible if and only if it preserves anonymity. We then show that any probabilistic scheduling policy that preserves anonymity has a deterministic equivalent that is admissible. As a by-product, we show that the deterministic restriction of an admissible probabilistic scheduling policy is itself admissible.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Theory of Two-Photon Interactions with Broadband Down-Converted Light   and Entangled Photons. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2859, "human_text": "  When two-photon interactions are induced by down-converted light with a bandwidth that exceeds the pump bandwidth, they can obtain a behavior that is pulse-like temporally, yet spectrally narrow. At low photon fluxes this behavior reflects the time and energy entanglement between the down-converted photons. However, two-photon interactions such as two-photon absorption (TPA) and sum-frequency generation (SFG) can exhibit such a behavior even at high power levels, as long as the final state (i.e. the atomic level in TPA, or the generated light in SFG) is narrowband enough. This behavior does not depend on the squeezing properties of the light, is insensitive to linear losses, and has potential applications. In this paper we describe analytically this behavior for travelling-wave down-conversion with continuous or pulsed pumping, both for high- and low-power regimes. For this we derive a quantum-mechanical expression for the down-converted amplitude generated by an arbitrary pump, and formulate operators that represent various two-photon interactions induced by broadband light. This model is in excellent agreement with experimental results of TPA and SFG with high power down-converted light and with entangled photons [Dayan et al., Phys. Rev. Lett. 93, 023005 (2004), Dayan et al., Phys. Rev. Lett. 94, 043602, (2005), Pe'er et al., Phys. Rev. Lett. 94, 073601 (2005)]. ", "machine_text": " We present a unified theory of light interactions with matter that successfully predicts the behavior of two-photon interactions with broadband down-converted light, squeezed light, and entangled photons. Our theory combines the well-known macroscopic equations of electromagnetic theory with a microscopic many-body theory of light-matter interactions that is based on the concept of virtual photons. The virtual photons are associated with the excited states of the atoms and molecules in the nonlinear optical media. We show that the theory can be used to explain a number of interesting phenomena, such as the spatial and temporal focusing of light, the effects of light upon different types of atoms and molecules, and the dynamics of photon pairs produced by parametric fluorescence in a nonlinear optical medium. The theory can be used to design new types of optical filters and to optimize the efficiency of parametric processes. It can also be used to predict new effects that are due to the correlated nature of light in the presence of macroscopic fields.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Predictions from non trivial Quark-Lepton complementarity. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2332, "human_text": "  The complementarity between the quark and lepton mixing matrices is shown to provide robust predictions. We obtain these predictions by first showing that the matrix V_M, product of the quark (CKM) and lepton (PMNS) mixing matrices, may have a zero (1,3) entry which is favored by experimental data.   We obtain that any theoretical model with a vanishing (1,3) entry of V_M that is in agreement with quark data, solar, and atmospheric mixing angle leads to $\\theta_{13}^{PMNS}=(9{^{+1}_{-2}})^\\circ$. This value is consistent with the present 90% CL experimental upper limit. We also investigate the prediction on the lepton phases. We show that the actual evidence, under the only assumption that the correlation matrix V_M product of CKM and PMNS has a zero in the entry (1,3), gives us a prediction for the three CP-violating invariants J, S_1, and S_2. A better determination of the lepton mixing angles will give stronger prediction for the CP-violating invariants in the lepton sector. These will be tested in the next generation experiments. Finally we compute the effect of non diagonal neutrino mass in \"l_i -> l_j gamma\" in SUSY theories with non trivial Quark-Lepton complementarity and a flavor symmetry. The Quark-Lepton complementarity and the flavor symmetry strongly constrain the theory and we obtain a clear prediction for the contribution to \"mu -> e gamma\" and the \"tau\" decays \"tau -> e gamma\" and \"tau -> mu gamma\". If the Dirac neutrino Yukawa couplings are degenerate but the low energy neutrino masses are not degenerate, then the lepton decays are related among them by the V_M entries. On the other hand, if the Dirac neutrino Yukawa couplings are hierarchical or the low energy neutrino masses are degenerate, then the prediction for the lepton decays comes from the CKM hierarchy. ", "machine_text": " We show that a general and rigidly fixed Quark-Lepton number generation mechanism in the strong interactions, with a non-trivial structure of the Quark-Lepton multiplets in the fundamental representation of the relevant symmetry group, is possible if the Quark-Lepton number is generated non-dynamically, i.e. independently on the quantum state of the system. The structure of the Quark-Lepton number generation mechanism in the strong interactions is governed by the geometry of the relevant symmetry group. Therefore the possibility of a non-trivial Quark-Lepton number generation mechanism in the strong interactions depends on the existence of a non-trivial geometry of the relevant symmetry group. We show that such a non-trivial geometry exists in the case of a certain family of spontaneously broken symmetries with a three-fold rotation axis, which includes the SU(2) symmetry group of the strong interactions. Within this framework we formulate the possibility of a general and rigidly fixed Quark-Lepton number generation mechanism in the strong interactions, with a non-trivial structure of the Quark-Lepton multiplets in the fundamental representation of the relevant symmetry group, as a non-trivial limit of a trivial Quark-Lepton number generation mechanism in the strong interactions, with a trivial structure of the Quark-Lepton multiplets in the fundamental representation of the relevant symmetry group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: SIM PlanetQuest Key Project Precursor Observations to Detect Gas Giant   Planets Around Young Stars. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3687, "human_text": "  We present a review of precursor observing programs for the SIM PlanetQuest Key project devoted to detecting Jupiter mass planets around young stars. In order to ensure that the stars in the sample are free of various sources of astrometric noise that might impede the detection of planets, we have initiated programs to collect photometry, high contrast images, interferometric data and radial velocities for stars in both the Northern and Southern hemispheres. We have completed a high contrast imaging survey of target stars in Taurus and the Pleiades and found no definitive common proper motion companions within one arcsecond (140 AU) of the SIM targets. Our radial velocity surveys have shown that many of the target stars in Sco-Cen are fast rotators and a few stars in Taurus and the Pleiades may have sub-stellar companions. Interferometric data of a few stars in Taurus show no signs of stellar or sub-stellar companions with separations of <5 mas. The photometric survey suggests that approximately half of the stars initially selected for this program are variable to a degree (1 sigma>0.1 mag) that would degrade the astrometric accuracy achievable for that star. While the precursor programs are still a work in progress, we provide a comprehensive list of all targets ranked according to their viability as a result of the observations taken to date. By far, the observable that moves the most targets from the SIM-YSO program is photometric variability. ", "machine_text": "  We present a preliminary design and analysis for a possible SIM PlanetQuest Key Project that would combine archival and new observations of young stars with giant planet detectability surveys to establish the occurrence and frequency of gas giant planets around low-mass stars (M\u22c5<< 2M\u2299), including those that are not gravitationally bound. We would detect these planets via their transit signatures as they pass in front of their host stars. We analyze the yield of such a survey with respect to various planet occurrence rates, orbital parameters, star spectral types, and telescope aperture. We find that PlanetQuest-scale telescopes could detect dozens of gas giants in low-mass star systems with an occurrence rate as low as 5%. We present a sample of targets, including several dozen M dwarf stars that are known to host giant planets, for which archival data may already be available, as well as a sample of over 100 young stars in the solar neighborhood that could be surveyed with current technology. We show that the sensitivity of a survey to detect a given planet depends sensitively on the star's spectral type and planet orbital parameters, and discuss the implications of this survey for understanding planet formation, evolution, and atmospheres.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Suzaku Observations of Active Galactic Nuclei Detected in the Swift/BAT   Survey: Discovery of \"New Type\" of Buried Supermassive Black Holes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1168, "human_text": "  We present the Suzaku broad band observations of two AGNs detected by the Swift/BAT hard X-ray (>15 keV) survey that did not have previous X-ray data, Swift J0601.9-8636 and Swift J0138.6-4001. The Suzaku spectra reveals in both objects a heavily absorbed power law component with a column density of NH =~ 10^{23.5-24} cm^{-2} that dominates above 10 keV, and an intense reflection component with a solid angle >~ $2\\pi$ from a cold, optically thick medium. We find that these AGNs have an extremely small fraction of scattered light from the nucleus, <~ 0.5% with respect to the intrinsic power law component. This indicates that they are buried in a very geometrically-thick torus with a small opening angle and/or have unusually small amount of gas responsible for scattering. In the former case, the geometry of Swift J0601.9-8636 should be nearly face-on as inferred from the small absorption for the reflection component. The discovery of two such objects in this small sample implies that there must be a significant number of yet unrecognized, very Compton thick AGNs viewed at larger inclination angles in the local universe, which are difficult to detect even in the currently most sensitive optical or hard X-ray surveys. ", "machine_text": "  We present Suzaku observations of 22 active galactic nuclei (AGN) detected in the Swift/ BAT survey, and find that they are all of the so-called \"new type\" of buried supermassive black holes (SMBH), which is characterized by very low levels of optical and NIR emission and by the presence of a obscuring torus around the black hole. We show that the accretion efficiency of the SMBH in the \"new type\" AGN is, on average, 1-2 orders of magnitude lower than that of the \"old type\" SMBH, and discuss the implications for the formation and evolution of SMBH and for the theory of accretion disc instabilities. We also show that the \"new type\" SMBH is less efficiently accreting than the SMBH in the \"old type\" AGN even at low accretion rates, and that the accretion efficiency is correlated with the accretion rate, which implies that the accretion disc is more stable than expected in the low- accretion-rate regime. We discuss the possibility that the \"new type\" SMBH is in a different evolutionary stage from the \"old type\" SMBH.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Analysis and packaging of radiochemical solar neutrino data. 1. Bayesian   approach. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2192, "human_text": "  According to current practice, the results of each run of a radiochemical solar neutrino experiment comprise an estimate of the flux and upper and lower error estimates. These estimates are derived by a maximum-likelihood procedure from the times of decay events in the analysis chamber. This procedure has the following shortcomings: (a) Published results sometimes include negative flux estimates. (b) Even if the flux estimate is non-negative, the probability distribution function implied by the flux and error estimates will extend into negative territory; and (c) The overall flux estimate derived from the results of a sequence of runs may differ substantially from an estimate made by a global analysis of all of the timing data taken together. These defects indicate that the usual packaging of data in radiochemical solar neutrino experiments provides an inadequate summary of the data, which implies a loss of information. This article reviews this problem from a Bayesian perspective, and suggests an alternative scheme for the packaging of radiochemical solar neutrino data, which is we believe free from the above objections. ", "machine_text": "  We have developed a new method for analyzing and packaging radiochemical solar neutrino data based on a Bayesian approach. The new method is more flexible and more powerful than the conventional method and can be used to extract the neutrino flux with better accuracy and to measure the relative energy spectrum of solar neutrinos. The conventional method is based on a least-square technique that has several limitations. The main drawbacks of the conventional method are that the model parameters cannot be obtained independently and that the statistical errors in the model parameters are not traceable. The new method overcomes these limitations and can be used to study the energy spectrum of solar neutrinos. The new method is more general and more flexible than the conventional method and can be used to analyze various types of radiochemical data, such as data from different types of detectors and data with different formats. The new method can be used to extract the neutrino flux with better accuracy and to measure the relative energy spectrum of solar neutrinos. The new method is based on a Bayesian approach that has been used to analyze various types of data, such as astronomical data, medical data, and data from particle physics experiments.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Finite-size effects in roughness distribution scaling. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1307, "human_text": "  We study numerically finite-size corrections in scaling relations for roughness distributions of various interface growth models. The most common relation, which considers the average roughness $<w_2>$ as scaling factor, is not obeyed in the steady states of a group of ballistic-like models in 2+1 dimensions, even when very large system sizes are considered. On the other hand, good collapse of the same data is obtained with a scaling relation that involves the root mean square fluctuation of the roughness, which can be explained by finite-size effects on second moments of the scaling functions. We also obtain data collapse with an alternative scaling relation that accounts for the effect of the intrinsic width, which is a constant correction term previously proposed for the scaling of $<w_2>$. This illustrates how finite-size corrections can be obtained from roughness distributions scaling. However, we discard the usual interpretation that the intrinsic width is a consequence of high surface steps by analyzing data of restricted solid-on-solid models with various maximal height differences between neighboring columns. We also observe that large finite-size corrections in the roughness distributions are usually accompanied by huge corrections in height distributions and average local slopes, as well as in estimates of scaling exponents. The molecular-beam epitaxy model of Das Sarma and Tamborenea in 1+1 dimensions is a case example in which none of the proposed scaling relations works properly, while the other measured quantities do not converge to the expected asymptotic values. Thus, although roughness distributions are clearly better than other quantities to determine the universality class of a growing system, it is not the final solution for this task. ", "machine_text": "  We consider statistical scaling laws for the roughness distribution in an unstable elementary particle driven by a small external drive, in the limit of large system size. The analysis is based on a stochastic interpretation of the roughness distribution. It is shown that a power law scaling of the statistical variance of the roughness with the system size is compatible with the possibility of finite size effects in the underlying stochastic dynamics, provided that the drive is not too large. The most relevant physical example is that of a small drive oscillating at the edge of a Hopfield stability window of a financial market. In this case, power law variance scaling may signal a Hopfield transition to a new stable state. We show that, if this happens, a scale invariant regime, in which the variance of the roughness remains constant when the system size is increased, ensues. We also analyze the case of a large drive and show that in this case the variance of the roughness is driven to zero in the large system size limit, without any finite size effects. Our results suggest that finite size effects in statistical roughness scaling are potentially relevant for critical transitions in financial markets and in other critical systems with small drives.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Modelling the energy dependencies of high-frequency QPO in black hole   X-ray binaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3394, "human_text": "  We model energy dependencies of the quasi periodic oscillations (QPO) in the model of disc epicyclic motions, with X-ray modulation caused by varying relativistic effects. The model was proposed to explain the high frequency QPO observed in X-ray binaries. We consider two specific scenarios for the geometry of accretion flow and spectral formation. Firstly, a standard cold accretion disc with an active X-ray emitting corona is assumed to oscillate. Secondly, only a hot X-ray emitting accretion flow oscillates, while the cold disc is absent at the QPO radius. We find that the QPO spectra are generally similar to the spectrum of radiation emitted at the QPO radius, and they are broadened by the relativistic effects. In particular, the QPO spectrum contains the disc component in the oscillating disc with a corona scenario. We also review the available data on energy dependencies of high frequency QPO, and we point out that they appear to lack the disc component in their energy spectra. This would suggest the hot flow geometry in the spectral states when high frequency QPO are observed. ", "machine_text": " We present a new model for the description of the energy dependencies of high-frequency quasinormal modes (QNMs) in black hole X-ray binaries. The model is based on the consideration of the equal-frequency contours in the portrait of the integrable contact interaction kernel. The model provides an explanation for the observed energy dependences of QNMs in terms of the non-monotonic structure of the integrable kernel and the related concentration of the coherent energy flux in the low-frequency region. The practical use of the model is illustrated by application to the analysis of the energy dependences of the QNMs in the black hole X-ray binaries HS 1700+1458 and 4U 1705-44.   We find that in both cases the low-frequency QNMs dominate the high-frequency QNMs and the concentrations of the coherent energy flux in the low-frequency region are in good agreement with the model expectations. In addition, the model provides an explanation for the observed ''hole punching'' effect in the energy distribution of QNMs. We also discuss the relevance of the model for the description of the energy dependences of QNMs in electromagneticarkers and X-ray sources in general.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Photon wave mechanics and position eigenvectors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3196, "human_text": "  One and two photon wave functions are derived by projecting the quantum state vector onto simultaneous eigenvectors of the number operator and a recently constructed photon position operator [Phys. Rev A 59, 954 (1999)] that couples spin and orbital angular momentum. While only the Landau-Peierls wave function defines a positive definite photon density, a similarity transformation to a biorthogonal field-potential pair of positive frequency solutions of Maxwell's equations preserves eigenvalues and expectation values. We show that this real space description of photons is compatible with all of the usual rules of quantum mechanics and provides a framework for understanding the relationships amongst different forms of the photon wave function in the literature. It also gives a quantum picture of the optical angular momentum of beams that applies to both one photon and coherent states. According to the rules of qunatum mechanics, this wave function gives the probability to count a photon at any position in space. ", "machine_text": "  We investigate the momentum and position wave mechanics of a photon. We show that the continuity equation, which corresponds to the continuity of the momentum density, is satisfied only if the momentum of a photon is related to its frequency and its velocity is equal to the speed of light. Within this framework, we derived the stationary-state solutions of the equation of continuity, which describe the elementary excitations of the momentum field. We found that the solution which corresponds to a free photon has a special structure. It is a superposition of two momentum waves, which have different frequencies and beat against each other. We also investigated the time-evolution of this state and derived the equation for the wave function, which describes the motion of a photon in a paramagnetic medium. The equation has a simple form, which allows one to solve it analytically and to investigate the dynamics of a photon in detail.  We also considered the problem of finding the position eigenvectors of the stress-energy tensor. We found that the problem can be solved analytically, provided that the symmetrical properties of the tensor are used. The solution shows that the position eigenvectors form a three-dimensional vortex, whose axis is the Poynting vector. We investigated the structure of this vortex and obtained the equations for the position, momentum, and velocity of the vortex core. We also derived an expression for the vortex core energy.  The results of this work can be used to solve various practical problems in photonics, which deal with the dynamics of photons in paramagnetic media. Our results show that the motion of a photon in such a medium can be well described by a simple equation, which has a meaningful physical meaning and can be solved analytically.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: CCD BV survey of 42 open clusters. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1364, "human_text": "  We present results of a photometric survey whose aim was to derive structural and astrophysical parameters for 42 open clusters. While our sample is definitively not representative of the total open cluster sample in the Galaxy, it does cover a wide range of cluster parameters and is uniform enough to allow for simple statistical considerations. BV wide-field CCD photometry was obtained for open clusters for which photometric, structural, and dynamical evolution parameters were determined. The limiting and core radii were determined by analyzing radial density profiles. The ages, reddenings, and distances were obtained from the solar metallicity isochrone fitting. The mass function was used to study the dynamical state of the systems, mass segregation effect and to estimate the total mass and number of cluster members. This study reports on the first determination of basic parameters for 11 out of 42 observed open clusters. The angular sizes for the majority of the observed clusters appear to be several times larger than the catalogue data indicate. The core and limiting cluster radii are correlated and the latter parameter is 3.2 times larger on average. The limiting radius increases with the cluster's mass, and both the limiting and core radii decrease in the course of dynamical evolution. For dynamically not advanced clusters, the mass function slope is similar to the universal IMF slope. For more evolved systems, the effect of evaporation of low-mass members is clearly visible. The initial mass segregation is present in all the observed young clusters, whereas the dynamical mass segregation appears in clusters older than about log(age)=8. Low-mass stars are deficient in the cores of clusters older than log(age)=8.5 and not younger than one relaxation time. ", "machine_text": "  We present a catalog of cluster member stars selected from a non-simultaneous, non- integrations of high-resolution, near-infrared images obtained with the Hubble Space Telescope's Wide Field and Planetary Camera 2. The catalog contains 42 open clusters, most of which are members of the Milky Way's thin disk. Our selection method, based on color-magnitude diagrams, has proven effective in rejecting field stars and foreground objects. We discuss the clusters' properties, including their temperatures, metallicities, distances, and age, as derived from an analysis of their color-magnitude diagrams and the cluster membership probabilities. We have verified our selection method by comparing the clusters' member stars with those from a previous catalog based on a simultaneous, two-color imaging survey. We find that our selection method agrees with the previous one, with an overlap of 89% of clusters and 94% of stars. We have compared our clusters to those in the literature and find that they are, in general, metal-poor, younger, and lie at larger distances than the clusters in the solar neighborhood. The probability distribution of the clusters' member stars is consistent with a single-zone cluster model with a double-pendulum formation in the outer regions, which is nearly unique to the thin-disk stellar population. Our catalog will be useful in the study of the dynamical and chemical evolution of the thin disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ordering phenomena in quasi one-dimensional organic conductors. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2135, "human_text": "  Low-dimensional organic conductors could establish themselves as model systems for the investigation of the physics in reduced dimensions. In the metallic state of a one-dimensional solid, Fermi-liquid theory breaks down and spin and charge degrees of freedom become separated. But the metallic phase is not stable in one dimension: as the temperature is reduced, the electronic charge and spin tend to arrange themselves in an ordered fashion due to strong correlations. The competition of the different interactions is responsible for which broken-symmetry ground state is eventually realized in a specific compound and which drives the system towards an insulating state.   Here we review the various ordering phenomena and how they can be identified by optic and magnetic measurements. While the final results might look very similar in the case of a charge density wave and a charge-ordered metal, for instance, the physical cause is completely different. When density waves form, a gap opens in the density of states at the Fermi energy due to nesting of the one-dimension Fermi surface sheets. When a one-dimensional metal becomes a charge-ordered Mott insulator, on the other hand, the short-range Coulomb repulsion localizes the charge on the lattice sites and even causes certain charge patterns.   We try to point out the similarities and conceptional differences of these phenomena and give an example for each of them. Particular emphasis will be put on collective phenomena which are inherently present as soon as ordering breaks the symmetry of the system. ", "machine_text": " We have investigated ordering phenomena in quasi one-dimensional organic conductors, specifically, in a model system consisting of a chain of regularly spaced acceptor sites embedded in a conducting organic matrix. Our results show that an applied electric field can induce a phase transition from a disordered conducting state to a ordered state with a sharp peak in the conductance at the threshold field. We have observed long-range ordering of the charge carriers as well as short-range ordering of the phases. Our results suggest that similar ordering phenomena may occur in other quasi one-dimensional organic conductors and organic magnets.  We have investigated the influence of an applied electric field on the transport properties of a quasi one-dimensional organic conductor, specifically, on a model system consisting of a chain of regularly spaced acceptor sites embedded in a conducting organic matrix. Our results show that an applied electric field can induce a phase transition from a disordered conducting state to a ordered state with a sharp peak in the conductance at the threshold field. We have observed long-range ordering of the charge carriers as well as short-range ordering of the phases. Our results suggest that similar ordering phenomena may occur in other quasi one-dimensional organic conductors and organic magnets.  We have investigated ordering phenomena in quasi one-dimensional organic conductors, specifically, in a model system consisting of a chain of regularly spaced acceptor sites embedded in a conducting organic matrix. Our results show that an applied electric field can induce a phase transition from a disordered conducting state to a ordered state with a sharp peak in the conductance at the threshold field. We have observed long-range ordering of the charge carriers as well as short-range ordering of the phases. Our results suggest that similar ordering phenomena may occur in other quasi one-dimensional organic conductors and organic magnets.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: (Non) Gauge Invariance of Wilsonian Effective Actions in   (Supersymmetric) Gauge Theories : A Critical Discussion. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0362, "human_text": "  We give a detailed critical discussion of the properties of Wilsonian effective actions, defined by integrating out all modes above a given scale $\\mu$. In particular, we provide a precise and relatively convenient prescription how to implement the infrared cutoff $\\mu$ in any loop integral that is manifestly Lorentz invariant and also preserves global linear symmetries such as e.g. supersymmetry. We discuss the issue of gauge invariance of effective actions in general and in particular when using background field gauge. Our prescription for the IR cutoff (as any such prescription) breaks the gauge symmetry. Using our prescription, we have explicitly computed, at one loop, many terms of the Wilsonian effective action for general gauge theories, involving bosonic and fermionic matter fields of arbitrary masses and in arbitrary representations, exhibiting the non-gauge invariant (as well as the gauge invariant) terms. However, for supersymmetric gauge theories all non-gauge invariant terms cancel within each supermultiplet. This is strong evidence that in supersymmetric gauge theories this indeed defines a Lorentz, susy and gauge invariant Wilsonian effective action. As a byproduct, we obtain the explicit one-loop Wilsonian couplings for all higher-derivative terms $F D^{2n}F$ in the effective action of arbitrary supersymmetric gauge theories. ", "machine_text": " We discuss the (non) gauge invariance of effective actions in gauge theories with a view towards clarifying the relation between the different notions of gauge invariance which are commonly used in the context of effective actions. In particular we focus on the question of whether the most commonly used definition of gauge invariance is the appropriate one in this context. We show that in general the answer is no, and that the standard definition is only meaningful if the effective action is understood as an effective Lagrangian density. We also review the notion of a gauge transformation as used in effective field theory and discuss the relation to the more abstract definition of a gauge transformation as a mapping which takes each physical state to a new state which is related by the Poincar\u00e9 group. We show that the standard definition of gauge invariance of effective actions is equivalent to the statement that the Poincare group acts on the space of effective Lagrangian densities. We finally discuss the relation of our results to the question of whether effective actions are unique.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Graviton Propagator in a Covariant Massive Gravity Theory. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1561, "human_text": "  We study the massive gravity theory proposed by Arkani-Hamed, Georgi and Schwartz. In this theory, the graviton becomes massive when general covariance is spontaneously broken through the introduction of a field that links two metrics, one of the which will eventually decouple. The excitation of this \"link\" field acts like a Goldstone boson in giving mass to the graviton. We work out the graviton and Goldstone boson propagators explicitly by means of gauge fixing terms similar to the renormalizability gauges used in gauge theories. With these propagators, we calculate the lowest order tree-level interaction between two external energy momentum tensors. The result is independent of the gauge parameter, but different from the prediction of massless gravity theory, i.e., general relativity. This difference remains even if the mass of the graviton goes to zero, in which case it gives the van Dam-Veltman-Zakharov (vDVZ) discontinuity between the propagators of a massive and massless linearized graviton. Moreover, we show that the Fierz-Pauli graviton mass term can be considered as the ``unitary gauge'' of a more general theory with an extra scalar field. We explicitly construct such a theory in which the vDVZ discontinuity arises with a graviton mass term that is different from the Fierz-Pauli mass term. This theory has a local Weyl symmetry under conformal transformations of the metric. In the case when the mass goes to zero, the Weyl summetry becomes a global symmetry. It is possible that the local Weyl symmetry will give a hint as to the form of the corresponding fully nonlinear theory having a nonzero graviton mass. ", "machine_text": "  We consider a covariant massive gravity theory in which the graviton propagator is a product of a scalar field and its dual tensor field. We show that this theory can be made symmetric under the exchange of the graviton and the dual tensor field, which is not the case in the standard theory. The resulting theory can be further simplified by using the constraint that the trace of the tensor field is proportional to the scalar field. The propagator obtained is shown to be symmetric and we further show that it can be written as a sum of two propagators, one of which is the standard graviton propagator in massive gravity and the other is a dual tensor field propagator. We further generalize this result to a theory with a non-minimally coupled scalar field and show that the propagator can always be expressed as a sum of two propagators, one of which is the standard graviton propagator and the other is a dual tensor field propagator. This result suggests that the non-minimally coupled scalar field has a meaningful physical interpretation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Galactic dark matter as a bulk effect on the brane. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2496, "human_text": "  The behavior of the angular velocity of a test particle moving in a stable circular orbit in the vacuum on the brane is considered. In the brane world scenario, the four dimensional effective Einstein equation acquire extra terms, called dark radiation and dark pressure, respectively, which arise from the embedding of the 3-brane in the bulk. A large number of independent observations have shown that the rotational velocities of test particles gravitating around galaxies tend, as a function of the distance from the galactic center, toward constant values. By assuming a constant tangential velocity, the general solution of the vacuum gravitational field equations on the brane can be obtained in an exact analytic form. This allows us to obtain the explicit form of the projections of the bulk Weyl tensor on the brane, and the equation of state of the dark pressure as a function of the dark radiation. The physical and geometrical quantities are expressed in terms of observable/measurable parameters, like the tangential velocity, the baryonic mass and the radius of the galaxy. We also analyze the dynamics of test particles by using methods from the qualitative analysis of dynamical systems, by assuming a simple linear equation of state for the dark pressure. The obtained results provide a theoretical framework for the observational testing at the extra-galactic scale of the predictions of the brane world models. ", "machine_text": " We have developed a theory of the structure and evolution of galactic haloes based on the idea that they are bulk effects of the matter distribution in the Galactic brane. In this picture, the haloes are seen as spatial modulations of the matter density, with a strength that depends on the total matter content of the Galaxy, and with a scale that depends on the bulk flow speed. We show that this theory naturally explains several properties of the observed haloes, such as their growth with galaxy's matter content, their peaked structure, and the large scatter in the observed sizes. We also show that the theory predicts a correlation between the bulk flow speed and the halo scale, which is in agreement with the observations. Our results suggest that the evolution of the haloes is driven by the bulk flow, and that the local matter distribution only has a minor effect.  We have constructed a cosmological model that naturally explains the observed correlation between the bulk flow speed and the halo scale. In our model, the haloes are bulk effects of the matter distribution in the brane, and they grow with the total matter content of the system. We show that this model predicts a correlation between the bulk flow speed and the halo scale, which is in agreement with the observations. Our results suggest that the evolution of the haloes is driven by the bulk flow, and that the local matter distribution only has a minor effect.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Longitudinal impedance and wake from XFEL undulators. Impact on   current-enhanced SASE schemes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.228, "human_text": "  In this article we derive longitudinal impedance and wake function for an undulator setup with arbitrary undulator parameter, taking into account a finite transverse size of the electron bunch. Earlier studies considered a line density-distribution of electrons instead. We focus our attention on the long-wavelength asymptote (compared with resonance wavelength), at large distance of the electron bunch from the undulator entrance compared to the overtaking length, and for large vacuum-chamber size compared to the typical transverse size of the field. These restrictions define a parameter region of interest for practical applications. We calculate a closed expression for impedance and wake function that may be evaluated numerically in the most general case. Such expression allows us to derive an analytical solution for a Gaussian transverse and longitudinal bunch shape. Finally, we study the feasibility of current-enhanced SASE schemes (ESASE) recently proposed for LCLS, that fall well-within our approximations. Numerical estimations presented in this paper indicate that impedance-induced energy spread is sufficient to seriously degrade the FEL performance. Our conclusion is in contrast with results in literature, where wake calculations for the LCLS case are given in free-space, as if the presence of the undulator were negligible. ", "machine_text": "  We investigate the impact of longitudinal impedance and wake from X-ray Free-Electron Lasers (XFELs) on current-enhanced schemes for SASE amplification. We consider the particular case of the FERMI@Elettra XFEL, which is an XFEL with a passive resonant cavity that provides a high-repetition-rate ultra-short pulse source in the energy range above 10 keV. We model the XFEL as a voltage-controlled current source in series with a variable resistance and a capacitor. The model allows us to evaluate the impedance of the XFEL as a function of the X-ray energy and the repetition rate. We find that the resulting impedance can be described by a sum of a low-frequency (RF) resistance and a high-frequency (zero-order) resistance. We then use a simple model to evaluate the wake in the X-ray energy range above 10 keV. We consider the particular case of a XFEL wake containing a single spot in the cross-sectional plane and a Gaussian distribution in the longitudinal direction. We find that, for XFELs with a high-repetition-rate (above 1 Hz) and high-energy (above 10 keV), the wake can be approximated by a short-circuit in the cross-sectional plane. We finally evaluate the impact of the XFEL impedance and wake on the current-enhanced scheme. We find that the XFEL wake creates a condition for a stable self-sustained electron discharge. We discuss the practical implications of our findings and their consequences for future research.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Empirical Photometric Redshifts of Luminous Red Galaxies and Clusters in   SDSS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.158, "human_text": "  In this work I discuss the necessary steps for deriving photometric redshifts for luminous red galaxies (LRGs) and galaxy clusters through simple empirical methods. The data used is from the Sloan Digital Sky Survey (SDSS). I show that with three bands only ({\\it gri}) it is possible to achieve results as accurate as the ones obtained by other techniques, generally based on more filters. In particular, the use of the $(g-i)$ color helps improving the final redshifts (especially for clusters), as this color monotonically increases up to $z \\sim 0.8$. For the LRGs I generate a catalog of $\\sim 1.5$ million objects at $z < 0.70$. The accuracy of this catalog is $\\sigma = 0.027$ for $z \\le 0.55$ and $\\sigma = 0.049$ for $0.55 < z \\le 0.70$. The photometric redshift technique employed for clusters is independent of a cluster selection algorithm. Thus, it can be applied to systems selected by any method or wavelength, as long as the proper optical photometry is available. When comparing the redshift listed in literature to the photometric estimate, the accuracy achieved for clusters is $\\sigma = 0.024$ for $z \\le 0.30$ and $\\sigma = 0.037$ for $030 < z \\le 0.55$. However, when considering the spectroscopic redshift as the mean value of SDSS galaxies on each cluster region, the accuracy is at the same level as found by other authors: $\\sigma = 0.011$ for $z \\le 0.30$ and $\\sigma = 0.016$ for $030 < z \\le 0.55$. The photometric redshift relation derived here is applied to thousands of cluster candidates selected elsewhere. I have also used galaxy photometric redshifts available in SDSS to identify groups in redshift space and then compare the redshift peak of the nearest group to each cluster redshift (ABRIDGED). ", "machine_text": "  We present an empirical method for determining the redshift of galaxies and clusters from their photometric redshifts in the SDSS. We determine the photo-redshift probability distribution function as a function of redshift, for galaxies in the SDSS whose redshift has already been determined spectroscopically. We show that the empirical distribution is consistent with the redshift being proportional to the observed shift in the color of the galaxies. We apply the method to a sample of luminous red galaxies (LRGs) and clusters in the SDSS, and determine the redshift of these galaxies and clusters. For the LRGs in our sample, we find that their redshifts are in the range 1.12 < z < 2.18, with a peak at 1.44. The average redshift of the clusters in our sample is 1.37, with a standard deviation of 0.07. We compare the distribution of the redshifts of our sample galaxies and clusters to the distribution expected from the photo-redshift probability distribution function, and find that they are consistent with each other. We conclude that the photo-redshift method is reliable for determining the redshift of galaxies and clusters in the SDSS.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for Heavy Neutral MSSM Higgs Bosons with CMS: Reach and   Higgs-Mass Precision. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0619, "human_text": "  The search for MSSM Higgs bosons will be an important goal at the LHC. We analyze the search reach of the CMS experiment for the heavy neutral MSSM Higgs bosons with an integrated luminosity of 30 or 60 fb^-1. This is done by combining the latest results for the CMS experimental sensitivities based on full simulation studies with state-of-the-art theoretical predictions of MSSM Higgs-boson properties. The results are interpreted in MSSM benchmark scenarios in terms of the parameters tan_beta and the Higgs-boson mass scale, M_A. We study the dependence of the 5 sigma discovery contours in the M_A-tan_beta plane on variations of the other supersymmetric parameters. The largest effects arise from a change in the higgsino mass parameter mu, which enters both via higher-order radiative corrections and via the kinematics of Higgs decays into supersymmetric particles. While the variation of $\\mu$ can shift the prospective discovery reach (and correspondingly the ``LHC wedge'' region) by about Delta tan_beta = 10, we find that the discovery reach is rather stable with respect to the impact of other supersymmetric parameters. Within the discovery region we analyze the accuracy with which the masses of the heavy neutral Higgs bosons can be determined. We find that an accuracy of 1-4% should be achievable, which could make it possible in favourable regions of the MSSM parameter space to experimentally resolve the signals of the two heavy MSSM Higgs bosons at the LHC. ", "machine_text": "  We present a search for heavy neutral MSSM Higgs bosons in the CMS final state with two un-correlated jets and a large missing ets. The analysis is based on the ets-channel results of a previously proposed method that uses the b-quark decay products to enhance the signal over the background. The method is tested on the LHC pp collisions at \\sqrt{s}=8 TeV, using a sample of events with b-jet and missing ets. We find 2 events in the signal region, compared to an expectation of 1.3+-0.7 events, corresponding to a significance of 2.1 standard deviations above the background. The observed cross section times the branching fraction is 2.5+-0.8 times the standard model prediction for a Higgs boson with a mass of 100 GeV/c^2, assuming that the Higgs boson is produced in association with a Z-boson and the Z-boson decays to neutrinos. We interpret this result as a search for heavy neutral Higgs bosons in the MSSM framework, with a mass of 100 GeV/c^2 or more, and we find no evidence for such bosons.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Concise theory of chiral lipid membranes. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.2707, "human_text": "  A theory of chiral lipid membranes is proposed on the basis of a concise free energy density which includes the contributions of the bending and the surface tension of membranes, as well as the chirality and orientational variation of tilting molecules. This theory is consistent with the previous experiments [J.M. Schnur \\textit{et al.}, Science \\textbf{264}, 945 (1994); M.S. Spector \\textit{et al.}, Langmuir \\textbf{14}, 3493 (1998); Y. Zhao, \\textit{et al.}, Proc. Natl. Acad. Sci. USA \\textbf{102}, 7438 (2005)] on self-assembled chiral lipid membranes of DC$_{8,9}$PC. A torus with the ratio between its two generated radii larger than $\\sqrt{2}$ is predicted from the Euler-Lagrange equations. It is found that tubules with helically modulated tilting state are not admitted by the Euler-Lagrange equations, and that they are less energetically favorable than helical ripples in tubules. The pitch angles of helical ripples are theoretically estimated to be about 0$^\\circ$ and 35$^\\circ$, which are close to the most frequent values 5$^\\circ$ and 28$^\\circ$ observed in the experiment [N. Mahajan \\textit{et al.}, Langmuir \\textbf{22}, 1973 (2006)]. Additionally, the present theory can explain twisted ribbons of achiral cationic amphiphiles interacting with chiral tartrate counterions. The ratio between the width and pitch of twisted ribbons is predicted to be proportional to the relative concentration difference of left- and right-handed enantiomers in the low relative concentration difference region, which is in good agreement with the experiment [R. Oda \\textit{et al.}, Nature (London) \\textbf{399}, 566 (1999)]. ", "machine_text": "  We propose a concise theory of chiral lipid membranes, which describes their structure, symmetry, and dynamic properties in terms of a small number of fundamental parameters. Our theory is based on the assumption that the chiral lipids form a structural network in which the hydrophobic parts of the molecules, due to their strong tendency to avoid water, are highly cross-linked, whereas the hydrophilic parts form an elastic matrix that can accommodate a large amount of water. The theory predicts that the initial static structure of a membrane will have an helical symmetry, due to the chiral nature of the lipids. However, this symmetry will be broken by the addition of water, which will induce a dynamic transition to a structures with a weaker symmetry, such as a lamellar or cubic phases. We show that the theory can quantitatively describe the main features of the dynamic transition, such as the temperature dependence of the mean lifetime of the different phases, and the dependence of the structure and dynamics on the concentration of the lipid. Our results suggest that the dynamics of the transition is governed by the elastic properties of the hydrophilic part of the lipids, and that the strong cross-linking of the hydrophobic part is responsible for the large number of possible alternative structures that can be stabilized by the addition of water.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: XO-2b: Transiting Hot Jupiter in a Metal-rich Common Proper Motion   Binary. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0003, "human_text": "  We report on a V=11.2 early K dwarf, XO-2 (GSC 03413-00005), that hosts a Rp=0.98+0.03/-0.01 Rjup, Mp=0.57+/-0.06 Mjup transiting extrasolar planet, XO-2b, with an orbital period of 2.615857+/-0.000005 days. XO-2 has high metallicity, [Fe/H]=0.45+/-0.02, high proper motion, mu_tot=157 mas/yr, and has a common proper motion stellar companion with 31\" separation. The two stars are nearly identical twins, with very similar spectra and apparent magnitudes. Due to the high metallicity, these early K dwarf stars have a mass and radius close to solar, Ms=0.98+/-0.02 Msolar and Rs=0.97+0.02/-0.01 Rsolar. The high proper motion of XO-2 results from an eccentric orbit (Galactic pericenter, Rper<4 kpc) well confined to the Galactic disk (Zmax~100 pc). In addition, the phase space position of XO-2 is near the Hercules dynamical stream, which points to an origin of XO-2 in the metal-rich, inner Thin Disk and subsequent dynamical scattering into the solar neighborhood. We describe an efficient Markov Chain Monte Carlo algorithm for calculating the Bayesian posterior probability of the system parameters from a transit light curve. ", "machine_text": "  We present phase-resolved transit photometry and transit spectroscopy of the hot Jupiter XO-2b as observed with the Hubble Space Telescope. We determine the orbital elements of the inner binary, finding a period of 87.5 \u00b1 0.3 min and a roughly equal-mass, low-inclination configuration. We measure the radius of XO-2b to be 1.325 RJ (1.013 R\u2299), which is larger than predicted by most prior estimates. We find the metallicity of XO-2b to be [Fe/H] = +0.10 \u00b1 0.09, which is significantly higher than the typical value for giant planets of [Fe/H] \u223c +0.01. The photometric phase curve is well described by a model in which the semi-major axis of the orbit is a linear function of phase. We fit the transit data with a model in which the metal-rich atmosphere produces a large pressure-induced recession of the effective stellar gravity from the visible disk, resulting in a very low limb-darkening slope and a nearly linear radial profile. The resulting regression gives a bulk density of \u03c1 = 0.71 \u00b1 0.06 \u03c1\u2299. This is only slightly higher than the value derived from a simple model in which the planet is treated as a uniform density sphere, \u03c1 = 0.66 \u03c1\u2299, but much lower than the value derived from a model in which the atmosphere has the same metallicity as the host star, \u03c1 = 1.31 \u03c1\u2299. We discuss these density models and their implications for atmospheric structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Iron line profiles and self-shadowing from relativistic thick accretion   discs. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.1796, "human_text": "  We present Fe Kalpha line profiles from and images of relativistic discs with finite thickness around a rotating black hole using a novel code. The line is thought to be produced by iron fluorescence of a relatively cold X-ray illuminated material in the innermost parts of the accretion disc and provides an excellent diagnostic of accretion flows in the vicinity of black holes. Previous studies have concentrated on the case of a thin, Keplerian accretion disc. This disc must become thicker and sub-Keplerian with increasing accretion rates. These can affect the line profiles and in turn can influence the estimation of the accretion disc and black hole parameters from the observed line profiles. We here embark on, for the first time, a fully relativistic computation which offers key insights into the effects of geometrical thickness and the sub-Keplerian orbital velocity on the line profiles. We include all relativistic effects such as frame-dragging, Doppler boost, time dilation, gravitational redshift and light bending. We find that the separation and the relative height between the blue and red peaks of the line profile diminish as the thickness of the disc increases. This code is also well-suited to produce accretion disc images. We calculate the redshift and flux images of the accretion disc and find that the observed image of the disc strongly depends on the inclination angle. The self-shadowing effect appears remarkable for a high inclination angle, and leads to the black hole shadow being completely hidden by the disc itself. ", "machine_text": " We present a systematic study of the effect of self-shadowing in the observed iron line profiles in spectroscopic observations of active galactic nuclei (AGN). We consider a simplified model of a thick accretion disc around a relativistically rotating supermassive black hole (SMBH), which has been employed previously to explain the so-called unified model of accretion disc lines. In this model the lines are formed by multiple reflections of the stellar light in the accretion disc. In the present work we carefully take into account the physical effects of self-shadowing, which is known to produce a blueshift of the observed lines. We show that self-shadowing produces a systematic shift of the model lines in the direction of the observed lines in low-mass X-ray binaries and AGN, if the SMBH is rotating relativistically and the disc is sufficiently thick. We evaluate the disc thickness for which this effect becomes important, and show that this thickness is consistent with the thickness required to explain the observed trend of line broadening with wavelength in the observed iron line profiles in a large sample of galaxies. We predict that in those galaxies in which the SMBH is rotating relativistically and the accretion disc is thick, the iron lines will be shifted by the effects of self-shadowing in the direction of the observed lines. This prediction can be tested by high-resolution spectroscopy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A Modest Proposal for the Astronomical Community. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0142, "human_text": "  Inspired by a recent astro-ph posting, I propose a creation of an Alternative History astro-ph archive (althistastro-ph). Such an archive would serve as a final resting place for the various telescope (and possibly other) proposals that were not successful. As we all know, from both submitting proposals and also from serving on various time allocation committees, many excellent proposals ``do not make it''. Creating such an AltHist archive would serve many goals, including venting the frustration of the authors and also providing possible amusement for the readers. These are worthy goals, but they alone would not warrant creating such an archive. The truly useful role of AltHistAstro-ph archive would be to match astronomers with unappreciated ideas with other astronomers with underutilized resources, hopefully leading in some cases to resurrection of old proposals and resulting publications in the regular astro-ph archive. Given the possible danger of a low signal-to-noise and possible confusion, a creation of a separate archive seems like a good idea, although it should be noted that low signal-to-noise is achieved on astro-ph quite often already. Finally, I include my own excellent, but rejected (twice), HST proposal, as an example of a potential AltHistAstro-ph posting. ", "machine_text": " We present a modest proposal for the astronomical community. Our motivation is the increasing burden on professional astronomers to secure funding for their research. We argue that the cost of funding astronomical research is high, while the return on investment is low. We show that the number of professional astronomers has grown dramatically over the past century, despite a comparatively small number of discoveries of fundamental importance. We suggest that, given the current state of affairs, professional astronomical research is an inefficient use of resources, and we propose that these resources be reallocated to increase the number of undergraduate students who receive degrees in astronomy. We demonstrate that a modest investment in this proposal would lead to a substantial increase in the number of amateur astronomers. We argue that, given the vastness of the universe and the limitations of human sensory perception, the amateur astronomer has a better chance of making a discovery of fundamental importance than a professional astronomer does. We conclude that the future of astronomical research lies with the amateur astronomer, and we urge professional astronomers to refocus their efforts on educating undergraduate astronomy students.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Nonlocal Excitation Spectra in 2D Doped Hubbard Model. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0581, "human_text": "  Single-particle excitation spectra of the two-dimensional Hubbard model on the square lattice near half filling and at zero temperature are investigated on the basis of the self-consistent projection operator method. The method guarantees a high accuracy of the spectra with high energy and high momentum resolutions. It takes into account long-range intersite correlations as well as the strong on-site correlations. Effects of nonlocal excitations are clarified by comparing the results with those of the single-site approximation. The calculated spectra verify the quantum Monte-Carlo results for finite temperatures. The spectra at the Fermi level yield a hole-like Fermi surface in the underdoped region and an electron-like Fermi surface in the overdoped region. From a numerical analysis of the momentum dependent effective mass and self-energy, it is concluded that a marginal Fermi-liquid like state persists even at finite doping concentrations in the strongly correlated region because a van Hove singularity is pinned to the Fermi surface. It is also found that a kink structure appears in the quasiparticle energy band in the same region. The kink is shown to be caused by a mixing between the quasiparticle band and an excitation band with strong short-range antiferromagnetic correlations. These results suggest an explanation for some of the unusual properties of the normal state in high-$T_{\\rm c}$ cuprates. ", "machine_text": " We investigate the nonlocal excitation spectra in one- and two-dimensional (1D and 2D) doped Hubbard models, which are extensively used to describe unconventional superconductors and thermoelectric materials, respectively. In both cases, we consider the model in the thermodynamic limit, i.e., for an infinite system size, and in the limit of a weak coupling to the thermal reservoir. In 1D, we use an exact diagonalization method and find the temperature dependence of the excitation spectrum, the thermodynamic limit of the thermoelectric figure of merit, and the dependence on the doping level. In 2D, we use a numerical renormalization group technique and find the existence of a Fano factor in the spectrum, whose sign depends on the doping level and the thermal fluctuations. We also find the temperature and size dependence of the spectrum and the thermodynamic limit of the thermoelectric figure of merit. Our results in both cases are consistent with the existence of a finite-size effect, which influences the low-temperature properties of the spectrum and the thermoelectric figure of merit.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Origin of the Galaxy Mass-Metallicity Relation and Implications for   Galactic Outflows. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.31, "human_text": "  (Abridged) Using cosmological hydrodynamic simulations in combination with analytic modeling, we show that the galaxy stellar mass-metallicity relation (MZR) provides strong constraints on galactic outflows across cosmic time. We compare three outflow models: No outflows, a \"constant wind\" (cw) model that emulates the popular Dekel & Silk (1986) scenario, and a ``momentum-driven wind\" (vzw) model. We find that only the vzw scaling reproduces the observed z~2 MZR's slope, amplitude, and scatter. Comparing our fully three-dimensional simulations with a simple one-zone chemical evolution model, we find that the MZR can be understood in terms of three parameters: (1) The equilibrium metallicity Z_eq=y*SFR/ACC (where y=true yield), reflecting the enrichment balance between star formation rate SFR and gas accretion rate ACC; (2) the dilution time t_d=M_g/ACC, representing the timescale for a galaxy to return to Z_eq after a metallicity-perturbing interaction; and (3) the blowout mass M_blowout, which is the galaxy stellar mass above which winds can escape its halo. When outflows with mass loading factor MLF are present, galaxies below M_blowout obey Z_eq = y/(1+MLF), while above M_blowout, Z_eq->y. Our cw model has M_blowout ~ 10^10 M_sun, which yields a sharp upturn in the MZR above this scale and a flat MZR with large scatter below it, in strong disagreement with observations. Our vzw model reproduces the observed Z_g \\propto M_*^0.3 because Z_eq \\propto MLF^-1 \\propto M_*^1/3 when MLF >> 1 (i.e. at low masses). The flattening of the MZR at M_* > 10^10.5 M_sun observed by Tremonti et al. (2004) reflects the mass scale where MLF~1, rather than a characteristic wind speed. The tight observed MZR scatter is ensured when t_d<1 dynamical time, which is only satisified at all masses and epochs in our momentum-driven wind model. ", "machine_text": "  We present here results of a numerical study of the origin of the galaxy mass-metallicity relation in a cosmological hydrodynamical framework. We find that the mass-metallicity relation is naturally explained by an outwards-driven chemically-homogeneous metal-poor accretion flow, where the accretion rate is proportional to the galaxy mass. We show that this relation can be formed in two different ways: (i) by an accretion flow that is uniform in mass but variable in metallicity, or (ii) by an accretion flow that is variable in mass and uniform in metallicity. In both cases the relation is stable against small fluctuations in the accretion flow, provided that the relative metallicity stays small. We discuss the cosmological implications of our results. In particular, we show that if the metallicity of the accretion flow is variable, the relation must have been formed in a very small volume, while if the metallicity is uniform, the relation can be formed in a large volume, provided that the mass of the accretion flow is variable. We also discuss the implications of our results for the origin of the chemical homogeneity of galaxies. We find that a chemically-homogeneous accretion flow, if it is metal-poor, can only be the result of a past massive accretion event, and that such an event must have been rare in the history of the galaxy. We finally comment on the hypothesis that the mass-metallicity relation is due to the evaporation of a massive molecular cloud, and we show that this hypothesis is inconsistent with the present-day distribution of metals in the galactic halo.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Shapes of Molecular Cloud Cores in Orion. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0359, "human_text": "  We investigate the intrinsic shapes of starless cores in the Orion GMC, using the prestellar core sample of Nutter and Ward-Thompson (2007), which is based on submillimeter SCUBA data. We employ a maximum-likelihood method to reconstruct the intrinsic distribution of ellipsoid axial ratios from the axial ratios of projected plane-of-the-sky core ellipses. We find that, independently of the details of the assumed functional form of the distribution, there is a strong preference for oblate cores of finite thickness. Cores with varying finite degrees of triaxiality are a better fit than purely axisymmetric cores although cores close to axisymmetry are not excluded by the data. The incidence of prolate starless cores in Orion is found to be very infrequent. We also test the consistency of the observed data with a uniform distribution of intrinsic shapes, which is similar to those found in gravoturbulent fragmentation simulations. This distribution is excluded at the 0.1% level. These findings have important implications for theories of core formation within molecular clouds. ", "machine_text": "  The Shapes of Molecular Cloud Cores in Orion  We present a catalog of 19 high-mass young stellar objects (YSOs) in the Orion molecular cloud. The data were obtained as part of the Sakai cluster survey with the Nobeyama Radio Observatory Millimeter/Submillimeter Telescope. We targeted a large number of sources which were observed with the WENSSEN (The Wisconsin-Indiana-Norway Superconducting Telescope) and were identified as likely to be high-mass YSOs. The majority of the sources are low-power millimeter sources. We observed these sources in three frequency bands, 42 GHz, 86 GHz, and 150 GHz, with a resolution of 1.3 arcmin. We find that the observed sources are distributed within three regions, which correspond to the regions where the WENSSEN data were obtained. These regions are the Northern Ridge, the Southern Ridge, and the stellar association \u03bd Orionis. We conclude that the non-detections in our survey are due to the following reasons: 1) the objects are very distant and thus appear small, 2) the objects are very compact and thus have a low surface brightness, and 3) the objects are very young and still hidden by the natal cloud. We derive a simple formula which is used to estimate the beaming ratio from the 42 GHz to 150 GHz data. We find that the beaming ratio is in the range of 2-4. We also find that the star formation efficiency in the regions of the Orion cloud we have surveyed is 5-10%. We present a catalog of 19 high-mass YSOs in the Orion cloud. The derived masses are 3-8 times the mass of the sun. The lifetime of the objects is estimated to be in the range of 5-10 thousand years. We find that the observed sources are not well described by a single power law. A possible explanation for this is that the cloud has been shedding stars throughout its lifetime. We discuss the future prospects of the field and the need for a large scale molecular cloud core survey.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The Wiretap Channel with Feedback: Encryption over the Channel. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2259, "human_text": "  In this work, the critical role of noisy feedback in enhancing the secrecy capacity of the wiretap channel is established. Unlike previous works, where a noiseless public discussion channel is used for feedback, the feed-forward and feedback signals share the same noisy channel in the present model. Quite interestingly, this noisy feedback model is shown to be more advantageous in the current setting. More specifically, the discrete memoryless modulo-additive channel with a full-duplex destination node is considered first, and it is shown that the judicious use of feedback increases the perfect secrecy capacity to the capacity of the source-destination channel in the absence of the wiretapper. In the achievability scheme, the feedback signal corresponds to a private key, known only to the destination. In the half-duplex scheme, a novel feedback technique that always achieves a positive perfect secrecy rate (even when the source-wiretapper channel is less noisy than the source-destination channel) is proposed. These results hinge on the modulo-additive property of the channel, which is exploited by the destination to perform encryption over the channel without revealing its key to the source. Finally, this scheme is extended to the continuous real valued modulo-$\\Lambda$ channel where it is shown that the perfect secrecy capacity with feedback is also equal to the capacity in the absence of the wiretapper. ", "machine_text": "  We consider the wiretap channel with feedback, in which the encoder has perfect information on the bits transmitted and the decoder has perfect information on the bits received. We show that if the encoder and the decoder have common knowledge of a random variable, whose value is independent of the bits transmitted, then the channel achieves the same rate as the noiseless wiretap channel. This answers positively a question of Costal and Vaaradhan. We show further that if the decoder does not know the random variable used by the encoder, then the channel achieves a rate that is close to the rate of the noiseless wiretap channel. This answers negatively a question of fireset.  We also study the encryption of the wiretap channel with feedback. We show that if the encryption is done at the encoder, then the encrypted channel achieves the same rate as the channel without encryption. This answers positively a question of Brandstetter and Immorlica. We show further that if the encryption is done at the decoder, then the encrypted channel achieves a rate that is close to the rate of the channel without encryption. This answers negatively a question of Brandstetter and Immorlica.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Gravitational Wave Signals from Chaotic System: A Point Mass with A Disk. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0719, "human_text": "  We study gravitational waves from a particle moving around a system of a point mass with a disk in Newtonian gravitational theory. A particle motion in this system can be chaotic when the gravitational contribution from a surface density of a disk is comparable with that from a point mass. In such an orbit, we sometimes find that there appears a phase of the orbit in which particle motion becomes to be nearly regular (the so-called ``stagnant motion'') for a finite time interval between more strongly chaotic phases. To study how these different chaotic behaviours affect on observation of gravitational waves, we investigate a correlation of the particle motion and the waves. We find that such a difference in chaotic motions reflects on the wave forms and energy spectra. The character of the waves in the stagnant motion is quite different from that either in a regular motion or in a more strongly chaotic motion. This suggests that we may make a distinction between different chaotic behaviours of the orbit via the gravitational waves. ", "machine_text": "  We investigate the possibility of detecting gravitational waves from a chaotic system consisting of a point mass M moving in a planar orbit around a rotating disk. We show that the presence of a quadrupole mode in the gravitational field of the system is guaranteed by the principles of general relativity, provided that the orbit of the point mass is sufficiently close to the equatorial plane of the disk. We evaluate the frequency spectrum of the quadrupole mode and show that it is possible to detect it by laser interferometry. We discuss the problem of extracting the signal from the noise background, due to the chaotic nature of the system, and evaluate the effect of measurement errors on the detectability of the signal. Our analysis shows that it is possible to detect the quadrupole mode from a chaotic system with a relatively small number of detectors, provided that the noise level is sufficiently low. We also evaluate the possibility of using the quadrupole mode as a means of extracting information about the internal structure of the disk.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Systematics of Soft Particle Production at RHIC: Lessons from PHOBOS. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3859, "human_text": "  The PHOBOS experiment has measured the properties of particle production in heavy ion collisions between sqrt(s_NN) of 20 and 200 GeV. The dependencies of charged particle yield on energy, system size, and both longitudinal and transverse momentum have been determined over close to the full kinematic range. Identified charged particles emitted near mid-rapidity have been studied over about 2 orders of magnitude in transverse momentum. This broad data set was found to be characterized by a small number of simple scalings which factorize to a surprising degree. This study has recently been extended by the addition of new data for Cu+Cu as well as new analyses of Au+Au data, including more peripheral collisions. In addition, the exploration of global properties has been expanded with the use of new techniques, including two-particle correlations, more sensitive searches for rare events, and more detailed studies of particles emitted at very forward rapidity. The characteristics of particle production which are revealed by this extensive data set will be described along with the implications for future data from the LHC. ", "machine_text": "  We present results of a systematic study of the systematics of particle production in hadron collisions at RHIC energies. We find that the data are consistent with a simple description in which the number of particles produced is proportional to the energy deposited in the particle maker, with a scale factor that depends only on the hadron energy and the number of constituent quarks. This is consistent with the idea that the particles are produced by quark-antiquark pairs that are created with a probability that depends only on the hadron energy and the number of constituent quarks. This is in contrast to the situation at lower energies, where the systematics of particle production has a strong dependence on the hadron momenta and on the number of constituent quarks. We show that this simple description of the systematics of particle production can be used to extract the average energy deposited in the particle maker by each constituent quark, independently of the number of constituent quarks. We find that the energy deposited by each constituent quark is consistent with the quark-antiquark pair production cross section, as expected from the quark- antiquark pair-to-particle conversion probability. We also show that the systematics of soft particle production at RHIC energies can be used to constrain the shape of the distribution of quark-antiquark pair production cross sections as a function of hadron energy, and we discuss the implications of our results for the study of quarkonia.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Report of the US long baseline neutrino experiment study. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4396, "human_text": "  This report provides the results of an extensive and important study of the potential for a U.S. scientific program that will extend our knowledge of neutrino oscillations well beyond what can be anticipated from ongoing and planned experiments worldwide. The program examined here has the potential to provide the U.S. particle physics community with world leading experimental capability in this intensely interesting and active field of fundamental research. Furthermore, this capability could be unique compared to anywhere else in the world because of the available beam intensity and baseline distances. The present study was initially commissioned in April 2006 by top research officers of Brookhaven National Laboratory and Fermi National Accelerator Laboratory and, as the study evolved, it also provided responses to questions formulated and addressed to the study group by the Neutrino Scientific Advisory Committee (NuSAG) of the U.S. DOE and NSF. The participants in the study, its Charge and history, plus the study results and conclusions are provided in this report and its appendices. A summary of the conclusions is provided in the Executive Summary. ", "machine_text": "  We present the results of a study of the potential of the US long baseline neutrino experiment to measure the Pontecorvo-Maki-Nakagami (PMN) neutrinos from radioactive neutrino sources in the northern hemisphere. The long baseline experiment consists of two detectors placed at opposite ends of a very large baseline, on the order of thousands of kilometers. The main purpose of the experiment is to measure the energy and flavor content of atmospheric neutrinos at the highest possible statistical significance and with the smallest possible systematic errors. This measurement can provide a direct determination of the neutrino mass and could also provide a precise measurement of the differences in the three neutrino masses. In addition to atmospheric neutrinos, the long baseline experiment is also sensitive to neutrinos from a number of other sources, including the PMN sources. We describe the simulation and analysis methods used to evaluate the capability of the long baseline experiment to measure the PMN neutrinos. We find that the experiment has the potential to measure the PMN neutrinos with a significance of a few sigma within a few years of operation and with a better sensitivity than any currently proposed dedicated PMN experiment.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: A remark on the number of steady states in a multiple futile cycle. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0036, "human_text": "  The multisite phosphorylation-dephosphorylation cycle is a motif repeatedly used in cell signaling. This motif itself can generate a variety of dynamic behaviors like bistability and ultrasensitivity without direct positive feedbacks. In this paper, we study the number of positive steady states of a general multisite phosphorylation-dephosphorylation cycle, and how the number of positive steady states varies by changing the biological parameters. We show analytically that (1) for some parameter ranges, there are at least n+1 (if n is even) or n (if n is odd) steady states; (2) there never are more than 2n-1 steady states (in particular, this implies that for n=2, including single levels of MAPK cascades, there are at most three steady states); (3) for parameters near the standard Michaelis-Menten quasi-steady state conditions, there are at most n+1 steady states; and (4) for parameters far from the standard Michaelis-Menten quasi-steady state conditions, there is at most one steady state. ", "machine_text": " We remark on the number of steady states in a multiple futile cycle. Let $\\mathbf{H}$ be a Hamiltonian system with $\\mathbf{H}=\\frac{\\mathbf{p}^2}{2m}+\\mathbf{V}$ where $\\mathbf{p}$ and $\\mathbf{V}$ are the momentum and velocity, respectively. Let $\\mathbf{H}=\\mathbf{H}^0$ be the ground state of $\\mathbf{H}$, and let $\\mathbf{H}=\\mathbf{H}^1$ be a first excited state of $\\mathbf{H}$, with $\\mathbf{H}^1=\\mathbf{H}^0+\\delta\\mathbf{V}$. We consider a multiple futile cycle in which the system goes from $\\mathbf{H}^0$ to $\\mathbf{H}^1$ and then back to $\\mathbf{H}^0$. The multiple futile cycle has $k$ terms, where $k\\in\\mathbb{N}$. For a small $\\epsilon>0$, the first term in the multiple futile cycle is given by $$\\mathbf{H}^0\\to\\mathbf{H}^1\\quad\\text{by}\\quad\\epsilon\\mathbf{V}=\\dot{\\mathbf{p}}.$$ The last term in the multiple futile cycle is given by $$\\mathbf{H}^1\\to\\mathbf{H}^0\\quad\\text{by}\\quad-\\epsilon\\dot{\\mathbf{p}}=\\mathbf{V}$$ where $\\dot{\\mathbf{p}}$ and $\\dot{\\mathbf{V}}$ are the time derivatives of $\\mathbf{p}$ and $\\mathbf{V}$, respectively. The other terms in the multiple futile cycle have the form $$\\mathbf{H}^0\\to\\mathbf{H}^1\\quad\\text{by}\\quad\\epsilon\\dot{\\mathbf{p}}=\\dot{\\mathbf{V}}\\quad\\text{and}\\quad\\mathbf{H}^1\\to\\mathbf{H}^0\\quad\\text{by}\\quad-\\epsilon\\dot{\\mathbf{V}}=\\dot{\\mathbf{p}}$$ where $\\dot{\\mathbf{p}}$ and $\\dot{\\mathbf{V}}$ are the time derivatives of $\\mathbf{p}$ and $\\mathbf{V}$, respectively. We show that the number of steady states in the multiple futile cycle is given by $$\\frac{k}{2}\\; .$$", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Atomic data from the Iron Project. LXIV. Radiative transition rates and   collision strengths for Ca II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3807, "human_text": "  This work reports radiative transition rates and electron impact excitation rate coefficients for levels of the n= 3, 4, 5, 6, 7, 8 configurations of Ca II. The radiative data were computed using the Thomas-Fermi-Dirac central potential method in the frozen core approximation and includes the polarization interaction between the valence electron and the core using a model potential. This method allows for configuration interactions (CI) and relativistic effects in the Breit-Pauli formalism. Collision strengths in LS-coupling were calculated in the close coupling approximation with the R-matrix method. Then, fine structure collision strengths were obtained by means of the intermediate-coupling frame transformation (ICFT) method which accounts for spin-orbit coupling effects. We present extensive comparisons with the most recent calculations and measurements for Ca II as well as a comparison between the core polarization results and the \"unpolarized\" values. We find that core polarization affects the computed lifetimes by up to 20%. Our results are in very close agreement with recent measurements for the lifetimes of metastable levels. The present collision strengths were integrated over a Maxwellian distribution of electron energies and the resulting effective collision strengths are given for a wide range of temperatures. Our effective collision strengths for the resonance transitions are within ~11% from previous values derived from experimental measurements, but disagree with latter computations using the distorted wave approximation. ", "machine_text": "  Atomic data from the Iron Project. LXIV. Radiative transition rates and collision strengths for Ca II  We present new empirical formulas for the radiative transition rates and collision strengths of the lowest five levels of the Ca II multiplet in the 1.5-3.4 keV region. The formulas are based on a complete evaluation of the relevant atomic data, including new measurement of the hyperfine structure constants and new calculations of the permanent dipole moment, which were performed as part of the Iron Project. The measurement of the hyperfine structure constants was performed by measuring the polarization of Ca II with a wave plate in front of a Ca K spectrometer. The accuracy of the measurement was evaluated by measuring the same constants in a separate experiment using a fully stabilized beam. The new calculations of the permanent dipole moment were performed with the aid of an atomic structure model based on the most recent shell-model calculations. The resulting dipole moment is in excellent agreement with recent measurements. We have derived new formulas for the radiative transition rates and collision strengths based on a formalism that includes all relevant atomic data. The accuracy of the new formulas is estimated to be about 10%.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: The substellar mass function in sigma Orionis. II. Optical,   near-infrared and IRAC/Spitzer photometry of young cluster brown dwarfs and   planetary-mass objects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0922, "human_text": "  We investigate the mass function in the substellar domain down to a few Jupiter masses in the young sigma Orionis open cluster (3+/-2 Ma, d = 360^+70_-60 pc). We have performed a deep IJ-band search, covering an area of 790 arcmin^2 close to the cluster centre. This survey was complemented with an infrared follow-up in the HKs- and Spitzer 3.6-8.0 mum-bands. Using colour-magnitude diagrams, we have selected 49 candidate cluster members in the magnitude interval 16.1 mag < I < 23.0 mag. Accounting for flux excesses at 8.0 mum and previously known spectral features of youth, 30 objects are bona fide cluster members. Four are first identified from our optical-near infrared data. Eleven have most probable masses below the deuterium burning limit and are classified as planetary-mass object candidates. The slope of the substellar mass spectrum (Delta N / Delta M = a M^-alpha) in the mass interval 0.11 Msol M < 0.006 Msol is alpha = +0.6+/-0.2. Any opacity mass-limit, if these objects form via fragmentation, may lie below 0.006 Msol. The frequency of sigma Orionis brown dwarfs with circumsubstellar discs is 47+/-15 %. The continuity in the mass function and in the frequency of discs suggests that very low-mass stars and substellar objects, even below the deuterium-burning mass limit, may share the same formation mechanism. ", "machine_text": " We present a comparison of the substellar mass function (SMF) of the young cluster Sigma Orionis based on optical, near-infrared (NIR), and IRAC/Spitzer photometry of brown dwarfs and planetary-mass objects. We show that the SMF of the low-mass members of Sigma Orionis, extending down to M-dwarfs, is well described by a power law with a linear trend of slope -1.35 \u00b1 0.06 and offset of +0.18 \u00b1 0.07. The young cluster members have a flatter SMF than do field stars, but the difference is not significant. This is consistent with the interpretation that the mass function of the low-mass members is shaped by the cumulative gravitational effects of the massive members. We find that the two sets of objects in the cluster with the largest number of members, those with M-band magnitudes between +0.8 and +1.8 and those with IRAC/Spitzer magnitudes between 2.9 and 3.4, have different power-law slopes and offsets, implying that the lowest-mass members of Sigma Orionis form in two distinct mass-function regimes. The offsets of the two SMFs are consistent with the lowest-mass members having formed in a manner that is relatively inefficient in terms of converting gas into solids. We discuss the implications of our findings for models of the formation of brown dwarfs and planetary-mass objects.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: On the Critical Ionization Velocity Effect in Interstellar Space and   Possible Detection of Related Continuum Emission. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3021, "human_text": "  Interstellar neutral hydrogen (HI) emission spectra manifest several families of linewidths whose numerical values (34, 13 & 6 km/s) appear to be related to the critical ionization velocities (CIVs) of the most abundant interstellar atomic species. Extended new analysis of HI emission profiles shows that the 34 km/s wide component, probably corresponding to the CIV for helium, is pervasive. The 34 km/s wide linewidth family is found in low-velocity (local) neutral hydrogen (HI) profiles as well as in the so-called high-velocity clouds. In addition, published studies of HI linewidths found in the Magellanic Stream, Very-High-Velocity Clouds, and Compact High-Velocity Clouds, all of which are believed to be intergalactic, have noted that typical values are of the same order. If the critical ionization velocity effect does play a role in interstellar space it may be expected to produce locally enhanced electron densities where rapidly moving neutral gas masses interact with surrounding plasma. Evidence is presented that suggests that this phenomenon is occurring in interstellar space. It manifests as a spatial association between peaks in HI structure offset with respect to peaks in high-frequency radio continuum data obtained with the Wilkinson Microwave Anisotropy Probe. ", "machine_text": " We propose a model for the critical ionization velocity effect in a weakly collisional plasma and examine the possibility of detecting the related continuum emission. Our model consists of a collisionless, unstable, and nonlinear stage, followed by a collisional stage with a simple power-law distribution of ionization equilibrium. We solve numerically the resulting kinetic equation and show that our model is consistent with the general features of the critical ionization velocity effect observed in the local interstellar medium, although a detailed comparison requires a kinetic treatment of the ionization equilibrium. We show that the effect is most efficiently detected in the frequency domain, and we derive a simple expression for the detection threshold in terms of the plasma and spectral parameters. Our results suggest that the critical ionization velocity effect is potentially detectable with existing and upcoming astronomical instruments, provided that the plasma is collisional and not too hot.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: 21-cm synthesis observations of VIRGOHI 21 - a possible dark galaxy in   the Virgo Cluster. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1586, "human_text": "  Many observations indicate that dark matter dominates the extra-galactic Universe, yet no totally dark structure of galactic proportions has ever been convincingly identified. Previously we have suggested that VIRGOHI 21, a 21-cm source we found in the Virgo Cluster using Jodrell Bank, was a possible dark galaxy because of its broad line-width (~200 km/s) unaccompanied by any visible gravitational source to account for it. We have now imaged VIRGOHI 21 in the neutral-hydrogen line and find what could be a dark, edge-on, spinning disk with the mass and diameter of a typical spiral galaxy. Moreover, VIRGOHI 21 has unquestionably been involved in an interaction with NGC 4254, a luminous spiral with an odd one-armed morphology, but lacking the massive interactor normally linked with such a feature. Numerical models of NGC 4254 call for a close interaction ~10^8 years ago with a perturber of ~10^11 solar masses. This we take as additional evidence for the massive nature of VIRGOHI 21 as there does not appear to be any other viable candidate. We have also used the Hubble Space Telescope to search for stars associated with the HI and find none down to an I band surface brightness limit of 31.1 +/- 0.2 mag/sq. arcsec. ", "machine_text": "  We present a sensitive search for ultra-faint galaxies in the region of the Virgo Cluster core. We have observed with the 21-cm technique a total of 972 hours of data on 883 galaxies in this region with the Australia Telescope, as part of the VIRGOHI survey, in order to search for an excess of radio sources in the region of the Virgo Cluster core. We have found strong evidence for the presence of a large (M >> 1011 Msun), extended radio source at a distance of  \u223c 7.7 kMpc (H0 = 100 km/s/Mpc), which we provisionally call VIRGOHI 21. The projected spatial extent of this source is  \u223c 70 kpc. We have detected eight compact sources within this source which we provisionally classify as globular clusters. The radio source has a peak in the middle at a distance of  \u223c 3.8 kMpc. We discuss a number of possible identifications for this source. We conclude that the simplest explanation is that VIRGOHI 21 is a globular cluster system in the process of accretion of a large number of globular clusters from another galaxy, possibly a satellite. We have detected three sources which are spatially coincident with galaxies in the local volume, two of which have radio sources which appear to be globular clusters, and the third of which is the radio galaxy MRK 1236. We discuss a number of other possible identifications for these sources. We present a class diagram for the sources in the local volume, and use this to make a prediction for the distribution of globular cluster systems in the local volume. We have also detected a further four sources which appear to be globular clusters, and a further eight sources which require further analysis.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Hadronic Gamma Rays from Supernova Remnants. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3854, "human_text": "  A gas cloud near a supernova remnant (SNR) provides a target for pp-collisions leading to subsequent gamma-ray emission through neutral pion decay. The assumption of a power-law ambient spectrum of accelerated particles with index near -2 is usually built into models predicting the spectra of very-high energy (VHE) gamma-ray emission from SNRs. However, if the gas cloud is located at some distance from the SNR shock, this assumption is not necessarily correct. In this case, the particles which interact with the cloud are those leaking from the shock and their spectrum is approximately monoenergetic with the injection energy gradually decreasing as the SNR ages. In the GLAST energy range the gamma-ray spectrum resulting from particle interactions with the gas cloud will be flatter than expected, with the cutoff defined by the pion momentum distribution in the laboratory frame. We evaluate the flux of particles escaping from a SNR shock and apply the results to the VHE diffuse emission detected by the HESS at the Galactic centre. ", "machine_text": " We have carried out a systematic study of the hadronic emission from twenty-eight supernova remnants, all of which have had their electron temperature measured with Si-PIN or Silicon-On-Sapphire (SOS) detectors. We find a strong correlation (r=0.67) between the hadronic energy and the electron temperature, in agreement with the predictions of the simple hadron-holder model. We show that the hadronic contribution to the total flux is on the order of 10-30%, depending on the energy range considered and the Remnant Spectral Index (RSI). The hadronic part of the energy spectrum can be described by two power laws, with indices of 1.6 and 2.3. The higher energy part of the hadronic spectrum shows an excess of emission with respect to the simple hadron-holder model, which we attribute to the presence of highly relativistic electrons. We find that the hadronic contribution to the total energy flux is positive for all but four of the remnants, in qualitative agreement with the result obtained from a study of the X-ray emission, where a negative contribution was found for the same remnants. We discuss the relevance of our results for the interpretation of the non-thermal emission from supernova remnants, and we point out that hadronic emission is probably the dominant source of non-thermal radio emission in the low frequency regime (", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Deconstructing dwarf galaxies: a Suprime-Cam survey of Andromeda II. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.152, "human_text": "  (Abridged) We present deep, sub-horizontal branch, multi-colour photometry of the Andromeda II dwarf spheroidal (And II dSph) taken with Subaru Suprime-Cam. We identify a red clump population in this galaxy, the first time this feature has been detected in a M31 dSph, which are normally characterized as having no significant intermediate age populations. We construct radial profiles for the various stellar populations and show that the horizontal branch has a nearly constant density spatial distribution out to large radius, whereas the reddest red giant branch stars are centrally concentrated in an exponential profile. We argue that these populations trace two distinct structural components in And II and show that this assumption provides a good match to the overall radial profile of this galaxy. The extended component dominates the stellar populations at large radius, whereas the exponential component dominates the inner few arcminutes. We show that the two components have very different stellar populations; the exponential component has an average age of $\\sim 7 - 10$ Gyrs old, is relatively metal-rich ([Fe/H] $\\sim -1$) but with a significant tail to low metallicities, and possesses a red clump. The extended component, on the other hand, is ancient ($\\sim 13$ Gyrs), metal-poor ([Fe/H] $\\sim -1.5$) with a narrower dispersion $\\sigma_{\\rm [Fe/H]} \\simeq 0.28$, and has a well developed blue horizontal branch. The extended component contains approximately three-quarters of the light of And II and its unusual density profile is unique in Local Group dwarf galaxies. This suggests that its formation and/or evolution may have been quite different to other dwarf galaxies. ", "machine_text": "  We present a catalog of 75 galaxies in the Andromeda II galaxy group from a survey of the region with Suprime-Cam on the Canada-France-Hawaii Telescope. This is the first survey of this region with a wide-field imager, and the first catalog of galaxies in a dwarf galaxy group. We describe the data and the analysis used to create the catalog. We find that the galaxies in our catalog are, on average, much more distant than local galaxies of similar optical luminosity, which demonstrates that the galaxies in the Andromeda II group are much fainter than local galaxies. We also show that the group has very little mass in stars or gas, in comparison to groups of galaxies of a similar optical magnitude. We discuss this in the context of the galaxies in the group, and also in the context of other dwarf galaxy groups. We show that a simple model in which galaxies in a group are brought together by a common expansion velocity, in contrast to groups which are held together by a massive central object, can explain many of the observed properties of the Andromeda II group.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Free Energy of Activation for the Comorosan Effect. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1504, "human_text": "  Initial reaction rate data for lactic dehydrogenase / pyruvate, lactic dehydrogenase / lactate and malic dehydrogenase / malate enzyme reactions were analyzed to obtain activation free energy changes of -329, -195 and -221 cal/mole, respectively, for rate increases associated with time-specific irradiation of the crystalline substrates prior to dissolution and incorporation in the reaction solutions. These energies, presumably, correspond to conformational or vibrational changes in the reactants or the activated complex. For the lactic dehydrogenase / pyruvate reaction, it is estimated that on the order of 10% of the irradiation energy (546 nm, 400 footcandles for 5 seconds) would be required to produce the observed reaction rate increase if a presumed photoproduct is consumed stoichiometrically with the pyruvate substrate. These findings are consistent with the proposition that the observed reaction rate enhancement involves photoproducts derived from oscillatory atmospheric gas reactions at the crystalline enzyme substrate surfaces rather than photo-excitations of the substrate molecules, per se. ", "machine_text": " Free Energy of Activation for the Comorosan Effect  We have developed a theory of the Comorosan Effect, which is the increase in the frequency of polarized light transmitted through a chiral plasmonic metasurface. The theory successfully describes the effect for a large range of parameters and explains the conditions for the optimal conversion. The theory also reveals the existence of a minimal energy of activation for the effect, which is a key finding that enables the design of metasurfaces that can switch from a state of no effect to a state of maximal effect with a small perturbation. The theory suggests that the switching is a first-order process and does not require an initial transient, in contrast to what is usually assumed in the theoretical description of optical phase transitions. The energy of activation is practically relevant because it sets a minimum amount of energy that is required to switch on the Comorosan Effect. We show that this energy can be supplied by a thermal source, and therefore the Comorosan Effect can be used for optical information processing. We also discuss the limitations of the theory and the effect.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Orbits of tori extended by finite groups and their polynomial hulls: the   case of connected complex orbits. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1095, "human_text": "  Let $V$ be a complex linear space, $G\\subset\\GL(V)$ be a compact group. We consider the problem of description of polynomial hulls $\\wh{Gv}$ for orbits $Gv$, $v\\in V$, assuming that the identity component of $G$ is a torus $T$. The paper contains a universal construction for orbits which satisfy the inclusion $Gv\\subset T^\\bbC v$ and a characterization of pairs $(G,V)$ such that it is true for a generic $v\\in V$. The hull of a finite union of $T$-orbits in $T^\\bbC v$ can be distinguished in $\\clos T^\\bbC v$ by a finite collection of inequalities of the type $\\abs{z_1}^{s_1}...\\abs{z_n}^{s_n}\\leq c$. In particular, this is true for $Gv$. If powers in the monomials are independent of $v$, $Gv\\subset T^\\bbC v$ for a generic $v$, and either the center of $G$ is finite or $T^\\bbC$ has an open orbit, then the space $V$ and the group $G$ are products of standard ones; the latter means that $G=S_nT$, where $S_n$ is the group of all permutations of coordinates and $T$ is either $\\bbT^n$ or $\\SU(n)\\cap\\bbT^n$, where $\\bbT^n$ is the torus of all diagonal matrices in $\\rU(n)$. The paper also contains a description of polynomial hulls for orbits of isotropy groups of bounded symmetric domains. This result is already known, but we formulate it in a different form and supply with a shorter proof. ", "machine_text": "  We continue our study of connected complex orbits, that is, the connected components of the complex torus $\\mathbb T^2=\\mathbb C^2/\\mathbb C^\\times$ extended by a finite group $G$. Let $\\mathcal F$ be the free $G$-module on $\\mathbb T^2$. We show that any connected complex orbit is isomorphic to a principal $\\mathcal F$-module. As an application, we give a description of the polynomial hull of a connected complex orbit in terms of the theory of Lagrangian subspaces of $\\mathcal F$.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Four quasars above redshift 6 discovered by the Canada-France High-z   Quasar Survey. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0914, "human_text": "  The Canada-France High-z Quasar Survey (CFHQS) is an optical survey designed to locate quasars during the epoch of reionization. In this paper we present the discovery of the first four CFHQS quasars at redshift greater than 6, including the most distant known quasar, CFHQS J2329-0301 at z=6.43. We describe the observational method used to identify the quasars and present optical, infrared, and millimeter photometry and optical and near-infrared spectroscopy. We investigate the dust properties of these quasars finding an unusual dust extinction curve for one quasar and a high far-infrared luminosity due to dust emission for another. The mean millimeter continuum flux for CFHQS quasars is substantially lower than that for SDSS quasars at the same redshift, likely due to a correlation with quasar UV luminosity. For two quasars with sufficiently high signal-to-noise optical spectra, we use the spectra to investigate the ionization state of hydrogen at z>5. For CFHQS J1509-1749 at z=6.12, we find significant evolution (beyond a simple extrapolation of lower redshift data) in the Gunn-Peterson optical depth at z>5.4. The line-of-sight to this quasar has one of the highest known optical depths at z~5.8. An analysis of the sizes of the highly-ionized near-zones in the spectra of two quasars at z=6.12 and z=6.43 suggest the IGM surrounding these quasars was substantially ionized before these quasars turned on. Together, these observations point towards an extended reionization process, but we caution that cosmic variance is still a major limitation in z>6 quasar observations. ", "machine_text": "  We present the discovery of four quasars above redshift 6 in the Canada-France High-z Quasar Survey. These quasars, with redshifts in the range 6.28\u20136.43, are the most distant quasars known. The discovery of these quasars involves the analysis of over one million quasars in the redshift range 2\u20137, and represents a search sensitivity of quasars withrest-frameopticalmagnitudes fainter than 16.5 mag. The discovery of these quasars has implications for models of the formation and evolution of the supermassive black holes that power quasars, the theory of gravity, and the structure of the intergalactic medium at these high redshifts.  We have discovered four quasars above redshift 6 in the Canada-France High-z Quasar Survey. These quasars, with redshifts in the range 6.28\u20136.43, are the most distant quasars known. The quasars have been discovered in a search of quasars in the redshift range 2\u20137 with rest-frame optical magnitudes fainter than 16.5 mag, and with an effective search sensitivity of approximately one quasar above redshift 6 per 350,000 quasars. The number of quasars found, four, is consistent with the hypothesis that the quasar number density is constant at all redshifts, and that the number density of the Universe at redshift 6 is four quasars per 350,000 quasars in the local Universe. We present photometric and spectroscopic observations of the quasars, and discuss the implications of the discovery for models of the formation and evolution of the supermassive black holes that power quasars, for the theory of gravity, and for the structure of the intergalactic medium at these high redshifts.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Observations and Modeling of Line Asymmetries in Chromospheric Flares. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.2436, "human_text": "  For many years various asymmetrical profiles of different spectral lines emitted from solar flares have been frequently observed. These asymmetries or line shifts are caused predominantly by vertical mass motions in flaring layers and they provide a good diagnostics for plasma flows during solar flares. There are many controversial results of observations and theoretical analysis of plasma flows in solar chromospheric flares. The main difficulty is the interpretation of line shifts or asymmetries. For many years, methods based on bisector techniques were used but they give a reliable results only for some specific conditions and in most cases cannot be applied. The most promising approach is to use the non-LTE techniques applied for flaring atmosphere. The calculation of synthetic line profiles is performed with the radiative transfer techniques and the assumed physical conditions correspond to flaring atmosphere. I will present an overview of different observations and interpretations of line asymmetries in chromospheric flares. I will explain what we have learnt about the chromospheric evaporation in the frame of hydrodynamical models as well as reconnection models. A critical review will be done on the classical methods used to derive Doppler-shifts for optically thick chomospheric lines. In particular, details on the new approach for interpreting chromospheric line asymmetries based on the non-LTE techniques will be presented. ", "machine_text": " We present a comprehensive study of the non-axisymmetric structures in solar chromospheric flares, based on the observations of the Solar Dynamics Observatory (SDO) and the Solar Heliospheric Observatory (SOHO). We identify and characterize several types of such structures, including the kink-like, bipolar, and corkscrew, and discuss their possible physical origins. We find that the non-axisymmetric structures can be further classified into two groups based on their aspect ratios, where the aspect ratio is defined as the ratio of the length to the width of a structure. We show that small- aspect ratio (portrait) structures are likely to be related to the solar flux rope instability, while large- aspect ratio (landscape) structures are more likely to be related to the plasma concatenation instability. We also show that the occurrence rate of the non-axisymmetric structures is not uniform along the flare ribbons, but preferentially localized near the tips of the ribbons. We discuss this observation in the framework of a simple model in which the non-axisymmetric structures are treated as kink-like perturbations that evolve in a straight ribbon. We explain why the ribbon tips are the preferred locations for the occurrence of such structures. Our results suggest that the non-axisymmetric structures play an important role in the evolution of solar chromospheric flares and may be responsible for the kinetic energy injection into the Sun's corona.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Effect of temperature-dependent shape anisotropy on coercivity with   aligned Stoner-Wohlfarth soft ferromagnets. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0195, "human_text": "  The temperature variation effect of shape anisotropy on the coercivity, HC(T), for the aligned Stoner-Wohlfarth (SW) soft ferromagnets, such as fcc Ni, fcc Co and bcc Fe, are investigated within the framework of Neel-Brown (N-B) analysis. An extended N-B equation is thus proposed,by introducing a single dimensionless correction function, the reduced magnetization, m(\\tao) = MS(T)/MS(0), in which \\tao = T/TC is the reduced temperature, MS(T) is the saturation magnetization, and TC is the Curie temperature. The factor, m(\\tao), accounts for the temperature-dependent effect of the shape anisotropy. The constants, H0 and E0, are for the switching field at zero temperature and the potential barrier at zero field, respectively. According to this newly derived equation, the blocking temperature above which the properties of superparamagnetism show up is described by the expression, TB = E0m^2(\\tao)/[kBln(t/t0)], with the extra correction factor m^2(\\tao). The possible effect on HC(T) and the blocking temperature, TB, attributed to the downshift of TC resulting from the finite size effect has been discussed also. ", "machine_text": " We study the effect of temperature-dependent shape anisotropy on the coercivity of a thermally assisted magnetic recording system comprising of a Stoner-Wohlfarth soft ferromagnet (SFM) with anisotropic easy axis, a hard ferromagnet (FM), and a Heisenberg antiferromagnet (AFM) with isotropic easy plane. We find that in the presence of a finite thermal activation energy, a thermally induced lattice distortion in the SFM with anisotropic easy axis can induce a distribution of multiple magnetic domains with different sizes and shapes, which results in a decrease of the coercivity of the SFM. By taking into account the effect of anisotropic shape, our result shows a good agreement with the recent experimental observations in which the coercivity of a thermally assisted magnetic recording system comprising of a Stoner-Wohlfarth soft ferromagnet with anisotropic easy axis, a hard ferromagnet, and a Heisenberg antiferromagnet with isotropic easy plane is found to be decreased with increasing the thermal activation energy.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Structural fingerprinting in the transmission electron microscope:   Overview and opportunities to implement enhanced strategies for nanocrystal   identification. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2021, "human_text": "  This paper illustrates the prospective need for structural fingerprinting methods for nanocrystals. A review of the existing fingerprinting methods for crystal structures by means of transmission electron microscopy which work for a single setting of the specimen goniometer is given. Suggestions are made on how some of these methods could be enhanced when nanocrystals and novel instrumentation are involved, i.e. when either the kinematic or quasi-kinematic scattering approximations are sufficiently well satisfied. A novel strategy for lattice-fringe fingerprinting of nanocrystals from Fourier transforms of high-resolution phase contrast transmission electron microscopy images is briefly outlined. Nanocrystal structure specific limitations to the application of this strategy are discussed. An appeal is made to share the structural data of nanocrystals freely over the internet and infrastructure that would allow this sharing is mentioned. A shorter version of this paper has been accepted for publication in a special issue on the Structure of Nanocrystals of the Zeitschrift fuer Kristallographie, International journal for structural, physical, and chemical aspects of crystalline materials. ", "machine_text": "  Structural fingerprinting in the transmission electron microscope: Overview and opportunities to implement enhanced strategies for nanocrystal identification  The ability to determine the precise structural and compositional fingerprint of a nanocrystal is important for its unambiguous identification and reliable interpretation of experimental data. For this purpose, the use of transmission electron microscopy (TEM) has been widely adopted as a powerful tool for nanocrystal characterization. In this review article, we discuss the principles and key ideas underlying the use of TEM for structural fingerprinting of nanocrystals, and we highlight opportunities to implement enhanced strategies for nanocrystal identification that go beyond conventional approaches. We describe the motivation for the research, the key ideas and methodology, the results obtained, the problem the work attempts to solve and any practical or theoretical applications from the findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Impact of spin-zero particle-photon interactions on light polarization   in external magnetic fields. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.1961, "human_text": "  If the recent PVLAS results on polarization changes of a linearly polarized laser beam passing through a magnetic field are interpreted by an axion-like particle, it is almost certain that it is not a standard QCD axion. Considering this, we study the general effective interactions of photons with spin-zero particles without restricting the latter to be a pseudo-scalar or a scalar, i.e., a parity eigenstate. At the lowest order in effective field theory, there are two dimension-5 interactions, each of which has previously been treated separately for a pseudo-scalar or a scalar particle. By following the evolution in an external magnetic field of the system of spin-zero particles and photons, we compute the changes in light polarization and the transition probability for two experimental set-ups: one-way propagation and round-trip propagation. While the first may be relevant for astrophysical sources of spin-zero particles, the second applies to laboratory optical experiments like PVLAS. In the one-way propagation, interesting phenomena can occur for special configurations of polarization where, for instance, transition occurs but light polarization does not change. For the round-trip propagation, however, the standard results of polarization changes for a pseudoscalar or a scalar are only modified by a factor that depends on the relative strength of the two interactions. ", "machine_text": " We investigate the effect of a spin-zero particle-photon interaction on the polarization of light in external magnetic fields. We show that the spin-zero particle can be treated as a single photon with an effective mass, and the optical response can be obtained by using the effective photon theory. The exact solution of the effective photon theory is derived for the special case of a single-particle problem. The solution shows that the light polarization in the external magnetic field is altered by the spin-zero particle-photon interaction, and the change in the light polarization is dependent on the ratio of the effective photon momentum to the light momentum. The general solution of the effective photon theory for a multi-particle problem is obtained by using the formalism of the single-particle solution. The formalism of the general solution can be used to calculate the optical response of a spin-zero particle to an external magnetic field, and it can also be used to calculate the collective optical response of a collection of spin-zero particles to an external magnetic field. The results obtained in this paper can be used to study the light polarization in systems where the light is interacting with spin-zero particles in an external magnetic field, and the results can also be used to design optical devices that use the spin-zero particle-photon interaction to control the light polarization.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Fractionally charged excitations on frustrated lattices. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0521, "human_text": "  Systems of strongly correlated fermions on certain geometrically frustrated lattices at particular filling factors support excitations with fractional charges $\\pm e/2$. We calculate quantum mechanical ground states, low--lying excitations and spectral functions of finite lattices by means of numerical diagonalization. The ground state of the most thoroughfully studied case, the criss-crossed checkerboard lattice, is degenerate and shows long--range order. Static fractional charges are confined by a weak linear force, most probably leading to bound states of large spatial extent. Consequently, the quasi-particle weight is reduced, which reflects the internal dynamics of the fractionally charged excitations. By using an additional parameter, we fine--tune the system to a special point at which fractional charges are manifestly deconfined--the so--called Rokhsar--Kivelson point. For a deeper understanding of the low--energy physics of these models and for numerical advantages, several conserved quantum numbers are identified. ", "machine_text": "  We consider a model of an antiferromagnetic insulator with a small magnetic moment $\\mu$ in an applied external magnetic field $H$. At low temperatures, below the quantum critical temperature $T_c$, the system remains in its stable state, but on increasing the temperature, a number of excitations with fractional charges $\\pm e/2$ appear, which are related to the formation of a spectral gap. We show that, for a certain range of temperatures, these excitations can be stable against thermal fluctuations. Our results are consistent with the idea that a system with $\\pm e/2$ excitations is in a glassy state, and they suggest that such a state can be achieved by a small change in the number of quasiparticles from a state with all excitations having the charge $e$. The model we study is an extension of the Sherrington- Kirkpatrick model, which has a number of experimental realizations. Our results are consistent with the behavior observed in spin glasses, but we also show that a small change in the number of quasiparticles can lead to a glassy state with a different number of excitations than the one found in a spin glass.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Ultracold Thermalization of $^7$Li and $^{87}$Rb. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.275, "human_text": "  We report on measurements of cross-species thermalization inside a magnetically trapped spin-polarized mixture of $^{87}$Rb and $^7$Li atoms with both atoms in their respective low field seeking magnetic substates $|F=2,m_F=2\\right>$. Measurement of the thermalization velocity in the ultracold regime below $10 \\mu$K allows for the derivation of the absolute value of the pure triplet s-wave scattering length governing the interaction. We find $|a_{7,87}|=(59\\pm19) a_{\\rm B}$. We propose to study both species in the condensed regime to derive the sign of $a_{7,87}$. In this context, we present numerical solutions to the coupled Gross-Pitaevskii equation based on the hypothesis of a positive sign. According to the simulations, phase separation of the Li and Rb $|2,2\\right>$ clouds occurs along with a mean-field stabilization allowing for larger atom numbers of condensed $^7$Li atoms before collapse sets in. Observation of this mean-field stabilization would directly fix the sign of $a_{7,87}$. We discuss our results in the light of this proposal. ", "machine_text": "  We report on a theoretical investigation of the ultra-cold thermodynamics of $^7$Li and $^{87}$Rb. We consider a model in which the particle-to-hole conversion due to Auger processes is included in the Bogoliubov-de Gennes (B-d-G) equations. The study is motivated by recent experiments on the condensation of $^7$Li at temperatures in the range $\\sim 10$ to $\\sim 40$ millikelvins, and on the possible extension of the corresponding theory to the case of $^{87}$Rb. Our main results can be summarized as follows. (i) In the limit of an infinite nuclear spin, the condensation temperature of $^7$Li is given by $\\sim 150$ millikelvins; (ii) We show than non- Fermi liquid effects, like the presence of a quadrupole moment, may have a dramatic effect on the condensation temperature; (iii) In the framework of the Bogoliubov-de Gennes approach, we show that an exact mapping between the single-particle basis renormalization and the hole basis renormalization can be obtained; (iv) The theory of $^{87}$Rb is discussed in the framework of the B-d-G approach, and some possible directions for a quantitative theory are pointed out; (v) The model is further studied in the framework of the Migdal-Eliashberg theory, and the effects of a finite number of Auger states are discussed.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Polarimetric studies of comet Hale-Bopp. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.3208, "human_text": "  In the present work, the non-spherical dust grain characteristics of comet Hale-Bopp are studied using the T-matrix method and the modified power law distribution function. It is found that the observed data fits very well with the power index ($\\alpha) = - 3$. The best fit values of complex refractive index $(n, k)$ and the aspect ratio (E) at $\\alpha = - 3$ are calculated to be $(1.382, 0.035, 0.936)$ and $(1.379, 0.041,0.936)$ at $\\lambda = 0.485 \\mu m$ and $0.684\\mu m$ respectively. Kerola & Larson (K-L) analysed the same comet using the T-matrix method and the power law distribution function ($\\alpha = -3$), and found that the prolate grains can explain the observed polarization in a more satisfactory manner as compared to the other shapes. But their analysis could not reproduce the negative polarization branch beyond scattering angle $157^0$. However, the results obtained from the present work successfully generate the expected negative polarization curve beyond $157^0$ and the fitting in this case is much better than K-L's work. So it is concluded from the present study that the use of modified power law distribution function (with $\\alpha = - 3$) can fit the observed data in a better way, as compared to the power law distribution function used by previous authors. ", "machine_text": "  Abstract We present a multi-band polarimetric study of comet Hale-Bopp. Two independent measurements were made: one using a polarimeter in the I band (643 nm), and the other using the E- and F-band polarimeter sensitive in the blue (470 nm) and green (540 nm) regions. These two measurements were made simultaneously during the night of 6 April 1997, when the comet was at a heliocentric distance of 1.44 AU, and the Earth was at a photovoltaic distance of 1.04 AU. We obtained the comet's polarization spectrum in the I band, which consists of a P-band (oriented in the same sense as the local polarization of the incident light) and an S-band (oriented in the opposite sense). We also obtained the ratio of the linear polarization in the E- and F-bands, which shows a strong variation as a function of wavelength. We found that the P-band in the I band increases linearly with the heliocentric distance, while the S-band decreases, so that the total polarization increases. We have explained this behavior on the basis of the increase in the size of the comet as it approaches the Sun, which increases the amount of surface polarization. We found a strong correlation between the total polarization in the I band and the ratio of the polarizations in the E- and F-bands. This correlation can be explained in terms of the two-layer model, according to which the emission from the inner layer is depolarized, while the outer layer emits linearly polarized light, and the intensity ratio of these two layers is constant as a function of the heliocentric distance. We also calculated the polarization of the light scattered by the coma, and found a good agreement between our theoretical prediction and the observation.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Classical potential describes martensitic phase transformations between   the $\\alpha$, $\\beta$ and $\\omega$ titanium phases. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1764, "human_text": "  A description of the martensitic transformations between the $\\alpha$, $\\beta$ and $\\omega$ phases of titanium that includes nucleation and growth requires an accurate classical potential. Optimization of the parameters of a modified embedded atom potential to a database of density-functional calculations yields an accurate and transferable potential as verified by comparison to experimental and density functional data for phonons, surface and stacking fault energies and energy barriers for homogeneous martensitic transformations. Molecular dynamics simulations map out the pressure-temperature phase diagram of titanium. For this potential the martensitic phase transformation between $\\alpha$ and $\\beta$ appears at ambient pressure and 1200 K, between $\\alpha$ and $\\omega$ at ambient conditions, between $\\beta$ and $\\omega$ at 1200 K and pressures above 8 GPa, and the triple point occurs at 8GPa and 1200 K. Molecular dynamics explorations of the dynamics of the martensitic $\\alpha-\\omega$ transformation show a fast-moving interface with a low interfacial energy of 30 meV/\\AA$^2$. The potential is applicable to the study of defects and phase transformations of Ti. ", "machine_text": " We have developed a new approach to describe the martensitic phase transformations between the $\\alpha$, $\\beta$ and $\\omega$ titanium phases. The potential includes a balancing term that enables exact balancing of the Gibbs free energy of the $\\alpha$ and $\\omega$ phases. The formalism also includes an activity coefficient that enables the description of the $\\beta$ phase at finite $\\beta$ content. The potential describes the phase diagram of the $\\alpha$-titanium - $\\beta$-titanium - $\\omega$-titanium system in the entire composition range. The potential also describes the phase diagram of the $\\alpha$-titanium - $\\beta$-titanium - $\\alpha$-titanium - $\\omega$-titanium system in the entire composition range. We have also developed a new approach to describe the martensitic phase transformations between the $\\alpha$, $\\beta$ and $\\omega$ phases in the $\\alpha$-titanium - $\\beta$-titanium - $\\alpha$-titanium - $\\omega$-titanium system. The potential includes a balancing term that enables exact balancing of the Gibbs free energy of the $\\alpha$ and $\\omega$ phases. The formalism also includes an activity coefficient that enables the description of the $\\beta$ phase at finite $\\beta$ content. The potential describes the phase diagram of the $\\alpha$-titanium - $\\beta$-titanium - $\\alpha$-titanium - $\\omega$-titanium system in the entire composition range. The potential also describes the phase diagram of the $\\alpha$-titanium - $\\beta$-titanium - $\\alpha$-titanium - $\\omega$-titanium system in the entire composition range.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Conformational gel analysis and graphics: Measurement of side chain   rotational isomer populations by NMR and molecular mechanics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0229, "human_text": "  Conformational gel analysis and graphics systematically identifies and evaluates plausible alternatives to the side chain conformations found by conventional peptide or protein structure determination methods. The proposed analysis determines the populations of side chain rotational isomers and the probability distribution of these populations. The following steps are repeated for each side chain of a peptide or protein: first, extract the local molecular mechanics of side chain rotational isomerization from a single representative global conformation; second, expand the predominant set of rotational isomers to include all probable rotational isomers down to those that constitute just a small percentage of the population; and third, evaluate the constraints vicinal coupling constants and NOESY cross relaxation rates place on rotational isomer populations. In this article we apply conformational gel analysis to the cobalt glycyl-leucine dipeptide and detail the steps necessary to generalize the analysis to other amino acid side chains in other peptides and proteins. For a side chain buried within a protein interior, it is noteworthy that the set of probable rotational isomers may contain one or more rotational isomers that are not identified by conventional NMR structure determination methods. In cases such as this the conformational gel graphics fully accounts for the interplay of molecular mechanics and NMR data constraints on the population estimates. The analysis is particularly suited to identifying side chain rotational isomers that constitute a small percentage of the population, but nevertheless might be structurally and functionally very significant. ", "machine_text": " We present a method of measuring side chain conformational space and assessing the population of rotameric isomers by NMR spectroscopy and molecular mechanics (MM) calculations. The method is based on the observation that the chemical shift data of an amino acid residue in a protein can be described by a three-dimensional distribution ofgaussian peaks, each peak corresponding to a rotameric isomer. By a least-squares fit to the experimental data, the heights and positions of the gaussian peaks can be obtained. From the distribution of the peaks in the three-dimensional space, the number of side chain rotameric isomers and their populations can be obtained. To demonstrate the method, the conformational space of four residues (two glycine residues, one alanine residue, and one serine residue) in the protein cytochrome c was analyzed. The results were compared with those obtained by the molecular dynamics (MD) method. It was found that the two methods gave similar results for the glycine residues, but the NMR method gave slightly different results for the alanine and serine residues from those obtained by the MD method.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Quantum theory of exciton-photon coupling in photonic crystal slabs with   embedded quantum wells. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0396, "human_text": "  A theoretical description of radiation-matter coupling for semiconductor-based photonic crystal slabs is presented, in which quantum wells are embedded within the waveguide core layer. A full quantum theory is developed, by quantizing both the electromagnetic field with a spatial modulation of the refractive index and the exciton center of mass field in a periodic piecewise constant potential. The second-quantized hamiltonian of the interacting system is diagonalized with a generalized Hopfield method, thus yielding the complex dispersion of mixed exciton-photon modes including losses. The occurrence of both weak and strong coupling regimes is studied, and it is concluded that the new eigenstates of the system are described by quasi-particles called photonic crystal polaritons, which can occur in two situations: (i) below the light line, when a resonance between exciton and non-radiative photon levels occurs (guided polaritons), (ii) above the light line, provided the exciton-photon coupling is larger than the intrinsic radiative damping of the resonant photonic mode (radiative polaritons). For a square lattice of air holes, it is found that the energy minimum of the lower polariton branch can occur around normal incidence. The latter result has potential implications for the realization of polariton parametric interactions in photonic crystal slabs. ", "machine_text": "  We theoretically study the coupling between photonic crystal slabs and embedded quantum wells in a unified framework that combines the principles of quantum theory of optical fields and many-body perturbation theory. The coupling strength is found to be dependent on the inter-subband transition dipole moment as well as the phonon-phonon coupling in the quantum well. We show that the strength of coupling can be enhanced by a factor as large as four by optimization of the device parameters. Our theory also predicts a strong dependence of the coupling strength on the ratio of the slab thickness to the inter-subband transition energy. We show that this ratio can be made large by using a thin quantum well in a thick slab, which can lead to a strong coupling even in the absence of a dipole moment. The theory also predicts a strong blue-shift of the coupled light, which can be utilized to achieve lasing at short wavelengths. We also discuss the limitations of our theory in the strong coupling regime.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: MINOS Results, Progress and Future Prospects. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.4655, "human_text": "  The MINOS long baseline experiment has been collecting neutrino beam data since March 2005 and has accumulated 3 x 10^{20} protons-on-target (POT) to date. MINOS uses Fermilab's NuMI neutrino beam which is measured by two steel-scintillator tracking calorimeters, one at Fermilab and the other 735 km downstream, in northern Minnesota. By observing the oscillatory structure in the neutrino energy spectrum, MINOS can precisely measure the neutrino oscillation parameters in the atmospheric sector. From analysis of the first year of data, corresponding to 1.27 x 10^{20} POT, these parameters were determined to be |\\Delta m^2_{32}|=2.74^{+0.44}_{-0.26} x 10^{-3} eV^2 and sin^2(2\\theta_{23})>0.87 (68% C.L.). MINOS is able to measure the neutrino velocity by comparing the arrival times of the neutrino beam in its two detectors. Using a total of 473 Far Detector events, (v-c)/c = (5.1 +/- 2.9) x 10^{-5} (68% C.L.) was measured. In addition, we report recent progress in the analysis of neutral current events and give an outline of experimental goals for the future. ", "machine_text": "  We present results and prospects of the MINOS long-term experiment to search for neutral particles with a mass larger than that of the WIMP. The experiment is based on a multi-detector concept, with two detectors in the detector cavern: a large-aperture detector (LAD) to measure the momentum of incoming particles and a small-aperture detector (SAD) to measure their direction and energy. The main result is the world-best limit for a direct search for Lorentz-evading particles with a mass greater than the WIMP, set at 1.3 times the Standard Model cross section for a 80 GeV/c^2 WIMP. We also present an updated measurement of the muon neutrino energy spectrum, based on a exposure of 250 ktonne-years, and a search for long-lived neutral particles with the LAD. We also report on progress in the development of the next-generation search detector, based on a single-pixel tracker and a three-dimensional bolometer, and prospects for a precise measurement of the neutrino mass with the next-generation experiment.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Geochemistry of U and Th and its Influence on the Origin and Evolution   of the Crust of Earth and the Biological Evolution. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.1089, "human_text": "  We have investigated the migration behaviors of uranium (U) and thorium (Th) in Earth and other terrestrial planets. Theoretical models of U and Th migration have been proposed. These models suggest that the unique features of Earth are closely connected with its unique U and Th migration models and distribution patterns. In the Earth, U and Th can combine with oxidative volatile components and water, migrate up to the asthenosphere position to form an enrichment zone (EZ) of U and Th first, and then migrate up further to the crusts through magmatism and metamorphism. We emphasize that the formation of an EZ of U, Th and other heat-producing elements is a prerequisite for the formation of a plate tectonic system. The heat-producing elements, currently mainly U and Th, in the EZ are also the energy sources that drive the formation and evolution of the crust of Earth and create special granitic continental crusts. In other terrestrial planets, including Mercury, Venus, and Mars, an EZ can not be formed because of a lack of oxidative volatile components and water. For this reason, a plate tectonic system can not been developed in these planets. We also emphasize the influence of U and Th in EZ on the development and evolution of life on Earth. We propose that since the Earth and planets were born in a united solar system, there should be some common mechanisms to create the similarities and differences between them. We have tried to develop an integrated view to explain some problems in the tectonics of Earth and evolution, bio-evolution, and planetary dynamics through U and Th geochemistry. We believe that a comprehensive exploration on energy sources and their evolution is a good way to build bridges between different disciplines of science in order to better understand the Earth and planets. ", "machine_text": " The motivation for this work is to determine the geochemical signature of U and Th in the Earth's crust and its relation to the origin and evolution of the Earth. The key ideas and methodology are to use the existing data on the concentrations of U and Th in the Earth's crust and to use the results of previous research on the origin and evolution of the Earth's crust to determine the geochemical signature of U and Th in the Earth's crust. The results obtained are that the geochemical signature of U and Th in the Earth's crust is consistent with the Earth's crust being a product of the accretion and differentiation of the planet. The problem this work attempts to solve is to determine the geochemical signature of U and Th in the Earth's crust and its relation to the origin and evolution of the Earth. The practical application of this work is to provide a better understanding of the Earth's history and its evolution. The theoretical application of this work is to provide a better understanding of the geochemistry of U and Th in the Earth's crust.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Bondi accretion in the early universe. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.0864, "human_text": "  This paper presents a study of quasi-steady spherical accretion in the early Universe, before the formation of the first stars and galaxies. The main motivation is to derive the basic formulas that will be used in a companion paper to calculate the accretion luminosity of primordial black holes and their effect on the cosmic ionization history.   The following cosmological effects are investigated: the coupling of the gas to the CMB photon fluid (i.e., Compton drag), Hubble expansion, and the growth of the dark matter halo seeded by the gravitational potential of the central point mass. The gas equations of motion are solved assuming either a polytropic or an isothermal equation of state. We consider the cases in which the accreting object is a point mass or a spherical dark matter halo with power-law density profile, as predicted by the theory of \"secondary infall''. Analytical solutions for the sonic radius and fitting formulas for the accretion rate are provided.   Different accretion regimes exist depending on the mass of the accreting object. If the black hole mass is smaller than 50-100 Msun, gas accretion is unaffected by Compton drag. A point mass and an extended dark halo of equal mass accrete at the same rate if M>5000 Msun, while smaller mass dark halos accrete less efficiently than the equivalent point mass. For masses M>3 x 10^4 Msun, the viscous term due to the Hubble expansion becomes important and the assumption of quasi-steady flow fails. Hence, the steady Bondi solutions transition to the time-dependent self-similar solutions for \"cold cosmological infall\". ", "machine_text": "  We propose a model for Bondi accretion in the early universe in which the accretion rate varies harmonically in space. In our model the amplitude of the spatial variation is small compared to the typical size of the universe, so the variance of the accretion rate is simply proportional to the average accretion rate. We show that this model can explain the observed correlation between the large-scale structure of the universe and the small-scale structure of the primordial perturbations. We also show that this model can naturally explain why the universe is so homogeneous on large scales. We find that this model can quantitatively reproduce the observed power spectrum, without the need to introduce non-Gaussian corrections. Our model also naturally explains why the correlation function is positive on large scales, without the need for the often invoked anti-correlation mechanism. In addition, our model can also explain why the current universe is so homogeneous on large scales. We show that our model predicts that the galaxies should be distributed in a way that is consistent with the observed large-scale structure, without the need to introduce the cold dark matter model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Multifractality and scale invariance in human heartbeat dynamics. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 706.2415, "human_text": "  Human heart rate is known to display complex fluctuations. Evidence of multifractality in heart rate fluctuations in healthy state has been reported [Ivanov et al., Nature {\\bf 399}, 461 (1999)]. This multifractal character could be manifested as a dependence on scale or beat number of the probability density functions (PDFs) of the heart rate increments. On the other hand, scale invariance has been recently reported in a detrended analysis of healthy heart rate increments [Kiyono et al., Phys. Rev. Lett. {\\bf 93}, 178103 (2004)]. In this paper, we resolve this paradox by clarifying that the scale invariance reported is actually exhibited by the PDFs of the sum of detrended healthy heartbeat intervals taken over different number of beats, and demonstrating that the PDFs of detrended healthy heart rate increments are scale dependent. Our work also establishes that this scale invariance is a general feature of human heartbeat dynamics, which is shared by heart rate fluctuations in both healthy and pathological states. ", "machine_text": "  Multifractality and scale invariance in human heartbeat dynamics  The heart is a highly nonlinear system, and the dynamics of the heartbeat are influenced by a wide range of physiological mechanisms. We investigated the dynamic structure of heartbeats recorded from a healthy young male, using  sampled arterial pressure and electrocardiographic data. Both the systolic and  diastolic components of the heartbeat were found to be well described by  piecewise power-law functions, which are characterized by a few distinct  fractal scales. The scaling properties of the heartbeat dynamics were  further investigated by means of the Hurst coefficient, which was found to be  significantly different from zero for both the systolic (Hurst = 0.79) and  diastolic (Hurst = 0.69) components. These results suggest that the  heartbeat dynamics are driven by a combination of local, nonlinear  processes, which give rise to scale-invariant behavior, and nonlocal,  processes that introduce additional degrees of freedom and account for  the fractal structure.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Phase transition in the two-component symmetric exclusion process with   open boundaries. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0596, "human_text": "  We consider single-file diffusion in an open system with two species $A,B$ of particles. At the boundaries we assume different reservoir densities which drive the system into a non-equilibrium steady state. As a model we use an one-dimensional two-component simple symmetric exclusion process with two different hopping rates $D_A,D_B$ and open boundaries. For investigating the dynamics in the hydrodynamic limit we derive a system of coupled non-linear diffusion equations for the coarse-grained particle densities. The relaxation of the initial density profile is analyzed by numerical integration. Exact analytical expressions are obtained for the self-diffusion coefficients, which turns out to be length-dependent, and for the stationary solution. In the steady state we find a discontinuous boundary-induced phase transition as the total exterior density gradient between the system boundaries is varied. At one boundary a boundary layer develops inside which the current flows against the local density gradient. Generically the width of the boundary layer and the bulk density profiles do not depend on the two hopping rates. At the phase transition line, however, the individual density profiles depend strongly on the ratio $D_A/D_B$. Dynamic Monte Carlo simulation confirm our theoretical predictions. ", "machine_text": " We consider a symmetric exclusion process with two components and open boundaries. We show a transition from a state with one global exclusion to a state with multiple exclusions, which can be viewed as a phase transition from a product to a disjoint sum. The motivation for this work is to understand the effects of non-Markovian dynamics on the statistical properties of the symmetric exclusion process. The key ideas and methodology are to use the rigorous formulation of the symmetric exclusion process with open boundaries and the associated rigorous relationships between different measures of the process. The results obtained are the construction of a necessary and sufficient condition for a phase transition to a state with multiple exclusions, and the derivation of a simple expression for the stationary distribution of the process in this state. The problem this work attempts to solve is to understand the effects of non-Markovian dynamics on the symmetric exclusion process. The practical application of this work is in understanding the behavior of the symmetric exclusion process in the presence of non-Markovian dynamics, which can be important in various applications such as mobile communications and computer networks. The theoretical application of this work is in the understanding of the effects of non-Markovian dynamics on the statistical properties of random processes.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Spin Evolution of Accreting Neutron Stars: Nonlinear Development of the   R-mode Instability. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0799, "human_text": "  The nonlinear saturation of the r-mode instability and its effects on the spin evolution of Low Mass X-ray Binaries (LMXBs) are modeled using the triplet of modes at the lowest parametric instability threshold. We solve numerically the coupled equations for the three mode amplitudes in conjunction with the spin and temperature evolution equations. We observe that very quickly the mode amplitudes settle into quasi-stationary states. Once these states are reached, the mode amplitudes can be found algebraically and the system of equations is reduced from eight to two equations: spin and temperature evolution. Eventually, the system may reach thermal equilibrium and either (1) undergo a cyclic evolution with a frequency change of at most 10%, (2) evolve toward a full equilibrium state in which the accretion torque balances the gravitational radiation emission, or (3) enter a thermogravitational runaway on a very long timescale of about $10^6$ years. Alternatively, a faster thermal runaway (timescale of about 100 years) may occur. The sources of damping considered are shear viscosity, hyperon bulk viscosity and boundary layer viscosity. We vary proprieties of the star such as the hyperon superfluid transition temperature T_c, the fraction of the star that is above the threshold for direct URCA reactions, and slippage factor, and map the different scenarios we obtain to ranges of these parameters. For all our bound evolutions the r-mode amplitude remains small $\\sim 10^{-5}$. The spin frequency is limited by boundary layer viscosity to $\\nu_{max} \\sim 800 Hz [S_{ns}/(M_{1.4} R_6)]^{4/11} T_8^{-2/11}$. We find that for $\\nu > 700$ Hz the r-mode instability would be active for about 1 in 1000 LMXBs and that only the gravitational waves from LMXBs in the local group of galaxies could be detected by advanced LIGO interferometers. ", "machine_text": "  We study the development of the r-mode instability and the spin evolution of a young and active neutron star through the model-free auto-correlation function analysis of the low-frequency (below 1 Hz) broadband observations from the Advanced LIGO detectors. Our primary motivation is to understand the role of the r-mode instability in the spin evolution of the young neutron star. Our analysis shows that the r-mode instability is strongly dependent on the spin frequency and the torque-to- inertia ratio. In our model-free analysis, we show that the r-mode instability first develops in a nonlinear fashion and then becomes self-sustained. We explain this development in terms of the interplay between the r-mode instability and the spin evolution of the star. Once the r-mode instability becomes self-sustained, its amplitude continues to increase, causing the spin frequency to increase further, until the star starts to show regular periodicity. At that stage, the torque-to-inertia ratio is too large to be supported by the r-mode instability, and the star enters a full gravity-wave orbit, with a frequency equal to the orbital frequency. We also show that, even if the r-mode instability is strong, the star will not lose much angular momentum if the spin frequency is already close to the gravity-wave frequency. Our results suggest that the r-mode instability has little effect on the spin evolution of a young neutron star if the spin frequency is close to the gravity-wave frequency. We also discuss the effects of the intrinsic nonlinearity of the r-mode instability on the measurement of the gravity waves by advanced LIGO detectors.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Sensor Networks with Random Links: Topology Design for Distributed   Consensus. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0954, "human_text": "  In a sensor network, in practice, the communication among sensors is subject to:(1) errors or failures at random times; (3) costs; and(2) constraints since sensors and networks operate under scarce resources, such as power, data rate, or communication. The signal-to-noise ratio (SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link. These probabilities are then a proxy for the SNR under which the links operate. The paper studies the problem of designing the topology, i.e., assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint. To consider this problem, we address a number of preliminary issues: (1) model the network as a random topology; (2) establish necessary and sufficient conditions for mean square sense (mss) and almost sure (a.s.) convergence of average consensus when network links fail; and, in particular, (3) show that a necessary and sufficient condition for both mss and a.s. convergence is for the algebraic connectivity of the mean graph describing the network topology to be strictly positive. With these results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques. We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost. ", "machine_text": "  Sensor Networks with Random Links: Topology Design for Distributed Consensus  We consider the problem of achieving distributed consensus in a wireless sensor network with randomly formed links. We show that the underlying topology of the network has a strong impact on the ability of the network to reach consensus, and in particular, that a lack of connectivity can lead to a consensus failure. To address this problem, we propose a topology design strategy that aims to maximize the number of connected components of the network, while also minimizing the number of links between different components. Our strategy is based on the idea of jointly designing the position and orientation of the sensors, so as to control the formation of links between them. We show that our proposed topology design can significantly improve the performance of the network in terms of its ability to reach consensus, and we demonstrate the effectiveness of our design strategy using both simulations and theoretical analysis.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Lower order terms in the 1-level density for families of holomorphic   cuspidal newforms. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.0924, "human_text": "  The Katz-Sarnak density conjecture states that, in the limit as the conductors tend to infinity, the behavior of normalized zeros near the central point of families of L-functions agree with the N -> oo scaling limits of eigenvalues near 1 of subgroups of U(N). Evidence for this has been found for many families by studying the n-level densities; for suitably restricted test functions the main terms agree with random matrix theory. In particular, all one-parameter families of elliptic curves with rank r over Q(T) and the same distribution of signs of functional equations have the same limiting behavior. We break this universality and find family dependent lower order correction terms in many cases; these lower order terms have applications ranging from excess rank to modeling the behavior of zeros near the central point, and depend on the arithmetic of the family. We derive an alternate form of the explicit formula for GL(2) L-functions which simplifies comparisons, replacing sums over powers of Satake parameters by sums of the moments of the Fourier coefficients lambda_f(p). Our formula highlights the differences that we expect to exist from families whose Fourier coefficients obey different laws (for example, we expect Sato-Tate to hold only for non-CM families of elliptic curves). Further, by the work of Rosen and Silverman we expect lower order biases to the Fourier coefficients in families of elliptic curves with rank over Q(T); these biases can be seen in our expansions. We analyze several families of elliptic curves and see different lower order corrections, depending on whether or not the family has complex multiplication, a forced torsion point, or non-zero rank over Q(T). ", "machine_text": "  We compute the lower order terms in the 1-level density for families of holomorphic cusp forms. We show that these terms are related to the higher order terms in the 1-level density for individual cusp forms. As an application, we give an asymptotic formula for the number of non-trivial equivalence classes of cuspidal newforms of a given level and weight.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Magnetic Excitations in La2CuO4 probed by Indirect Resonant Inelastic   X-ray Scattering. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 705.0263, "human_text": "  Recent experiments on La$_2$CuO$_4$ suggest that indirect resonant inelastic X-ray scattering (RIXS) might provide a probe for transversal spin dynamics. We present in detail a systematic expansion of the relevant magnetic RIXS cross section by using the ultrashort core-hole lifetime (UCL) approximation. We compute the scattering intensity and its momentum dependence in leading order of the UCL expansion. The scattering is due to two-magnon processes and is calculated within a linear spin-wave expansion of the Heisenberg spin model for this compound, including longer range and cyclic spin interactions. We observe that the latter terms in the Hamiltonian enhance the first moment of the spectrum if they strengthen the antiferromagnetic ordering. The theoretical spectra agree very well with experimental data, including the observation that scattering intensity vanishes for the transferred momenta ${\\bf q} = (0,0)$ and ${\\bf q} = (\\pi,\\pi)$. We show that at finite temperature there is an additional single-magnon contribution to the scattering with a spectral weight proportional to $T^3$. We also compute the leading corrections to the UCL approximation and find them to be small, putting the UCL results on a solid basis. All this univocally points to the conclusion that the observed low temperature RIXS intensity in La$_2$CuO$_4$ is due to two-magnon scattering. ", "machine_text": " We report on the nature of the magnetic excitations in La2CuO4 probed by indirect resonant inelastic X-ray scattering. We found a good agreement between the theoretical prediction and the experimental data for the three-dimensional structure of the magnetic excitations. The theory also predicts the presence of a non-degenerate singlet state at finite-temperature. Our data are consistent with the presence of a non-degenerate singlet state with a magnetic moment of 2.4 Bohr magneton. We found good agreement between the theory and the experiment for the temperature dependence of the singlet fraction. Our results indicate that the singlet state is a true quantum state, which is in strong disagreement with the predictions of the simple Perdew-Burke-Ernzerhof (PBE) model. We also found a good agreement between the theory and the experiment for the three-dimensional structure of the triplet excitations. We found that the PBE model can accurately describe the temperature dependence of the triplet fraction. We found that the line width of the triplet excitations increases with temperature in agreement with the theoretical prediction. Our results indicate that the triplet excitations are a true quantum state, which is in strong disagreement with the predictions of the simple PBE model.", "model": "command-xlarge-nightly", "source": "arxiv"}
{"prompt": "Generate an abstract for work with title: Search for Radiative Decays of Upsilon(1S) into eta and eta'. Describe the motivation for the research, the key ideas and methodology, the results obtained, problem work attempts to solve and any practical or theoretical applications from your findings or implications for future research in a formal academic and scientific writing voice. Use the first plural person form. Use active voice.", "source_id": 704.3063, "human_text": "  We report on a search for the radiative decay of Upsilon(1S) to the pseudoscalar mesons eta and etaprime in 21.2 +/- 0.2 times 10^6 Upsilon(1S) decays collected with the CLEO III detector at the Cornell Electron Storage Ring (CESR). The eta meson was reconstructed in the three modes eta to gamma-gamma, eta to pi+pi-pi0 and eta to 3pi0. The etaprime meson was reconstructed in the mode etaprime to pi+ pi- eta with eta decaying through any of the above three modes, and also etaprime to gamma rho, where rho decays to pi^+ pi^-.   Five out of the seven sub-modes are found to be virtually background-free. In four of them we find no signal candidates and in one Upsilon(1S) to gamma-etaprime, etaprime to pi+ pi- eta, eta to pi+pi-pi0 there are two good signal candidates, which is insufficient evidence to claim a signal. The other two sub-modes eta to gamma-gamma and etaprime to gamma rho are background limited, and show no excess of events in their signal regions. We combine the results from different channels and obtain upper limits at the 90% C.L. which are B(Upsilon(1S) to gamma eta) < 1.0 times 10^-6 and B(Upsilon(1S) to gamma etaprime) < 1.9 times 10^-6. Our limits are an order of magnitude tighter than the previous ones and below the predictions made by some theoretical models. ", "machine_text": " We present a search for radiative decays of Upsilon(1S) into eta and eta'., and update our previous search for radiative decays of Upsilon(1S) into eta and eta'., eta', and eta''.. We use a data sample collected with the BaBar detector at the PEP-II asymmetric-energy e+e- collider, containing 232 million $Upsilon(1S)$ mesons produced in $pp$ collisions at $\\sqrt{s}=1.96 TeV$.. We find 2 events consistent with $Upsilon(1S)\\to \\eta \\ell^{+} \\ell^{-}$, and 2 events consistent with $Upsilon(1S)\\to \\eta' \\ell^{+} \\ell^{-}$, for a total of 4 events. We observe no events consistent with $Upsilon(1S)\\to \\eta'' \\ell^{+} \\ell^{-}$, and place an upper limit on the cross section for this decay at $1.5 \\times 10^{-5}$ cm$^{2}$. We also place limits on the cross sections for $Upsilon(1S)$ radiative decays to $J/\\Psi$ mesons, where $J$ is a charm quark and $\\Psi$ is a lighter quark, and for $Upsilon(1S)$ radiative decays to $D/\\Gamma$ mesons, where $D$ is a charm antiquark and $\\Gamma$ is a lighter antiquark..", "model": "command-xlarge-nightly", "source": "arxiv"}
